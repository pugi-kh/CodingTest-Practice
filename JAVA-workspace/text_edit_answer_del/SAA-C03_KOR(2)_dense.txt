Exam : SAA-C03-KOR(2) 
Title : Amazon AWS Certified Solutions Architect - Associate (SAA-C03 Korean Version) 
Version : Examtopics(Q501~Q1019) + Itexamdump V22.65(Q1~Q101) 
Ps. 정답이 애매한 문제들은 (?? 마크가 있는문제) 있는 문제는 링크를 통해 정답을 다시 
한번 꼭 확인해서 공부하세요. 
한글 시험이 덤프 적중률이 높습니다. 다만 한글 시험의 경우 번역기가 달라서 덤프 번역과 
실제 시험 번역이 상의 할 수 있습니다. 
※신규로 추가된 Q982~Q1019 문항은 아직 디스커션이 적어서 정답이 정확하지 않을 수도 
있습니다.  
Q501 
회사는 고객 결제 데이터를 Amazon S3 의 회사 데이터 레이크로 수집하려고 합니다. 
회사는 평균적으로 1 분마다 결제 데이터를 수신합니다. 회사는 결제 데이터를 실시간으로 
분석하기를 원합니다. 그런 다음 회사는 데이터를 데이터 레이크로 수집하려고 합니다. 
이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon Kinesis Data Streams 를 사용하여 데이터를 수집하십시오. AWS Lambda 를 
사용하여 실시간으로 데이터를 분석합니다. 
B. AWS Glue 를 사용하여 데이터를 수집합니다. Amazon Kinesis Data Analytics 를 사용하여 
데이터를 실시간으로 분석하십시오. 
C. Amazon Kinesis Data Firehose 를 사용하여 데이터를 수집합니다. Amazon Kinesis Data 
Analytics 를 사용하여 데이터를 실시간으로 분석하십시오. 
D. Amazon API Gateway 를 사용하여 데이터를 수집합니다. AWS Lambda 를 사용하여 
실시간으로 데이터를 분석합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109421-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q502 
회사는 Amazon EC2 에서 콘텐츠 관리 시스템(CMS)을 사용하는 웹 사이트를 운영합니다. 
CMS 는 단일 EC2 인스턴스에서 실행되며 데이터 계층에 Amazon Aurora MySQL 다중 AZ 
DB 인스턴스를 사용합니다. 웹 사이트 이미지는 EC2 인스턴스 내부에 탑재된 Amazon 
Elastic Block Store(Amazon EBS) 볼륨에 저장됩니다. 
웹 사이트의 성능과 복원력을 개선하기 위해 솔루션 설계자가 취해야 하는 작업 조합은 
무엇입니까? (2 개 선택) 
A. 웹 사이트 이미지를 모든 EC2 인스턴스에 탑재된 Amazon S3 버킷으로 이동합니다. 
B. 기본 EC2 인스턴스의 NFS 공유를 사용하여 웹사이트 이미지를 공유합니다. 이 공유를 
다른 EC2 인스턴스에 마운트합니다. 
C. 모든 EC2 인스턴스에 탑재된 Amazon Elastic File System(Amazon EFS) 파일 
시스템으로 웹 사이트 이미지를 이동합니다. 
D. 기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하여 Auto 
Scaling 그룹의 일부로 Application Load Balancer 뒤에 새 인스턴스를 프로비저닝합니다. 
최소 2 개의 인스턴스를 유지하도록 Auto Scaling 그룹을 구성합니다. 웹 사이트에 대한 
AWS Global Accelerator 에서 액셀러레이터를 구성합니다. 
E. 기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하여 Auto 
Scaling 그룹의 일부로 Application Load Balancer 뒤에 새 인스턴스를 프로비저닝합니다. 
최소 2 개의 인스턴스를 유지하도록 Auto Scaling 그룹을 구성합니다. 웹 사이트에 대한 
Amazon CloudFront 배포를 구성합니다. 
Answer: C, E 
https://www.examtopics.com/discussions/amazon/view/109420-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
옵션 C 는 웹 사이트 이미지를 모든 EC2 인스턴스에 탑재된 Amazon EFS 파일 시스템으로 
이동하는 기능을 제공합니다. Amazon EFS 는 여러 EC2 인스턴스에서 동시에 액세스할 수 
있는 확장 가능하고 완벽하게 관리되는 파일 스토리지 솔루션을 제공합니다. 이렇게 하면 
모든 인스턴스에서 웹 사이트 이미지에 효율적이고 일관되게 액세스할 수 있으므로 옵션 
E 에서 성능이 향상됩니다. Auto Scaling 그룹은 최소 2 개의 인스턴스를 유지 관리하여 
비정상 인스턴스를 자동으로 교체하여 복원력을 보장합니다. 
또한 웹 사이트에 대해 Amazon CloudFront 배포를 구성하면 최종 사용자에게 더 가까운 
엣지 위치에서 콘텐츠를 캐싱하여 지연 시간을 줄이고 콘텐츠 전송을 개선하여 성능을 더욱 
향상시킵니다. 
따라서 이러한 작업을 결합하면 효율적인 이미지 저장 및 콘텐츠 전달을 통해 웹 사이트의 
성능이 향상됩니다. 
Q503 
회사에서 인프라 모니터링 서비스를 실행합니다. 이 회사는 서비스가 고객 AWS 계정의 
데이터를 모니터링할 수 있는 새로운 기능을 구축하고 있습니다. 새로운 기능은 고객 
계정에서 AWS API 를 호출하여 Amazon EC2 인스턴스를 설명하고 Amazon CloudWatch 
지표를 읽습니다. 
회사는 가장 안전한 방법으로 고객 계정에 대한 액세스 권한을 얻기 위해 무엇을 해야 
합니까? 
A. 고객이 회사 계정에 대한 읽기 전용 EC2 및 CloudWatch 권한과 신뢰 정책을 사용하여 
계정에 IAM 역할을 생성하는지 확인합니다. 
B. 토큰 판매기를 구현하는 서버리스 API 를 생성하여 읽기 전용 EC2 및 CloudWatch 
권한이 있는 역할에 대한 임시 AWS 자격 증명을 제공합니다. 
C. 고객이 자신의 계정에서 읽기 전용 EC2 및 CloudWatch 권한을 가진 IAM 사용자를 
생성하는지 확인합니다. 비밀 관리 시스템에서 고객 액세스 및 비밀 키를 암호화하고 
저장합니다. 
D. 고객이 자신의 계정에 Amazon Cognito 사용자를 생성하여 읽기 전용 EC2 및 
CloudWatch 권한이 있는 IAM 역할을 사용하는지 확인합니다. 암호 관리 시스템에서 
Amazon Cognito 사용자 및 암호를 암호화하고 저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109595-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
고객이 자신의 계정에서 필요한 권한이 있는 IAM 역할을 생성하도록 함으로써 회사는 AWS 
Identity and Access Management(IAM)를 사용하여 교차 계정 액세스를 설정할 수 있습니다. 
신뢰 정책은 회사의 AWS 계정이 일시적으로 고객의 IAM 역할을 맡도록 허용하여 고객 
계정 내의 지정된 리소스(EC2 인스턴스 및 CloudWatch 지표)에 대한 액세스 권한을 
부여합니다. 이 접근 방식은 회사가 필요한 권한만 요청하고 고객의 장기 액세스 키나 
사용자 자격 증명을 요구하지 않기 때문에 최소 권한 원칙을 따릅니다. 
Q504 
회사는 수백 개의 AWS 계정에 걸쳐 있는 us-east-1 리전의 여러 VPC 를 연결해야 합니다. 
회사의 네트워킹 팀에는 클라우드 네트워크를 관리하기 위한 자체 AWS 계정이 있습니다. 
VPC 를 연결하기 위한 운영상 가장 효율적인 솔루션은 무엇입니까? 
A. 각 VPC 간에 VPC 피어링 연결을 설정합니다. 연결된 각 서브넷의 경로 테이블을 
업데이트합니다. 
B. 인터넷을 통해 각 VPC 를 연결하도록 각 VPC 에서 NAT 게이트웨이와 인터넷 
게이트웨이를 구성합니다. 
C. 네트워킹 팀의 AWS 계정에서 AWS Transit Gateway 를 생성합니다. 각 VPC 에서 정적 
경로를 구성합니다. 
D. 각 VPC 에 VPN 게이트웨이를 배포합니다. 네트워킹 팀의 AWS 계정에 전송 VPC 를 
생성하여 각 VPC 에 연결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109690-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
AWS Transit Gateway 는 여러 VPC, 온프레미스 네트워크 및 원격 네트워크를 연결하기 
위한 확장성이 뛰어난 중앙 집중식 허브입니다. 단일 진입점을 제공하고 필요한 연결 수를 
줄임으로써 네트워크 연결을 단순화합니다. 이 시나리오에서 네트워킹 팀의 AWS 계정에 
AWS Transit Gateway 를 배포하면 여러 VPC 에서 네트워크 연결을 효율적으로 관리하고 
제어할 수 있습니다. 
Q505 
한 회사에 야간 배치 작업을 실행하여 데이터를 처리하는 Amazon EC2 인스턴스가 
있습니다. EC2 인스턴스는 온디맨드 결제를 사용하는 Auto Scaling 그룹에서 실행됩니다. 
한 인스턴스에서 작업이 실패하면 다른 인스턴스가 작업을 다시 처리합니다. 배치 작업은 
현지 시간으로 매일 오전 12 시에서 오전 6 시 사이에 실행됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 EC2 인스턴스를 제공하는 솔루션은 
무엇입니까? 
A. 배치 작업이 사용하는 Auto Scaling 그룹의 인스턴스 제품군을 포함하는 Amazon EC2 용 
1 년 절약 플랜을 구매합니다. 
B. 배치 작업이 사용하는 Auto Scaling 그룹에 있는 인스턴스의 특정 인스턴스 유형 및 
운영 체제에 대해 1 년 예약 인스턴스를 구매합니다. 
C. Auto Scaling 그룹에 대한 새 시작 템플릿을 생성합니다. 인스턴스를 스팟 인스턴스로 
설정합니다. CPU 사용량에 따라 확장하도록 정책을 설정합니다. 
D. Auto Scaling 그룹에 대한 새 시작 템플릿을 생성합니다. 인스턴스 크기를 늘립니다. 
CPU 사용량에 따라 확장하도록 정책을 설정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109691-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q506 
소셜 미디어 회사는 웹사이트용 기능을 구축하고 있습니다. 이 기능을 통해 사용자는 
사진을 업로드할 수 있습니다. 회사는 대규모 이벤트 기간 동안 수요가 크게 증가할 것으로 
예상하고 웹사이트가 사용자의 업로드 트래픽을 처리할 수 있는지 확인해야 합니다. 
MOST 확장성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 사용자의 브라우저에서 응용 프로그램 서버로 파일을 업로드합니다. 파일을 Amazon S3 
버킷으로 전송합니다. 
B. AWS Storage Gateway 파일 게이트웨이를 프로비저닝합니다. 사용자의 브라우저에서 
파일 게이트웨이로 직접 파일을 업로드합니다. 
C. 애플리케이션에서 Amazon S3 미리 서명된 URL 을 생성합니다. 사용자 브라우저에서 S3 
버킷으로 직접 파일을 업로드합니다. 
D. Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝합니다. 사용자의 
브라우저에서 파일 시스템으로 직접 파일을 업로드합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109692-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q507 
회사에 여행 발권을 위한 웹 애플리케이션이 있습니다. 이 애플리케이션은 북미 지역의 
단일 데이터 센터에서 실행되는 데이터베이스를 기반으로 합니다. 회사는 글로벌 사용자 
기반에 서비스를 제공하기 위해 응용 프로그램을 확장하려고 합니다. 회사는 
애플리케이션을 여러 AWS 리전에 배포해야 합니다. 예약 데이터베이스 업데이트 시 평균 
대기 시간은 1 초 미만이어야 합니다. 
이 회사는 여러 지역에 걸쳐 웹 플랫폼을 별도로 배포하려고 합니다. 그러나 회사는 전 
세계적으로 일관된 단일 기본 예약 데이터베이스를 유지해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 권장해야 합니까? 
A. Amazon DynamoDB 를 사용하도록 애플리케이션을 변환합니다. 중앙 예약 테이블에 전역 
테이블을 사용합니다. 각 지역 배포에서 올바른 지역 엔드포인트를 사용합니다. 
B. 데이터베이스를 Amazon Aurora MySQL 데이터베이스로 마이그레이션합니다. 각 지역에 
Aurora 읽기 전용 복제본을 배포합니다. 데이터베이스에 액세스하려면 각 지역 배포에서 
올바른 지역 엔드포인트를 사용하세요. 
C. 데이터베이스를 Amazon RDS for MySQL 데이터베이스로 마이그레이션합니다. 각 리전에 
MySQL 읽기 전용 복제본을 배포합니다. 데이터베이스에 액세스하려면 각 지역 배포에서 
올바른 지역 엔드포인트를 사용하세요. 
D. 애플리케이션을 Amazon Aurora Serverless 데이터베이스로 마이그레이션합니다. 각 
지역에 데이터베이스 인스턴스를 배포합니다. 각 지역 배포에서 올바른 지역 엔드포인트를 
사용하여 데이터베이스에 액세스합니다. AWS Lambda 함수를 사용하여 각 리전에서 이벤트 
스트림을 처리하여 데이터베이스를 동기화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109608-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q508 
한 회사에서 여러 Microsoft Windows Server 워크로드를 us-west-1 리전에서 실행되는 
Amazon EC2 인스턴스로 마이그레이션했습니다. 회사는 필요에 따라 이미지를 생성하기 
위해 워크로드를 수동으로 백업합니다. 
us-west-1 리전에서 자연 재해가 발생한 경우 회사는 us-west-2 리전에서 워크로드를 
신속하게 복구하기를 원합니다. 회사는 EC2 인스턴스에서 24 시간 이상의 데이터 손실을 
원하지 않습니다. 회사는 또한 EC2 인스턴스의 모든 백업을 자동화하려고 합니다. 
최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) 
A. Amazon EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 생성하여 태그 기반 
백업을 생성합니다. 하루에 두 번 실행되도록 백업을 예약합니다. 필요에 따라 이미지를 
복사합니다. 
B. Amazon EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 생성하여 태그 기반 
백업을 생성합니다. 하루에 두 번 실행되도록 백업을 예약합니다. us-west-2 리전에 대한 
복사본을 구성합니다. 
C. AWS Backup 을 사용하여 us-west-1 및 us-west-2 에 백업 볼트를 생성합니다. 태그 
값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 백업 데이터를 us-west-2 에 
복사하기 위해 예약된 작업으로 실행할 AWS Lambda 함수를 생성합니다. 
D. AWS Backup 을 사용하여 백업 볼트를 생성합니다. AWS Backup 을 사용하여 태그 값을 
기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 사본의 대상을 us-west-2 로 
정의합니다. 하루에 두 번 실행할 백업 일정을 지정합니다. 
E. AWS Backup 을 사용하여 백업 볼트를 생성합니다. AWS Backup 을 사용하여 태그 값을 
기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 하루에 두 번 실행할 백업 일정을 
지정합니다. 요청 시 us-west-2 에 복사합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/109530-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명:・ 
옵션 B 는 EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 사용하여 백업 
프로세스를 자동화할 것을 제안합니다. 하루에 두 번 실행되도록 정책을 구성하고 
uswest-2 리전에 대한 복사본을 지정함으로써 회사는 정기적인 백업이 생성되고 대체 
리전에 복사되도록 할 수 있습니다. 
옵션 D 는 중앙 집중식 백업 관리 솔루션을 제공하는 AWS Backup 사용을 제안합니다. 
태그 값을 기반으로 백업 볼트 및 백업 계획을 생성함으로써 회사는 EC2 인스턴스에 대한 
백업 프로세스를 자동화할 수 있습니다. 
백업 일정은 하루에 두 번 실행되도록 설정할 수 있으며 복사 대상은 us-west-2 리전으로 
정의할 수 있습니다. 
두 옵션 모두 백업 프로세스를 자동화하고 백업을 us-west-2 리전에 복사하는 것을 
포함하여 재해 발생 시 데이터 복원력을 보장합니다. 이러한 솔루션은 AWS 서비스에서 
제공하는 자동화된 백업 및 복사 메커니즘을 활용하여 관리 작업을 최소화합니다. 
Q509 
회사에서 이미지 처리를 위한 2 계층 애플리케이션을 운영하고 있습니다. 애플리케이션은 
각각 1 개의 퍼블릭 서브넷과 1 개의 프라이빗 서브넷이 있는 2 개의 가용 영역을 
사용합니다. 웹 계층용 ALB(Application Load Balancer)는 퍼블릭 서브넷을 사용합니다. 
애플리케이션 계층의 Amazon EC2 인스턴스는 프라이빗 서브넷을 사용합니다. 
사용자는 응용 프로그램이 예상보다 느리게 실행되고 있다고 보고합니다. 웹 서버 로그 
파일의 보안 감사 결과 애플리케이션이 소수의 IP 주소로부터 수백만 건의 불법 요청을 
받고 있는 것으로 나타났습니다. 솔루션 설계자는 회사가 보다 영구적인 솔루션을 조사하는 
동안 즉각적인 성능 문제를 해결해야 합니다. 
이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. 웹 계층에 대한 인바운드 보안 그룹을 수정합니다. 리소스를 소비하는 IP 주소에 대한 
거부 규칙을 추가합니다. 
B. 웹 계층 서브넷에 대한 네트워크 ACL 을 수정합니다. 리소스를 소비하는 IP 주소에 대한 
인바운드 거부 규칙을 추가합니다. 
C. 애플리케이션 계층에 대한 인바운드 보안 그룹을 수정합니다. 리소스를 소비하는 IP 
주소에 대한 거부 규칙을 추가합니다. 
D. 애플리케이션 계층 서브넷에 대한 네트워크 ACL 을 수정합니다. 리소스를 소비하는 IP 
주소에 대한 인바운드 거부 규칙을 추가합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109531-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
퍼블릭 서브넷의 첫 번째 항목에서 요청을 거부하고 프라이빗 서브넷에 도달하는 것을 
허용하지 마십시오. 
이 시나리오에서 보안 감사는 애플리케이션이 소수의 IP 주소로부터 수백만 건의 불법 
요청을 수신하고 있음을 보여줍니다. 이 문제를 해결하려면 웹 계층 서브넷에 대한 
네트워크 ACL(액세스 제어 목록)을 수정하는 것이 좋습니다. 리소스를 소비하는 IP 주소를 
특별히 대상으로 하는 인바운드 거부 규칙을 추가함으로써 네트워크 ACL 은 불법 트래픽이 
웹 서버에 도달하기 전에 서브넷 수준에서 차단할 수 있습니다. 이는 웹 계층의 과도한 
로드를 완화하고 애플리케이션의 성능을 향상시키는 데 도움이 됩니다. 
Q510 
글로벌 마케팅 회사에는 ap-southeast-2 지역 및 eu-west-1 지역에서 실행되는 
애플리케이션이 있습니다. eu-west-1 의 VPC 에서 실행되는 애플리케이션은 
ap-southeast-2 의 VPC 에서 실행되는 데이터베이스와 안전하게 통신해야 합니다. 
이러한 요구 사항을 충족하는 네트워크 설계는 무엇입니까? 
A. eu-west-1 VPC 와 ap-southeast-2 VPC 간에 VPC 피어링 연결을 생성합니다. 
ap-southeast-2 보안 그룹의 데이터베이스 서버 IP 주소에서 오는 트래픽을 허용하는 
인바운드 규칙을 eu-west-1 애플리케이션 보안 그룹에 생성합니다. 
B. ap-southeast-2 VPC 와 eu-west-1 VPC 간에 VPC 피어링 연결을 구성합니다. 서브넷 
경로 테이블을 업데이트합니다. eu-west-1 에 있는 애플리케이션 서버의 보안 그룹 ID 를 
참조하는 ap-southeast-2 데이터베이스 보안 그룹에서 인바운드 규칙을 생성합니다. 
C. ap-southeast-2 VPC 와 eu-west-1 VPUpdate 서브넷 라우팅 테이블 간에 VPC 피어링 
연결을 구성합니다. ap-southeast-2 데이터베이스 보안 그룹에서 eu-west-1 애플리케이션 
서버 IP 주소의 트래픽을 허용하는 인바운드 규칙을 생성합니다. 
D. eu-west-1 VPC 와 ap-southeast-2 VPC 간에 피어링 연결이 있는 전송 게이트웨이를 
생성합니다. 전송 게이트웨이가 올바르게 피어링되고 라우팅이 구성되면 eu-west-1 에 
있는 애플리케이션 서버의 보안 그룹 ID 를 참조하는 데이터베이스 보안 그룹에 인바운드 
규칙을 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109708-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
다른 리전에 있는 피어 VPC 의 보안 그룹을 참조할 수 없습니다. 대신 피어 VPC 의 CIDR 
블록을 사용하십시오. 
https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-securitygroups.html 
Q511 
회사에서 PostgreSQL 데이터베이스 스키마를 사용하는 소프트웨어를 개발하고 있습니다. 
회사는 회사 개발자를 위해 여러 개발 환경과 데이터베이스를 구성해야 합니다. 평균적으로 
각 개발 환경은 8 시간 근무 시간의 절반을 사용합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 자체 Amazon Aurora PostgreSQL 데이터베이스로 각 개발 환경 구성 
B. 자체 Amazon RDS for PostgreSQL 단일 AZ DB 인스턴스로 각 개발 환경 구성 
C. 자체 Amazon Aurora 온디맨드 PostgreSQL 호환 데이터베이스로 각 개발 환경 구성 
D. Amazon S3 Object Select 를 사용하여 자체 Amazon S3 버킷으로 각 개발 환경 구성 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109532-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q512 
회사는 계정으로 태그가 지정된 리소스와 함께 AWS Organizations 를 사용합니다. 이 
회사는 또한 AWS Backup 을 사용하여 AWS 인프라 리소스를 백업합니다. 회사는 모든 
AWS 리소스를 백업해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 태그가 지정되지 않은 모든 리소스를 식별하려면 AWS Config 를 사용하십시오. 
프로그래밍 방식으로 식별된 리소스에 태그를 지정합니다. 백업 계획에서 태그를 
사용합니다. 
B. AWS Config 를 사용하여 실행 중이 아닌 모든 리소스를 식별합니다. 해당 리소스를 백업 
볼트에 추가합니다. 
C. 모든 AWS 계정 소유자가 리소스를 검토하여 백업해야 하는 리소스를 식별하도록 
요구합니다. 
D. Amazon Inspector 를 사용하여 규정을 준수하지 않는 모든 리소스를 식별합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109709-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q513 
소셜 미디어 회사는 사용자가 AWS 클라우드에서 호스팅되는 애플리케이션에 이미지를 
업로드할 수 있도록 허용하려고 합니다. 회사는 이미지가 여러 장치 유형에 표시될 수 
있도록 이미지 크기를 자동으로 조정하는 솔루션이 필요합니다. 애플리케이션은 하루 종일 
예측할 수 없는 트래픽 패턴을 경험합니다. 회사는 확장성을 극대화하는 고가용성 솔루션을 
찾고 있습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 이미지 크기를 조정하고 이미지를 Amazon S3 버킷에 저장하기 위해 AWS Lambda 
함수를 호출하는 Amazon S3 에서 호스팅되는 정적 웹 사이트를 생성합니다. 
B. AWS Step Functions 를 호출하여 이미지 크기를 조정하고 Amazon RDS 데이터베이스에 
이미지를 저장하는 Amazon CloudFront 에서 호스팅되는 정적 웹 사이트를 생성합니다. 
C. Amazon EC2 인스턴스에서 실행되는 웹 서버에서 호스팅되는 동적 웹 사이트를 
만듭니다. EC2 인스턴스에서 실행되는 프로세스를 구성하여 이미지 크기를 조정하고 
Amazon S3 버킷에 이미지를 저장합니다. 
D. Amazon Simple Queue Service(Amazon SQS)에서 크기 조정 작업을 생성하는 자동 확장 
Amazon Elastic Container Service(Amazon ECS) 클러스터에서 호스팅되는 동적 웹 
사이트를 생성합니다. 크기 조정 작업을 처리하기 위해 Amazon EC2 인스턴스에서 
실행되는 이미지 크기 조정 프로그램을 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109713-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
Amazon S3 와 AWS Lambda 를 함께 사용하면 확장성과 가용성이 뛰어난 이미지 크기 조정 
기능을 제공하는 서버리스 아키텍처를 생성할 수 있습니다. 
솔루션이 작동하는 방식은 다음과 같습니다. 
사용자가 업로드한 원본 이미지를 저장하도록 Amazon S3 버킷을 설정합니다. 
새 이미지가 업로드될 때마다 AWS Lambda 함수를 호출하도록 S3 버킷에서 이벤트 
트리거를 구성합니다. 
Lambda 함수는 업로드된 이미지를 검색하고, 장치 요구 사항에 따라 필요한 크기 조정 
작업을 수행하고, 크기 조정된 이미지를 S3 버킷 또는 크기 조정된 이미지용으로 지정된 
다른 버킷에 다시 저장하도록 설계할 수 있습니다. 
사용자에게 제공하기 위해 크기 조정된 이미지에 공개적으로 액세스할 수 있도록 Amazon 
S3 버킷을 구성합니다. 
Q514 
회사는 Amazon EC2 인스턴스에서 마이크로서비스 애플리케이션을 실행하고 있습니다. 이 
회사는 확장성을 위해 애플리케이션을 Amazon Elastic Kubernetes Service(Amazon EKS) 
클러스터로 마이그레이션하려고 합니다. 회사는 보안 규정 준수를 유지하기 위해 
엔드포인트 프라이빗 액세스를 true 로 설정하고 엔드포인트 퍼블릭 액세스를 false 로 
설정하여 Amazon EKS 제어 플레인을 구성해야 합니다. 회사는 또한 사설 서브넷에 데이터 
플레인을 배치해야 합니다. 그러나 회사는 노드가 클러스터에 가입할 수 없기 때문에 오류 
알림을 받았습니다. 
노드가 클러스터에 가입하도록 허용하는 솔루션은 무엇입니까? 
A. AWS Identity and Access Management(IAM)에서 필요한 권한을 AmazonEKSNodeRole 
IAM 역할에 부여합니다. 
B. 노드가 컨트롤 플레인에 액세스할 수 있도록 인터페이스 VPC 엔드포인트를 생성합니다. 
C. 퍼블릭 서브넷에서 노드를 재생성합니다. EC2 노드에 대한 보안 그룹을 제한합니다. 
D. 노드의 보안 그룹에서 아웃바운드 트래픽을 허용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109534-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
클러스터의 VPC 내 Kubernetes API 요청(예: 노드와 컨트롤 플레인 통신)은 프라이빗 VPC 
엔드포인트를 사용합니다. 
https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html 
Q515 
회사에서 온프레미스 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 회사는 Amazon 
Redshift 를 솔루션으로 사용하려고 합니다. 
이 시나리오에서 Amazon Redshift 에 적합한 사용 사례는 무엇입니까? (3 개 선택) 
A. 기존의 컨테이너화된 이벤트 기반 애플리케이션으로 데이터에 액세스하기 위한 데이터 
API 지원 
B. 클라이언트 측 및 서버 측 암호화 지원 
C. 지정된 시간 동안 애플리케이션이 활성 상태가 아닐 때 분석 워크로드 구축 
D. 백엔드 데이터베이스에 대한 부담을 줄이기 위한 데이터 캐싱 
E. 페타바이트 규모의 데이터와 분당 수천만 건의 요청을 지원하도록 전 세계적으로 확장 
F. AWS Management Console 을 사용하여 클러스터의 보조 복제본 생성 
Answer: B, C, E 
https://www.examtopics.com/discussions/amazon/view/109535-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q516 
회사는 고객이 재무 정보를 검색할 수 있도록 고객에게 API 인터페이스를 제공합니다. 
회사는 연중 최대 사용 시간에 더 많은 수의 요청을 예상합니다. 
회사는 API 가 고객 만족을 보장하기 위해 낮은 대기 시간으로 일관되게 응답하도록 
요구합니다. 회사는 API 에 컴퓨팅 호스트를 제공해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Application Load Balancer 및 Amazon Elastic Container Service(Amazon ECS)를 
사용합니다. 
B. 프로비저닝된 동시성과 함께 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. 
C. Application Load Balancer 및 Amazon Elastic Kubernetes Service(Amazon EKS) 
클러스터를 사용합니다. 
D. 예약된 동시성과 함께 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109719-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon API Gateway 는 개발자가 모든 규모에서 API 를 쉽게 생성, 게시, 유지 관리, 
모니터링 및 보호할 수 있게 해주는 완전관리형 서비스입니다. AWS Lambda 는 서버를 
프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스입니다. 
Lambda 는 들어오는 요청에 따라 자동으로 확장되지만 수요가 갑자기 증가하면 함수의 새 
인스턴스를 초기화하는 데 시간이 걸릴 수 있습니다. 이로 인해 API 에 대한 긴 대기 시간 
또는 콜드 스타트가 발생할 수 있습니다. 이를 방지하기 위해 함수가 초기화되고 언제든지 
응답할 준비가 되도록 프로비저닝된 동시성을 사용할 수 있습니다. 프로비저닝된 동시성은 
또한 확장이 성능에 미치는 영향을 줄임으로써 API 의 지연 시간을 일관되게 줄이는 데 
도움이 됩니다. 
참조: 
https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integr
ationslambda.html 
https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html 
Q517 
한 회사에서 보관 목적으로 모든 AWS Systems Manager Session Manager 로그를 Amazon 
S3 버킷으로 보내려고 합니다. 
어떤 솔루션이 가장 운영 효율성이 높은 이 요구 사항을 충족합니까? 
A. Systems Manager 콘솔에서 S3 로깅을 활성화합니다. 세션 데이터를 보낼 S3 버킷을 
선택합니다. 
B. Amazon CloudWatch 에이전트를 설치합니다. 모든 로그를 CloudWatch 로그 그룹에 
푸시합니다. 보관 목적으로 그룹에서 S3 버킷으로 로그를 내보냅니다. 
C. 모든 서버 로그를 중앙 S3 버킷에 업로드할 Systems Manager 문서를 생성합니다. 
Amazon EventBridge 를 사용하여 매일 계정에 있는 모든 서버에 대해 Systems Manager 
문서를 실행하십시오. 
D. Amazon CloudWatch 에이전트를 설치합니다. 모든 로그를 CloudWatch 로그 그룹에 
푸시합니다. 수신 로그 이벤트를 Amazon Kinesis Data Firehose 전송 스트림으로 푸시하는 
CloudWatch 로그 구독을 생성합니다. Amazon S3 를 대상으로 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109536-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q518 
애플리케이션은 Amazon RDS MySQL DB 인스턴스를 사용합니다. RDS 데이터베이스의 
디스크 공간이 부족해지고 있습니다. 솔루션 설계자는 다운타임 없이 디스크 공간을 늘리고 
싶어합니다. 
최소한의 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. RDS 에서 스토리지 자동 확장 활성화 
B. RDS 데이터베이스 인스턴스 크기 늘리기 
C. RDS 데이터베이스 인스턴스 스토리지 유형을 프로비저닝된 IOPS 로 변경 
D. RDS 데이터베이스 백업, 저장 용량 증가, 데이터베이스 복원 및 이전 인스턴스 중지 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109721-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q519 
컨설팅 회사는 전 세계 고객에게 전문 서비스를 제공합니다. 이 회사는 고객이 AWS 에서 
데이터를 신속하게 수집하고 분석할 수 있는 솔루션과 도구를 제공합니다. 회사는 고객이 
셀프 서비스 목적으로 사용할 공통 솔루션 및 도구 집합을 중앙에서 관리하고 배포해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 고객을 위한 AWS CloudFormation 템플릿을 생성합니다. 
B. 고객을 위한 AWS Service Catalog 제품을 만듭니다. 
C. 고객을 위한 AWS Systems Manager 템플릿을 생성합니다. 
D. 고객을 위한 AWS Config 항목을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109722-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q520 
한 회사에서 Amazon EC2 인스턴스에서 실행할 새 웹 애플리케이션을 설계하고 있습니다. 
애플리케이션은 백엔드 데이터 스토리지에 Amazon DynamoDB 를 사용합니다. 
애플리케이션 트래픽은 예측할 수 없습니다. 회사는 데이터베이스에 대한 응용 프로그램 
읽기 및 쓰기 처리량이 보통에서 높을 것으로 예상합니다. 회사는 애플리케이션 트래픽에 
대응하여 확장해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 DynamoDB 테이블 구성은 
무엇입니까? 
A. DynamoDB 표준 테이블 클래스를 사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB 를 
구성합니다. DynamoDB Auto Scaling 을 정의된 최대 용량으로 설정합니다. 
B. DynamoDB Standard 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB 를 
구성합니다. 
C. DynamoDB Standard Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 
사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB 를 구성합니다. DynamoDB Auto 
Scaling 을 정의된 최대 용량으로 설정합니다. 
D. DynamoDB Standard Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 
사용하여 온디맨드 모드에서 DynamoDB 를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109539-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
웹 애플리케이션을 위한 가장 비용 효율적인 DynamoDB 테이블 구성은 DynamoDB 
Standard 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB 를 구성하는 것입니다. 
이 구성을 사용하면 회사는 애플리케이션 트래픽에 따라 확장하고 애플리케이션이 
테이블에서 수행하는 읽기 및 쓰기 요청에 대해서만 비용을 지불할 수 있습니다. 
온디맨드 모드는 용량 계획 없이 초당 수천 개의 요청을 처리할 수 있는 유연한 청구 
옵션입니다. 온디맨드 모드는 들어오는 트래픽을 기준으로 테이블 용량을 자동으로 
조정하고 실제로 수행된 읽기 및 쓰기 요청에 대해서만 요금을 청구합니다. 온디맨드 
모드는 예측할 수 없거나 가변적인 워크로드가 있는 애플리케이션 또는 사용한 만큼만 
비용을 지불하는 용이성을 선호하는 애플리케이션에 적합합니다. 
DynamoDB 표준 테이블 클래스는 대부분의 워크로드에 대한 기본이자 권장 테이블 
클래스입니다. DynamoDB Standard 테이블 클래스는 DynamoDB Standard-Infrequent 
Access(DynamoDB Standard-IA) 테이블 클래스보다 낮은 처리량 비용을 제공하며 
처리량이 주요 비용인 테이블에 대해 더 비용 효율적입니다. DynamoDB Standard 테이블 
클래스는 DynamoDB Standard-IA 테이블 클래스와 동일한 성능, 내구성 및 가용성을 
제공합니다. 
다른 옵션은 비용 효율적이지 않거나 사용 사례에 적합하지 않기 때문에 올바르지 않습니다. 
DynamoDB 표준 테이블 클래스를 사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB 를 
구성하고 DynamoDB Auto Scaling 을 정의된 최대 용량으로 설정하는 것은 올바르지 
않습니다. 이 구성에는 테이블 용량을 수동으로 예측하고 관리해야 하므로 솔루션에 
복잡성과 비용이 추가되기 때문입니다. 
프로비저닝 모드는 사용자가 테이블에 대한 읽기 및 쓰기 용량 단위의 양을 지정하고 
사용량에 관계없이 예약된 용량에 대해 비용을 청구하도록 요구하는 청구 옵션입니다. 
프로비저닝 모드는 예측 가능하거나 안정적인 워크로드가 있는 애플리케이션이나 용량 
설정을 보다 세밀하게 제어해야 하는 애플리케이션에 적합합니다. 
DynamoDB Standard-Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 
사용하여 DynamoDB 를 프로비저닝된 읽기 및 쓰기로 구성하고 DynamoDB 자동 
스케일링을 정의된 최대 용량으로 설정하는 것은 중간에서 높은 처리량의 테이블에서는 
비용 효율적이지 않기 때문에 올바르지 않습니다. 
DynamoDB Standard-IA 테이블 클래스는 DynamoDB Standard 테이블 클래스보다 
스토리지 비용은 낮지만 처리량 비용은 더 높습니다. DynamoDB Standard-IA 테이블 
클래스는 자주 액세스하지 않는 데이터를 저장하는 테이블과 같이 스토리지 비용이 가장 큰 
테이블에 최적화되어 있습니다. DynamoDB Standard-Infrequent Access(DynamoDB 
Standard-IA) 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB 를 구성하는 것은 
올바르지 않습니다. 왜냐하면 이 구성은 중간에서 높은 처리량을 가진 테이블에 대해서는 
비용 효율적이지 않기 때문입니다. 위에서 언급한 것처럼 DynamoDB Standard-IA 테이블 
클래스는 DynamoDB Standard 테이블 클래스보다 처리량 비용이 높기 때문에 스토리지 
비용 절감으로 인한 절감 효과를 상쇄할 수 있습니다. 
Q521 
소매 회사에는 여러 비즈니스가 있습니다. 각 비즈니스의 IT 팀은 자체 AWS 계정을 
관리합니다. 각 팀 계정은 AWS Organizations 에서 조직의 일부입니다. 각 팀은 팀 자체 
AWS 계정의 Amazon DynamoDB 테이블에서 제품 재고 수준을 모니터링합니다. 
회사는 공유 AWS 계정에 중앙 재고 보고 애플리케이션을 배포하고 있습니다. 
애플리케이션은 모든 팀의 DynamoDB 테이블에서 항목을 읽을 수 있어야 합니다. 
이러한 요구 사항을 가장 안전하게 충족하는 인증 옵션은 무엇입니까? 
A. 인벤토리 애플리케이션 계정에서 DynamoDB 를 AWS Secrets Manager 와 통합합니다. 
Secrets Manager 의 올바른 암호를 사용하여 DynamoDB 테이블을 인증하고 읽도록 
애플리케이션을 구성합니다. 30 일마다 비밀 순환을 예약합니다. 
B. 모든 비즈니스 계정에서 프로그래밍 방식 액세스 권한이 있는 IAM 사용자를 생성합니다. 
올바른 IAM 사용자 액세스 키 ID 와 보안 액세스 키를 사용하여 DynamoDB 테이블을 
인증하고 읽도록 애플리케이션을 구성합니다. 30 일마다 IAM 액세스 키를 수동으로 
교체합니다. 
C. 모든 비즈니스 계정에서 DynamoDB 테이블에 대한 역할 액세스 권한을 부여하는 
정책과 인벤토리 애플리케이션 계정의 특정 역할을 신뢰하는 신뢰 정책을 사용하여 
BU_ROLE 이라는 IAM 역할을 생성합니다. 인벤토리 계정에서 STS AssumeRole API 작업에 
대한 액세스를 허용하는 APP_ROLE 이라는 역할을 생성합니다. APP_ROLE 을 사용하도록 
애플리케이션을 구성하고 DynamoDB 테이블을 읽기 위해 교차 계정 역할 BU_ROLE 을 
수임합니다. 
D. DynamoDB 를 AWS Certificate Manager(ACM)와 통합합니다. DynamoDB 를 인증하기 
위해 ID 인증서를 생성합니다. 올바른 인증서를 사용하여 DynamoDB 테이블을 인증하고 
읽도록 애플리케이션을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109703-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q522 
회사는 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 컨테이너 
애플리케이션을 실행합니다. 회사의 작업량은 하루 종일 일정하지 않습니다. 회사는 
Amazon EKS 가 워크로드에 따라 확장 및 축소되기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 
선택) 
A. AWS Lambda 함수를 사용하여 EKS 클러스터의 크기를 조정합니다. 
B. Kubernetes Metrics Server 를 사용하여 수평적 포드 자동 확장을 활성화합니다. 
C. Kubernetes Cluster Autoscaler 를 사용하여 클러스터의 노드 수를 관리합니다. 
D. Amazon API Gateway 를 사용하여 Amazon EKS 에 연결합니다. 
E. AWS App Mesh 를 사용하여 네트워크 활동을 관찰합니다. 
Answer: B, C 
https://www.examtopics.com/discussions/amazon/view/109702-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
https://docs.aws.amazon.com/eks/latest/userguide/horizontal-pod-autoscaler.html 
https://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html 
수평적 포드 자동 확장은 해당 리소스의 CPU 사용률을 기반으로 배포, 복제 컨트롤러 또는 
복제 세트의 포드 수를 자동으로 확장하는 Kubernetes 의 기능입니다. CPU 사용량 
데이터를 제공하려면 Kubernetes Metrics Server 와 같은 메트릭 소스가 필요합니다. 
클러스터 자동 크기 조정은 Pod 가 실패하거나 다른 노드로 다시 예약될 때 클러스터의 
노드 수를 자동으로 조정하는 Kubernetes 의 기능입니다. 클러스터 2 에 가입하는 EC2 
인스턴스를 관리하려면 AWS Auto Scaling 그룹과의 통합이 필요합니다. 이 솔루션은 
수평적 포드 자동 확장과 클러스터 자동 확장을 모두 사용하여 Amazon EKS 가 워크로드에 
따라 확장 및 축소되도록 할 수 있습니다. 
Q523 
회사에서 마이크로서비스 기반 서버리스 웹 애플리케이션을 실행합니다. 애플리케이션은 
여러 Amazon DynamoDB 테이블에서 데이터를 검색할 수 있어야 합니다. 솔루션 설계자는 
애플리케이션의 기본 성능에 영향을 주지 않고 데이터를 검색할 수 있는 기능을 
애플리케이션에 제공해야 합니다. 
운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS AppSync 파이프라인 해석기 
B. Lambda@Edge 기능이 있는 Amazon CloudFront 
C. AWS Lambda 함수를 사용하는 엣지 최적화 Amazon API Gateway 
D. DynamoDB 커넥터를 사용한 Amazon Athena Federated Query 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109701-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
A?? 
Q524 
회사에서 IAM 권한과 관련된 액세스 거부 오류 및 무단 오류를 분석하고 문제를 
해결하려고 합니다. 회사에서 AWS CloudTrail 을 켰습니다. 
최소한의 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Glue 를 사용하고 사용자 지정 스크립트를 작성하여 오류에 대한 CloudTrail 로그를 
쿼리합니다. 
B. AWS Batch 를 사용하고 사용자 지정 스크립트를 작성하여 오류에 대한 CloudTrail 
로그를 쿼리합니다. 
C. Amazon Athena 쿼리로 CloudTrail 로그를 검색하여 오류를 식별합니다. 
D. Amazon QuickSight 로 CloudTrail 로그를 검색합니다. 오류를 식별하는 대시보드를 
만듭니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/111425-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q525 
회사에서 기존 AWS 사용 비용을 운영 비용 대시보드에 추가하려고 합니다. 솔루션 
설계자는 회사가 프로그래밍 방식으로 사용 비용에 액세스할 수 있는 솔루션을 추천해야 
합니다. 회사는 현재 연도의 비용 데이터에 액세스하고 향후 12 개월의 비용을 예측할 수 
있어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 페이지 매김과 함께 AWS Cost Explorer API 를 사용하여 사용 비용 관련 데이터에 
액세스합니다. 
B. 다운로드 가능한 AWS Cost Explorer 보고서 .csv 파일을 사용하여 사용 비용 관련 
데이터에 액세스합니다. 
C. FTP 를 통해 회사에 사용 비용 데이터를 전송하도록 AWS 예산 작업을 구성합니다. 
D. 사용 비용 데이터에 대한 AWS 예산 보고서를 생성합니다. SMTP 를 통해 회사에 
데이터를 보냅니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/111278-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q526 
솔루션 설계자가 애플리케이션의 복원력을 검토하고 있습니다. 솔루션 설계자는 최근에 
데이터베이스 관리자가 확장 연습의 일부로 애플리케이션의 Amazon Aurora PostgreSQL 
데이터베이스 작성자 인스턴스를 장애 조치했음을 확인했습니다. 장애 조치로 인해 
애플리케이션에 3 분의 다운타임이 발생했습니다. 
최소한의 운영 오버헤드로 확장 연습의 중단 시간을 줄이는 솔루션은 무엇입니까? 
A. 장애 조치 중 로드를 처리하기 위해 클러스터에서 더 많은 Aurora PostgreSQL 읽기 
전용 복제본을 생성합니다. 
B. 동일한 AWS 리전에서 보조 Aurora PostgreSQL 클러스터를 설정합니다. 장애 조치 중에 
보조 클러스터의 작성자 엔드포인트를 사용하도록 애플리케이션을 업데이트합니다. 
C. 장애 조치 중 로드를 처리할 Amazon ElastiCache for Memcached 클러스터를 
생성합니다. 
D. 데이터베이스에 대한 Amazon RDS 프록시를 설정합니다. 프록시 엔드포인트를 
사용하도록 애플리케이션을 업데이트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/111245-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q527 
한 회사에 단일 AWS 리전에서 실행되는 리전 구독 기반 스트리밍 서비스가 있습니다. 
아키텍처는 Amazon EC2 인스턴스의 웹 서버와 애플리케이션 서버로 구성됩니다. EC2 
인스턴스는 Elastic Load Balancer 뒤의 Auto Scaling 그룹에 있습니다. 아키텍처에는 여러 
가용 영역에 걸쳐 확장되는 Amazon Aurora 글로벌 데이터베이스 클러스터가 포함됩니다. 
이 회사는 전 세계적으로 확장하고 응용 프로그램의 가동 중지 시간을 최소화하기를 
원합니다. 
어떤 솔루션이 가장 내결함성을 제공합니까? 
A. 웹 계층 및 애플리케이션 계층에 대한 Auto Scaling 그룹을 확장하여 두 번째 리전의 
가용 영역에 인스턴스를 배포합니다. Aurora 글로벌 데이터베이스를 사용하여 기본 리전과 
두 번째 리전에 데이터베이스를 배포합니다. 두 번째 리전에 대한 장애 조치 라우팅 정책과 
함께 Amazon Route 53 상태 확인을 사용합니다. 
B. 웹 계층과 애플리케이션 계층을 두 번째 리전에 배포합니다. 두 번째 리전에 Aurora 
PostgreSQL 교차 리전 Aurora 복제본을 추가합니다. 두 번째 리전에 대한 장애 조치 
라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. 필요에 따라 보조를 
기본으로 승격합니다. 
C. 웹 계층과 애플리케이션 계층을 두 번째 리전에 배포합니다. 두 번째 리전에서 Aurora 
PostgreSQL 데이터베이스를 생성합니다. AWS Database Migration Service(AWS DMS)를 
사용하여 기본 데이터베이스를 두 번째 리전에 복제합니다. 두 번째 리전에 대한 장애 조치 
라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. 
D. 웹 계층과 애플리케이션 계층을 두 번째 지역에 배포합니다. Amazon Aurora 글로벌 
데이터베이스를 사용하여 기본 리전과 두 번째 리전에 데이터베이스를 배포합니다. 두 번째 
리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. 
필요에 따라 보조를 기본으로 승격합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/111428-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 애플리케이션에 고가용성과 중복성을 제공하는 두 번째 리전에 웹 계층과 
애플리케이션 계층을 배포하기 때문에 가장 효율적입니다. 또한 단일 Aurora 
데이터베이스가 여러 AWS 지역에 걸쳐 있을 수 있도록 하는 기능인 Amazon Aurora 
글로벌 데이터베이스를 사용합니다. 또한 기본 지역과 두 번째 지역에 데이터베이스를 
배포하여 지연 시간이 짧은 글로벌 읽기 및 지역 중단 시 빠른 복구를 제공합니다. 또한 두 
번째 리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용하여 
다른 리전의 정상적인 엔드포인트로 트래픽을 라우팅하여 데이터 보호를 제공합니다. 또한 
필요에 따라 보조를 기본으로 승격하여 한 번에 리전 중 하나에서 쓰기 작업을 허용하여 
데이터 일관성을 제공합니다. 이 솔루션은 전 세계적으로 확장하고 해당 애플리케이션의 
다운타임을 최소화해야 한다는 요구 사항을 충족합니다. 
옵션 A 는 웹 계층 및 애플리케이션 계층에 대한 Auto Scaling 그룹을 확장하여 두 번째 
리전의 가용 영역에 인스턴스를 배포하기 때문에 효율성이 떨어집니다. 이렇게 하면 별도로 
배포하는 것보다 더 높은 비용과 복잡성이 발생할 수 있습니다. 또한 Aurora 글로벌 
데이터베이스를 사용하여 기본 리전과 두 번째 리전에 데이터베이스를 배포합니다. 이는 
맞습니다. 그러나 두 번째 리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 
상태 확인을 사용하지 않으므로 트래픽이 비정상 엔드포인트로 라우팅될 수 있습니다. 
옵션 B 는 웹 계층과 애플리케이션 계층을 올바른 두 번째 리전에 배포하기 때문에 
효율성이 떨어집니다. 또한 두 번째 리전에 Aurora PostgreSQL 교차 리전 Aurora 복제본을 
추가하여 리전 간 읽기 확장성을 제공합니다. 그러나 리전 간 복제본보다 더 빠른 복제 및 
복구를 제공하는 Aurora 글로벌 데이터베이스를 사용하지 않습니다. 또한 올바른 두 번째 
리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. 
그러나 필요에 따라 보조를 기본으로 승격하지 않으므로 데이터 불일치 또는 손실이 발생할 
수 있습니다. 
옵션 C 는 웹 계층과 애플리케이션 계층을 올바른 두 번째 리전에 배포하기 때문에 
효율성이 떨어집니다. 
또한 두 번째 리전에 Aurora PostgreSQL 데이터베이스를 생성하여 리전 간 데이터 
중복성을 제공합니다. 그러나 별도의 데이터베이스를 생성하는 것보다 더 빠른 복제 및 
복구를 제공하는 Aurora 글로벌 데이터베이스 또는 리전 간 복제본을 사용하지 않습니다. 
또한 AWS DMS(AWS Database Migration Service)를 사용하여 기본 데이터베이스를 두 번째 
리전에 복제하여 서로 다른 소스와 대상 간에 데이터 마이그레이션을 제공합니다. 그러나 
AWS DMS 를 사용하는 것보다 더 빠른 복제 및 복구를 제공하는 Aurora 글로벌 
데이터베이스 또는 리전 간 복제본을 사용하지 않습니다. 또한 올바른 두 번째 리전에 대한 
장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. 
Q528 
데이터 분석 회사에서 일괄 처리 시스템을 AWS 로 마이그레이션하려고 합니다. 회사는 
FTP 를 통해 하루 동안 주기적으로 수천 개의 작은 데이터 파일을 받습니다. 온프레미스 
배치 작업은 밤새 데이터 파일을 처리합니다. 그러나 배치 작업 실행을 완료하는 데 몇 
시간이 걸립니다. 
회사는 AWS 솔루션이 파일을 전송하는 FTP 클라이언트에 대한 변경을 최소화하면서 
가능한 한 빨리 수신 데이터 파일을 처리하기를 원합니다. 파일이 성공적으로 처리된 후 
솔루션은 수신 데이터 파일을 삭제해야 합니다. 각 파일을 처리하는 데 3~8 분이 
소요됩니다. 
운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. FTP 서버를 실행하는 Amazon EC2 인스턴스를 사용하여 수신 파일을 Amazon S3 
Glacier Flexible Retrieval 의 객체로 저장합니다. AWS Batch 에서 작업 대기열을 구성합니다. 
Amazon EventBridge 규칙을 사용하여 S3 Glacier Flexible Retrieval 에서 야간에 객체를 
처리하는 작업을 호출합니다. 작업이 개체를 처리한 후 개체를 삭제합니다. 
B. FTP 서버를 실행하는 Amazon EC2 인스턴스를 사용하여 수신 파일을 Amazon Elastic 
Block Store(Amazon EBS) 볼륨에 저장합니다. AWS Batch 에서 작업 대기열을 구성합니다. 
Amazon EventBridge 규칙을 사용하여 EBS 볼륨에서 야간에 파일을 처리하는 작업을 
호출합니다. 작업이 파일을 처리한 후 파일을 삭제합니다. 
C. AWS Transfer Family 를 사용하여 들어오는 파일을 Amazon Elastic Block Store(Amazon 
EBS) 볼륨에 저장할 FTP 서버를 생성합니다. AWS Batch 에서 작업 대기열을 구성합니다. 
각 파일이 도착하면 Amazon S3 이벤트 알림을 사용하여 AWS Batch 에서 작업을 
호출합니다. 작업이 파일을 처리한 후 파일을 삭제합니다. 
D. AWS Transfer Family 를 사용하여 Amazon S3 Standard 에 수신 파일을 저장할 FTP 
서버를 생성합니다. 파일을 처리하고 처리 후 파일을 삭제하는 AWS Lambda 함수를 
생성합니다. 파일이 도착하면 S3 이벤트 알림을 사용하여 Lambda 함수를 호출합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/111317-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 AWS Transfer Family 를 사용하여 저비용 고가용성 스토리지 서비스인 Amazon 
S3 Standard 에 수신 파일을 저장할 수 있는 FTP 서버를 생성하기 때문에 운영상 가장 
효율적입니다. 또한 AWS Lambda 를 사용하여 파일을 처리하고 처리 후 삭제합니다. 이는 
배치 스케줄링이나 인프라 관리가 필요하지 않은 확장 가능한 서버리스 솔루션입니다. 또한 
S3 이벤트 알림을 사용하여 파일이 도착하면 Lambda 함수를 호출하여 수신 데이터 파일을 
거의 실시간으로 처리할 수 있습니다. 
옵션 A 는 Amazon S3 Standard 보다 검색 비용이 높고 검색 시간이 긴 콜드 스토리지 
클래스인 Amazon S3 Glacier Flexible Retrieval 을 사용하기 때문에 효율성이 떨어집니다. 
또한 EventBridge 규칙을 사용하여 야간에 작업을 호출하므로 들어오는 데이터 파일을 
가능한 한 빨리 처리해야 한다는 요구 사항을 충족하지 않습니다. 
옵션 B 는 EBS 볼륨을 사용하여 수신 파일을 저장하기 때문에 효율성이 떨어집니다. 이는 
Amazon S3 보다 비용이 높고 내구성이 낮은 블록 스토리지 서비스입니다. 또한 
EventBridge 규칙을 사용하여 야간에 작업을 호출하므로 들어오는 데이터 파일을 가능한 
한 빨리 처리해야 한다는 요구 사항을 충족하지 않습니다. 
옵션 C 는 EBS 볼륨을 사용하여 수신 파일을 저장하기 때문에 효율성이 떨어집니다. 이는 
Amazon S3 보다 비용이 높고 내구성이 낮은 블록 스토리지 서비스입니다. 또한 AWS 
Batch 를 사용하여 파일을 처리하므로 컴퓨팅 리소스와 작업 대기열을 관리해야 합니다. 
Q529 
회사에서 워크로드를 AWS 로 마이그레이션하고 있습니다. 회사는 데이터베이스에 거래 및 
민감한 데이터를 가지고 있습니다. 이 회사는 AWS 클라우드 솔루션을 사용하여 보안을 
강화하고 데이터베이스의 운영 오버헤드를 줄이려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 데이터베이스를 Amazon EC2 로 마이그레이션합니다. 암호화에 AWS Key Management 
Service(AWS KMS) AWS 관리형 키를 사용합니다. 
B. 데이터베이스를 Amazon RDS 로 마이그레이션 유휴 암호화 구성. 
C. 데이터를 Amazon S3 로 마이그레이션합니다. 데이터 보안 및 보호를 위해 Amazon 
Macie 를 사용합니다. 
D. 데이터베이스를 Amazon RDS 로 마이그레이션합니다. 데이터 보안 및 보호를 위해 
Amazon CloudWatch Logs 를 사용하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/111246-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q530 
회사에 TCP 및 UDP 멀티플레이어 게임 기능이 있는 온라인 게임 응용 프로그램이 
있습니다. 이 회사는 Amazon Route 53 을 사용하여 애플리케이션 트래픽이 서로 다른 AWS 
리전에 있는 여러 NLB(Network Load Balancer)를 가리키도록 합니다. 회사는 사용자 
증가에 대비하여 애플리케이션 성능을 개선하고 온라인 게임의 지연 시간을 줄여야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. NLB 앞에 Amazon CloudFront 배포를 추가합니다. Cache-Control max-age 매개변수를 
늘리십시오. 
B. NLB 를 ALB(Application Load Balancer)로 교체합니다. 지연 시간 기반 라우팅을 
사용하도록 Route 53 을 구성합니다. 
C. NLB 앞에 AWS Global Accelerator 를 추가합니다. 올바른 수신기 포트를 사용하도록 
Global Accelerator 끝점을 구성합니다. 
D. NLB 뒤에 Amazon API Gateway 엔드포인트를 추가합니다. API 캐싱을 활성화합니다. 
다른 단계에 대한 메서드 캐싱을 재정의합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/111271-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q531 
회사는 타사 데이터 피드와 통합해야 합니다. 데이터 피드는 웹후크를 보내 새 데이터를 
사용할 준비가 되면 외부 서비스에 알립니다. 개발자는 회사에서 웹후크 콜백을 수신할 때 
데이터를 검색하는 AWS Lambda 함수를 작성했습니다. 개발자는 제 3 자가 호출할 수 
있도록 Lambda 함수를 제공해야 합니다. 
이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Lambda 함수에 대한 함수 URL 을 생성합니다. Webhook 에 대한 Lambda 함수 URL 을 
타사에 제공합니다. 
B. Lambda 함수 앞에 ALB(Application Load Balancer)를 배포합니다. Webhook 에 대한 
ALB URL 을 타사에 제공합니다. 
C. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. Lambda 함수에 
주제를 연결합니다. Webhook 에 대한 제 3 자에게 SNS 주제의 공개 호스트 이름을 
제공합니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 대기열을 Lambda 
함수에 연결합니다. Webhook 에 대해 타사에 SQS 대기열의 공개 호스트 이름을 
제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/111430-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
함수 URL 은 HTTPS 를 통해 함수를 호출하는 데 사용할 수 있는 Lambda 함수의 고유 
식별자입니다. 함수가 배포된 AWS 리전의 API 엔드포인트와 function1 의 이름 또는 
ARN 으로 구성됩니다. Lambda 함수에 대한 함수 URL 을 생성함으로써 솔루션은 제 3 자가 
Lambda 함수를 가장 효율적으로 호출할 수 있도록 할 수 있습니다. 
1. Lambda 함수 앞에 Application Load Balancer(ALB)를 배포합니다. Webhook 에 대한 
ALB URL 을 타사에 제공합니다. 이 솔루션은 HTTPS 를 통해 Lambda 함수를 호출하는 데 
필요하지 않은 추가 리소스(ALB)를 생성하고 관리하기 때문에 최고의 운영 효율성 요구 
사항을 충족하지 않습니다. 
2. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. Lambda 함수에 
주제를 연결합니다. Webhook 에 대한 제 3 자에게 SNS 주제의 공개 호스트 이름을 
제공합니다. Amazon SNS 주제에는 웹훅으로 사용할 수 있는 공개 호스트 이름이 없기 
때문에 이 솔루션은 작동하지 않습니다. SNS 주제는 외부 소스로부터 메시지를 받는 것이 
아니라 구독자에게 메시지를 게시하는 데 사용됩니다. 
3. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 대기열을 Lambda 
함수에 연결합니다. Webhook 에 대해 타사에 SQS 대기열의 공개 호스트 이름을 
제공합니다. Amazon SQS 대기열에는 웹훅으로 사용할 수 있는 공개 호스트 이름이 없기 
때문에 이 솔루션은 작동하지 않습니다. SQS 대기열은 외부 소스에서 메시지를 수신하는 
것이 아니라 AWS 서비스 간에 메시지를 전송, 저장 및 수신하는 데 사용됩니다. 
참조 URL: 
https://docs.aws.amazon.com/lambda/latest/dg/lambda-api-permissions-ref.html 
Q532 
회사는 AWS 리전에 워크로드가 있습니다. 고객은 Amazon API Gateway REST API 를 
사용하여 워크로드에 연결하고 액세스합니다. 이 회사는 Amazon Route 53 을 DNS 
공급자로 사용합니다. 회사는 모든 고객에게 개별적이고 안전한 URL 을 제공하고자 합니다. 
가장 높은 운영 효율성으로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3 개 
선택) 
A. 등록기관에 필요한 도메인을 등록합니다. Route 53 호스팅 영역에서 와일드카드 사용자 
지정 도메인 이름을 생성하고 API 게이트웨이 엔드포인트를 가리키는 영역에 기록합니다. 
B. 다른 리전에 있는 AWS Certificate Manager(ACM)의 도메인과 일치하는 와일드카드 
인증서를 요청합니다. 
C. Route 53 에서 필요에 따라 각 고객에 대한 호스팅 영역을 생성합니다. API 게이트웨이 
엔드포인트를 가리키는 영역 레코드를 생성합니다. 
D. 동일한 리전의 AWS Certificate Manager(ACM)에서 사용자 지정 도메인 이름과 일치하는 
와일드카드 인증서를 요청합니다. 
E. API Gateway 에서 각 고객에 대해 여러 API 끝점을 만듭니다. 
F. API Gateway 에서 REST API 용 사용자 정의 도메인 이름을 생성합니다. AWS Certificate 
Manager(ACM)에서 인증서를 가져옵니다. 
Answer: A, D, F 
https://www.examtopics.com/discussions/amazon/view/111382-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
API Gateway REST API 를 사용하는 모든 고객에게 개별 보안 URL 을 제공하려면 다음 
단계를 수행해야 합니다. 
a) 등록 기관에 필요한 도메인을 등록합니다. Route 53 호스팅 영역에서 와일드카드 사용자 
지정 도메인 이름을 생성하고 API 게이트웨이 엔드포인트를 가리키는 영역에 기록합니다. 
이 단계를 통해 API Gateway 에서 생성한 기본 도메인 이름 대신 API 에 대한 사용자 지정 
도메인 이름을 사용할 수 있습니다. 와일드카드 사용자 지정 도메인 이름은 도메인 이름 
아래의 모든 하위 도메인(예: customer1.example.com 또는 customer2.example.com)을 
사용하여 API 에 액세스할 수 있음을 의미합니다. 도메인 이름을 등록 대행자(예: Route 53 
또는 타사 등록 대행자)에 등록하고 도메인 이름에 대해 Route 53 에 호스팅 영역을 
생성해야 합니다. 또한 별칭 레코드를 사용하여 API Gateway 엔드포인트를 가리키는 
호스팅 영역에 레코드를 생성해야 합니다. 
d) 동일한 리전의 AWS Certificate Manager(ACM)에서 사용자 지정 도메인 이름과 일치하는 
와일드카드 인증서를 요청합니다. 이 단계에서는 ACM 에서 발급한 인증서를 사용하여 
HTTPS 로 API 를 보호할 수 있습니다. 와일드카드 인증서는 도메인 이름 아래의 모든 하위 
도메인(예: *.example.com)과 일치할 수 있음을 의미합니다. 사용자 지정 도메인 이름과 
일치하는 ACM 에서 인증서를 요청하거나 가져와 도메인 이름을 소유하고 있는지 확인해야 
합니다. 또한 API 와 동일한 리전에서 인증서를 요청해야 합니다. 
f) API Gateway 에서 REST API 용 사용자 지정 도메인 이름을 생성합니다. AWS Certificate 
Manager(ACM)에서 인증서를 가져옵니다. 이 단계에서는 사용자 지정 도메인 이름을 API 와 
연결하고 ACM 의 인증서를 사용하여 HTTPS 를 활성화할 수 있습니다. API Gateway 에서 
REST API 용 사용자 지정 도메인 이름을 생성하고 ACM 에서 인증서 ARN 을 지정해야 
합니다. 또한 사용자 지정 도메인 이름에서 API 단계로 경로를 매핑하는 기본 경로 매핑을 
생성해야 합니다. 
Q533 
회사는 Amazon S3 에 데이터를 저장합니다. 규정에 따르면 데이터에는 개인 식별 
정보(PII)가 포함되어서는 안 됩니다. 이 회사는 최근 S3 버킷에 PII 가 포함된 일부 개체가 
있음을 발견했습니다. 회사는 S3 버킷에서 PII 를 자동으로 감지하고 회사의 보안 팀에 
알려야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Macie 를 사용하십시오. Amazon EventBridge 규칙을 생성하여 Macie 결과에서 
SensitiveData 이벤트 유형을 필터링하고 보안 팀에 Amazon Simple Notification 
Service(Amazon SNS) 알림을 보냅니다. 
B. Amazon GuardDuty 를 사용합니다. GuardDuty 결과에서 중요한 이벤트 유형을 
필터링하고 보안 팀에 Amazon Simple Notification Service(Amazon SNS) 알림을 보내는 
Amazon EventBridge 규칙을 생성합니다. 
C. Amazon Macie 를 사용합니다. Amazon EventBridge 규칙을 생성하여 Macie 결과에서 
SensitiveData:S3Object/Personal 이벤트 유형을 필터링하고 보안 팀에 Amazon Simple 
Queue Service(Amazon SQS) 알림을 보냅니다. 
D. Amazon GuardDuty 를 사용합니다. GuardDuty 결과에서 중요한 이벤트 유형을 
필터링하고 보안 팀에 Amazon Simple Queue Service(Amazon SQS) 알림을 보내는 
Amazon EventBridge 규칙을 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/111432-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Macie 는 또한 다양한 소스의 데이터를 사용하여 애플리케이션을 쉽게 연결할 수 
있게 해주는 서버리스 이벤트 버스인 Amazon EventBridge 로 결과를 보낼 수 있습니다. 
Macie 결과에서 SensitiveData 이벤트 유형을 필터링하고 보안 팀에 Amazon SNS 알림을 
보내는 EventBridge 규칙을 생성할 수 있습니다. Amazon SNS 는 구독자 또는 다른 
애플리케이션에 메시지를 보낼 수 있는 완전 관리형 메시징 서비스입니다. 
참조: 
https://docs.aws.amazon.com/macie/latest/userguide/macie-findings.html#macie-findin
gseventbridge 
Q534 
회사에서 여러 AWS 계정에 대한 로깅 솔루션을 구축하려고 합니다. 회사는 현재 모든 
계정의 로그를 중앙 집중식 계정에 저장합니다. 회사는 VPC 흐름 로그와 AWS CloudTrail 
로그를 저장하기 위해 중앙 집중식 계정에 Amazon S3 버킷을 생성했습니다. 모든 로그는 
빈번한 분석을 위해 30 일 동안 가용성이 높아야 하며, 백업 목적으로 추가 60 일 동안 
유지되고 생성 후 90 일 후에 삭제되어야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 생성 후 30 일이 지나면 객체를 S3 Standard 스토리지 클래스로 전환합니다. 90 일 후에 
객체를 삭제하도록 Amazon S3 에 지시하는 만료 작업을 작성합니다. 
B. 생성 후 30 일이 지나면 객체를 S3 Standard-Infrequent Access(S3 Standard-IA) 
스토리지 클래스로 전환합니다. 90 일 후에 모든 객체를 S3 Glacier Flexible Retrieval 
스토리지 클래스로 이동합니다. 90 일 후에 객체를 삭제하도록 Amazon S3 에 지시하는 만료 
작업을 작성합니다. 
C. 생성 후 30 일이 지나면 객체를 S3 Glacier Flexible Retrieval 스토리지 클래스로 
전환합니다. 90 일 후에 객체를 삭제하도록 Amazon S3 에 지시하는 만료 작업을 
작성합니다. 
D. 생성 후 30 일이 지나면 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA) 
스토리지 클래스로 전환합니다. 90 일 후에 모든 객체를 S3 Glacier Flexible Retrieval 
스토리지 클래스로 이동합니다. 90 일 후에 객체를 삭제하도록 Amazon S3 에 지시하는 만료 
작업을 작성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/111434-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q535 
회사에서 워크로드를 위해 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터를 
구축하고 있습니다. Amazon EKS 에 저장되는 모든 암호는 Kubernetes etcd 키-값 
저장소에서 암호화되어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 새 AWS Key Management Service(AWS KMS) 키를 생성합니다. AWS Secrets Manager 를 
사용하여 Amazon EKS 에서 모든 비밀을 관리, 교체 및 저장하십시오. 
B. 새 AWS Key Management Service(AWS KMS) 키를 생성합니다. Amazon EKS 
클러스터에서 Amazon EKS KMS 비밀 암호화를 활성화합니다. 
C. 기본 옵션으로 Amazon EKS 클러스터를 생성합니다. Amazon Elastic Block 
Store(Amazon EBS) CSI(Container Storage Interface) 드라이버를 추가 기능으로 
사용합니다. 
D. alias/aws/ebs 별칭으로 새 AWS Key Management Service(AWS KMS) 키를 생성합니다. 
계정에 대해 기본 Amazon Elastic Block Store(Amazon EBS) 볼륨 암호화를 활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/111385-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q536 
회사에서 PostgreSQL 데이터베이스용 Amazon RDS 프로덕션에 대한 거의 실시간에 
가까운 읽기 전용 액세스 권한을 데이터 과학자에게 제공하려고 합니다. 데이터베이스는 
현재 단일 AZ 데이터베이스로 구성되어 있습니다. 데이터 과학자는 프로덕션 
데이터베이스에 영향을 미치지 않는 복잡한 쿼리를 사용합니다. 회사는 가용성이 높은 
솔루션이 필요합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 유지 관리 기간에 기존 프로덕션 데이터베이스를 확장하여 데이터 과학자에게 충분한 
성능을 제공합니다. 
B. 단일 AZ 에서 더 큰 보조 대기 인스턴스가 있는 다중 AZ 인스턴스 배포로 설정을 
변경합니다. 데이터 과학자에게 보조 인스턴스에 대한 액세스 권한을 제공합니다. 
C. 단일 AZ 에서 다중 AZ 인스턴스 배포로 설정을 변경합니다. 데이터 과학자를 위한 두 
개의 추가 읽기 복제본을 제공합니다. 
D. 단일 AZ 에서 2 개의 읽기 가능한 대기 인스턴스가 있는 다중 AZ 클러스터 배포로 
설정을 변경합니다. 데이터 과학자에게 읽기 엔드포인트를 제공합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/111435-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q537 
한 회사가 3 개의 가용 영역에서 작동하는 AWS 클라우드에서 3 계층 웹 애플리케이션을 
실행합니다. 애플리케이션 아키텍처에는 Application Load Balancer, 사용자 세션 상태를 
호스팅하는 Amazon EC2 웹 서버, EC2 인스턴스에서 실행되는 MySQL 데이터베이스가 
있습니다. 회사는 애플리케이션 트래픽이 갑자기 증가할 것으로 예상합니다. 이 회사는 
미래의 애플리케이션 용량 수요를 충족하고 3 개의 가용 영역 모두에서 고가용성을 
보장하기 위해 확장할 수 있기를 원합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 다중 AZ DB 클러스터 배포를 통해 MySQL 데이터베이스를 MySQL 용 Amazon RDS 로 
마이그레이션합니다. 고가용성 Redis 용 Amazon ElastiCache 를 사용하여 세션 데이터를 
저장하고 읽기를 캐시하십시오. 세 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 
서버를 마이그레이션합니다. 
B. 다중 AZ DB 클러스터 배포를 통해 MySQL 데이터베이스를 MySQL 용 Amazon RDS 로 
마이그레이션합니다. 고가용성 Memcached 용 Amazon ElastiCache 를 사용하여 세션 
데이터를 저장하고 읽기를 캐시하십시오. 세 개의 가용 영역에 있는 Auto Scaling 그룹으로 
웹 서버를 마이그레이션합니다. 
C. MySQL 데이터베이스를 Amazon DynamoDB 로 마이그레이션 DynamoDB 
Accelerator(DAX)를 사용하여 읽기를 캐시합니다. DynamoDB 에 세션 데이터를 저장합니다. 
세 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 서버를 마이그레이션합니다. 
D. 단일 가용 영역에서 MySQL 데이터베이스를 MySQL 용 Amazon RDS 로 
마이그레이션합니다. 고가용성 Redis 용 Amazon ElastiCache 를 사용하여 세션 데이터를 
저장하고 읽기를 캐시하십시오. 세 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 
서버를 마이그레이션합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/111386-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 답변은 향후 애플리케이션 용량 요구 사항을 충족하기 위한 확장 요구 사항을 충족하고 
세 가용 영역 모두에서 고가용성을 보장하기 때문에 정답입니다. 다중 AZ DB 클러스터 
배포를 사용하여 MySQL 데이터베이스를 MySQL 용 Amazon RDS 로 마이그레이션함으로써 
회사는 여러 가용 영역에서 데이터베이스의 자동 장애 조치, 백업 및 패치 적용의 이점을 
누릴 수 있습니다. 고가용성 Redis 용 Amazon ElastiCache 를 사용하여 회사는 가용 영역 
전체에서 장애 조치할 수 있는 빠른 인 메모리 데이터 저장소에 세션 데이터 및 캐시 
읽기를 저장할 수 있습니다. 3 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 서버를 
마이그레이션함으로써 회사는 수요 및 트래픽 패턴에 따라 웹 서버 용량을 자동으로 확장할 
수 있습니다. 
참조: 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html 
https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-sc
aling.html 
Q538 
글로벌 비디오 스트리밍 회사는 Amazon CloudFront 를 콘텐츠 배포 네트워크(CDN)로 
사용합니다. 회사는 여러 국가에 단계적으로 콘텐츠를 배포하려고 합니다. 회사는 회사가 
콘텐츠를 배포하는 국가 밖에 있는 시청자가 콘텐츠를 볼 수 없도록 해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 허용 목록을 사용하여 CloudFront 의 콘텐츠에 지리적 제한을 추가합니다. 사용자 지정 
오류 메시지를 설정합니다. 
B. 제한된 콘텐츠에 대한 새로운 URL 을 설정합니다. 서명된 URL 및 쿠키를 사용하여 
액세스 권한을 부여합니다. 사용자 지정 오류 메시지를 설정합니다. 
C. 회사가 배포하는 콘텐츠에 대한 데이터를 암호화합니다. 사용자 지정 오류 메시지를 
설정합니다. 
D. 제한된 콘텐츠에 대한 새 URL 을 만듭니다. 서명된 URL 에 대한 시간 제한 액세스 
정책을 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/111387-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q539 
회사에서 AWS 클라우드를 사용하여 온프레미스 DR(재해 복구) 구성을 개선하려고 합니다. 
회사의 핵심 프로덕션 비즈니스 애플리케이션은 가상 머신(VM)에서 실행되는 Microsoft 
SQL Server Standard 를 사용합니다. 애플리케이션의 RPO(복구 시점 목표)는 30 초 
이하이고 RTO(복구 시간 목표)는 60 분입니다. DR 솔루션은 가능한 한 비용을 최소화해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Always On 가용성 그룹과 함께 Microsoft SQL Server Enterprise 를 사용하여 온프레미스 
서버와 AWS 간에 다중 사이트 활성/활성 설정을 구성합니다. 
B. AWS 에서 SQL Server 데이터베이스용 웜 대기 Amazon RDS 를 구성합니다. 변경 데이터 
캡처(CDC)를 사용하도록 AWS DMS(AWS Database Migration Service)를 구성합니다. 
C. 디스크 변경 사항을 AWS 에 파일럿 라이트로 복제하도록 구성된 AWS Elastic Disaster 
Recovery 를 사용합니다. 
D. 타사 백업 소프트웨어를 사용하여 매일 밤 백업을 캡처합니다. Amazon S3 에 보조 백업 
세트를 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/111301-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
C?? 
Q540 
회사에는 Oracle 데이터베이스를 사용하여 고객 정보를 처리하고 저장하는 온프레미스 
서버가 있습니다. 이 회사는 AWS 데이터베이스 서비스를 사용하여 더 높은 가용성을 
달성하고 애플리케이션 성능을 개선하고자 합니다. 회사는 또한 기본 데이터베이스 
시스템에서 보고를 오프로드하려고 합니다. 
운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Database Migration Service(AWS DMS)를 사용하여 여러 AWS 리전에서 Amazon 
RDS DB 인스턴스를 생성합니다. 보고 기능은 기본 DB 인스턴스와 별도의 DB 인스턴스를 
가리킵니다. 
B. 단일 AZ 배포에서 Amazon RDS 를 사용하여 Oracle 데이터베이스를 생성합니다. 기본 
DB 인스턴스와 동일한 영역에 읽기 전용 복제본을 생성합니다. 보고 기능을 읽기 전용 
복제본으로 지정합니다. 
C. 다중 AZ 클러스터 배포에 배포된 Amazon RDS 를 사용하여 Oracle 데이터베이스를 
생성합니다. 클러스터 배포에서 리더 인스턴스를 사용하도록 보고 기능에 지시합니다. 
D. 다중 AZ 인스턴스 배포에 배포된 Amazon RDS 를 사용하여 Amazon Aurora 
데이터베이스를 생성합니다. 보고 기능을 판독기 인스턴스에 지시합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/111439-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Aurora 는 MySQL 및 PostgreSQL 과 호환되는 완전관리형 관계형 
데이터베이스입니다. MySQL 보다 최대 5 배, PostgreSQL 보다 최대 3 배 뛰어난 성능을 
제공합니다. 또한 여러 가용 영역에 걸쳐 데이터를 복제하고 데이터를 Amazon S31 에 
지속적으로 백업하여 고가용성과 내구성을 제공합니다. 다중 AZ 인스턴스 배포에 배포된 
Amazon RDS 를 사용하여 Amazon Aurora 데이터베이스를 생성함으로써 솔루션은 더 높은 
가용성을 달성하고 애플리케이션 성능을 개선할 수 있습니다. 
Amazon Aurora 는 기본 인스턴스와 동일한 기본 스토리지를 공유하는 별도의 인스턴스인 
읽기 전용 복제본을 지원합니다. 읽기 전용 복제본을 사용하여 기본 인스턴스에서 읽기 
전용 쿼리를 오프로드하고 성능을 향상할 수 있습니다. 읽기 전용 복제본은 보고 기능에도 
사용할 수 있습니다. 
보고 기능을 판독기 인스턴스로 지정함으로써 솔루션은 기본 데이터베이스 시스템에서 
보고를 오프로드할 수 있습니다. 
1. AWS Database Migration Service(AWS DMS)를 사용하여 여러 AWS 리전에서 Amazon 
RDS DB 인스턴스 생성 보고 기능이 기본 DB 인스턴스와 별도의 DB 인스턴스를 
가리키도록 합니다. 이 솔루션은 AWS 데이터베이스 서비스 사용 요구 사항을 충족하지 
않습니다. AWS DMS 는 데이터베이스 서비스 자체가 아니라 사용자가 데이터베이스를 
AWS 로 마이그레이션하는 데 도움을 주는 서비스이기 때문입니다. 또한 서로 다른 
리전에서 여러 DB 인스턴스를 생성해야 하므로 복잡성과 비용이 증가할 수 있습니다. 
2. 단일 AZ 배포에서 Amazon RDS 를 사용하여 Oracle 데이터베이스 생성 기본 DB 
인스턴스와 동일한 영역에 읽기 전용 복제본을 생성합니다. 보고 기능을 읽기 전용 
복제본으로 지정합니다. 단일 AZ 배포는 가용 영역 중단 시 장애 조치 보호를 제공하지 
않으므로 이 솔루션은 고가용성 달성 요구 사항을 충족하지 않습니다. 또한 Oracle 을 
데이터베이스 엔진으로 사용하므로 Aurora보다 더 나은 성능을 제공하지 못할 수 있습니다. 
3. 다중 AZ 클러스터 배포에 배포된 Amazon RDS 를 사용하여 Oracle 데이터베이스 생성 
클러스터 배포에서 리더 인스턴스를 사용하도록 보고 기능에 지시합니다. Oracle 이 
Aurora 보다 더 나은 성능을 제공하지 않을 수 있으므로 이 솔루션은 애플리케이션 성능 
향상 요구 사항을 충족하지 않습니다. 또한 Oracle 이 아닌 Aurora 에서만 지원되는 
클러스터 배포를 사용합니다. 
참조:  
https://aws.amazon.com/rds/aurora/ 
Q541 
회사에서 AWS 에서 웹 애플리케이션을 구축하려고 합니다. 웹 사이트에 대한 클라이언트 
액세스 요청은 예측할 수 없으며 오랫동안 유휴 상태일 수 있습니다. 가입비를 지불한 
고객만이 웹 애플리케이션에 로그인하고 사용할 수 있습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (3 개 선택) 
A. Amazon DynamoDB 에서 사용자 정보를 검색하는 AWS Lambda 함수를 생성합니다. 
RESTful API 를 수락할 Amazon API Gateway 엔드포인트를 생성합니다. API 호출을 Lambda 
함수로 보냅니다. 
B. Application Load Balancer 뒤에 Amazon Elastic Container Service(Amazon ECS) 
서비스를 생성하여 Amazon RDS 에서 사용자 정보를 검색합니다. RESTful API 를 수락할 
Amazon API Gateway 엔드포인트를 생성합니다. API 호출을 Lambda 함수로 보냅니다. 
C. 사용자를 인증하기 위해 Amazon Cognito 사용자 풀을 생성합니다. 
D. 사용자를 인증하기 위해 Amazon Cognito 자격 증명 풀을 생성합니다. 
E. AWS Amplify를 사용하여 HTML, CSS 및 JS로 프런트엔드 웹 콘텐츠를 제공합니다. 통합 
Amazon CloudFront 구성을 사용합니다. 
F. PHP, CSS 및 JS 와 함께 Amazon S3 정적 웹 호스팅을 사용합니다. Amazon 
CloudFront 를 사용하여 프런트엔드 웹 콘텐츠를 제공합니다. 
Answer: A, C, E 
https://www.examtopics.com/discussions/amazon/view/111440-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
참고 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html 
Q542 
미디어 회사는 Amazon CloudFront 배포를 사용하여 인터넷을 통해 콘텐츠를 제공합니다. 
회사는 프리미엄 고객만 미디어 스트림과 파일 콘텐츠에 액세스할 수 있기를 원합니다. 
회사는 모든 콘텐츠를 Amazon S3 버킷에 저장합니다. 회사는 또한 영화 대여나 음악 
다운로드와 같은 특정 목적을 위해 주문형 콘텐츠를 고객에게 제공합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. S3 서명 쿠키를 생성하여 프리미엄 고객에게 제공합니다. 
B. 프리미엄 고객에게 CloudFront 서명 URL 을 생성하고 제공합니다. 
C. 원본 액세스 제어(OAC)를 사용하여 비프리미엄 고객의 액세스를 제한합니다. 
D. 비프리미엄 고객을 차단하기 위해 필드 수준 암호화를 생성하고 활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/111441-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* CloudFront 서명된 URL: 이 URL 을 사용하면 Amazon CloudFront 배포를 통해 제공되는 
콘텐츠에 대한 제한된 액세스를 제공할 수 있습니다. 프리미엄 고객에게 시간 제한이 있는 
액세스 권한을 부여하기 위해 서명된 URL 을 생성할 수 있습니다. 
* 콘텐츠 제한: 
* CloudFront 서명된 URL 을 사용하면 S3 에 저장된 미디어 스트림 및 파일 콘텐츠에 대한 
액세스를 제어할 수 있습니다. 
* 이러한 URL 은 만료 시간으로 사용자 정의할 수 있으므로 특정 기간 동안에만 액세스가 
가능하므로 영화 대여 또는 음악 다운로드와 같은 시나리오에 유용합니다. 
* 보안 및 유연성: 
* 서명된 URL 은 인증된 사용자(프리미엄 고객)만 제한된 콘텐츠에 액세스할 수 있도록 
보장합니다. 
* 이 접근 방식은 CloudFront 및 S3 와 원활하게 통합되어 추가 오버헤드 없이 액세스 
제어를 관리하는 효율적인 방법을 제공합니다. 
* 운영 효율성: CloudFront 서명 URL 을 사용하면 AWS 관리형 서비스를 활용하여 액세스 
제어의 복잡성을 처리하고 사용자 지정 구현 및 유지 관리의 필요성을 줄입니다. 
Q543 
회사는 개별적으로 블리딩된 여러 AWS 계정에서 Amazon EC2 인스턴스를 실행합니다. 이 
회사는 최근 저축 피안을 구입했습니다. 회사의 비즈니스 요구 사항 변경으로 인해 회사는 
많은 수의 EC2 인스턴스를 폐기했습니다. 회사는 다른 AWS 계정에서 Savings Plan 할인을 
사용하려고 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 마스터 계정의 AWS 계정 관리 콘솔에서 결제 기본 설정 섹션의 할인 공유를 켭니다. 
B. 기존 Savings Plan 을 구매한 계정의 AWS 계정 관리 콘솔에서 결제 기본 설정 섹션의 
할인 공유를 켭니다. 모든 계정을 포함합니다. 
C. AWS Organizations 마스터 계정에서 AWS Resource Access Manager(AWS RAM)를 
사용하여 다른 계정과 Savings Plan 을 공유합니다. 
D. 새 지급인 계정의 AWS Organizations 에서 조직을 생성합니다. 다른 AWS 계정을 
초대하여 마스터 계정에서 조직에 가입합니다. 
E. 기존 EC2 인스턴스 및 Savings Plan 을 사용하여 기존 AWS 계정의 AWS 
Organizations 에 조직을 생성합니다. 다른 AWS 계정을 초대하여 마스터 계정에서 조직에 
가입합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/111442-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q544 
소매 회사는 퍼블릭 REST API 에 지역 Amazon API Gateway API 를 사용합니다. API 
Gateway 엔드포인트는 Amazon Route 53 별칭 레코드를 가리키는 사용자 지정 도메인 
이름입니다. 솔루션 아키텍트는 고객에게 최소한의 영향을 미치고 데이터 손실을 
최소화하는 솔루션을 생성하여 새 버전의 API 를 릴리스해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. API 게이트웨이에 대한 카나리아 릴리스 배포 단계를 생성합니다. 최신 API 버전을 
배포합니다. 트래픽의 적절한 비율을 카나리아 단계로 지정합니다. API 검증 후 카나리아 
단계를 프로덕션 단계로 승격합니다. 
B. OpenAPI YAML 파일 형식의 새 API 버전으로 새 API 게이트웨이 엔드포인트를 
생성합니다. API Gateway 의 API 에 병합 모드에서 가져오기-업데이트 작업을 사용합니다. 
API 의 새 버전을 프로덕션 단계에 배포합니다. 
C. OpenAPI JSON 파일 형식의 새 API 버전으로 새 API 게이트웨이 엔드포인트를 
생성합니다. 덮어쓰기 모드에서 업데이트로 가져오기 작업을 API Gateway 의 API 에 
사용합니다. API 의 새 버전을 프로덕션 단계에 배포합니다. 
D. API 정의의 새 버전으로 새 API 게이트웨이 엔드포인트를 생성합니다. 새 API Gateway 
API 에 대한 사용자 지정 도메인 이름을 생성합니다. Route 53 별칭 레코드가 새 API 
Gateway API 사용자 지정 도메인 이름을 가리키도록 합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/111450-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명:・ 
이 답변은 고객에게 미치는 영향을 최소화하고 데이터 손실을 최소화하면서 API 의 새 
버전을 릴리스하기 위한 요구 사항을 충족하므로 정확합니다. 카나리아 릴리스 배포는 
테스트 목적으로 API 의 새 버전을 배포하고 기본 버전은 동일한 단계에서 일반 작업을 
위해 프로덕션 릴리스로 배포된 상태로 유지하는 소프트웨어 개발 전략입니다. 카나리아 
릴리스 배포에서 총 API 트래픽은 미리 구성된 비율로 프로덕션 릴리스와 카나리아 
릴리스로 무작위로 분리됩니다. 일반적으로 카나리아 릴리스는 API 트래픽의 작은 비율을 
수신하고 프로덕션 릴리스가 나머지를 차지합니다. 업데이트된 API 기능은 카나리아를 통한 
API 트래픽에만 표시됩니다. 카나리아 트래픽 비율을 조정하여 테스트 범위 또는 성능을 
최적화할 수 있습니다. 카나리아 트래픽을 작게 유지하고 선택을 무작위로 유지함으로써 
대부분의 사용자는 새 버전의 잠재적인 버그로 인해 언제든지 악영향을 받지 않으며 단일 
사용자도 항상 악영향을 받지 않습니다. 테스트 메트릭이 요구 사항을 통과한 후 canary 
릴리스를 프로덕션 릴리스로 승격하고 배포에서 canary 를 비활성화할 수 있습니다. 이렇게 
하면 생산 단계에서 새로운 기능을 사용할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/apigateway/latest/developerguide/canary-release.html 
Q545 
회사는 회사의 기본 웹 사이트를 사용할 수 없는 경우 사용자를 백업 정적 오류 페이지로 
안내하려고 합니다. 기본 웹 사이트의 DNS 레코드는 Amazon Route 53 에서 호스팅됩니다. 
도메인은 Application Load Balancer(ALB)를 가리킵니다. 회사는 변경 및 인프라 
오버헤드를 최소화하는 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 지연 시간 라우팅 정책을 사용하도록 Route 53 레코드를 업데이트합니다. 트래픽이 가장 
반응이 빠른 엔드포인트로 전송되도록 Amazon S3 버킷에서 호스팅되는 정적 오류 
페이지를 레코드에 추가합니다. 
B. Route 53 활성-수동 장애 조치 구성을 설정합니다. Route 53 상태 확인에서 ALB 
엔드포인트가 비정상이라고 판단하면 Amazon S3 버킷에서 호스팅되는 정적 오류 페이지로 
트래픽을 보냅니다. 
C. 정적 오류 페이지를 엔드포인트로 호스팅하는 Amazon EC2 인스턴스와 ALB 를 사용하여 
Route 53 활성-활성 구성을 설정합니다. ALB 에 대한 상태 확인이 실패한 경우에만 
인스턴스에 요청을 보내도록 Route 53 을 구성합니다. 
D. 다중값 응답 라우팅 정책을 사용하도록 Route 53 레코드를 업데이트합니다. 상태 확인을 
만듭니다. 상태 확인이 통과되면 트래픽을 웹사이트로 안내합니다. 상태 확인을 통과하지 
못한 경우 Amazon S3 에서 호스팅되는 정적 오류 페이지로 트래픽을 보냅니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/116974-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 1: 
Route 53 상태 확인을 사용하여 활성-활성 및 활성-수동 장애 조치 구성을 구성할 수 
있습니다. 능동-수동 장애 조치 : 기본 리소스 또는 리소스 그룹을 대부분의 시간 동안 
사용할 수 있도록 하고 모든 기본 리소스를 사용할 수 없는 경우에 대비하여 보조 리소스 
또는 리소스 그룹을 대기 상태로 유지하려는 경우 활성-수동 장애 조치 구성을 사용합니다. 
쿼리에 응답할 때 Route 53 에는 정상적인 기본 리소스만 포함됩니다. 모든 기본 리소스가 
비정상인 경우 Route 53 은 DNS 쿼리에 대한 응답으로 정상적인 보조 리소스만 포함하기 
시작합니다. 
https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html 
설명 2: 
이 솔루션은 기본 웹 사이트를 사용할 수 없는 경우 사용자를 백업 정적 오류 페이지로 
안내하여 변경 및 인프라 오버헤드를 최소화하는 요구 사항을 충족합니다. Route 53 
활성-수동 장애 조치 구성은 정상인 경우 기본 리소스로, 기본 리소스가 비정상인 경우 
보조 리소스로 트래픽을 라우팅할 수 있습니다. Route 53 상태 확인은 ALB 엔드포인트의 
상태를 모니터링하고 필요할 때 장애 조치를 트리거할 수 있습니다. 정적 오류 페이지는 
웹사이트로 구성된 S3 버킷에서 호스팅할 수 있으며 이는 정적 콘텐츠를 제공하는 
간단하고 비용 효율적인 방법입니다. 
대기 시간 라우팅 정책을 사용하면 사용자에 대한 가장 낮은 네트워크 대기 시간을 
기반으로 트래픽을 라우팅할 수 있지만 장애 조치 기능을 제공하지 않기 때문에 옵션 A 는 
올바르지 않습니다. 
ALB 및 EC2 인스턴스와 함께 활성-활성 구성을 사용하면 인프라 오버헤드와 복잡성이 
증가할 수 있고 EC2 인스턴스가 항상 정상 상태임을 보장하지 않기 때문에 옵션 C 는 
올바르지 않습니다. 
다중값 응답 라우팅 정책을 사용하면 쿼리에 대해 여러 값을 반환할 수 있지만 장애 조치 
기능을 제공하지 않기 때문에 옵션 D 는 올바르지 않습니다. 
참조: 
https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-failover.ht
ml 
https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html 
Q546 
회사의 IT 비용에 대한 최근 분석에서는 백업 비용을 줄여야 할 필요성이 강조되었습니다. 
회사의 CIO 는 온프레미스 백업 인프라를 단순화하고 물리적 백업 테이프 사용을 제거하여 
비용을 절감하고자 합니다. 회사는 온프레미스 백업 애플리케이션 및 워크플로우에 대한 
기존 투자를 보존해야 합니다. 
솔루션 설계자는 무엇을 추천해야 합니까? 
A. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway 를 
설정합니다. 
B. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템을 
설정합니다. 
C. iSCSI 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 
시스템을 설정합니다. 
D. iSCSI-가상 테이프 라이브러리(VTL) 인터페이스를 사용하여 백업 애플리케이션과 
연결하도록 AWS Storage Gateway 를 설정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/116975-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 온프레미스 백업 인프라를 단순화하고 물리적 백업 테이프의 사용을 
제거하여 비용을 절감할 수 있습니다. iSCSI-가상 테이프 라이브러리(VTL) 인터페이스를 
사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway 를 설정함으로써 회사는 
S3 또는 Glacier 의 가상 테이프에 백업 데이터를 저장할 수 있습니다. 이를 통해 AWS 
스토리지 서비스를 활용하는 동시에 온프레미스 백업 애플리케이션 및 워크플로에 대한 
기존 투자를 보존합니다. 
Q547 
회사는 서로 다른 위치에 데이터 수집 센서를 가지고 있습니다. 데이터 수집 센서는 대량의 
데이터를 회사로 스트리밍합니다. 이 회사는 대용량 스트리밍 데이터를 수집하고 처리하기 
위해 AWS 에서 플랫폼을 설계하려고 합니다. 솔루션은 확장 가능해야 하며 거의 
실시간으로 데이터 수집을 지원해야 합니다. 회사는 향후 보고를 위해 데이터를 Amazon 
S3 에 저장해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Kinesis Data Firehose를 사용하여 스트리밍 데이터를 Amazon S3에 전달합니다. 
B. AWS Glue 를 사용하여 스트리밍 데이터를 Amazon S3 에 전달합니다. 
C. AWS Lambda 를 사용하여 스트리밍 데이터를 전달하고 데이터를 Amazon S3 에 
저장합니다. 
D. AWS DMS(AWS Database Migration Service)를 사용하여 스트리밍 데이터를 Amazon 
S3 에 전달합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/116976-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
최소한의 운영 오버헤드로 대용량 스트리밍 데이터를 수집하고 처리하려면 Amazon Kinesis 
Data Firehose 가 적합한 솔루션입니다. Amazon Kinesis Data Firehose 는 스트리밍 데이터를 
캡처, 변환하여 Amazon S3 또는 기타 대상으로 전달할 수 있습니다. Amazon Kinesis Data 
Firehose 는 데이터 처리량에 맞춰 자동으로 확장하고 모든 양의 데이터를 처리할 수 
있습니다. Amazon Kinesis Data Firehose 는 프로비저닝이나 관리를 위해 서버가 필요하지 
않은 완전관리형 서비스이기도 합니다. 
Q548 
회사에는 재무, 데이터 분석 및 개발 부서를 위한 별도의 AWS 계정이 있습니다. 비용 및 
보안 문제 때문에 회사는 각 AWS 계정이 사용할 수 있는 서비스를 제어하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Systems Manager 템플릿을 사용하여 각 부서에서 사용할 수 있는 AWS 서비스를 
제어합니다. 
B. AWS Organizations 의 각 부서에 대한 조직 단위(OU)를 생성합니다. 서비스 제어 
정책(SCP)을 OU 에 연결합니다. 
C. AWS CloudFormation 을 사용하여 각 부서에서 사용할 수 있는 AWS 서비스만 자동으로 
프로비저닝합니다. 
D. 특정 AWS 서비스의 사용을 관리 및 제어하기 위해 AWS 계정의 AWS Service 
Catalog 에 제품 목록을 설정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/116977-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS Organizations: AWS Organizations 를 사용하면 여러 AWS 계정을 생성하고 중앙에서 
관리할 수 있습니다. 계정을 조직 단위(OU)로 구성하고 이러한 단위에 정책을 적용할 수 
있습니다. 
* 조직 단위(OU): 
* 재무, 데이터 분석, 개발 등 각 부서에 대해 별도의 OU 를 만듭니다. 
* 각 부서의 해당 AWS 계정을 해당 OU 에 배치합니다. 
* 서비스 제어 정책(SCP): 
* SCP 는 OU 의 계정에서 사용할 수 있는 AWS 서비스 및 작업을 제한할 수 있는 
정책입니다. 
* SCP 를 생성하여 각 부서에서 사용할 수 있는 서비스를 정의하고 이러한 정책을 적절한 
OU 에 연결합니다. 
* SCP 는 OU 내 계정 내의 모든 IAM 사용자, 그룹 및 역할에 적용되어 서비스 사용에 대한 
중앙 집중식 제어를 제공합니다. 
* 운영 효율성: AWS Organizations 및 SCP 를 사용하면 운영 오버헤드를 최소화하면서 
여러 계정에 걸쳐 권한을 관리할 수 있는 확장 가능하고 중앙 집중화된 방법을 제공합니다. 
Q549 
회사에서 전자상거래 웹 사이트를 위한 다중 계층 애플리케이션을 만들었습니다. 
웹사이트는 퍼블릭 서브넷에 상주하는 Application Load Balancer, 퍼블릭 서브넷의 웹 계층, 
프라이빗 서브넷의 Amazon EC2 인스턴스에서 호스팅되는 MySQL 클러스터를 사용합니다. 
MySQL 데이터베이스는 타사 공급자가 인터넷에서 호스팅하는 제품 카탈로그 및 가격 
정보를 검색해야 합니다. 솔루션 설계자는 운영 오버헤드를 늘리지 않고 보안을 극대화하는 
전략을 고안해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. VPC 에 NAT 인스턴스를 배포합니다. NAT 인스턴스를 통해 모든 인터넷 기반 트래픽을 
라우팅합니다. 
B. 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다. 인터넷 바인딩된 모든 트래픽을 NAT 
게이트웨이로 보내도록 프라이빗 서브넷 라우팅 테이블을 수정합니다. 
C. 인터넷 게이트웨이를 구성하고 VPModify 프라이빗 서브넷 라우팅 테이블에 연결하여 
인터넷 바인딩 트래픽을 인터넷 게이트웨이로 보냅니다. 
D. 가상 프라이빗 게이트웨이를 구성하고 VPC 에 연결합니다. 인터넷 바인딩 트래픽을 가상 
프라이빗 게이트웨이로 보내도록 프라이빗 서브넷 라우팅 테이블을 수정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/116978-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
프라이빗 서브넷의 MySQL 데이터베이스가 공개적으로 노출되지 않고 인터넷에 액세스할 
수 있도록 하려면 NAT 게이트웨이가 적합한 솔루션입니다. NAT 게이트웨이를 사용하면 
프라이빗 서브넷의 인스턴스가 인터넷이나 다른 AWS 서비스에 연결할 수 있지만 인터넷이 
해당 인스턴스와 연결을 시작하는 것은 방지됩니다. NAT 게이트웨이는 퍼블릭 서브넷에 
상주하며 짧은 대기 시간으로 높은 트래픽 처리량을 처리할 수 있습니다. NAT 게이트웨이는 
운영 오버헤드가 필요하지 않은 관리형 서비스이기도 합니다. 
Q550 
회사에서 AWS Key Management Service(AWS KMS) 키를 사용하여 AWS Lambda 환경 
변수를 암호화하고 있습니다. 솔루션 설계자는 환경 변수를 해독하고 사용하는 데 필요한 
권한이 있는지 확인해야 합니다. 
올바른 권한을 구현하기 위해 솔루션 설계자가 수행해야 하는 단계는 무엇입니까? (2 개 
선택) 
A. Lambda 리소스 정책에 AWS KMS 권한을 추가합니다. 
B. Lambda 실행 역할에 AWS KMS 권한을 추가합니다. 
C. Lambda 함수 정책에 AWS KMS 권한을 추가합니다. 
D. AWS KMS 키 정책에서 Lambda 실행 역할을 허용합니다. 
E. AWS KMS 키 정책에서 Lambda 리소스 정책을 허용합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/116979-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
B 와 D 는 정답입니다. Lambda 실행 역할에 환경 변수를 해독하고 사용할 수 있는 권한이 
있고 AWS KMS 키 정책에 따라 Lambda 실행 역할이 키를 사용할 수 있도록 허용하기 
때문입니다. Lambda 실행 역할은 AWS KMS 와 같은 AWS 리소스에 액세스할 수 있는 
권한을 Lambda 함수에 부여하는 IAM 역할입니다. AWS KMS 키 정책은 키에 대한 
액세스를 제어하는 리소스 기반 정책입니다. Lambda 실행 역할에 AWS KMS 권한을 
추가하고 AWS KMS 키 정책에서 Lambda 실행 역할을 허용함으로써 솔루션 아키텍트는 
환경 변수를 암호화하고 해독하기 위한 올바른 권한을 구현할 수 있습니다. 
Q551 
회사에 보고서를 생성하는 재무 응용 프로그램이 있습니다. 보고서 크기는 평균 50KB 이며 
Amazon S3 에 저장됩니다. 보고서는 생산 후 첫 주 동안 자주 액세스되며 몇 년 동안 
저장해야 합니다. 보고서는 6 시간 이내에 검색할 수 있어야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. S3 Standard 를 사용합니다. S3 수명 주기 규칙을 사용하여 7 일 후에 보고서를 S3 
Glacier 로 전환합니다. 
B. S3 Standard 를 사용합니다. S3 수명 주기 규칙을 사용하여 7 일 후에 보고서를 S3 
Standard-Infrequent Access(S3 Standard-IA)로 전환합니다. 
C. S3 Intelligent-Tiering 을 사용합니다. 보고서를 S3 Standard-Infrequent Access(S3 
Standard-IA) 및 S3 Glacier 로 전환하도록 S3 Intelligent-Tiering 을 구성합니다. 
D. S3 Standard 를 사용합니다. S3 수명 주기 규칙을 사용하여 7 일 후에 보고서를 S3 
Glacier Deep Archive 로 전환합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/116896-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
첫 주 동안 자주 액세스하고 수년간 보관해야 하는 보고서를 저장하고 검색하려면 S3 
Standard 와 S3 Glacier 가 적합한 솔루션입니다. S3 Standard 는 자주 액세스하는 데이터에 
대해 높은 내구성, 가용성 및 성능을 제공합니다. S3 Glacier 는 저렴한 비용으로 장기 
데이터 보관을 위한 안전하고 내구성 있는 스토리지를 제공합니다. S3 수명 주기 규칙을 
사용하면 7 일 후에 보고서를 S3 Standard 에서 S3 Glacier 로 전환할 수 있으므로 스토리지 
비용을 줄일 수 있습니다. S3 Glacier 는 6 시간 이내 검색도 지원합니다. 
Q552 
회사는 Amazon EC2 인스턴스의 비용을 최적화해야 합니다. 회사는 또한 2~3 개월마다 
EC2 인스턴스의 유형과 제품군을 변경해야 합니다. 
이러한 요구 사항을 충족하기 위해 회사는 무엇을 해야 합니까? 
A. 3 년 기간 동안 부분 선결제 예약 인스턴스를 구매합니다. 
B. 1 년 기간 동안 선결제 없는 컴퓨팅 절감 플랜을 구매합니다. 
C. 1 년 기간 동안 모든 선결제 예약 인스턴스를 구매합니다. 
D. 1 년 기간 동안 All Upfront EC2 Instance Savings Plan 을 구매합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/116897-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q553 
솔루션 설계자는 회사의 Amazon S3 버킷을 검토하여 개인 식별 정보(PII)를 검색해야 
합니다. 회사는 us-east-1 지역 및 us-west-2 지역에 PII 데이터를 저장합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 각 리전에서 Amazon Macie 를 구성합니다. Amazon S3 에 있는 데이터를 분석하는 
작업을 생성합니다. 
B. 모든 지역에 대해 AWS Security Hub 를 구성합니다. Amazon S3 에 있는 데이터를 
분석하는 AWS Config 규칙을 생성합니다. 
C. Amazon S3 에 있는 데이터를 분석하도록 Amazon Inspector 를 구성합니다. 
D. Amazon S3 에 있는 데이터를 분석하도록 Amazon GuardDuty 를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117206-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q554 
회사의 SAP 애플리케이션에는 온프레미스 환경에 백엔드 SQL Server 데이터베이스가 
있습니다. 이 회사는 온프레미스 애플리케이션과 데이터베이스 서버를 AWS 로 
마이그레이션하려고 합니다. 회사는 SAP 데이터베이스의 높은 요구 사항을 충족하는 
인스턴스 유형이 필요합니다. 온프레미스 성능 데이터에 따르면 SAP 애플리케이션과 
데이터베이스 모두 메모리 사용률이 높습니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 애플리케이션에 최적화된 컴퓨팅 인스턴스 제품군을 사용하십시오. 데이터베이스에 
메모리 최적화 인스턴스 제품군을 사용하십시오. 
B. 애플리케이션과 데이터베이스 모두에 스토리지 최적화 인스턴스 제품군을 사용하십시오. 
C. 애플리케이션과 데이터베이스 모두에 대해 메모리 최적화 인스턴스 제품군을 
사용하십시오. 
D. 애플리케이션에 고성능 컴퓨팅(HPC) 최적화 인스턴스 제품군을 사용합니다. 
데이터베이스에 메모리 최적화 인스턴스 제품군을 사용하십시오. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/117442-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 메모리 최적화 인스턴스: 이 인스턴스는 메모리에서 대규모 데이터 세트를 처리하는 
워크로드에 빠른 성능을 제공하도록 설계되었습니다. SAP 와 같은 고성능 데이터베이스와 
메모리 활용도가 높은 애플리케이션에 이상적입니다. 
* 높은 메모리 활용도: SAP 애플리케이션과 SQL Server 데이터베이스 모두 온프레미스 
성능 데이터에 따라 메모리 수요가 높습니다. 메모리 최적화 인스턴스는 필요한 메모리 
용량과 성능을 제공합니다. 
* 인스턴스 유형: 
* SAP 애플리케이션의 경우 메모리 최적화 인스턴스를 사용하면 애플리케이션이 높은 
워크로드를 효율적으로 처리할 수 있는 충분한 메모리를 확보할 수 있습니다. 
* SQL Server 데이터베이스의 경우 메모리 최적화 인스턴스는 높은 메모리 처리량으로 
최적의 데이터베이스 성능을 보장합니다. 
* 운영 효율성: 애플리케이션과 데이터베이스 모두에 동일한 인스턴스 제품군을 사용하면 
관리가 단순화되고 두 구성 요소 모두 성능 요구 사항을 충족할 수 있습니다. 
Q555 
회사는 퍼블릭 및 프라이빗 서브넷이 있는 VPC 에서 애플리케이션을 실행합니다. VPC 는 
여러 가용 영역에 걸쳐 확장됩니다. 애플리케이션은 프라이빗 서브넷의 Amazon EC2 
인스턴스에서 실행됩니다. 애플리케이션은 Amazon Simple Queue Service(Amazon SQS) 
대기열을 사용합니다. 
솔루션 설계자는 EC2 인스턴스와 SQS 대기열 간의 연결을 설정하기 위한 보안 솔루션을 
설계해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon SQS 용 인터페이스 VPC 엔드포인트를 구현합니다. 프라이빗 서브넷을 
사용하도록 엔드포인트를 구성합니다. 프라이빗 서브넷에 있는 EC2 인스턴스의 트래픽을 
허용하는 인바운드 액세스 규칙이 있는 보안 그룹을 엔드포인트에 추가합니다. 
B. Amazon SQS 용 인터페이스 VPC 엔드포인트를 구현합니다. 퍼블릭 서브넷을 사용하도록 
엔드포인트를 구성합니다. 프라이빗 서브넷에 있는 EC2 인스턴스의 액세스를 허용하는 
VPC 엔드포인트 정책을 인터페이스 엔드포인트에 연결합니다. 
C. Amazon SQS 용 인터페이스 VPC 엔드포인트를 구현합니다. 퍼블릭 서브넷을 사용하도록 
엔드포인트를 구성합니다. 지정된 VPC 엔드포인트의 요청만 허용하는 인터페이스 VPC 
엔드포인트에 Amazon SQS 액세스 정책을 연결합니다. 
D. Amazon SQS 용 게이트웨이 엔드포인트를 구현합니다. 프라이빗 서브넷에 NAT 
게이트웨이를 추가합니다. SQS 대기열에 대한 액세스를 허용하는 EC2 인스턴스에 IAM 
역할을 연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/116983-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q556 
솔루션 설계자는 AWS CloudFormation 템플릿을 사용하여 3 계층 웹 애플리케이션을 
배포합니다. 웹 애플리케이션은 웹 계층과 Amazon DynamoDB 테이블에서 사용자 
데이터를 저장하고 검색하는 애플리케이션 계층으로 구성됩니다. 웹 및 애플리케이션 
계층은 Amazon EC2 인스턴스에서 호스팅되며 데이터베이스 계층은 공개적으로 액세스할 
수 없습니다. 애플리케이션 EC2 인스턴스는 템플릿에서 API 자격 증명을 노출하지 않고 
DynamoDB 테이블에 액세스해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. DynamoDB 테이블을 읽을 IAM 역할을 생성합니다. 인스턴스 프로필을 참조하여 역할을 
애플리케이션 인스턴스와 연결합니다. 
B. DynamoDB 테이블에서 읽고 쓰는 데 필요한 권한이 있는 IAM 역할을 생성합니다. EC2 
인스턴스 프로필에 역할을 추가하고 인스턴스 프로필을 애플리케이션 인스턴스와 
연결합니다. 
C. AWS CloudFormation 템플릿의 파라미터 섹션을 사용하여 사용자가 DynamoDB 
테이블에서 읽고 쓰는 데 필요한 권한이 있는 이미 생성된 IAM 사용자의 액세스 및 비밀 
키를 입력하도록 합니다. 
D. DynamoDB 테이블에서 읽고 쓰는 데 필요한 권한이 있는 AWS CloudFormation 
템플릿에서 IAM 사용자를 생성합니다. GetAtt 기능을 사용하여 액세스 및 비밀 키를 
검색하고 사용자 데이터를 통해 애플리케이션 인스턴스에 전달합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/117434-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 애플리케이션 EC2 인스턴스는 템플릿에 API 자격 증명을 노출하지 않고도 
DynamoDB 테이블에 액세스할 수 있습니다. DynamoDB 테이블에서 읽고 쓰는 데 필요한 
권한이 있는 IAM 역할을 생성하고 이를 EC2 인스턴스 프로필에 추가하면 애플리케이션 
인스턴스는 AWS 에서 자동으로 교체하는 임시 보안 자격 증명을 사용할 수 있습니다. 이는 
EC2 인스턴스에서 AWS 리소스에 대한 액세스 권한을 부여하는 안전한 모범 사례 
방법입니다. 
Q557 
솔루션 설계자는 분석 애플리케이션을 관리합니다. 애플리케이션은 Amazon S3 버킷에 
대량의 반구조화된 데이터를 저장합니다. 솔루션 설계자는 병렬 데이터 처리를 사용하여 
데이터를 더 빠르게 처리하려고 합니다. 또한 솔루션 설계자는 Amazon Redshift 
데이터베이스에 저장된 정보를 사용하여 데이터를 보강하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Athena 를 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 
AWS Glue 를 사용하여 S3 데이터를 보강합니다. 
B. Amazon EMR 을 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 
Amazon EMR 을 사용하여 S3 데이터를 보강합니다. 
C. Amazon EMR 을 사용하여 S3 데이터를 처리합니다. 데이터를 보강할 수 있도록 Amazon 
Kinesis Data Streams 를 사용하여 S3 데이터를 Amazon Redshift 로 이동합니다. 
D. AWS Glue 를 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 AWS 
Lake Formation 을 사용하여 S3 데이터를 보강합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/117344-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q558 
회사에는 동일한 AWS 계정 내의 us-west-2 리전에 위치한 두 개의 VPC 가 있습니다. 
회사는 이러한 VPC 간의 네트워크 트래픽을 허용해야 합니다. 매월 VPC 간에 약 
500GB 의 데이터 전송이 발생합니다. 
이러한 VPC 를 연결하는 가장 비용 효율적인 솔루션은 무엇입니까? 
A. AWS Transit Gateway 를 구현하여 VPC 를 연결합니다. VPC 간 통신에 전송 게이트웨이를 
사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다. 
B. VPC 간에 AWS Site-to-Site VPN 터널을 구현합니다. VPC 간 통신에 VPN 터널을 
사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다. 
C. VPC 간에 VPC 피어링 연결을 설정합니다. VPC 간 통신에 VPC 피어링 연결을 
사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다. 
D. VPC 간에 1GB AWS Direct Connect 연결을 설정합니다. VPC 간 통신에 Direct Connect 
연결을 사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/117053-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
동일한 AWS 계정 내 동일한 리전에 있는 두 개의 VPC 를 연결하려면 VPC 피어링이 가장 
비용 효과적인 솔루션입니다. VPC 피어링을 사용하면 게이트웨이, VPN 연결 또는 AWS 
Transit Gateway 없이도 VPC 간의 직접 네트워크 트래픽을 허용할 수 있습니다. 또한 VPC 
피어링은 VPC 간 데이터 전송에 대한 추가 요금을 발생시키지 않습니다. 
Q559 
회사는 서로 다른 제품군에 대해 AWS 에서 여러 애플리케이션을 호스팅합니다. 
애플리케이션은 Amazon EC2 인스턴스 및 Application Load Balancer 를 비롯한 다양한 
컴퓨팅 리소스를 사용합니다. 애플리케이션은 여러 AWS 리전의 AWS Organizations 에서 
동일한 조직의 다른 AWS 계정에서 실행됩니다. 각 제품군의 팀은 개별 계정의 각 컴퓨팅 
리소스에 태그를 지정했습니다. 
회사는 조직의 통합 청구 기능에서 각 제품군의 비용에 대한 자세한 정보를 원합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. AWS 결제 콘솔에서 특정 AWS 생성 태그를 선택합니다. 
B. AWS 결제 콘솔에서 특정 사용자 정의 태그를 선택합니다. 
C. AWS 리소스 그룹 콘솔에서 특정 사용자 정의 태그를 선택합니다. 
D. 각 AWS 계정에서 선택한 태그를 활성화합니다. 
E. 조직 마스터 계정에서 선택한 태그를 활성화합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/117403-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
사용자 정의 태그는 AWS 리소스에 적용하여 분류하고 추적할 수 있는 키-값 쌍입니다. 
사용자 정의 태그를 사용하여 비용을 할당하고 AWS 결제 콘솔에서 세부 결제 보고서를 
생성할 수도 있습니다. 비용 할당을 위해 사용자 정의 태그를 사용하려면 조직의 모든 회원 
계정에 대한 모든 권한을 갖는 루트 계정인 조직 마스터 계정에서 태그를 활성화해야 
합니다. 활성화되면 사용자 정의 태그가 비용 할당 보고서의 열로 표시되며 제품 라인별로 
비용을 필터링하고 그룹화하는 데 사용할 수 있습니다. 이 솔루션은 기존 태깅 전략을 
활용하고 코드 개발이나 수동 개입이 필요하지 않으므로 최소한의 운영 오버헤드로 요구 
사항을 충족합니다. 
Q560 
회사의 솔루션 아키텍트가 AWS Organizations 를 사용하는 AWS 다중 계정 솔루션을 
설계하고 있습니다. 솔루션 설계자는 회사의 계정을 OU(조직 단위)로 구성했습니다. 
솔루션 설계자는 OU 계층 구조에 대한 모든 변경 사항을 식별할 솔루션이 필요합니다. 
솔루션은 또한 회사의 운영 팀에 변경 사항을 알려야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Control Tower 를 사용하여 AWS 계정을 프로비저닝합니다. 계정 드리프트 알림을 
사용하여 OU 계층 구조의 변경 사항을 식별합니다. 
B. AWS Control Tower 를 사용하여 AWS 계정을 프로비저닝합니다. AWS Config 집계 
규칙을 사용하여 OU 계층 구조의 변경 사항을 식별합니다. 
C. AWS Service Catalog 를 사용하여 조직에서 계정을 생성합니다. AWS CloudTrail 조직 
추적을 사용하여 OU 계층 구조의 변경 사항을 식별합니다. 
D. AWS CloudFormation 템플릿을 사용하여 조직에서 계정을 생성합니다. 스택에서 
드리프트 감지 작업을 사용하여 OU 계층 구조에 대한 변경 사항을 식별합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117021-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q561 
회사의 웹 사이트는 매일 수백만 건의 요청을 처리하며 요청 수는 계속 증가하고 있습니다. 
솔루션 설계자는 웹 애플리케이션의 응답 시간을 개선해야 합니다. 솔루션 설계자는 
애플리케이션이 Amazon DynamoDB 테이블에서 제품 세부 정보를 검색할 때 지연 시간을 
줄여야 한다고 결정합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. DynamoDB Accelerator(DAX) 클러스터를 설정합니다. DAX 를 통해 모든 읽기 요청을 
라우팅합니다. 
B. DynamoDB 테이블과 웹 애플리케이션 사이에 Redis 용 Amazon ElastiCache 를 
설정합니다. Redis 를 통해 모든 읽기 요청을 라우팅합니다. 
C. DynamoDB 테이블과 웹 애플리케이션 사이에 Amazon ElastiCache for Memcached 를 
설정합니다. Memcached 를 통해 모든 읽기 요청을 라우팅합니다. 
D. 테이블에 Amazon DynamoDB 스트림을 설정하고 AWS Lambda 가 테이블에서 읽고 
Amazon ElastiCache 를 채우도록 합니다. ElastiCache 를 통해 모든 읽기 요청을 
라우팅합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117022-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 Amazon DynamoDB 테이블에서 제품 세부 정보를 검색할 때 웹 
애플리케이션의 응답 시간을 개선하고 지연 시간을 줄일 수 있습니다. DynamoDB 
Accelerator(DAX) 클러스터를 설정함으로써 회사는 최대 10 배의 성능 향상을 제공하는 
DynamoDB 용 완전 관리형 고가용성 인 메모리 캐시를 사용할 수 있습니다. 모든 읽기 
요청을 DAX 를 통해 라우팅함으로써 회사는 DynamoDB 테이블에 대한 읽기 작업 수를 
줄이고 사용자 경험을 향상시킬 수 있습니다. 
Q562 
솔루션 설계자는 VPC 의 Amazon EC2 인스턴스에서 Amazon DynamoDB 에 대한 API 
호출이 인터넷을 통해 이동하지 않도록 해야 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? (2 개 
선택) 
A. 엔드포인트에 대한 라우팅 테이블 항목을 생성합니다. 
B. DynamoDB 용 게이트웨이 엔드포인트를 생성합니다. 
C. Amazon EC2 용 인터페이스 엔드포인트를 생성합니다. 
D. VPC 의 각 서브넷에서 끝점에 대한 탄력적 네트워크 인터페이스를 만듭니다. 
E. 엔드포인트의 보안 그룹에 보안 그룹 항목을 생성하여 액세스를 제공합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/117251-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q563 
회사는 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터와 온프레미스 
Kubernetes 클러스터 모두에서 애플리케이션을 실행합니다. 회사는 중앙 위치에서 모든 
클러스터와 워크로드를 보기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon CloudWatch Container Insights 를 사용하여 클러스터 정보를 수집하고 
그룹화합니다. 
B. Amazon EKS 커넥터를 사용하여 모든 Kubernetes 클러스터를 등록하고 연결합니다. 
C. AWS Systems Manager 를 사용하여 클러스터 정보를 수집하고 봅니다. 
D. Amazon EKS Anywhere 를 기본 클러스터로 사용하여 기본 Kubernetes 명령으로 다른 
클러스터를 봅니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/117023-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q564 
회사에서 전자상거래 애플리케이션을 구축 중이며 중요한 고객 정보를 저장해야 합니다. 
회사는 고객이 웹사이트에서 구매 거래를 완료할 수 있는 기능을 제공해야 합니다. 회사는 
또한 민감한 고객 데이터를 데이터베이스 관리자로부터 보호해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Elastic Block Store(Amazon EBS) 볼륨에 민감한 데이터를 저장합니다. EBS 
암호화를 사용하여 데이터를 암호화합니다. IAM 인스턴스 역할을 사용하여 액세스를 
제한합니다. 
B. MySQL 용 Amazon RDS 에 민감한 데이터를 저장합니다. AWS Key Management 
Service(AWS KMS) 클라이언트 측 암호화를 사용하여 데이터를 암호화합니다. 
C. 민감한 데이터를 Amazon S3 에 저장합니다. AWS Key Management Service(AWS KMS) 
서버 측 암호화를 사용하여 데이터를 암호화합니다. S3 버킷 정책을 사용하여 액세스를 
제한하십시오. 
D. 민감한 데이터를 Windows Server 용 Amazon FSx 에 저장합니다. 응용 프로그램 서버에 
파일 공유를 탑재합니다. Windows 파일 권한을 사용하여 액세스를 제한하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/117024-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 중요한 고객 정보를 관리형 AWS 서비스에 저장하고 고객이 웹 
사이트에서 구매 거래를 완료할 수 있는 기능을 제공할 수 있습니다. AWS Key Management 
Service(AWS KMS) 클라이언트 측 암호화를 사용하여 회사는 데이터를 MySQL 용 Amazon 
RDS 로 보내기 전에 암호화할 수 있습니다. 애플리케이션만이 암호화 키에 액세스할 수 
있으므로 이를 통해 데이터베이스 관리자로부터도 민감한 고객 데이터가 보호됩니다. 
Q565 
회사에는 트랜잭션 데이터를 처리하는 온프레미스 MySQL 데이터베이스가 있습니다. 
회사는 데이터베이스를 AWS 클라우드로 마이그레이션하고 있습니다. 마이그레이션된 
데이터베이스는 데이터베이스를 사용하는 회사의 애플리케이션과 호환성을 유지해야 합니다. 
마이그레이션된 데이터베이스는 또한 수요가 증가하는 기간 동안 자동으로 확장되어야 
합니다. 
이러한 요구 사항을 충족하는 마이그레이션 솔루션은 무엇입니까? 
A. 기본 MySQL 도구를 사용하여 데이터베이스를 MySQL 용 Amazon RDS 로 
마이그레이션합니다. 탄력적 스토리지 확장을 구성합니다. 
B. mysqldump 유틸리티를 사용하여 데이터베이스를 Amazon Redshift 로 
마이그레이션합니다. Amazon Redshift 클러스터에 대해 Auto Scaling 을 켭니다. 
C. AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon 
Aurora 로 마이그레이션합니다. Aurora Auto Scaling 을 켭니다. 
D. AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon 
DynamoDB 로 마이그레이션합니다. Auto Scaling 정책을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/117025-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
호환성과 확장성을 갖춘 MySQL 데이터베이스를 AWS 로 마이그레이션하려면 Amazon 
Aurora 가 적합한 옵션입니다. Aurora 는 MySQL 과 호환되며 Aurora Auto Scaling 을 통해 
자동으로 확장할 수 있습니다. AWS Database Migration Service(AWS DMS)를 사용하면 가동 
중지 시간을 최소화하면서 온프레미스에서 Aurora 로 데이터베이스를 마이그레이션할 수 
있습니다. 
Q566 
회사는 2 개의 가용 영역에 걸쳐 VPC 에서 여러 Amazon EC2 Linux 인스턴스를 실행합니다. 
인스턴스는 계층적 디렉터리 구조를 사용하는 애플리케이션을 호스팅합니다. 
애플리케이션은 공유 스토리지에서 동시에 빠르게 읽고 쓸 수 있어야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon S3 버킷을 생성합니다. VPC 의 모든 EC2 인스턴스에서 액세스를 허용합니다. 
B. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 각 EC2 
인스턴스에서 EFS 파일 시스템을 탑재합니다. 
C. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 
시스템을 생성합니다. EBS 볼륨을 모든 EC2 인스턴스에 연결합니다. 
D. 각 EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 
시스템을 만듭니다. 여러 EC2 인스턴스 간에 EBS 볼륨을 동기화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/116902-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 EC2 인스턴스는 두 가용 영역에 걸쳐 공유 스토리지에 동시에 빠르게 읽고 쓸 
수 있습니다. Amazon EFS 는 여러 EC2 인스턴스에서 탑재할 수 있는 확장 가능하고 
탄력적이며 가용성이 높은 파일 시스템을 제공합니다. Amazon EFS 는 높은 수준의 
처리량과 IOPS, 일관되게 낮은 지연 시간을 지원합니다. Amazon EFS 는 또한 높은 수준의 
동시성을 지원하는 NFSv4 잠금 업그레이드 및 다운그레이드를 지원합니다. 
Q567 
솔루션 설계자는 건물 내 비즈니스 테넌트의 시간당 에너지 소비량을 저장할 워크로드를 
설계하고 있습니다. 센서는 각 테넌트의 사용량을 합산하는 HTTP 요청을 통해 
데이터베이스에 공급합니다. 솔루션 설계자는 가능한 경우 관리 서비스를 사용해야 합니다. 
워크로드는 솔루션 설계자가 독립적인 구성 요소를 추가함에 따라 향후 더 많은 기능을 
받게 됩니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Lambda 함수와 함께 Amazon API Gateway 를 사용하여 센서에서 데이터를 
수신하고, 데이터를 처리하고, Amazon DynamoDB 테이블에 데이터를 저장합니다. 
B. Amazon EC2 인스턴스의 Auto Scaling 그룹에서 지원하는 Elastic Load Balancer 를 
사용하여 센서에서 데이터를 수신하고 처리합니다. Amazon S3 버킷을 사용하여 처리된 
데이터를 저장합니다. 
C. AWS Lambda 함수와 함께 Amazon API Gateway 를 사용하여 센서에서 데이터를 
수신하고, 데이터를 처리하고, Amazon EC2 인스턴스의 Microsoft SQL Server Express 
데이터베이스에 데이터를 저장합니다. 
D. Amazon EC2 인스턴스의 Auto Scaling 그룹에서 지원하는 Elastic Load Balancer 를 
사용하여 센서에서 데이터를 수신하고 처리합니다. Amazon Elastic File System(Amazon EFS) 
공유 파일 시스템을 사용하여 처리된 데이터를 저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117026-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Lambda 에서 이벤트 기반 프로그래밍 모델을 사용하고 운영 오버헤드를 줄이려면 
Amazon API Gateway 와 Amazon DynamoDB 가 적합한 솔루션입니다. Amazon API 
Gateway 는 센서로부터 데이터를 수신하고 AWS Lambda 함수를 호출하여 데이터를 처리할 
수 있습니다. AWS Lambda 는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행하고 
수신 요청에 따라 자동으로 확장할 수 있습니다. Amazon DynamoDB 는 일관된 성능으로 
모든 양의 데이터를 처리할 수 있는 빠르고 유연한 NoSQL 데이터베이스에 데이터를 
저장할 수 있습니다. 
Q568 
솔루션 설계자는 엔지니어링 도면을 저장하고 보는 데 사용되는 새 웹 애플리케이션의 
스토리지 아키텍처를 설계하고 있습니다. 모든 애플리케이션 구성 요소는 AWS 인프라에 
배포됩니다. 
응용 프로그램 디자인은 사용자가 엔지니어링 도면이 로드될 때까지 기다리는 시간을 
최소화하기 위해 캐싱을 지원해야 합니다. 애플리케이션은 페타바이트의 데이터를 저장할 
수 있어야 합니다. 
솔루션 설계자는 어떤 스토리지 및 캐싱 조합을 사용해야 합니까? 
A. Amazon CloudFront 를 사용하는 Amazon S3 
B. Amazon ElastiCache 를 사용하는 Amazon S3 Glacier 
C. Amazon CloudFront 를 사용하는 Amazon Elastic Block Store(Amazon EBS) 볼륨 
D. Amazon ElastiCache 를 사용하는 AWS Storage Gateway 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117027-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
캐싱 지원을 통해 엔지니어링 도면을 저장하고 보려면 Amazon S3 및 Amazon 
CloudFront 가 적합한 솔루션입니다. Amazon S3 는 높은 내구성, 가용성 및 성능으로 모든 
양의 데이터를 저장할 수 있습니다. Amazon CloudFront 는 엔지니어링 도면을 사용자에게 
더 가까운 엣지 로케이션에 배포하여 지연 시간을 줄이고 사용자 경험을 향상시킬 수 
있습니다. Amazon CloudFront 는 엔지니어링 도면을 엣지 로케이션에 캐시할 수도 있으므로 
사용자가 도면이 로드될 때까지 기다리는 시간을 최소화할 수 있습니다. 
Q569 
Amazon EventBridge 규칙은 타사 API 를 대상으로 합니다. 타사 API 가 수신 트래픽을 
수신하지 않았습니다. 솔루션 설계자는 규칙 조건이 충족되고 있는지 여부와 규칙의 대상이 
호출되고 있는지 확인해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS/Events 의 네임스페이스에서 Amazon CloudWatch 의 지표를 확인하십시오. 
B. Amazon Simple Queue Service(Amazon SQS) 데드 레터 대기열의 이벤트를 검토합니다. 
C. Amazon CloudWatch Logs 에서 이벤트를 확인합니다. 
D. EventBridge 이벤트에 대한 AWS CloudTrail 의 추적을 확인합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117377-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q570 
회사에는 매주 금요일 저녁에 실행되는 대규모 워크로드가 있습니다. 워크로드는 
us-east-1 리전의 두 가용 영역에 있는 Amazon EC2 인스턴스에서 실행됩니다. 
일반적으로 회사는 항상 두 개 이상의 인스턴스를 실행하지 않아야 합니다. 그러나 회사는 
정기적으로 반복되는 증가된 워크로드를 처리하기 위해 금요일마다 최대 6 개의 인스턴스로 
확장하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon EventBridge 에서 미리 알림을 생성하여 인스턴스를 확장하십시오. 
B. 예약된 작업이 있는 Auto Scaling 그룹을 생성합니다. 
C. 수동 조정을 사용하는 Auto Scaling 그룹을 생성합니다. 
D. 자동 조정을 사용하는 Auto Scaling 그룹을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/116903-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Auto Scaling 그룹은 유사한 특성을 공유하고 수요에 따라 자동으로 확장 또는 축소될 수 
있는 EC2 인스턴스 모음입니다. Auto Scaling 그룹에는 특정 시간에 특정 크기로 
확장하도록 그룹에 지시하는 구성인 예약된 작업이 있을 수 있습니다. 이러한 방식으로 
회사는 매주 금요일 저녁 최대 6 개의 인스턴스로 확장하여 증가된 워크로드를 처리하고, 
다른 시간에는 2 개의 인스턴스로 축소하여 비용을 절감할 수 있습니다. 이 솔루션은 수동 
개입이나 사용자 지정 스크립트가 필요하지 않으므로 최소한의 운영 오버헤드로 요구 
사항을 충족합니다. 
Q571 
회사에서 REST API 를 만들고 있습니다. 회사에는 TLS 사용에 대한 엄격한 요구 사항이 
있습니다. 회사는 API 엔드포인트에 TLSv1.3 을 요구합니다. 또한 회사는 TLS 인증서에 
서명하기 위해 특정 공개 타사 인증 기관(CA)을 요구합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 로컬 시스템을 사용하여 타사 CI 가 서명한 인증서를 생성하고 인증서를 AWS Certificate 
Manager(ACM)로 가져옵니다. 사용자 지정 도메인을 사용하여 Amazon API Gateway 에서 
HTTP API 를 생성합니다. 인증서를 사용하도록 사용자 지정 도메인을 구성합니다. 
B. 타사 CA 가 서명한 AWS Certificate Manager(ACM)에서 인증서를 생성합니다. 사용자 
지정 도메인을 사용하여 Amazon API Gateway 에서 HTTP API 를 생성합니다. 인증서를 
사용하도록 사용자 지정 도메인을 구성합니다. 
C. AWS Certificate Manager(ACM)를 사용하여 타사 CA 에서 서명한 인증서를 생성합니다. 
인증서를 AWS Certificate Manager(ACM)로 가져옵니다. Lambda 함수 URL 을 사용하여 
AWS Lambda 함수를 생성합니다. 인증서를 사용하도록 Lambda 함수 URL 을 구성합니다. 
D. 타사 CA 에서 서명한 AWS Certificate Manager(ACM)에서 인증서를 생성합니다. Lambda 
함수 URL 을 사용하여 AWS Lambda 함수를 생성합니다. 인증서를 사용하도록 Lambda 
함수 URL 을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/116904-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q572 
회사는 AWS 에서 애플리케이션을 실행합니다. 애플리케이션이 일관되지 않은 사용량을 
수신합니다. 애플리케이션은 AWS Direct Connect 를 사용하여 온프레미스 MySQL 호환 
데이터베이스에 연결합니다. 온프레미스 데이터베이스는 지속적으로 최소 2GiB 의 메모리를 
사용합니다. 
회사는 온프레미스 데이터베이스를 관리형 AWS 서비스로 마이그레이션하려고 합니다. 
회사는 자동 확장 기능을 사용하여 예기치 않은 작업 부하 증가를 관리하려고 합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 기본 읽기 및 쓰기 용량 설정으로 Amazon DynamoDB 데이터베이스를 
프로비저닝합니다. 
B. 최소 용량이 1 Aurora 용량 단위(ACU)인 Amazon Aurora 데이터베이스를 
프로비저닝합니다. 
C. 최소 용량이 1 Aurora 용량 단위(ACU)인 Amazon Aurora Serverless v2 데이터베이스를 
프로비저닝합니다. 
D. 2GiB 의 메모리로 Amazon RDS for MySQL 데이터베이스를 프로비저닝합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/117029-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 온프레미스 데이터베이스를 Auto Scaling 기능을 지원하고 관리 
오버헤드가 가장 적은 관리형 AWS 서비스로 마이그레이션할 수 있습니다. Amazon Aurora 
Serverless v2 는 워크로드 수요에 따라 컴퓨팅 용량을 자동으로 확장하는 Amazon Aurora 의 
구성입니다. 단 몇 초 만에 수백 건에서 수십만 건의 트랜잭션을 확장할 수 있습니다. 
Amazon Aurora Serverless v2 는 MySQL 호환 데이터베이스와 AWS Direct Connect 연결도 
지원합니다. 
Q573 
회사에서 AWS Lambda 와 함께 이벤트 기반 프로그래밍 모델을 사용하려고 합니다. 회사는 
Java 11 에서 실행되는 Lambda 함수의 시작 지연 시간을 줄이려고 합니다. 회사는 
애플리케이션에 대한 엄격한 지연 시간 요구 사항이 없습니다. 이 회사는 함수가 확장될 때 
콜드 스타트와 이상치 대기 시간을 줄이려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Lambda 프로비저닝된 동시성을 구성합니다. 
B. Lambda 함수의 제한 시간을 늘립니다. 
C. Lambda 함수의 메모리를 늘립니다. 
D. Lambda SnapStart 를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/116925-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Java 11 에서 실행되는 Lambda 함수의 시작 지연 시간을 줄이기 위해 Lambda 
SnapStart 가 적합한 솔루션입니다. Lambda SnapStart 는 Java 11 기능에 대한 더 빠른 콜드 
스타트와 더 낮은 이상치 지연 시간을 지원하는 기능입니다. Lambda SnapStart 는 사전 
초기화된 JVM(Java Virtual Machine)을 사용하여 기능을 실행하므로 초기화 시간과 메모리 
공간이 줄어듭니다. Lambda SnapStart 에는 추가 비용이 발생하지 않습니다. 
Q574 
금융 서비스 회사는 Amazon RDS for MySQL 데이터베이스를 사용하는 새로운 
애플리케이션을 출시했습니다. 회사는 응용 프로그램을 사용하여 주식 시장 추세를 
추적합니다. 회사는 매주 말 2 시간 동안만 애플리케이션을 작동하면 됩니다. 회사는 
데이터베이스 실행 비용을 최적화해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 기존 RDS for MySQL 데이터베이스를 Aurora Serverless v2 MySQL 데이터베이스 
클러스터로 마이그레이션합니다. 
B. 기존 RDS for MySQL 데이터베이스를 Aurora MySQL 데이터베이스 클러스터로 
마이그레이션합니다. 
C. 기존 RDS for MySQL 데이터베이스를 MySQL 을 실행하는 Amazon EC2 인스턴스로 
마이그레이션합니다. EC2 인스턴스에 대한 인스턴스 예약을 구매합니다. 
D. 기존 RDS for MySQL 데이터베이스를 MySQL 컨테이너 이미지를 사용하여 작업을 
실행하는 Amazon Elastic Container Service(Amazon ECS) 클러스터로 마이그레이션합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117272-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q575 
회사는 AWS 리전의 Application Load Balancer 뒤에 있는 Amazon Elastic Kubernetes 
Service(Amazon EKS)에 애플리케이션을 배포합니다. 애플리케이션은 PostgreSQL 
데이터베이스 엔진에 데이터를 저장해야 합니다. 회사는 데이터베이스의 데이터가 가용성이 
높기를 원합니다. 회사는 또한 읽기 워크로드를 위한 증가된 용량이 필요합니다. 
이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 전역 테이블로 구성된 Amazon DynamoDB 데이터베이스 테이블을 생성합니다. 
B. 다중 AZ 배포로 Amazon RDS 데이터베이스를 생성합니다. 
C. 다중 AZ DB 클러스터 배포로 Amazon RDS 데이터베이스를 생성합니다. 
D. 리전 간 읽기 전용 복제본으로 구성된 Amazon RDS 데이터베이스를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/116969-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q576 
회사는 Amazon API Gateway 및 AWS Lambda 를 사용하여 AWS 에서 RESTful 서버리스 웹 
애플리케이션을 구축하고 있습니다. 이 웹 애플리케이션의 사용자는 지리적으로 분산되며 
회사는 이러한 사용자에 대한 API 요청 대기 시간을 줄이려고 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 유형의 엔드포인트를 사용해야 
합니까? 
A. 프라이빗 엔드포인트 
B. 지역 엔드포인트 
C. 인터페이스 VPC 엔드포인트 
D. 엣지 최적화 엔드포인트 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/116906-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
엣지 최적화 API 엔드포인트는 API 요청을 가장 가까운 CloudFront POP(Point of 
Presence)로 라우팅하므로 지리적으로 분산된 클라이언트에 가장 적합합니다. 이렇게 하면 
대기 시간이 줄어들고 API 성능이 향상됩니다. 엣지 최적화 엔드포인트는 API Gateway 
REST API 의 기본 유형입니다. 
지역 API 엔드포인트는 API와 동일한 지역에 있는 클라이언트를 위한 것이며 CloudFront를 
사용하여 요청을 라우팅하지 않습니다. 프라이빗 API 엔드포인트는 인터페이스 VPC 
엔드포인트를 사용하여 VPC 에서만 액세스할 수 있는 API 엔드포인트입니다. 지역 또는 
개인 끝점은 지리적으로 분산된 사용자의 대기 시간을 줄이는 요구 사항을 충족하지 
않습니다. 
Q577 
회사는 Amazon CloudFront 배포를 사용하여 웹 사이트의 콘텐츠 페이지를 제공합니다. 
회사는 고객이 회사 웹 사이트에 액세스할 때 TLS 인증서를 사용하도록 해야 합니다. 
회사는 TLS 인증서의 생성 및 갱신을 자동화하려고 합니다. 
이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? 
A. CloudFront 보안 정책을 사용하여 인증서를 생성합니다. 
B. CloudFront 원본 액세스 제어(OAC)를 사용하여 인증서를 생성합니다. 
C. AWS Certificate Manager(ACM)를 사용하여 인증서를 생성합니다. 도메인에 대해 DNS 
검증을 사용하십시오. 
D. AWS Certificate Manager(ACM)를 사용하여 인증서를 생성합니다. 도메인에 대한 이메일 
유효성(검증) 검사를 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/117037-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q578 
한 회사에서 Amazon DynamoDB 를 데이터베이스 계층으로 사용하는 서버리스 
애플리케이션을 배포했습니다. 응용 프로그램의 사용자가 크게 증가했습니다. 이 회사는 
데이터베이스 응답 시간을 밀리초에서 마이크로초로 개선하고 데이터베이스에 대한 요청을 
캐시하기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. DynamoDB 가속기(DAX)를 사용합니다. 
B. 데이터베이스를 Amazon Redshift 로 마이그레이션합니다. 
C. 데이터베이스를 Amazon RDS 로 마이그레이션합니다. 
D. Redis 용 Amazon ElastiCache 를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/117038-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q579 
회사에서 PostgreSQL 용 Amazon RDS 를 사용하는 애플리케이션을 실행합니다. 
애플리케이션은 평일 업무 시간에만 트래픽을 수신합니다. 회사는 이 사용량을 기반으로 
비용을 최적화하고 운영 오버헤드를 줄이려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS 의 인스턴스 스케줄러를 사용하여 시작 및 중지 일정을 구성하십시오. 
B. 자동 백업을 끕니다. 데이터베이스의 매주 수동 스냅샷을 생성합니다. 
C. 최소 CPU 사용률을 기준으로 데이터베이스를 시작하고 중지하는 사용자 지정 AWS 
Lambda 함수를 생성합니다. 
D. 모든 Upfront 예약 DB 인스턴스를 구매합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/116924-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS 솔루션의 인스턴스 스케줄러는 Amazon Elastic Compute Cloud(Amazon EC2) 및 
Amazon Relational Database Service(Amazon RDS) 인스턴스의 시작 및 중지를 
자동화합니다. 이 솔루션은 사용하지 않는 리소스를 중지하고 필요할 때 시작하여 운영 
비용을 절감하는 데 도움이 됩니다 1. 이 솔루션을 사용하면 명령줄 인터페이스(CLI) 또는 
SSM 유지 관리 기간을 사용하여 맞춤형 일정과 기간을 정의할 수 있습니다. 선결제 없음, 
부분 선결제, 전체 선결제 등 예약 DB 인스턴스에 대한 다양한 결제 옵션 중에서 선택할 
수도 있습니다. 
참고: 
https://aws.amazon.com/ko/solutions/implementations/instance-scheduler-on-aws/?nc1
=h_ls 
Q580 
회사는 로컬로 연결된 스토리지를 사용하여 온프레미스에서 대기 시간에 민감한 
애플리케이션을 실행합니다. 이 회사는 애플리케이션을 AWS 클라우드로 옮기기 위해 
리프트 앤 시프트 방식을 사용하고 있습니다. 회사는 애플리케이션 아키텍처를 변경하기를 
원하지 않습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon EC2 인스턴스로 Auto Scaling 그룹을 구성합니다. Amazon FSx for Lustre 파일 
시스템을 사용하여 애플리케이션을 실행합니다. 
B. Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Amazon Elastic Block 
Store(Amazon EBS) GP2 볼륨을 사용하여 애플리케이션을 실행합니다. 
C. Amazon EC2 인스턴스로 Auto Scaling 그룹을 구성합니다. OpenZFS 파일 시스템용 
Amazon FSx 를 사용하여 애플리케이션을 실행합니다. 
D. Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Amazon Elastic Block 
Store(Amazon EBS) GP3 볼륨을 사용하여 애플리케이션을 실행합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/117663-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q581 
회사는 Amazon EC2 인스턴스에서 상태 저장 프로덕션 애플리케이션을 실행합니다. 
애플리케이션을 항상 실행하려면 최소 2 개의 EC2 인스턴스가 필요합니다. 
솔루션 설계자는 응용 프로그램을 위한 고가용성 및 내결함성 아키텍처를 설계해야 합니다. 
솔루션 설계자는 EC2 인스턴스의 Auto Scaling 그룹을 생성합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자가 수행해야 하는 추가 단계는 
무엇입니까? 
A. Auto Scaling 그룹의 최소 용량을 2 로 설정합니다. 하나의 가용 영역에 하나의 온디맨드 
인스턴스를 배포하고 두 번째 가용 영역에 하나의 온디맨드 인스턴스를 배포합니다. 
B. Auto Scaling 그룹의 최소 용량을 4 개로 설정합니다. 하나의 가용 영역에 2 개의 
온디맨드 인스턴스를 배포하고 두 번째 가용 영역에 2 개의 온디맨드 인스턴스를 
배포합니다. 
C. Auto Scaling 그룹의 최소 용량을 2 로 설정합니다. 하나의 가용 영역에 4 개의 스팟 
인스턴스를 배포합니다. 
D. Auto Scaling 그룹의 최소 용량을 4 로 설정합니다. 하나의 가용 영역에 2 개의 온디맨드 
인스턴스를 배포하고 두 번째 가용 영역에 2 개의 스팟 인스턴스를 배포합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/116968-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q582 
전자상거래 회사는 Amazon Route 53 을 DNS 공급자로 사용합니다. 이 회사는 온프레미스 
및 AWS 클라우드에서 웹 사이트를 호스팅합니다. 회사의 온프레미스 데이터 센터는 
us-west-1 지역 근처에 있습니다. 회사는 eu-central-1 지역을 사용하여 웹사이트를 
호스팅합니다. 회사는 웹사이트 로딩 시간을 최대한 최소화하고자 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 지리적 위치 라우팅 정책을 설정합니다. us-west-1 근처에 있는 트래픽을 온프레미스 
데이터 센터로 보냅니다. eu-central-1 근처에 있는 트래픽을 eu-central-1 로 보냅니다. 
B. eu-central-1 근처에 있는 모든 트래픽을 eu-central-1 로 라우팅하고 온프레미스 
데이터 센터 근처에 있는 모든 트래픽을 온프레미스 데이터 센터로 라우팅하는 간단한 
라우팅 정책을 설정합니다. 
C. 레이턴시 라우팅 정책을 설정합니다. 정책을 us-west-1 과 연결합니다. 
D. 가중치 기반 라우팅 정책을 설정합니다. eu-central-1 과 온프레미스 데이터 센터 간에 
트래픽을 균등하게 분할합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/118597-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q583 
회사는 물리적 테이프에 5PB 의 아카이빙된 데이터를 가지고 있습니다. 회사는 규정 준수를 
위해 테이프의 데이터를 10 년 더 보존해야 합니다. 회사는 향후 6 개월 내에 AWS 로 
마이그레이션하기를 원합니다. 테이프를 저장하는 데이터 센터에는 1Gbps 업링크 인터넷 
연결이 있습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 온프레미스에서 테이프의 데이터를 읽습니다. 로컬 NFS 스토리지에 데이터를 
준비합니다. AWS DataSync 를 사용하여 데이터를 Amazon S3 Glacier Flexible Retrieval 로 
마이그레이션합니다. 
B. 온프레미스 백업 애플리케이션을 사용하여 테이프에서 데이터를 읽고 Amazon S3 
Glacier Deep Archive 에 직접 씁니다. 
C. 테이프 게이트웨이가 있는 여러 AWS Snowball 디바이스를 주문합니다. Snowball 의 
가상 테이프에 물리적 테이프를 복사합니다. Snowball 디바이스를 AWS 로 배송합니다. 수명 
주기 정책을 생성하여 테이프를 Amazon S3 Glacier Deep Archive 로 이동합니다. 
D. 온프레미스 테이프 게이트웨이를 구성합니다. AWS 클라우드에서 가상 테이프를 
생성합니다. 백업 소프트웨어를 사용하여 물리적 테이프를 가상 테이프에 복사합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/117215-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q584 
한 회사에서 대량의 데이터를 병렬로 처리하는 애플리케이션을 배포하고 있습니다. 회사는 
워크로드에 Amazon EC2 인스턴스를 사용할 계획입니다. 노드 그룹이 동일한 기본 
하드웨어를 공유하지 못하도록 네트워크 아키텍처를 구성할 수 있어야 합니다. 
이러한 요구 사항을 충족하는 네트워킹 솔루션은 무엇입니까? 
A. 분산 배치 그룹에서 EC2 인스턴스를 실행합니다. 
B. EC2 인스턴스를 별도의 계정으로 그룹화합니다. 
C. 전용 테넌시로 EC2 인스턴스를 구성합니다. 
D. 공유 테넌시로 EC2 인스턴스를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/119485-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 대량의 데이터를 병렬로 처리하고 노드 그룹이 동일한 기본 하드웨어를 
공유하는 것을 방지하는 애플리케이션을 배포할 수 있습니다. 분산 배치 그룹에서 EC2 
인스턴스를 실행함으로써 회사는 서로 다른 기본 하드웨어에서 소수의 인스턴스를 시작하여 
상관 오류를 줄일 수 있습니다. 분산 배치 그룹은 각 인스턴스가 랙 수준에서 서로 
격리되도록 보장합니다. 
Q585 
솔루션 아키텍트는 장애 조치 AWS 지역에서 Amazon EC2 용량을 제공하기 위한 재해 
복구(DR) 전략을 설계하고 있습니다. 비즈니스 요구 사항에 따르면 DR 전략은 장애 조치 
지역의 용량을 충족해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 장애 조치 지역에서 온디맨드 인스턴스를 구매합니다. 
B. 장애 조치 지역에서 EC2 Savings Plan 을 구매합니다. 
C. 장애 조치 지역에서 지역 예약 인스턴스를 구매합니다. 
D. 장애 조치 지역에서 용량 예약을 구매합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/119642-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q586 
회사에는 AWS Organizations 조직의 일부로 5 개의 조직 단위(OU)가 있습니다. 각 OU 는 
회사가 소유한 5 개 비즈니스와 연관되어 있습니다. 회사의 연구개발(R&D) 사업이 회사에서 
분리되어 자체 조직이 필요할 것입니다. 솔루션 설계자는 이 목적을 위해 별도의 새 관리 
계정을 생성합니다. 
솔루션 설계자는 새 마스터 계정에서 다음에 무엇을 수행해야 합니까? 
A. 전환하는 동안 R&D AWS 계정이 두 조직의 일부가 되도록 하십시오. 
B. R&D AWS 계정이 이전 조직을 떠난 후 R&D AWS 계정을 새 조직의 일부로 초대합니다. 
C. 새 조직에 새 R&D AWS 계정을 생성합니다. 이전 R&D AWS 계정의 리소스를 새 R&D 
AWS 계정으로 마이그레이션합니다. 
D. R&D AWS 계정이 새 조직에 가입하도록 합니다. 새 마스터 계정을 이전 조직의 
구성원으로 만드세요. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/119645-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 솔루션 아키텍트는 연구 개발(R&D) 비즈니스를 위한 별도의 조직을 만들고 AWS 
계정을 새 조직으로 이동할 수 있습니다. R&D AWS 계정이 이전 조직을 떠난 후 새 조직의 
일부가 되도록 초대함으로써 솔루션 아키텍트는 두 조직 간에 중복이나 충돌이 없는지 
확인할 수 있습니다. R&D AWS 계정은 새 조직에 가입하라는 초대를 수락하거나 거부할 수 
있습니다. 일단 수락되면 새 조직에서 적용하는 모든 정책과 통제가 적용됩니다. 
Q587 
한 회사는 분석을 처리하고 예측하기 위해 다양한 웹 애플리케이션에서 고객 활동을 
캡처하는 솔루션을 설계하고 있습니다. 웹 애플리케이션에서의 고객 활동은 예측할 수 
없으며 갑자기 증가할 수 있습니다. 회사에는 다른 웹 애플리케이션과 통합되는 솔루션이 
필요합니다. 솔루션에는 보안 목적을 위한 인증 단계가 포함되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에서 수신하는 정보를 
저장하는 Amazon Elastic Container Service(Amazon ECS) 컨테이너 인스턴스 앞에 
게이트웨이 로드 밸런서(GWLB)를 구성합니다. 승인은 GWLB 에서 해결됩니다. 
B. 회사가 Amazon S3 버킷에 수신하는 정보를 저장하는 Amazon Kinesis 데이터 스트림 
앞에 Amazon API Gateway 엔드포인트를 구성합니다. AWS Lambda 함수를 사용하여 
인증을 해결합니다. 
C. 회사가 Amazon S3 버킷에 수신하는 정보를 저장하는 Amazon Kinesis Data Firehose 
앞에 Amazon API Gateway 엔드포인트를 구성합니다. API Gateway Lambda 권한 부여자를 
사용하여 권한 부여를 해결합니다. 
D. 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에서 수신하는 정보를 
저장하는 Amazon Elastic Container Service(Amazon ECS) 컨테이너 인스턴스 앞에 
게이트웨이 로드 밸런서(GWLB)를 구성합니다. AWS Lambda 함수를 사용하여 인증을 
해결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/119576-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q588 
한 전자 상거래 회사는 Microsoft SQL Server Enterprise Edition 을 실행하는 Amazon RDS 
DB 인스턴스에 대한 재해 복구 솔루션을 원합니다. 회사의 현재 복구 지점 목표(RPO)와 
복구 시간 목표(RTO)는 24 시간입니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 지역 간 읽기 전용 복제본을 생성하고 읽기 전용 복제본을 기본 인스턴스로 승격합니다. 
B. AWS Database Migration Service(AWS DMS)를 사용하여 RDS 교차 지역 복제를 
생성합니다. 
C. 24 시간마다 교차 리전 복제를 사용하여 기본 백업을 Amazon S3 버킷에 복사합니다. 
D. 24 시간마다 자동 스냅샷을 다른 리전으로 복사합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/119718-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명:・ 
이 솔루션은 가장 비용 효율적이며 24 시간의 RPO 및 RTO 요구 사항을 충족합니다. 
자동 스냅샷: Amazon RDS 는 정기적으로 DB 인스턴스의 스냅샷을 자동으로 생성합니다. 
이러한 스냅샷을 24 시간마다 다른 AWS 리전에 복사하면 다른 지리적 위치에 백업을 
사용할 수 있으므로 재해 복구 기능을 제공할 수 있습니다. 
RPO 및 RTO: 회사의 RPO 와 RTO 가 모두 24 시간이므로 매일 스냅샷을 다른 리전에 
복사하면 충분합니다. 재해가 발생하면 대상 리전의 가장 최근 스냅샷에서 DB 인스턴스를 
복원할 수 있습니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(교차 리전 읽기 복제본): 이 옵션은 복구 시간을 단축할 수 있지만 다른 리전에서 
진행 중인 복제 및 리소스 사용으로 인해 비용이 더 많이 듭니다. 
옵션 B(DMS 교차 리전 복제): 지속적인 복제에는 효과적이지만 24 시간 RPO/RTO 를 
감안하면 필요하지 않은 복잡성과 비용이 발생합니다. 
옵션 C(지역 간 네이티브 백업 복사): 이 방법은 수동 단계가 더 많고 자동 스냅샷 
복사만큼 간단한 솔루션을 제공하지 않습니다. 
Q589 
한 회사는 고정 세션이 활성화된 Application Load Balancer 뒤에 있는 Auto Scaling 그룹의 
Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 웹 서버는 현재 사용자 세션 
상태를 호스팅합니다. 회사는 웹 서버 중단 시 고가용성을 보장하고 사용자 세션 상태 
손실을 방지하기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Memcached 인스턴스용 Amazon ElastiCache 를 사용하여 세션 데이터를 저장합니다. 
Memcached 용 ElastiCache 를 사용하여 세션 상태를 저장하도록 애플리케이션을 
업데이트합니다. 
B. Redis 용 Amazon ElastiCache 를 사용하여 세션 상태를 저장합니다. Redis 용 
ElastiCache 를 사용하여 세션 상태를 저장하도록 애플리케이션을 업데이트합니다. 
C. AWS Storage Gateway 캐싱 볼륨을 사용하여 세션 데이터를 저장합니다. AWS Storage 
Gateway 캐싱 볼륨을 사용하여 세션 상태를 저장하도록 애플리케이션을 업데이트합니다. 
D. Amazon RDS 를 사용하여 세션 상태를 저장합니다. Amazon RDS 를 사용하여 세션 
상태를 저장하도록 애플리케이션을 업데이트합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/119487-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q590 
한 회사는 회사의 온프레미스 데이터 센터에서 MySQL DB 인스턴스용 Amazon RDS 로 
MySQL 데이터베이스를 마이그레이션했습니다. 회사는 회사의 일일 평균 워크로드를 
충족하도록 RDS DB 인스턴스의 크기를 조정했습니다. 한 달에 한 번 회사에서 보고서에 
대한 쿼리를 실행할 때 데이터베이스 성능이 느려집니다. 회사는 보고서를 실행하고 일일 
작업 부하의 성능을 유지 관리할 수 있는 기능을 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터베이스의 읽기 전용 복제본을 생성합니다. 쿼리를 읽기 전용 복제본으로 
보냅니다. 
B. 데이터베이스 백업을 생성합니다. 백업을 다른 DB 인스턴스로 복원합니다. 쿼리를 새 
데이터베이스로 보냅니다. 
C. 데이터를 Amazon S3 로 내보냅니다. Amazon Athena 를 사용하여 S3 버킷을 쿼리합니다. 
D. 추가 워크로드를 수용할 수 있도록 DB 인스턴스의 크기를 조정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/119719-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q591 
회사는 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 컨테이너 
애플리케이션을 실행합니다. 애플리케이션에는 고객을 관리하고 주문하는 마이크로서비스가 
포함되어 있습니다. 회사는 들어오는 요청을 적절한 마이크로서비스로 라우팅해야 합니다. 
이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. AWS 로드 밸런서 컨트롤러를 사용하여 Network Load Balancer 를 프로비저닝하십시오. 
B. AWS Load Balancer Controller 를 사용하여 Application Load Balancer 를 
프로비저닝합니다. 
C. AWS Lambda 함수를 사용하여 요청을 Amazon EKS 에 연결합니다. 
D. Amazon API Gateway 를 사용하여 요청을 Amazon EKS 에 연결합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/119574-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q592 
회사는 AWS 를 사용하여 저작권이 있는 이미지에 대한 액세스 권한을 판매합니다. 회사의 
글로벌 고객 기반은 이러한 이미지에 빠르게 액세스할 수 있어야 합니다. 회사는 특정 
국가의 사용자에 대한 접근을 거부해야 합니다. 회사는 가능한 한 비용을 최소화하려고 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 를 사용하여 이미지를 저장하십시오. MFA(다단계 인증) 및 퍼블릭 버킷 
액세스를 활성화합니다. 고객에게 S3 버킷에 대한 링크를 제공합니다. 
B. Amazon S3를 사용하여 이미지를 저장합니다. 각 고객에 대해 IAM 사용자를 생성합니다. 
S3 버킷에 액세스할 수 있는 권한이 있는 그룹에 사용자를 추가합니다. 
C. ALB(Application Load Balancer) 뒤에 있는 Amazon EC2 인스턴스를 사용하여 이미지를 
저장합니다. 회사가 서비스를 제공하는 국가에만 인스턴스를 배포하세요. 고객에게 특정 
국가의 인스턴스에 대한 ALB 에 대한 링크를 제공하십시오. 
D. Amazon S3 를 사용하여 이미지를 저장합니다. 지리적 제한이 있는 이미지를 배포하려면 
Amazon CloudFront 를 사용하십시오. 각 고객이 CloudFront 의 데이터에 액세스할 수 
있도록 서명된 URL 을 제공합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/119573-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q593 
솔루션 아키텍트는 가용성이 뛰어난 Redis 용 Amazon ElastiCache 기반 솔루션을 설계하고 
있습니다. 솔루션 아키텍트는 장애로 인해 로컬 및 AWS 리전 내에서 성능 저하 또는 
데이터 손실이 발생하지 않도록 해야 합니다. 솔루션은 노드 수준과 지역 수준에서 
고가용성을 제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 여러 노드가 포함된 샤드가 있는 다중 AZ Redis 복제 그룹을 사용하십시오. 
B. Redis AOF(Append Only Files)가 활성화된 여러 노드가 포함된 Redis 샤드를 
사용합니다. 
C. 복제 그룹에 두 개 이상의 읽기 전용 복제본이 있는 다중 AZ Redis 클러스터를 
사용합니다. 
D. Auto Scaling 이 활성화된 여러 노드가 포함된 Redis 샤드를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/119572-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q594 
회사는 AWS 로 마이그레이션하고 애플리케이션에 Amazon EC2 온디맨드 인스턴스를 
사용할 계획입니다. 마이그레이션 테스트 단계에서 기술 팀은 애플리케이션이 완전히 
생산되기 위해 메모리를 실행하고 로드하는 데 오랜 시간이 걸린다는 사실을 관찰했습니다. 
다음 테스트 단계에서 애플리케이션 실행 시간을 단축할 솔루션은 무엇입니까? 
A. 두 개 이상의 EC2 온디맨드 인스턴스를 시작합니다. Auto Scaling 기능을 활성화하고 
다음 테스트 단계에서 EC2 온디맨드 인스턴스를 사용할 수 있도록 하십시오. 
B. EC2 스팟 인스턴스를 시작하여 애플리케이션을 지원하고 다음 테스트 단계에서 사용할 
수 있도록 애플리케이션을 확장합니다. 
C. 최대 절전 모드를 활성화한 상태에서 EC2 온디맨드 인스턴스를 시작합니다. 다음 
테스트 단계에서 EC2 Auto Scaling 웜 풀을 구성합니다. 
D. 용량 예약을 통해 EC2 온디맨드 인스턴스를 시작합니다. 다음 테스트 단계에서 추가 
EC2 인스턴스를 시작하십시오. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/119570-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
다음 테스트 단계에서 애플리케이션 시작 시간을 줄이는 솔루션은 최대 절전 모드가 설정된 
EC2 온디맨드 인스턴스를 시작하고 EC2 Auto Scaling 웜 풀을 구성하는 것입니다. 이 
솔루션을 사용하면 애플리케이션을 처음부터 시작하는 대신 최대 절전 모드에서 다시 
시작할 수 있으므로 시간과 리소스를 절약할 수 있습니다. 최대 절전 모드는 EC2 
인스턴스의 메모리(RAM) 상태를 루트 EBS 볼륨에 유지한 다음 인스턴스를 중지합니다. 
인스턴스가 재개되면 EBS 볼륨에서 메모리 상태를 복원하고 빠르게 생산성을 발휘합니다. 
EC2 Auto Scaling 웜 풀은 필요할 때 확장할 준비가 되어 있는 사전 초기화된 인스턴스 
풀을 유지하는 데 사용할 수 있습니다. Warm 풀은 최대 절전 모드 인스턴스를 지원할 수도 
있으므로 시작 시간과 확장 비용을 더욱 줄일 수 있습니다. 
다른 솔루션은 시작 시간을 단축하지 않거나, 가용성을 보장하지 않거나, 필요에 따라 
온디맨드 인스턴스를 사용하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. 
Auto Scaling 기능이 있는 두 개 이상의 EC2 온디맨드 인스턴스를 시작해도 각 인스턴스가 
여전히 초기화 프로세스를 거쳐야 하므로 애플리케이션의 시작 시간이 줄어들지 않습니다. 
EC2 스팟 인스턴스를 시작한다고 해서 가용성이 보장되는 것은 아닙니다. 용량에 대한 
수요가 높아지면 언제든지 AWS 가 스팟 인스턴스를 중단할 수 있기 때문입니다. 용량 
예약을 통해 EC2 온디맨드 인스턴스를 시작하면 인스턴스에 사용할 수 있는 용량이 
충분한지 확인만 할 뿐 사전 초기화는 하지 않으므로 애플리케이션 시작 시간이 줄어들지 
않습니다. 
Q595 
회사의 애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 
회사는 해당 애플리케이션이 일주일 중 임의의 요일에 갑작스러운 트래픽 증가를 
경험한다는 사실을 발견했습니다. 회사는 갑작스러운 트래픽 증가 중에도 애플리케이션 
성능을 유지하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Auto Scaling 그룹의 크기를 변경하려면 수동 스케일링을 사용하십시오. 
B. 예측 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 
C. 동적 스케일링을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 
D. 일정 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/119569-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q596 
전자상거래 애플리케이션은 Amazon EC2 인스턴스에서 실행되는 PostgreSQL 
데이터베이스를 사용합니다. 월별 판매 이벤트 중에 데이터베이스 사용량이 증가하고 
애플리케이션에 대한 데이터베이스 연결 문제가 발생합니다. 후속 월별 판매 이벤트에 대한 
트래픽은 예측할 수 없으며 이는 판매 예측에 영향을 미칩니다. 회사는 예측할 수 없는 
트래픽 증가가 있을 때 성능을 유지해야 합니다. 
가장 비용 효과적인 방법으로 이 문제를 해결하는 솔루션은 무엇입니까? 
A. PostgreSQL 데이터베이스를 Amazon Aurora Serverless v2 로 마이그레이션합니다. 
B. 증가된 사용량을 수용하기 위해 EC2 인스턴스의 PostgreSQL 데이터베이스에 대한 자동 
크기 조정을 활성화합니다. 
C. 더 큰 인스턴스 유형을 사용하여 PostgreSQL 데이터베이스를 PostgreSQL 용 Amazon 
RDS 로 마이그레이션합니다. 
D. 증가된 사용량을 수용하기 위해 PostgreSQL 데이터베이스를 Amazon Redshift 로 
마이그레이션합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/119590-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q597 
회사는 Amazon API Gateway 및 AWS Lambda 를 사용하여 AWS 에서 내부 서버리스 
애플리케이션을 호스팅합니다. 회사 직원들은 매일 애플리케이션을 사용하기 시작할 때 
대기 시간이 길어지는 문제를 보고합니다. 회사는 대기 시간을 줄이고 싶어합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. API 게이트웨이 조절 한도를 늘리십시오. 
B. 직원이 매일 애플리케이션을 사용하기 전에 Lambda 프로비저닝 동시성을 높이기 위해 
예약된 조정을 설정합니다. 
C. Amazon CloudWatch 경보를 생성하여 매일 시작 시 경보 대상으로 Lambda 함수를 
시작합니다. 
D. Lambda 함수 메모리를 늘립니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/119465-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q598 
연구 회사에서는 온프레미스 장치를 사용하여 분석용 데이터를 생성합니다. 회사는 AWS 
클라우드를 사용하여 데이터를 분석하려고 합니다. 장치는 .csv 파일을 생성하고 SMB 파일 
공유에 데이터 쓰기를 지원합니다. 회사 분석가는 SQL 명령을 사용하여 데이터를 쿼리할 
수 있어야 합니다. 분석가는 하루 종일 주기적으로 쿼리를 실행합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (3 개 선택) 
A. Amazon S3 파일 게이트웨이 모드로 온프레미스에 AWS Storage Gateway 를 배포합니다. 
B. Amazon FSx File Gateway 를 통해 온프레미스에 AWS Storage Gateway 를 배포합니다. 
C. Amazon S3 에 있는 데이터를 기반으로 테이블을 생성하도록 AWS Glue 크롤러를 
설정합니다. 
D. EMRFS(EMR 파일 시스템)를 사용하여 Amazon EMR 클러스터를 설정하여 Amazon S3 에 
있는 데이터를 쿼리합니다. 분석가에 대한 액세스를 제공합니다. 
E. Amazon S3 에 있는 데이터를 쿼리하도록 Amazon Redshift 클러스터를 설정합니다. 
분석가에 대한 액세스를 제공합니다. 
F. Amazon S3 에 있는 데이터를 쿼리하도록 Amazon Athena 를 설정합니다. 분석가에 대한 
액세스를 제공합니다. 
Answer: A, C, F 
https://www.examtopics.com/discussions/amazon/view/119563-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
비용 효율적인 방식으로 사용 사례의 요구 사항을 충족하려면 다음 단계를 수행하는 것이 
좋습니다. 
Amazon S3 파일 게이트웨이 모드로 온프레미스에 AWS Storage Gateway 를 배포합니다. 
이를 통해 회사는 장치에서 생성된 .csv 파일을 SMB 파일 공유에 쓸 수 있으며, 이 파일은 
Amazon S3 버킷에 객체로 저장됩니다. AWS Storage Gateway 는 온프레미스 환경을 AWS 
스토리지와 통합하는 하이브리드 클라우드 스토리지 서비스입니다. Amazon S3 파일 
게이트웨이 모드는 Amazon S3 에 연결하고 거의 무제한의 클라우드 스토리지에 액세스할 
수 있는 원활한 방법을 제공합니다. 
Amazon S3 에 있는 데이터를 기반으로 테이블을 생성하도록 AWS Glue 크롤러를 
설정합니다. 이를 통해 회사는 표준 SQL 을 사용하여 Amazon S3 버킷에 저장된 데이터를 
쿼리할 수 있습니다. AWS Glue 는 데이터 준비 및 분석을 단순화하는 서버리스 데이터 통합 
서비스입니다. AWS Glue 크롤러는 다양한 소스의 데이터를 자동으로 검색 및 분류하고 
AWS Glue 데이터 카탈로그에 메타데이터 테이블을 생성할 수 있습니다. 데이터 카탈로그는 
데이터 소스에 대한 정보와 이에 액세스하는 방법을 저장하는 중앙 저장소입니다. 
Amazon S3 에 있는 데이터를 쿼리하도록 Amazon Athena 를 설정합니다. 이는 회사 
분석가에게 표준 SQL 을 사용하여 Amazon S3 에서 직접 데이터를 분석할 수 있는 서버리스 
및 대화형 쿼리 서비스를 제공합니다. Amazon Athena 는 AWS Glue 데이터 카탈로그와 
통합되어 있으므로 사용자는 크롤러가 정의한 데이터 원본 테이블에서 Athena 를 쉽게 
가리킬 수 있습니다. 
Amazon Athena 는 실행된 쿼리에 대해서만 비용을 청구하고 쿼리당 지불 가격 모델을 
제공하므로 정기적인 쿼리에 비용 효율적인 옵션입니다. 
다른 옵션은 비용 효율적이지 않거나 사용 사례에 적합하지 않기 때문에 올바르지 않습니다. 
Amazon FSx 파일 게이트웨이 모드에서 온프레미스로 AWS Storage Gateway 를 배포하는 
것은 올바르지 않습니다. 이 모드는 사용 사례에 필요하지 않은 AWS 의 완전 관리형 
Windows 파일 공유에 대한 지연 시간이 짧은 액세스를 제공하기 때문입니다. Amazon 
S3 에 있는 데이터를 쿼리하기 위해 EMR 파일 시스템(EMRFS)을 사용하여 Amazon EMR 
클러스터를 설정하는 것은 올바르지 않습니다. 이 옵션에는 EC2 인스턴스 클러스터 설정 
및 관리가 포함되어 솔루션에 복잡성과 비용이 추가되기 때문입니다. Amazon S3 에 있는 
데이터를 쿼리하도록 Amazon Redshift 클러스터를 설정하는 것은 올바르지 않습니다. 이 
옵션에는 솔루션에 오버헤드와 비용을 추가하는 노드 클러스터의 프로비저닝 및 관리도 
포함되기 때문입니다. 
Q599 
한 회사에서 Amazon Elastic Container Service(Amazon ECS) 클러스터와 Amazon RDS DB 
인스턴스를 사용하여 결제 처리 애플리케이션을 구축하고 실행하려고 합니다. 회사는 규정 
준수를 위해 온프레미스 데이터 센터에서 애플리케이션을 실행합니다. 
솔루션 아키텍트는 AWS Outposts 를 솔루션의 일부로 사용하려고 합니다. 솔루션 설계자는 
회사의 운영 팀과 협력하여 애플리케이션을 구축하고 있습니다. 
회사 운영팀에서는 어떤 활동을 담당하나요? (3 개를 선택하세요.) 
A. Outposts 랙에 탄력적인 전원 및 네트워크 연결을 제공합니다. 
B. Outposts 에서 실행되는 가상화 하이퍼바이저, 스토리지 시스템 및 AWS 서비스를 
관리합니다. 
C. 데이터 센터 환경의 물리적 보안 및 액세스 제어. 
D. Outposts 랙 내의 전원 공급 장치, 서버 및 네트워킹 장비를 포함한 Outposts 인프라의 
가용성. 
E. Outposts 구성 요소의 물리적 유지 관리. 
F. 서버 오류 및 유지 관리 이벤트를 완화하기 위해 Amazon ECS 클러스터에 추가 용량을 
제공합니다. 
Answer: A, C, F 
https://www.examtopics.com/discussions/amazon/view/119530-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
A, C, E?? 
Q600 
회사는 TCP 기반 애플리케이션을 회사의 VPC 로 마이그레이션할 계획입니다. 
애플리케이션은 회사 데이터 센터의 하드웨어 어플라이언스를 통해 비표준 TCP 포트에서 
공개적으로 액세스할 수 있습니다. 이 퍼블릭 엔드포인트는 짧은 대기 시간으로 초당 최대 
300 만 개의 요청을 처리할 수 있습니다. 회사는 AWS 의 새로운 퍼블릭 엔드포인트에 대해 
동일한 수준의 성능을 요구합니다. 
이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. NLB(Network Load Balancer)를 배포합니다. 애플리케이션에 필요한 TCP 포트를 통해 
공개적으로 액세스할 수 있도록 NLB 를 구성합니다. 
B. ALB(Application Load Balancer)를 배포합니다. 애플리케이션에 필요한 TCP 포트를 통해 
공개적으로 액세스할 수 있도록 ALB 를 구성하십시오. 
C. 애플리케이션에 필요한 TCP 포트를 수신하는 Amazon CloudFront 배포를 배포합니다. 
Application Load Balancer 를 원본으로 사용합니다. 
D. 애플리케이션에 필요한 TCP 포트로 구성된 Amazon API Gateway API 를 배포합니다. 
요청을 처리하기 위해 프로비저닝된 동시성을 사용하여 AWS Lambda 함수를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/121205-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q601 
회사는 PostgreSQL DB 인스턴스용 Amazon RDS 에서 중요 데이터베이스를 실행합니다. 이 
회사는 가동 중지 시간과 데이터 손실을 최소화하면서 Amazon Aurora PostgreSQL 로 
마이그레이션하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. RDS for PostgreSQL DB 인스턴스의 DB 스냅샷을 생성하여 새로운 Aurora PostgreSQL 
DB 클러스터를 채웁니다. 
B. RDS for PostgreSQL DB 인스턴스의 Aurora 읽기 전용 복제본을 생성합니다. Aurora 읽기 
복제를 새로운 Aurora PostgreSQL DB 클러스터로 승격합니다. 
C. Amazon S3 에서 데이터 가져오기를 사용하여 데이터베이스를 Aurora PostgreSQL DB 
클러스터로 마이그레이션합니다. 
D. pg_dump 유틸리티를 사용하여 PostgreSQL 용 RDS 데이터베이스를 백업합니다. 새 
Aurora PostgreSQL DB 클러스터로 백업을 복원합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/121210-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q602 
회사의 인프라는 Amazon Elastic Block Store(Amazon EBS) 스토리지를 사용하는 수백 개의 
Amazon EC2 인스턴스로 구성됩니다. 솔루션 아키텍트는 재해 발생 후 모든 EC2 
인스턴스를 복구할 수 있는지 확인해야 합니다. 
최소한의 노력으로 이 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍습니다. EBS 스토리지에서 새 
EC2 인스턴스를 시작하려면 AWS CloudFormation 템플릿을 생성하세요. 
B. 각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍습니다. AWS Elastic 
Beanstalk 를 사용하여 EC2 템플릿 기반으로 환경을 설정하고 EBS 스토리지를 연결하세요. 
C. AWS Backup을 사용하여 전체 EC2 인스턴스 그룹에 대한 백업 계획을 설정합니다. AWS 
Backup API 또는 AWS CLI 를 사용하면 여러 EC2 인스턴스의 복원 프로세스 속도를 높일 
수 있습니다. 
D. 각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍고 Amazon 머신 
이미지(AMI)를 복사하는 AWS Lambda 함수를 생성합니다. 복사된 AMI 로 복원을 수행하고 
EBS 스토리지를 연결하는 또 다른 Lambda 함수를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/121212-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q603 
최근 한 회사가 AWS 클라우드로 마이그레이션했습니다. 회사는 반구조화된 데이터 세트의 
대규모 병렬 주문형 처리를 위한 서버리스 솔루션을 원합니다. 데이터는 Amazon S3 에 
저장되는 로그, 미디어 파일, 판매 거래 및 IoT 센서 데이터로 구성됩니다. 회사는 데이터 
세트에 있는 수천 개의 항목을 병렬로 처리하는 솔루션을 원합니다. 
가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 인라인 모드에서 AWS Step Functions 맵 상태를 사용하여 데이터를 병렬로 처리합니다. 
B. 분산 모드에서 AWS Step Functions 맵 상태를 사용하여 데이터를 병렬로 처리합니다. 
C. AWS Glue 를 사용하여 데이터를 병렬로 처리합니다. 
D. 여러 AWS Lambda 함수를 사용하여 데이터를 병렬로 처리합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/121211-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q604 
회사는 6주 안에 10PB의 데이터를 Amazon S3로 마이그레이션할 예정입니다. 현재 데이터 
센터에는 인터넷에 대한 500Mbps 업링크가 있습니다. 다른 온프레미스 애플리케이션은 
업링크를 공유합니다. 회사는 이 일회성 마이그레이션 작업에 인터넷 대역폭의 80%를 
사용할 수 있습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터를 Amazon S3 로 마이그레이션하고 자동으로 데이터를 확인하도록 AWS 
DataSync 를 구성합니다. 
B. rsync 를 사용하여 데이터를 Amazon S3 로 직접 전송합니다. 
C. AWS CLI 와 여러 복사 프로세스를 사용하여 데이터를 Amazon S3 에 직접 보냅니다. 
D. 여러 AWS Snowball 디바이스를 주문합니다. 데이터를 장치에 복사합니다. 디바이스를 
AWS 로 보내 데이터를 Amazon S3 에 복사합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/121186-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q605 
회사에는 온프레미스 ISCSI(Internet Small Computer Systems Interface) 네트워크 스토리지 
서버가 여러 대 있습니다. 회사는 AWS 클라우드로 이동하여 이러한 서버의 수를 줄이고 
싶어합니다. 솔루션 설계자는 자주 사용되는 데이터에 대한 짧은 대기 시간 액세스를 
제공하고 최소한의 인프라 변경으로 온프레미스 서버에 대한 종속성을 줄여야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 파일 게이트웨이를 배포합니다. 
B. Amazon S3 에 대한 백업과 함께 Amazon Elastic Block Store(Amazon EBS) 스토리지를 
배포합니다. 
C. 저장된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. 
D. 캐시된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/121170-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Storage Gateway 볼륨 게이트웨이(캐시 볼륨): 이 구성을 사용하면 기본 데이터를 
Amazon S3 에 저장하는 동시에 자주 액세스하는 데이터를 캐시에 로컬로 유지하여 액세스 
지연 시간을 단축할 수 있습니다. 
* 짧은 지연 시간 액세스: 자주 액세스하는 데이터는 온프레미스에 로컬로 캐시되어 짧은 
지연 시간 액세스를 제공하는 반면, 자주 액세스하지 않는 데이터는 Amazon S3 에 비용 
효율적으로 저장됩니다. 
* 구현: 
* 온프레미스 또는 가상 환경에 Storage Gateway 어플라이언스를 배포합니다. 
* 캐시된 볼륨이 있는 볼륨 게이트웨이로 구성합니다. 
* 볼륨을 생성하고 이러한 볼륨을 사용하도록 애플리케이션을 구성합니다. 
* 최소한의 인프라 변경: 이 솔루션은 기존 온프레미스 인프라와 원활하게 통합되므로 
변경이 최소화되고 온프레미스 스토리지 서버에 대한 종속성이 줄어듭니다. 
Q606 
솔루션 아키텍트는 비즈니스 사용자가 Amazon S3 에 객체를 업로드할 수 있는 
애플리케이션을 설계하고 있습니다. 솔루션은 객체 내구성을 극대화해야 합니다. 또한 
객체는 언제든지 언제든지 쉽게 사용할 수 있어야 합니다. 사용자는 객체가 업로드된 후 
처음 30 일 이내에 객체에 자주 액세스하지만 30 일보다 오래된 객체에는 사용자가 
액세스할 가능성이 훨씬 적습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. S3 수명 주기 규칙을 사용하여 모든 객체를 S3 Standard 에 저장하여 30 일 후에 객체를 
S3 Glacier 로 전환합니다. 
B. 30 일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하려면 S3 
수명 주기 규칙을 사용하여 모든 객체를 S3 Standard 에 저장합니다. 
C. 30 일 후에 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하는 S3 
수명 주기 규칙을 사용하여 모든 객체를 S3 Standard 에 저장합니다. 
D. S3 수명 주기 규칙을 사용하여 모든 객체를 S3 Intelligent-Tiering 에 저장하여 30 일 
후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/121214-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q607 
한 회사가 온프레미스 데이터 센터에서 AWS 클라우드로 2 계층 애플리케이션을 
마이그레이션했습니다. 데이터 계층은 12TB 의 범용 SSD Amazon Elastic Block 
Store(Amazon EBS) 스토리지를 갖춘 Oracle 용 Amazon RDS 의 다중 AZ 배포입니다. 이 
애플리케이션은 평균 문서 크기가 6MB 인 이진 대형 개체(BLOB)로 데이터베이스의 문서를 
처리하고 저장하도록 설계되었습니다. 
시간이 지남에 따라 데이터베이스 크기가 증가하여 성능이 저하되고 스토리지 비용이 
증가했습니다. 회사는 데이터베이스 성능을 개선해야 하며 가용성과 탄력성이 뛰어난 
솔루션이 필요합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. RDS DB 인스턴스 크기를 줄입니다. 스토리지 용량을 24TiB 로 늘립니다. 스토리지 
유형을 마그네틱으로 변경합니다. 
B. RDS DB 인스턴스 크기를 늘리십시오. 스토리지 용량을 24Ti 로 늘립니다. 스토리지 
유형을 프로비저닝된 IOPS 로 변경합니다. 
C. Amazon S3 버킷을 생성합니다. S3 버킷에 문서를 저장하도록 애플리케이션을 
업데이트합니다. 기존 데이터베이스에 개체 메타데이터를 저장합니다. 
D. Amazon DynamoDB 테이블을 생성합니다. DynamoDB 를 사용하도록 애플리케이션을 
업데이트합니다. AWS Database Migration Service(AWS DMS)를 사용하여 Oracle 
데이터베이스에서 DynamoDB 로 데이터를 마이그레이션합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/121215-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q608 
회사에는 전 세계 20,000 개 이상의 소매점 위치에 배포된 클라이언트에게 서비스를 
제공하는 애플리케이션이 있습니다. 애플리케이션은 포트 443에서 HTTPS를 통해 노출되는 
백엔드 웹 서비스로 구성됩니다. 애플리케이션은 ALB(Application Load Balancer) 뒤의 
Amazon EC2 인스턴스에서 호스팅됩니다. 소매점은 공용 인터넷을 통해 웹 애플리케이션과 
통신합니다. 회사는 각 소매점에서 현지 ISP 가 할당한 IP 주소를 등록할 수 있도록 
허용합니다. 
회사 보안팀에서는 소매점에서 등록한 IP 주소로만 접속을 제한하여 애플리케이션 
엔드포인트의 보안을 강화할 것을 권장합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS WAF 웹 ACL 을 ALB 와 연결합니다. ALB 의 IP 규칙 세트를 사용하여 트래픽을 
필터링합니다. 등록된 IP 주소를 포함하도록 규칙의 IP 주소를 업데이트합니다. 
B. AWS Firewall Manager 를 배포하여 ALConfigure 방화벽 규칙을 관리하여 AL 로의 
트래픽을 제한합니다. 등록된 IP 주소를 포함하도록 방화벽 규칙을 수정합니다. 
C. Amazon DynamoDB 테이블에 IP 주소를 저장합니다. ALB 에서 AWS Lambda 인증 
기능을 구성하여 수신 요청이 등록된 IP 주소에서 오는지 확인합니다. 
D. ALB 의 공용 인터페이스가 포함된 서브넷에서 네트워크 ACL 을 구성합니다. 등록된 각 
IP 주소에 대한 항목으로 네트워크 ACL 의 수신 규칙을 업데이트합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/121216-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS WAF(웹 애플리케이션 방화벽): AWS WAF 를 사용하면 사용자가 지정한 조건에 따라 
웹 요청을 차단하거나 허용하는 사용자 지정 규칙을 생성할 수 있습니다. 
* 웹 ACL(액세스 제어 목록): 
* 웹 ACL 을 생성하고 이를 ALB 와 연결합니다. 
* IP 규칙 세트를 사용하여 애플리케이션에 액세스할 수 있는 소매점의 IP 주소를 
지정합니다. 
* 보안 및 유연성: 
* AWS WAF 는 액세스 제어를 관리하는 확장 가능한 방법을 제공하여 등록된 IP 주소의 
트래픽만 허용되도록 합니다. 
* IP 규칙 세트를 동적으로 업데이트하여 필요에 따라 IP 주소를 추가하거나 제거할 수 
있습니다. 
* 운영 단순성: 웹 ACL 과 함께 AWS WAF 를 사용하는 것은 간단하며 ALB 와 원활하게 
통합되어 IP 주소를 기반으로 액세스 제어를 관리하기 위한 효율적인 솔루션을 제공합니다. 
Q609 
회사에서 AWS Lake Formation 을 사용하여 AWS 에 데이터 분석 플랫폼을 구축하고 
있습니다. 플랫폼은 Amazon S3 및 Amazon RDS 와 같은 다양한 소스에서 데이터를 
수집합니다. 회사는 중요한 정보가 포함된 데이터 부분에 대한 액세스를 방지하기 위한 
보안 솔루션이 필요합니다. 
A. Lake Formation 테이블에 액세스할 수 있는 권한이 포함된 IAM 역할을 생성합니다. 
B. 데이터 필터를 생성하여 행 수준 보안 및 셀 수준 보안을 구현합니다. 
C. Lake Formation 이 다시 데이터를 수집하기 전에 민감한 정보를 제거하는 AWS Lambda 
함수를 생성합니다. 
D. Lake Formation 테이블에서 민감한 정보를 주기적으로 쿼리하고 제거하는 AWS Lambda 
함수를 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/121162-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 Lake Formation 과 통합된 엔진 및 쿼리 결과의 특정 데이터에 대한 액세스를 
제한하는 사양인 데이터 필터를 사용하기 때문에 가장 효율적입니다. 데이터 필터는 중요한 
정보가 포함된 데이터 부분에 대한 액세스를 방지하는 기술인 행 수준 보안 및 셀 수준 
보안을 구현하는 데 사용할 수 있습니다. Data Catalog 테이블에 대한 Lake Formation 
권한을 부여할 때 데이터 필터를 적용할 수 있으며 PartiQL 표현식을 사용하여 조건에 따라 
데이터를 필터링할 수 있습니다. 이 솔루션은 중요한 정보가 포함된 데이터 부분에 대한 
액세스를 방지하는 보안 솔루션을 제공해야 한다는 요구 사항을 충족합니다. 
옵션 A 는 IAM 정책을 사용하여 Lake Formation 의 데이터에 대한 액세스 권한을 부여하는 
방법인 Lake Formation 테이블에 대한 액세스 권한이 포함된 IAM 역할을 사용하기 때문에 
효율성이 떨어집니다. 그러나 이것은 중요한 정보가 포함된 데이터 부분에 대한 액세스를 
방지하는 방법을 제공하지 않습니다. 
옵션 C 는 Lake Formation 이 데이터를 수집하기 전에 민감한 정보를 제거하는 AWS 
Lambda 함수를 사용하기 때문에 효율성이 떨어집니다. 이는 서버리스 함수를 사용하여 
데이터 정리 또는 변환을 수행하는 방법입니다. 그러나 여기에는 애플리케이션 코드 및 
논리에 대한 상당한 변경이 포함될 수 있으며 데이터 손실 또는 불일치가 발생할 수도 
있습니다. 
옵션 D 는 서버리스 함수를 사용하여 데이터 정리 또는 변환을 수행하는 방법인 Lake 
Formation 테이블에서 민감한 정보를 주기적으로 쿼리하고 제거하는 AWS Lambda 함수를 
사용하기 때문에 효율성이 떨어집니다. 그러나 여기에는 애플리케이션 코드 및 논리에 대한 
상당한 변경이 포함될 수 있으며 데이터 손실 또는 불일치가 발생할 수도 있습니다. 
Q610 
회사는 VPC 에서 실행되는 Amazon EC2 인스턴스를 배포합니다. EC2 인스턴스는 나중에 
데이터를 처리할 수 있도록 소스 데이터를 Amazon S3 버킷에 로드합니다. 규정 준수법에 
따라 데이터는 공용 인터넷을 통해 전송되어서는 안 됩니다. 회사의 온프레미스 데이터 
센터에 있는 서버는 EC2 인스턴스에서 실행되는 애플리케이션의 출력을 사용합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon EC2 용 인터페이스 VPC 엔드포인트를 배포합니다. 회사와 VPC 간에 AWS 
Site-to-Site VPN 연결을 생성합니다. 
B. Amazon S3 용 게이트웨이 VPC 엔드포인트를 배포합니다. 온프레미스 네트워크와 VPC 
간에 AWS Direct Connect 연결을 설정합니다. 
C. VPC 에서 S3 버킷으로의 AWS Transit Gateway 연결을 설정합니다. 회사와 VPC 간에 
AWS Site-to-Site VPN 연결을 생성합니다. 
D. NAT 게이트웨이에 대한 경로가 있는 프록시 EC2 인스턴스를 설정합니다. S3 데이터를 
가져오고 애플리케이션 인스턴스에 공급하도록 프록시 EC2 인스턴스를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/121217-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q611 
회사에는 제 3 자 공급업체로부터 거의 실시간으로 데이터를 수신할 수 있는 REST 기반 
인터페이스가 있는 애플리케이션이 있습니다. 일단 수신되면 애플리케이션은 추가 분석을 
위해 데이터를 처리하고 저장합니다. 애플리케이션이 Amazon EC2 인스턴스에서 실행 
중입니다. 
타사 공급업체에서 애플리케이션에 데이터를 보낼 때 503 서비스를 사용할 수 없음 오류가 
많이 발생했습니다. 데이터 볼륨이 급증하면 컴퓨팅 용량이 최대 한도에 도달하고 
애플리케이션이 모든 요청을 처리할 수 없게 됩니다. 
보다 확장 가능한 솔루션을 제공하기 위해 솔루션 설계자는 어떤 디자인을 권장해야 
합니까? 
A. Amazon Kinesis Data Streams 를 사용하여 데이터를 수집하십시오. AWS Lambda 함수를 
사용하여 데이터를 처리합니다. 
B. 기존 애플리케이션 위에 Amazon API Gateway 를 사용하십시오. 타사 공급업체에 대한 
할당량 제한이 있는 사용량 계획을 만듭니다. 
C. Amazon Simple 알림 서비스(Amazon SNS)를 사용하여 데이터를 수집합니다. Application 
Load Balancer 뒤의 Auto Scaling 그룹에 EC2 인스턴스를 배치합니다. 
D. 애플리케이션을 컨테이너로 다시 패키징합니다. Auto Scaling 그룹과 함께 EC2 시작 
유형을 사용하는 Amazon Elastic Container Service(Amazon ECS)를 사용하여 
애플리케이션을 배포합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/121218-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q612 
회사에는 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 
애플리케이션은 Amazon S3 버킷의 민감한 정보를 처리해야 합니다. 애플리케이션은 S3 
버킷에 연결하기 위해 인터넷을 사용해서는 안 됩니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 인터넷 게이트웨이를 구성하십시오. 인터넷 게이트웨이에서의 액세스를 허용하도록 S3 
버킷 정책을 업데이트합니다. 새 인터넷 게이트웨이를 사용하도록 애플리케이션을 
업데이트합니다. 
B. VPN 연결을 구성합니다. VPN 연결에서 액세스를 허용하도록 S3 버킷 정책을 
업데이트합니다. 새 VPN 연결을 사용하도록 애플리케이션을 업데이트하세요. 
C. NAT 게이트웨이를 구성합니다. NAT 게이트웨이에서의 액세스를 허용하도록 S3 버킷 
정책을 업데이트합니다. 새 NAT 게이트웨이를 사용하도록 애플리케이션을 업데이트합니다. 
D. VPC 엔드포인트를 구성합니다. VPC 엔드포인트에서의 액세스를 허용하도록 S3 버킷 
정책을 업데이트합니다. 새 VPC 엔드포인트를 사용하도록 애플리케이션을 업데이트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/121159-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q613 
회사는 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 컨테이너 
애플리케이션을 실행합니다. EKS 클러스터는 Kubernetes 비밀 객체에 민감한 정보를 
저장합니다. 회사는 정보가 암호화되었는지 확인하기를 원합니다. 어떤 솔루션이 이러한 
요구 사항을 충족합니까? 
최소한의 운영 오버헤드로 요구 사항을 충족합니까? 
A. 컨테이너 애플리케이션을 사용하여 AWS Key Management Service(AWS KMS)를 
사용하여 정보를 암호화합니다. 
B. AWS Key Management Service(AWS KMS)를 사용하여 EKS 클러스터에서 비밀 암호화를 
활성화합니다. 
C. AWS KMS(AWS Key Management Service)를 사용하여 정보를 암호화하는 AWS Lambda 
tuncuon 을 구현합니다. 
D. AWS Systems Manager Parameter Store 를 사용하여 AWS Key Management Service(AWS 
KMS)를 사용하여 정보를 암호화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/121158-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 최소한의 운영 오버헤드로 EKS 클러스터의 Kubernetes 비밀 개체를 
암호화할 수 있습니다. EKS 클러스터에서 비밀 암호화를 활성화함으로써 회사는 AWS Key 
Management Service(AWS KMS)를 사용하여 저장된 비밀을 암호화하고 해독하기 위한 
암호화 키를 생성하고 관리할 수 있습니다. 이는 EKS 클러스터의 중요한 정보를 보호하는 
간단하고 안전한 방법입니다. 
Q614 
한 회사는 다음 구성 요소로 구성된 새로운 다중 계층 웹 애플리케이션을 설계하고 
있습니다. 
• Auto Scaling 그룹의 일부로 Amazon EC2 인스턴스에서 실행되는 웹 및 애플리케이션 
서버 
• 데이터 저장을 위한 Amazon RDS DB 인스턴스 
솔루션 설계자는 웹 서버만 액세스할 수 있도록 애플리케이션 서버에 대한 액세스를 
제한해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 애플리케이션 서버 앞에 AWS PrivateLink 를 배포합니다. 웹 서버만 애플리케이션 서버에 
액세스할 수 있도록 네트워크 ACL 을 구성합니다. 
B. 애플리케이션 서버 앞에 VPC 엔드포인트를 배포합니다. 웹 서버만 애플리케이션 서버에 
액세스할 수 있도록 보안 그룹을 구성합니다. 
C. 애플리케이션 서버의 Auto Scaling 그룹이 포함된 대상 그룹으로 Network Load 
Balancer 를 배포합니다. 웹 서버만 애플리케이션 서버에 액세스할 수 있도록 네트워크 
ACL 을 구성합니다. 
D. 애플리케이션 서버의 Auto Scaling 그룹이 포함된 대상 그룹과 함께 Application Load 
Balancer 를 배포합니다. 웹 서버만 애플리케이션 서버에 액세스할 수 있도록 보안 그룹을 
구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/121157-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* ALB(Application Load Balancer): ALB 는 HTTP/HTTPS 트래픽을 애플리케이션 서버로 
라우팅하는 데 적합합니다. 고급 라우팅 기능을 제공하고 Auto Scaling 그룹과 잘 
통합됩니다. 
* 대상 그룹 구성: 
* 애플리케이션 서버에 대한 대상 그룹을 생성하고 이 대상 그룹에 Auto Scaling 그룹을 
등록합니다. 
* 웹 서버의 요청을 애플리케이션 서버로 전달하도록 ALB 를 구성합니다. 
* 보안 그룹 설정: 
* 웹 서버 보안 그룹의 트래픽만 허용하도록 애플리케이션 서버의 보안 그룹을 구성합니다. 
* 이렇게 하면 웹 서버만 애플리케이션 서버에 액세스할 수 있으므로 액세스 제한 요구 
사항을 충족합니다. 
* 이익: 
* 보안: 보안 그룹을 사용하여 액세스를 제한하면 의도한 트래픽만 허용되는 안전한 환경이 
보장됩니다. 
* 확장성: ALB 는 Auto Scaling 그룹과 원활하게 작동하여 애플리케이션이 다양한 로드를 
효율적으로 처리할 수 있도록 보장합니다. 
Q615 
한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS)에서 고객을 대상으로 하는 
중요한 애플리케이션을 실행하고 있습니다. 애플리케이션에는 마이크로서비스 아키텍처가 
있습니다. 회사는 중앙 위치에서 애플리케이션의 측정항목과 로그를 수집, 집계, 요약하는 
솔루션을 구현해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 기존 EKS 클러스터에서 Amazon CloudWatch 에이전트를 실행합니다. CloudWatch 
콘솔에서 지표와 로그를 봅니다. 
B. 기존 EKS 클러스터에서 AWS App Mesh 를 실행합니다. App Mesh 콘솔에서 지표와 
로그를 확인하세요. 
C. 데이터 이벤트를 캡처하도록 AWS CloudTrail 을 구성합니다. Amazon OpenSearch 
Service 를 사용하여 CloudTrail 을 쿼리합니다. 
D. 기존 EKS 클러스터에 Amazon CloudWatch Container Insights 를 구성합니다. 
CloudWatch 콘솔에서 지표와 로그를 봅니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/121154-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q616 
한 회사가 AWS 에 최신 제품을 배포했습니다. 제품은 Network Load Balancer 뒤의 Auto 
Scaling 그룹에서 실행됩니다. 회사는 제품의 객체를 Amazon S3 버킷에 저장합니다. 
이 회사는 최근 자사 시스템에 대한 악의적인 공격을 경험했습니다. 회사에는 AWS 계정의 
악의적인 활동, 워크로드 및 S3 버킷에 대한 액세스 패턴을 지속적으로 모니터링하는 
솔루션이 필요합니다. 또한 솔루션은 의심스러운 활동을 보고하고 대시보드에 정보를 
표시해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 결과를 모니터링하고 AWS Config 에 보고하도록 Amazon Macie 를 구성합니다. 
B. 결과를 모니터링하고 AWS CloudTrail 에 보고하도록 Amazon Inspector 를 구성합니다. 
C. 결과를 모니터링하고 AWS Security Hub 에 보고하도록 Amazon GuardDuty 를 
구성합니다. 
D. 결과를 모니터링하고 Amazon EventBridge 에 보고하도록 AWS Config 를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/121177-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon GuardDuty 는 AWS 계정과 워크로드 전체에서 악의적인 활동과 무단 행동을 
지속적으로 모니터링하는 위협 탐지 서비스입니다. GuardDuty 는 AWS CloudTrail 이벤트 
로그, Amazon VPC 흐름 로그 및 DNS 로그와 같은 데이터 소스를 분석하여 손상된 
인스턴스, 정찰, 포트 스캐닝 및 데이터 유출과 같은 잠재적인 위협을 식별합니다. 
GuardDuty 는 AWS 계정 및 워크로드의 보안 상태에 대한 포괄적인 보기를 제공하는 
서비스인 AWS Security Hub 에 조사 결과를 보고할 수 있습니다. Security Hub 는 여러 AWS 
서비스 및 파트너 솔루션의 보안 경고를 집계, 구성 및 우선순위를 지정하여 대시보드에 
표시합니다. 이 솔루션은 AWS 계정의 악의적인 활동, 워크로드 및 S3 버킷에 대한 액세스 
패턴을 지속적으로 모니터링, 보고 및 시각화할 수 있으므로 요구 사항을 충족합니다. 
Q617 
회사에서 온프레미스 데이터 센터를 AWS 로 마이그레이션하려고 합니다. 데이터 센터는 
NFS 기반 파일 시스템에 데이터를 저장하는 스토리지 서버를 호스팅합니다. 스토리지 
서버는 200GB 의 데이터를 보유합니다. 회사는 기존 서비스를 중단하지 않고 데이터를 
마이그레이션해야 합니다. AWS 의 여러 리소스는 NFS 프로토콜을 사용하여 데이터에 
액세스할 수 있어야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. Lustre 파일 시스템용 Amazon FSx 를 생성합니다. 
B. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 
C. 데이터를 수신할 Amazon S3 버킷을 생성합니다. 
D. 운영 체제 복사 명령을 수동으로 사용하여 데이터를 AWS 대상으로 푸시합니다. 
E. 온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치합니다. 온프레미스 위치와 
AWS 간에 DataSync 작업을 사용합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/121176-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
102 문제와 중복 
Q618 
한 회사에서는 us-east-1 리전에 볼륨으로 마운트된 SMB 파일 공유가 있는 Amazon EC2 
인스턴스에 Amazon FSx for Windows File Server 를 사용하려고 합니다. 회사는 계획된 
시스템 유지 관리 또는 계획되지 않은 서비스 중단에 대해 5 분의 복구 지점 목표(RPO)를 
가지고 있습니다. 회사는 파일 시스템을 us-west-2 리전에 복제해야 합니다. 복제된 
데이터는 5 년 동안 어떤 사용자도 삭제해서는 안 됩니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 단일 AZ 2 배포 유형을 사용하는 us-east-1 에 FSx for Windows File Server 파일 
시스템을 생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 
포함된 일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 규정 준수 모드로 
AWS Backup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다. 
B. 다중 AZ 배포 유형이 있는 us-east-1 에 FSx for Windows File Server 파일 시스템을 
생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 포함된 
일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 거버넌스 모드에서 AWS 
Backup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다. 
C. 다중 AZ 배포 유형이 있는 us-east-1 에 FSx for Windows File Server 파일 시스템을 
생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 포함된 
일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 규정 준수 모드로 AWS 
Backup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다. 
D. 단일 AZ 2 배포 유형이 있는 us-east-1 에 FSx for Windows File Server 파일 시스템을 
생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 포함된 
일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 거버넌스 모드에서 AWS 
Backup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/121219-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q619 
솔루션 아키텍트는 표준 보안 제어를 유지하면서 AWS Organizations 를 통해 개발자에게 
개별 AWS 계정을 제공하려는 회사를 위한 보안 솔루션을 설계하고 있습니다. 개별 
개발자는 자신의 계정에 대해 AWS 계정 루트 사용자 수준 액세스 권한을 가지게 되므로 
솔루션 설계자는 새 개발자 계정에 적용되는 필수 AWS CloudTrail 구성이 수정되지 
않았는지 확인하려고 합니다. 
이러한 요구사항을 충족하는 작업은 무엇인가요? 
A. CloudTrail 변경을 금지하는 IAM 정책을 생성합니다. 루트 사용자에게 연결합니다. 
B. 조직 추적 옵션이 활성화된 개발자 계정 내에서 CloudTrail 에 새 추적을 생성합니다. 
C. CloudTrail 변경을 금지하는 서비스 제어 정책(SCP)을 생성하고 이를 개발자 계정에 
연결합니다. 
D. 마스터 계정의 Amazon 리소스 이름(ARN)에서만 변경을 허용하는 정책 조건을 
사용하여 CloudTrail 에 대한 서비스 연결 역할을 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/121220-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q620 
한 회사가 AWS 클라우드에 비즈니스에 중요한 애플리케이션을 배포할 계획입니다. 
애플리케이션에는 일관되고 지연 시간이 짧은 성능을 갖춘 내구성 있는 스토리지가 
필요합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 유형의 스토리지를 권장해야 
합니까? 
A. 인스턴스 스토어 볼륨 
B. Memcached 클러스터용 Amazon ElastiCache 
C. 프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨 
D. 처리량 최적화 HDD Amazon Elastic Block Store(Amazon EBS) 볼륨 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/121221-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q621 
온라인 사진 공유 회사는 us-west-1 지역에 있는 Amazon S3 버킷에 사진을 저장합니다. 
회사는 us-east-1 지역에 모든 새 사진의 사본을 저장해야 합니다. 
최소한의 운영 노력으로 이 요구 사항을 충족할 수 있는 솔루션은 무엇입니까? 
A. us-east-1 에 두 번째 S3 버킷을 생성합니다. S3 교차 리전 복제를 사용하여 기존 S3 
버킷의 사진을 두 번째 S3 버킷으로 복사합니다. 
B. 기존 S3 버킷의 CORS(교차 원본 리소스 공유) 구성을 생성합니다. CORS 규칙의 
AllowedOrigin 요소에 us-east-1 을 지정합니다. 
C. 여러 가용 영역에 걸쳐 us-east-1 에 두 번째 S3 버킷을 생성합니다. S3 수명 주기 
규칙을 생성하여 두 번째 S3 버킷에 사진을 저장합니다. 
D. us-east-1 에 두 번째 S3 버킷을 생성합니다. 객체 생성 및 업데이트 이벤트에 대한 S3 
이벤트 알림을 구성하여 AWS Lambda 함수를 호출하여 기존 S3 버킷의 사진을 두 번째 
S3 버킷으로 복사합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/121222-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: ・ 
* 요구 사항 이해: 
회사는 us-west-1 지역의 S3 버킷에서 useast-1 지역의 모든 새 사진 사본을 저장해야 
합니다. 
* 옵션 분석: 
* 지역 간 복제: 
구성되면 최소한의 운영 노력으로 여러 지역에 객체를 자동으로 복제합니다. 
* CORS 구성: 
복제가 아닌 다른 도메인에서 웹 페이지의 리소스를 요청하는 데 사용됩니다. 
* S3 수명 주기 규칙: 
지역 간 복제가 아닌 동일한 버킷 내에서 스토리지 클래스 간의 객체 전환을 관리합니다. 
* Lambda 를 사용한 S3 이벤트 알림: 
지역 간 복제에 비해 추가 구성 및 관리가 필요합니다. 
* 최상의 솔루션: 
* S3 지역 간 복제: 
이 솔루션은 최소한의 운영 노력으로 요구 사항을 충족하면서 객체를 다른 지역에 복제하는 
자동화되고 효율적인 방법을 제공합니다. 
Q622 
한 회사에서 구독자를 위한 새로운 웹 애플리케이션을 만들고 있습니다. 애플리케이션은 
정적 단일 페이지와 영구 데이터베이스 계층으로 구성됩니다. 아침에 4 시간 동안 
애플리케이션의 사용자는 수백만 명에 달하지만 나머지 시간에는 애플리케이션의 사용자가 
수천 명에 불과합니다. 회사의 데이터 설계자는 스키마를 빠르게 발전시킬 수 있는 기능을 
요청했습니다. 
이러한 요구 사항을 충족하고 가장 뛰어난 확장성을 제공하는 솔루션은 무엇입니까? (2 개 
선택) 
A. Amazon DynamoDB 를 데이터베이스 솔루션으로 배포합니다. 온디맨드 용량을 
프로비저닝합니다. 
B. Amazon Aurora 를 데이터베이스 솔루션으로 배포합니다. 서버리스 DB 엔진 모드를 
선택합니다. 
C. Amazon DynamoDB 를 데이터베이스 솔루션으로 배포합니다. DynamoDB Auto Scaling 이 
활성화되어 있는지 확인합니다. 
D. 정적 콘텐츠를 Amazon S3 버킷에 배포합니다. S3 버킷을 원본으로 사용하여 Amazon 
CloudFront 배포를 프로비저닝합니다. 
E. Auto Scaling 그룹의 Amazon EC2 인스턴스 전체에 정적 콘텐츠용 웹 서버를 배포합니다. 
Amazon Elastic File System(Amazon EFS) 볼륨의 콘텐츠를 주기적으로 새로 고치도록 
인스턴스를 구성합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/121223-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
C, D?? 
Q623 
회사는 Amazon API Gateway 를 사용하여 타사 서비스 공급자가 액세스하는 REST API 를 
관리합니다. 회사는 SQL 주입 및 크로스 사이트 스크립팅 공격으로부터 REST API 를 
보호해야 합니다. 
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까? 
A. AWS Shield 를 구성합니다. 
B. AWS WAF 를 구성합니다. 
C. Amazon CloudFront 배포를 사용하여 API 게이트웨이를 설정합니다. CloudFront 에서 
AWS Shield 를 구성합니다. 
D. Amazon CloudFront 배포로 API 게이트웨이를 설정합니다. CloudFront 에서 AWS WAF 를 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/121172-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* CloudFront 가 포함된 Amazon API Gateway: API Gateway 를 사용하면 API 를 생성, 배포 
및 관리할 수 있으며, CloudFront 는 짧은 지연 시간과 빠른 전송 속도로 콘텐츠를 제공하는 
CDN 을 제공합니다. 
* AWS WAF(웹 애플리케이션 방화벽): 
* SQL 주입 및 XSS(교차 사이트 스크립팅)를 비롯한 일반적인 웹 공격으로부터 보호하기 
위해 CloudFront 에서 AWS WAF 를 구성할 수 있습니다. 
* WAF 를 사용하면 특정 공격 패턴을 차단하는 사용자 지정 규칙을 생성하고 중앙에서 
관리할 수 있습니다. 
* 구성: 
* Amazon API Gateway 를 사용하여 API 를 배포합니다. 
* API 게이트웨이 앞에 Amazon CloudFront 배포를 설정합니다. 
* CloudFront 배포에서 AWS WAF 를 구성하여 보안 규칙을 적용합니다. 
* 운영 효율성: 이 솔루션은 관리형 AWS 서비스를 활용하여 최소한의 운영 오버헤드로 
강력한 보호 기능을 제공하므로 광범위한 사용자 지정 구현 없이 API의 보안을 보장합니다. 
Q624 
회사에서는 사용자에게 AWS 리소스에 대한 액세스 권한을 제공하려고 합니다. 이 회사에는 
1,500 명의 사용자가 있으며 회사 네트워크의 Active Directory 사용자 그룹을 통해 
온프레미스 리소스에 대한 액세스를 관리합니다. 그러나 회사는 사용자가 리소스에 
액세스하기 위해 다른 ID 를 유지해야 하는 것을 원하지 않습니다. 솔루션 아키텍트는 
온프레미스 리소스에 대한 액세스를 유지하면서 AWS 리소스에 대한 사용자 액세스를 
관리해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 회사의 각 사용자에 대해 IAM 사용자를 생성합니다. 각 사용자에게 적절한 정책을 
연결합니다. 
B. Active Directory 사용자 풀과 함께 Amazon Cognito 를 사용하십시오. 적절한 정책이 
연결된 역할을 생성합니다. 
C. 적절한 정책이 연결된 교차 계정 역할을 정의합니다. 역할을 Active Directory 그룹에 
매핑합니다. 
D. SAML(Security Assertion Markup Language) 2 0 기반 페더레이션을 구성합니다. 적절한 
정책이 연결된 역할을 생성합니다. 역할을 Active Directory 그룹에 매핑합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/125336-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q625 
한 회사가 여러 Application Load Balancer 뒤에 웹사이트를 호스팅하고 있습니다. 회사는 
전 세계적으로 콘텐츠에 대해 다양한 배포 권한을 가지고 있습니다. 솔루션 설계자는 배포 
권한을 위반하지 않고 사용자에게 올바른 콘텐츠가 제공되도록 해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 구성을 선택해야 합니까? 
A. AWS WAF 로 Amazon CloudFront 를 구성합니다. 
B. AWS WAF 로 Application Load Balancer 구성 
C. 지리적 위치 정책으로 Amazon Route 53 구성 
D. 지리 근접 라우팅 정책으로 Amazon Route 53 구성 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125337-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q626 
회사는 데이터를 온프레미스에 저장합니다. 데이터의 양은 회사가 사용할 수 있는 용량을 
초과하여 증가하고 있습니다. 회사는 온프레미스 위치에서 Amazon S3 버킷으로 데이터를 
마이그레이션하려고 합니다. 회사에는 전송 후 데이터 무결성을 자동으로 검증하는 
솔루션이 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Snowball Edge 디바이스 주문 S3 버킷으로의 온라인 데이터 전송을 수행하도록 
Snowball Edge 디바이스를 구성합니다. 
B. AWS DataSync 에이전트를 온프레미스에 배포합니다. S3 버킷으로의 온라인 데이터 
전송을 수행하도록 DataSync 에이전트를 구성합니다. 
C. 온프레미스에서 Amazon S3 파일 게이트웨이를 생성합니다. S3 버킷으로의 온라인 
데이터 전송을 수행하도록 S3 파일 게이트웨이를 구성합니다. 
D. 온프레미스에서 Amazon S3 Transfer Acceleration 에 액셀러레이터를 구성합니다. S3 
버킷으로의 온라인 데이터 전송을 수행하도록 액셀러레이터를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/125338-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 온프레미스 위치에서 Amazon S3 버킷으로 데이터를 마이그레이션하고 
전송 후 데이터 무결성을 자동으로 확인할 수 있습니다. AWS DataSync 에이전트를 
온프레미스에 배포함으로써 회사는 AWS 에서 대량의 데이터를 쉽게 이동할 수 있는 완전 
관리형 데이터 전송 서비스를 사용할 수 있습니다. S3 버킷으로의 온라인 데이터 전송을 
수행하도록 DataSync 에이전트를 구성함으로써 회사는 암호화, 압축, 대역폭 조절, 데이터 
검증과 같은 DataSync 의 기능을 활용할 수 있습니다. DataSync 는 각 전송 작업 후에 
소스와 대상 모두에서 데이터 무결성을 자동으로 확인합니다. 
Q627 
한 회사에서 두 대의 DNS 서버를 AWS 로 마이그레이션하려고 합니다. 이 서버는 총 약 
200 개의 영역을 호스팅하며 매일 평균 1 백만 건의 요청을 수신합니다. 이 회사는 두 
서버의 관리와 관련된 운영 오버헤드를 최소화하면서 가용성을 최대화하고자 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 추천해야 하나요? 
A. Amazon Route 53 콘솔 가져오기 영역 파일에서 200 개의 새 호스트 영역을 만듭니다. 
B. 하나의 대규모 Amazon EC2 인스턴스를 실행하여 영역 타일을 가져옵니다. 다운타임이 
발생하면 회사에 알릴 수 있도록 Amazon CloudWatch 알람 및 알림을 구성합니다. 
C. AWS 서버 마이그레이션 서비스(AWS SMS)를 사용하여 서버를 AWS 로 
마이그레이션합니다. 다운타임에 대해 회사에 알리도록 Amazon CloudWatch 알람 및 
알림을 구성합니다. 
D. 두 개의 가용 영역에 걸쳐 자동 확장 그룹에서 Amazon EC2 인스턴스를 시작합니다. 
영역 파일을 가져옵니다. 자동 스케일링 그룹에 대해 원하는 용량을 1 로 설정하고 최대 
용량을 3 으로 설정합니다. CPU 사용률에 따라 확장하도록 확장 알람을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/125541-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q628 
한 글로벌 기업이 AWS Organizations 의 여러 AWS 계정에서 애플리케이션을 실행합니다. 
회사의 애플리케이션은 멀티파트 업로드를 사용하여 AWS 리전의 여러 Amazon S3 버킷에 
데이터를 업로드합니다. 회사는 비용 준수 목적으로 불완전한 멀티파트 업로드에 대해 
보고하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 불완전한 멀티파트 업로드 객체 수를 보고하는 규칙으로 AWS Config 를 구성합니다. 
B. 불완전한 멀티파트 업로드 개체 수를 보고하는 SCP(서비스 제어 정책)를 만듭니다. 
C. 불완전한 멀티파트 업로드 객체 수를 보고하도록 S3 스토리지 렌즈를 구성합니다. 
D. S3 다중 지역 액세스 포인트를 생성하여 불완전한 멀티파트 업로드 객체 수를 
보고합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125459-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
S3 Storage Lens 는 AWS Organizations 의 여러 AWS 계정에 걸친 객체 스토리지 사용 및 
활동에 대한 조직 전체의 가시성을 제공하는 클라우드 스토리지 분석 기능입니다. S3 
스토리지 렌즈는 수집하여 S3 콘솔의 대화형 대시보드에 표시하는 지표 중 하나로 
불완전한 멀티파트 업로드 객체 수를 보고할 수 있습니다. S3 Storage Lens 는 추가 분석을 
위해 CSV 또는 Parquet 형식의 지표를 S3 버킷으로 내보낼 수도 있습니다. 이 솔루션은 
코드 개발이나 정책 변경이 필요하지 않으므로 최소한의 운영 오버헤드로 요구 사항을 
충족합니다. 
Q629 
한 회사가 MySQL 용 Amazon RDS 에서 프로덕션 데이터베이스를 실행하고 있습니다. 
회사에서는 보안 규정 준수를 위해 데이터베이스 버전을 업그레이드하려고 합니다. 
데이터베이스에는 중요한 데이터가 포함되어 있으므로 회사에서는 데이터 손실 없이 기능을 
업그레이드하고 테스트할 수 있는 빠른 솔루션을 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. RDS 수동 스냅샷을 생성합니다. MySQL 용 Amazon RDS 의 새 버전으로 
업그레이드하세요. 
B. 기본 백업 및 복원을 사용합니다. 업그레이드된 새 버전의 MySQL 용 Amazon RDS 로 
데이터를 복원합니다. 
C. AWS Database Migration Service(AWS DMS)를 사용하여 업그레이드된 새 버전의 
MySQL 용 Amazon RDS 에 데이터를 복제합니다. 
D. Amazon RDS 블루/그린 배포를 사용하여 프로덕션 변경 사항을 배포하고 테스트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/125460-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q630 
솔루션 설계자가 매일 한 번 실행되고 완료하는 데 최대 2 시간이 걸리는 데이터 처리 
작업을 만들고 있습니다. 작업이 중단되면 처음부터 다시 시작해야 합니다. 
솔루션 설계자가 가장 비용 효율적인 방식으로 이 문제를 해결하려면 어떻게 해야 하나요? 
A. 크론 작업에 의해 트리거되는 Amazon EC2 예약 인스턴스에서 로컬로 실행되는 
스크립트를 만듭니다. 
B. Amazon EventBridge 예약 이벤트에 의해 트리거되는 AWS Lambda 함수를 생성합니다. 
C. Amazon EventBridge 예약 이벤트에 의해 트리거되는 Amazon ECS(Amazon Elastic 
Container Service) Fargate 작업을 사용합니다. 
D. Amazon EventBridge 예약 이벤트에 의해 트리거된 Amazon EC2 에서 실행되는 Amazon 
ECS(Amazon Elastic Container Service) 작업을 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125542-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q631 
소셜 미디어 회사는 사용자 프로필, 관계 및 상호 작용에 대한 데이터베이스를 AWS 
클라우드에 저장하려고 합니다. 회사에는 데이터베이스의 변경 사항을 모니터링하는 
애플리케이션이 필요합니다. 애플리케이션은 데이터 엔터티 간의 관계를 분석하고 
사용자에게 권장 사항을 제공해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Neptune 을 사용하여 정보를 저장하십시오. Amazon Kinesis Data Streams 를 
사용하여 데이터베이스의 변경 사항을 처리합니다. 
B. Amazon Neptune 을 사용하여 정보를 저장합니다. Neptune Streams 를 사용하여 
데이터베이스의 변경 사항을 처리합니다. 
C. Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. 
Amazon Kinesis Data Streams 를 사용하여 데이터베이스의 변경 사항을 처리합니다. 
D. Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. 
Neptune Streams 를 사용하여 데이터베이스의 변경 사항을 처리합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/125113-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Amazon Neptune: Neptune 은 고도로 연결된 데이터를 저장하고 쿼리하는 데 최적화된 
완전관리형 그래프 데이터베이스 서비스입니다. 속성 그래프와 RDF 그래프 모델을 모두 
지원하므로 데이터 엔터티 간의 관계를 분석해야 하는 애플리케이션에 적합합니다. 
* Neptune Streams: Neptune Streams 는 그래프의 변경 사항을 캡처하고 이러한 변경 
사항을 다른 AWS 서비스로 스트리밍합니다. 이는 사용자 상호 작용 및 관계를 기반으로 
권장 사항을 제공하는 등 실시간 변경 사항을 모니터링하고 대응해야 하는 애플리케이션에 
유용합니다. 
* 최소 운영 오버헤드: Amazon Neptune 과 함께 Neptune Streams 를 직접 사용하면 
솔루션이 긴밀하게 통합되어 추가 구성 요소의 필요성이 줄어들고 운영 오버헤드가 
최소화됩니다. 이러한 통합은 변경 처리를 위해 Kinesis 와 같은 별도의 서비스가 필요하지 
않음으로써 아키텍처를 단순화합니다. 
Q632 
한 회사에서 대량의 데이터를 저장할 새로운 애플리케이션을 만들고 있습니다. 데이터는 
매시간 분석되며 여러 가용 영역에 배포된 여러 Amazon EC2 Linux 인스턴스에 의해 
수정됩니다. 필요한 저장 공간의 양은 향후 6 개월 동안 계속 증가할 것입니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 스토리지 솔루션을 권장해야 
합니까? 
A. Amazon S3 Glacier 에 데이터를 저장합니다. 애플리케이션 인스턴스에 대한 액세스를 
허용하도록 S3 Glacier 볼트 정책을 업데이트합니다. 
B. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 애플리케이션 
인스턴스에 EBS 볼륨을 탑재합니다. 
C. Amazon Elastic File System(Amazon EFS) 파일 시스템에 데이터를 저장합니다. 
애플리케이션 인스턴스에 파일 시스템을 마운트합니다. 
D. 애플리케이션 인스턴스 간에 공유되는 Amazon Elastic Block Store(Amazon EBS) 
프로비저닝된 IOPS 볼륨에 데이터를 저장합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125114-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q633 
회사는 PostgreSQL 다중 AZ DB 인스턴스용 Amazon RDS 에 데이터를 저장하는 
애플리케이션을 관리합니다. 트래픽 증가로 인해 성능 문제가 발생합니다. 회사에서는 
데이터베이스 쿼리가 성능 저하의 주요 원인이라고 판단합니다. 
솔루션 아키텍트는 애플리케이션 성능을 향상시키기 위해 무엇을 해야 합니까? 
A. 다중 AZ 대기 복제본에서 읽기 트래픽을 제공합니다. 
B. Transfer Acceleration 을 사용하도록 DB 인스턴스를 구성합니다. 
C. 원본 DB 인스턴스에서 읽기 전용 복제본을 생성합니다. 읽기 복제본에서 읽기 트래픽을 
제공합니다. 
D. 애플리케이션과 Amazon RDS 사이에 Amazon Kinesis Data Firehose 를 사용하여 
데이터베이스 요청의 동시성을 높입니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125513-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q634 
한 회사에서 다양한 기계에서 매일 10GB 의 원격 분석 데이터를 수집합니다. 이 회사는 
소스 데이터 계정의 Amazon S3 버킷에 데이터를 저장합니다. 
이 회사는 이 데이터를 분석에 사용하기 위해 여러 컨설팅 기관을 고용했습니다. 각 
대행사는 분석가를 위해 데이터에 대한 읽기 액세스 권한이 필요합니다. 회사는 보안과 
운영 효율성을 극대화하는 솔루션을 선택하여 소스 데이터 계정의 데이터를 공유해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇인가요? 
A. 각 기관의 데이터를 복제하도록 S3 글로벌 테이블을 구성합니다. 
B. S3 버킷을 제한된 시간 동안 공개합니다. 에이전시에게만 알립니다. 
C. 대행사가 소유한 계정에 대한 S3 버킷의 교차 계정 액세스를 구성합니다. 
D. 소스 데이터 계정의 각 분석가에 대해 IAM 사용자를 설정합니다. 각 사용자에게 S3 
버킷에 대한 액세스 권한을 부여합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125544-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q635 
한 회사에서 기본 AWS 리전에서 CIFS 및 NFS 파일 공유를 위해 NetApp ONTAP 용 
Amazon FSx 를 사용합니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션은 파일 
공유에 액세스합니다. 이 회사는 보조 리전에 스토리지 재해 복구(DR) 솔루션이 필요합니다. 
보조 리전에 복제된 데이터는 기본 리전과 동일한 프로토콜을 사용하여 액세스해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇인가요? 
A. 데이터를 Amazon S3 버킷에 복사하는 AWS 람다 함수를 생성합니다. S3 버킷을 보조 
리전으로 복제합니다. 
B. AWS 백업을 사용하여 ONTAP 용 FSx 볼륨의 백업을 생성합니다. 볼륨을 보조 리전으로 
복사합니다. 백업에서 새 FSx for ONTAP 인스턴스를 생성합니다. 
C. 보조 리전에 ONTAP 용 FSx 인스턴스를 생성합니다. NetApp SnapMirror 를 사용하여 
기본 리전에서 보조 리전으로 데이터를 복제합니다. 
D. Amazon Elastic 파일 시스템(Amazon EFS) 볼륨을 생성합니다. 현재 데이터를 볼륨으로 
마이그레이션합니다. 볼륨을 보조 리전으로 복제합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125545-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q636 
개발팀에서 AWS 람다 함수를 사용하는 이벤트 기반 애플리케이션을 만들고 있습니다. 
Amazon S3 버킷에 파일이 추가될 때 이벤트가 생성됩니다. 개발팀은 현재 Amazon S3 의 
이벤트 대상으로 Amazon SNS(Amazon Simple Notification Service)를 구성하고 있습니다. 
확장 가능한 방식으로 Amazon S3 의 이벤트를 처리하기 위해 솔루션 설계자는 무엇을 해야 
하나요? 
A. 이벤트가 Lambda 에서 실행되기 전에 Amazon ECS(Amazon Elastic Container 
Service)에서 이벤트를 처리하는 SNS 구독을 생성합니다. 
B. 이벤트가 Lambda 에서 실행되기 전에 Amazon Elastic Kubernetes Service(Amazon 
EKS)에서 이벤트를 처리하는 SNS 구독을 생성합니다. 
C. 이벤트를 Amazon SQS(Amazon Simple Queue Service)로 전송하는 SNS 구독을 
생성합니다. Lambda 함수를 트리거하도록 SOS 대기열을 구성합니다. 
D. AWS 서버 마이그레이션 서비스(AWS SMS)로 이벤트를 전송하는 SNS 구독을 만듭니다. 
SMS 이벤트에서 폴링하도록 람다 함수를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125546-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q637 
솔루션 설계자가 Amazon API 게이트웨이를 기반으로 새로운 서비스를 설계하고 있습니다. 
이 서비스의 요청 패턴은 예측할 수 없으며 초당 0 건의 요청에서 500 건 이상으로 갑자기 
변경될 수 있습니다. 백엔드 데이터베이스에 보존해야 하는 데이터의 총 크기는 현재 1GB 
미만이며 향후 증가를 예측할 수 없습니다. 데이터는 간단한 키-값 요청을 사용하여 쿼리할 
수 있습니다. 
이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇인가요? (두 가지 선택) 
A. AWS Fargate 
B. AWS Lambda 
C. Amazon DynamoDB 
D. Amazon EC2 Auto Scaling 
E. MySQL-compatible Amazon Aurora 
Answer: B, C 
https://www.examtopics.com/discussions/amazon/view/125547-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q638 
한 회사에서 연구 데이터를 수집하여 전 세계 직원들과 공유하고 있습니다. 이 회사는 
데이터를 수집하여 Amazon S3 버킷에 저장하고 AWS 클라우드에서 데이터를 처리하려고 
합니다. 회사는 데이터를 회사 직원들과 공유할 것입니다. 이 회사는 운영 오버헤드를 
최소화하는 AWS 클라우드의 안전한 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇인가요? 
A. AWS 람다 함수를 사용하여 S3 사전 지정 URL 을 생성합니다. 직원들에게 해당 URL 을 
사용하도록 지시합니다. 
B. 각 직원에 대해 IAM 사용자를 만듭니다. 각 직원에 대해 S3 액세스를 허용하는 IAM 
정책을 만듭니다. 직원들에게 AWS 관리 콘솔을 사용하도록 지시합니다. 
C. S3 파일 게이트웨이를 만듭니다. 업로드용 공유와 다운로드용 공유를 만듭니다. 직원이 
로컬 컴퓨터에 공유를 마운트하여 S3 파일 게이트웨이를 사용하도록 허용합니다. 
D. AWS Transfer Family SFTP 엔드포인트를 구성합니다. 사용자 지정 ID 공급자 옵션을 
선택합니다. AWS Secrets Manager 를 사용하여 사용자 자격 증명을 관리합니다. 직원들에게 
Transfer Family 를 사용하도록 지시합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/125574-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
C?? 
Q639 
한 회사에서 새로운 가구 재고 애플리케이션을 구축하고 있습니다. 이 회사는 여러 가용 
영역에 걸쳐 여러 개의 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. EC2 
인스턴스는 VPC 의 애플리케이션 로드 밸런서(ALB) 뒤에서 실행됩니다. 
솔루션 설계자가 들어오는 트래픽이 하나의 EC2 인스턴스에 편중되어 일부 요청에 대한 
지연 시간이 발생하는 것을 관찰했습니다. 
이 문제를 해결하려면 솔루션 설계자는 어떻게 해야 하나요? 
A. ALB 에서 세션 선호도(스티키 세션)를 비활성화합니다. 
B. ALB 를 네트워크 로드 밸런서로 교체합니다. 
C. 각 가용 영역에서 EC2 인스턴스 수 늘리기 
D. ALB 의 대상 그룹에 대한 상태 확인 빈도 조정 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/125575-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q640 
한 회사에서 AWS 람다 함수를 사용하여 Amazon S3 에서 파일을 다운로드하고 암호를 
해독하는 애플리케이션 워크플로우가 있습니다. 이러한 파일은 AWS 키 관리 서비스(AWS 
KMS) 키를 사용하여 암호화됩니다. 솔루션 설계자는 필요한 권한이 올바르게 설정되도록 
보장하는 솔루션을 설계해야 합니다. 
어떤 작업 조합으로 이를 달성할 수 있나요? (두 가지 선택) 
A. 람다 함수의 리소스 정책에 kms:암호 해독 권한을 첨부합니다. 
B. KMS 키의 정책에서 Lambda IAM 역할에 대한 암호 해독 권한을 부여합니다. 
C. KMS 키의 정책에서 Lambda 리소스 정책에 대한 암호 해독 권한을 부여합니다. 
D. kms:암호 해독 권한이 있는 새 IAM 정책을 만들고 이 정책을 Lambda 함수에 
첨부합니다. 
E. kms:암호 해독 권한이 있는 새 IAM 역할을 만들고 실행 역할을 Lambda 함수에 
연결합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/125579-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q641 
회사에서 재무 검토를 위해 AWS 비용을 모니터링하려고 합니다. 클라우드 운영팀은 AWS 
조직 관리 계정에서 모든 구성원 계정에 대한 AWS 비용 및 사용량 보고서를 쿼리하는 
아키텍처를 설계하고 있습니다. 팀은 이 쿼리를 한 달에 한 번 실행하고 청구서에 대한 
자세한 분석을 제공해야 합니다. 
이러한 요구 사항을 충족하는 가장 확장 가능하고 비용 효율적인 방법은 무엇인가요? 
A. 관리 계정에서 비용 및 사용량 보고서를 사용 설정합니다. Amazon Kinesis 에 보고서를 
전달합니다. 분석을 위해 Amazon EMR 을 사용합니다. 
B. 관리 계정에서 비용 및 사용량 보고서를 활성화합니다. Amazon S3 에 보고서를 
전달합니다. 분석을 위해 Amazon Athena 를 사용합니다. 
C. 회원 계정에 대한 비용 및 사용량 보고서를 활성화합니다. Amazon S3 에 보고서를 
전달합니다. 분석을 위해 Amazon Redshift 를 사용합니다. 
D. 회원 계정에 대한 비용 및 사용량 보고서를 사용하도록 설정합니다. Amazon Kinesis 에 
보고서를 전달합니다. 분석을 위해 Amazon QuickSight 를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/125580-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q642 
회사에서 AWS 클라우드의 Auto Scaling 그룹에 속한 Amazon EC2 인스턴스에서 게임 
애플리케이션을 실행하려고 합니다. 응용 프로그램은 UDP 패킷을 사용하여 데이터를 
전송합니다. 회사는 트래픽이 증가하거나 감소함에 따라 애플리케이션이 확장 및 축소될 수 
있도록 하려고 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Auto Scaling 그룹에 Network Load Balancer 를 연결합니다. 
B. Auto Scaling 그룹에 Application Load Balancer 를 연결합니다. 
C. 트래픽을 적절하게 라우팅하기 위해 가중치 정책이 있는 Amazon Route 53 레코드 
세트를 배포합니다. 
D. Auto Scaling 그룹의 EC2 인스턴스에 포트 전달로 구성된 NAT 인스턴스를 배포합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/125215-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 UDP 패킷을 사용하고 트래픽이 증가 및 감소함에 따라 확장 및 축소하여 
데이터를 전송하는 게임 애플리케이션 실행 요구 사항을 충족합니다. Network Load 
Balancer 는 매우 낮은 대기 시간으로 높은 처리량을 유지하면서 초당 수백만 건의 요청을 
처리할 수 있으며 TCP 및 UDP 프로토콜을 모두 지원합니다. Auto Scaling 그룹은 수요 및 
조정 정책에 따라 EC2 인스턴스 수를 자동으로 조정할 수 있습니다. 
Application Load Balancer 가 UDP 프로토콜을 지원하지 않고 HTTP 및 HTTPS 만 지원하기 
때문에 옵션 B 는 올바르지 않습니다. 
Amazon Route 53 은 다양한 정책을 기반으로 트래픽을 라우팅할 수 있는 DNS 
서비스이지만 로드 밸런싱 또는 확장 기능을 제공하지 않기 때문에 옵션 C 는 올바르지 
않습니다. 
옵션 D 는 
NAT 인스턴스는 프라이빗 서브넷의 인스턴스를 인터넷 또는 다른 AWS 서비스에 연결하는 
데 사용되지만 로드 밸런싱 또는 확장 기능을 제공하지 않기 때문에 올바르지 않습니다. 
참조: 
https://aws.amazon.com/blogs/aws/new-udp-load-balancing-for-network-load-balanc
er/ 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html 
A : UDP 패킷을 사용한다고 했으니 네트워크 계층 서비스인 NLB 가 적합. 
Q643 
한 회사에서 여러 브랜드를 위해 AWS 에서 여러 웹사이트를 운영하고 있습니다. 각 
웹사이트는 매일 수십 기가바이트의 웹 트래픽 로그를 생성합니다. 솔루션 설계자는 회사의 
개발자가 회사의 모든 웹사이트에 걸쳐 트래픽 패턴을 분석할 수 있도록 확장 가능한 
솔루션을 설계해야 합니다. 개발자의 이러한 분석은 몇 달에 걸쳐 일주일에 한 번씩 
온디맨드 방식으로 수행됩니다. 솔루션은 표준 SQL 로 쿼리를 지원해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇인가요? 
A. Amazon S3 에 로그를 저장합니다. Amazon Athena 를 사용하여 분석합니다. 
B. 로그를 Amazon RDS 에 저장합니다. 분석을 위해 데이터베이스 클라이언트를 
사용합니다. 
C. 로그를 Amazon OpenSearch Service에 저장합니다. 분석을 위해 OpenSearch Service를 
사용합니다. 
D. 로그를 Amazon EMR 클러스터에 저장합니다. SQL 기반 분석을 위해 지원되는 오픈 
소스 프레임워크를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/125581-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명:・ 
이 솔루션은 대량의 웹 트래픽 로그를 분석하는 데 가장 비용 효율적이고 확장성이 
뛰어납니다. 
Amazon S3: Amazon S3 에 로그를 저장하는 것은 확장성이 뛰어나고 내구성이 뛰어나며 
비용 효율적입니다. S3 는 대규모 데이터 저장소를 처리하도록 설계되어 여러 웹사이트에서 
매일 생성되는 수십 기가바이트의 로그 데이터를 저장하는 데 이상적입니다. 
Amazon Athena: Athena 는 표준 SQL 을 사용하여 S3 의 데이터를 분석할 수 있는 서버리스 
대화형 쿼리 서비스입니다. S3 에 저장된 데이터와 직접 작동하므로 데이터베이스에 
데이터를 로드할 필요가 없어 비용을 절감하고 복잡성을 줄일 수 있습니다. Athena 는 
쿼리에서 스캔한 데이터 양에 따라 요금을 청구하므로 일주일에 한 번만 발생하는 주문형 
분석을 위한 비용 효율적인 솔루션입니다. 
다른 옵션은 왜 안 되나요?: 
옵션 B(Amazon RDS): Amazon RDS 와 같은 관계형 데이터베이스에 로그를 저장하는 것은 
RDS 와 관련된 저장소 및 I/O 비용으로 인해 비용이 더 많이 듭니다. 또한 관리 오버헤드가 
더 많이 필요합니다. 
옵션 C(Amazon OpenSearch 서비스): OpenSearch 는 로그 데이터에 대한 전체 텍스트 
검색 및 분석에 적합한 옵션이지만, 주기적 SQL 기반 쿼리에 대한 Athena 의 단순성과 
비용 효율성에 비해 관리 비용이 더 많이 들고 복잡할 수 있습니다. 
옵션 D(Amazon EMR): EMR 은 대규모 데이터 처리를 처리할 수 있지만, 운영 오버헤드가 
더 많고 여기에서 필요한 임시 SQL 기반 분석 유형에는 과도할 수 있습니다. 
또한 클러스터를 유지 관리해야 하기 때문에 EMR 비용이 더 높을 수 있습니다. 
Q644 
국제적인 회사는 회사가 운영되는 각 국가별로 하위 도메인을 가지고 있습니다. 하위 
도메인의 형식은 example.com, country1.example.com, country2.example.com 입니다. 
회사의 워크로드는 애플리케이션 로드 밸런서 뒤에 있습니다. 회사는 전송 중인 웹사이트 
데이터를 암호화하려고 합니다. 
이러한 요구 사항을 충족하는 단계의 조합은 무엇인가요? (두 가지 선택) 
A. AWS ACM(인증서 관리자) 콘솔을 사용하여 최상위 도메인 example.com 에 대한 일반 
인증서와 *.example.com 에 대한 와일드카드 인증서를 요청합니다. 
B. AWS ACM(인증서 관리자) 콘솔을 사용하여 최상위 도메인 example.com 에 대한 비공개 
인증서 및 *.example.com 에 대한 와일드카드 인증서를 요청합니다. 
C. AWS ACM(인증서 관리자) 콘솔을 사용하여 최상위 도메인 example.com 에 대한 공개 
및 비공개 인증서를 요청합니다. 
D. 이메일 주소로 도메인 소유권을 유효성(검증) 검사합니다. 필요한 DNS 레코드를 DNS 
공급업체에 추가하여 DNS 유효성(검증) 검사로 전환합니다. 
E. DNS 공급업체에 필요한 DNS 레코드를 추가하여 도메인의 도메인 소유권을 유효성(검증) 
검사합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/125582-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q645 
회사는 온프레미스 키 관리자에서 암호화 키를 사용해야 합니다. 키 관리자는 규제 및 규정 
준수 요구 사항으로 인해 AWS 클라우드 외부에 있습니다. 이 회사는 AWS 클라우드 
외부에 보관되어 있고 여러 공급업체의 다양한 외부 키 관리자를 지원하는 암호화 키를 
사용하여 암호화 및 암호 해독을 관리하고자 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇인가요? 
A. CloudHSM 클러스터로 지원되는 AWS CloudHSM 키 저장소를 사용합니다. 
B. 외부 키 관리자가 지원하는 AWS 키 관리 서비스(AWS KMS) 외부 키 저장소를 
사용합니다. 
C. 기본 AWS 키 관리 서비스(AWS KMS) 관리형 키 저장소를 사용합니다. 
D. AWS CloudHSM 클러스터가 지원하는 사용자 지정 키 저장소를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/125583-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q646 
솔루션 설계자는 AWS 클라우드에서 고성능 컴퓨팅(HPC) 워크로드를 호스팅해야 합니다. 
워크로드는 수백 개의 Amazon EC2 인스턴스에서 실행되며 대규모 데이터 세트의 분산 
처리를 위해 공유 파일 시스템에 대한 병렬 액세스가 필요합니다. 데이터 세트는 여러 
인스턴스에서 동시에 액세스됩니다. 워크로드에는 1ms 이내의 액세스 지연 시간이 
필요합니다. 처리가 완료된 후 엔지니어는 수동 후처리를 위해 데이터 세트에 액세스해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇인가요? 
A. 공유 파일 시스템으로 Amazon EFS(Amazon Elastic File System)를 사용하세요. Amazon 
EFS 에서 데이터 세트에 액세스합니다. 
B. 공유 파일 시스템으로 사용할 Amazon S3 버킷을 마운트합니다. S3 버킷에서 직접 
후처리를 수행합니다. 
C. 공유 파일 시스템으로 Lustre 용 Amazon FSx 를 사용합니다. 후처리를 위해 파일 
시스템을 Amazon S3 버킷에 연결합니다. 
D. 처리 및 후처리를 위해 모든 인스턴스에 마운트할 수 있도록 Amazon S3 버킷을 
공유하도록 AWS 리소스 액세스 관리자를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125584-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q647 
한 게임 회사에서 VoIP(Voice over IP)를 사용하여 애플리케이션을 구축하고 있습니다. 
능력. 이 애플리케이션은 전 세계 사용자에게 트래픽을 제공합니다. 애플리케이션은 AWS 
리전 전체에 걸쳐 자동화된 장애 조치를 통해 가용성이 높아야 합니다. 회사는 사용자 
장치의 IP 주소 캐싱에 의존하지 않고 사용자의 대기 시간을 최소화하려고 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 상태 확인과 함께 AWS Global Accelerator 를 사용하십시오. 
B. 지리적 위치 라우팅 정책과 함께 Amazon Route 53 을 사용하십시오. 
C. 여러 오리진을 포함하는 Amazon CloudFront 배포를 생성합니다. 
D. 경로 기반 라우팅을 사용하는 Application Load Balancer 를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/125212-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q648 
일기 예보 회사는 수백 기가바이트의 데이터를 밀리초 미만의 지연 시간으로 처리해야 
합니다. 이 회사는 데이터 센터에 고성능 컴퓨팅(HPC) 환경을 갖추고 있으며 예보 기능을 
확장하고자 합니다. 
솔루션 설계자는 대량의 지속적인 처리량을 처리할 수 있는 고가용성 클라우드 스토리지 
솔루션을 찾아야 합니다. 솔루션에 저장된 파일은 전체 데이터 세트에 동시에 액세스하고 
처리할 수 있는 수천 개의 컴퓨팅 인스턴스에서 액세스할 수 있어야 합니다. 
이러한 요구사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 하나요? 
A. Lustre 스크래치 파일 시스템용 Amazon FSx 를 사용합니다. 
B. Lustre 퍼시스턴트 파일 시스템용 Amazon FSx 를 사용합니다. 
C. 버스팅 처리량 모드와 함께 Amazon Elastic 파일 시스템(Amazon EFS)을 사용합니다. 
D. 프로비저닝된 처리량 모드와 함께 Amazon EFS(Amazon Elastic File System)를 
사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/125586-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Amazon FSx for Lustre: Lustre 는 지속적으로 높은 처리량과 낮은 지연 시간을 갖춘 빠른 
스토리지가 필요한 워크로드를 위해 설계된 고성능 파일 시스템입니다. Amazon S3 와 
통합되어 HPC 환경에 적합합니다. 
* 영구 파일 시스템: 
* 영구 저장: 장기 저장 및 반복 사용에 적합하여 내구성과 가용성을 제공합니다. 
* 높은 처리량 및 낮은 대기 시간: 영구 Lustre 파일 시스템은 밀리초 미만의 대기 
시간으로 대량의 데이터를 처리하여 고성능 컴퓨팅 워크로드의 요구 사항을 충족할 수 
있습니다. 
* 동시 액세스: FSx for Lustre 를 사용하면 수천 개의 컴퓨팅 인스턴스가 대규모 데이터 
세트에 동시에 액세스하고 처리할 수 있어 대용량 데이터를 효율적으로 처리할 수 
있습니다. 
* 고가용성: FSx for Lustre 는 고가용성을 제공하도록 설계되었으며 AWS 에서 관리되므로 
운영 부담이 줄어듭니다. 
Q649 
전자 상거래 회사는 온프레미스에서 PostgreSQL 데이터베이스를 운영합니다. 
데이터베이스는 높은 IOPS 의 Amazon EBS(Amazon Elastic Block Store) 블록 스토리지를 
사용하여 데이터를 저장합니다. 초당 일일 피크 I/O 트랜잭션은 15,000 IOPS 를 초과하지 
않습니다. 이 회사는 데이터베이스를 PostgreSQL 용 Amazon RDS 로 마이그레이션하고 
디스크 스토리지 용량과 무관하게 디스크 IOPS 성능을 프로비저닝하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇인가요? 
A. 범용 SSD(gp2) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS 를 프로비저닝합니다. 
B. 프로비저닝된 IOPS SSD(io1) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS 를 
프로비저닝합니다. 
C. 범용 SSD(gp3) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS 를 프로비저닝합니다. 
D. EBS 마그네틱 볼륨 유형을 구성하여 최대 IOPS 를 달성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125588-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q650 
한 회사에서 온프레미스 Microsoft SQL Server 엔터프라이즈 에디션 데이터베이스를 
AWS 로 마이그레이션하려고 합니다. 회사의 온라인 애플리케이션은 이 데이터베이스를 
사용하여 트랜잭션을 처리합니다. 데이터 분석 팀은 동일한 프로덕션 데이터베이스를 
사용하여 분석 처리를 위한 보고서를 실행합니다. 이 회사는 가능한 한 관리형 서비스로 
전환하여 운영 오버헤드를 줄이려고 합니다. 
운영 오버헤드가 가장 적으면서 이러한 요구 사항을 충족하는 솔루션은 무엇인가요? 
A. Microsoft SOL Server 용 Amazon RDS 로 마이그레이션합니다. 보고 목적으로 읽기 
복제본 사용 
B. Amazon EC2 의 Microsoft SQL Server 로 마이그레이션합니다. 보고 목적으로 항상 켜짐 
읽기 복제본 사용 
C. Amazon DynamoDB 로 마이그레이션합니다. 보고 목적으로 DynamoDB 온디맨드 
복제본을 사용합니다. 
D. Amazon Aurora MySQL 로 마이그레이션합니다. 보고 목적으로 Aurora 읽기 복제본 사용 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/125589-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q651 
회사는 Amazon S3 버킷에 대량의 이미지 파일을 저장합니다. 이미지는 처음 180 일 동안 
쉽게 사용할 수 있어야 합니다. 다음 180 일 동안 이미지에 자주 액세스하지 않습니다. 
360 일이 지나면 이미지를 보관해야 하지만 요청 시 즉시 사용할 수 있어야 합니다. 5 년 
후에는 감사자만 이미지에 액세스할 수 있습니다. 감사자는 12 시간 이내에 이미지를 
검색할 수 있어야 합니다. 이 과정에서 이미지가 손실될 수 없습니다. 
개발자는 처음 180 일 동안 S3 Standard 스토리지를 사용합니다. 개발자는 S3 수명 주기 
규칙을 구성해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 180 일 후에 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 
360 일 후 S3 Glacier 즉시 검색, 5 년 후 S3 Glacier Deep Archive. 
B. 180 일 후에 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 
360 일 후 S3 Glacier 유연한 검색 및 5 년 후 S3 Glacier Deep Archive. 
C. 180 일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하고, 360 일 
후에 S3 Glacier Instant Retrieval 로 전환하고, 5 년 후에 S3 Glacier Deep Archive 로 
전환합니다. 
D. 180 일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하고, 360 일 
후에 S3 Glacier 유연한 검색으로, 5 년 후에 S3 Glacier Deep Archive 로 전환합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/125244-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q652 
매일 6 시간 동안 실행되는 대규모 데이터 워크로드가 있는 회사입니다. 프로세스가 
실행되는 동안 데이터가 손실되어서는 안 됩니다. 솔루션 설계자가 이 중요한 데이터 
워크로드를 지원하기 위해 Amazon EMR 클러스터 구성을 설계하고 있습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇인가요? 
A. 온디맨드 인스턴스에서 기본 노드 및 코어 노드를 실행하고 스팟 인스턴스에서 작업 
노드를 실행하는 장기 실행 클러스터를 구성합니다. 
B. 온디맨드 인스턴스에서 기본 노드 및 코어 노드를 실행하는 임시 클러스터와 스팟 
인스턴스에서 작업 노드를 실행하는 임시 클러스터를 구성합니다. 
C. On-Demand 인스턴스에서 기본 노드를 실행하고 스팟 인스턴스에서 코어 노드 및 작업 
노드를 실행하는 트랜지션 클러스터를 구성합니다. 
D. 온디맨드 인스턴스의 기본 노드, 스팟 인스턴스의 코어 노드 및 스팟 인스턴스의 작업 
노드를 실행하는 장기 실행 클러스터를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/125591-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q653 
회사는 사용자를 비용 센터에 매핑하는 Amazon RDS 데이터베이스를 유지 관리합니다. 
회사는 AWS Organizations 의 조직에 계정을 가지고 있습니다. 회사에는 조직의 특정 AWS 
계정에서 생성된 모든 리소스에 태그를 지정하는 솔루션이 필요합니다. 솔루션은 리소스를 
생성한 사용자의 비용 센터 ID 로 각 리소스에 태그를 지정해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 특정 AWS 계정을 마스터 계정에서 조직의 새로운 조직 단위(OU)로 이동합니다. 
리소스가 생성되기 전에 모든 기존 리소스에 올바른 비용 센터 태그가 있어야 하는 서비스 
제어 정책(SCP)을 생성합니다. 새 OU 에 SCP 를 적용합니다. 
B. Lambda 함수가 RDS 데이터베이스에서 적절한 비용 센터를 조회한 후 리소스에 태그를 
지정하는 AWS Lambda 함수를 생성합니다. AWS CloudTrail 이벤트에 반응하여 Lambda 
함수를 호출하는 Amazon EventBridge 규칙을 구성합니다. 
C. AWS CloudFormation 스택을 생성하여 AWS Lambda 함수를 배포합니다. RDS 
데이터베이스에서 적절한 비용 센터를 조회하고 리소스에 태그를 지정하도록 Lambda 
함수를 구성합니다. CloudFormation 스택을 호출하는 Amazon EventBridge 예약 규칙을 
생성합니다. 
D. 기본값으로 리소스에 태그를 지정하는 AWS Lambda 함수를 생성합니다. 리소스에 비용 
센터 태그가 누락된 경우 AWS CloudTrail 이벤트에 반응하여 Lambda 함수를 호출하는 
Amazon EventBridge 규칙을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/126867-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
Amazon Athena 는 Amazon S3 에 저장된 데이터에 대해 SQL 쿼리를 실행할 수 있는 
서비스입니다. 서버리스이므로 인프라를 프로비저닝하거나 관리할 필요가 없습니다. 실행한 
쿼리와 스캔한 데이터 양에 대해서만 비용을 지불하면 됩니다. 
Amazon Athena 를 사용하여 Amazon S3 에서 데이터를 쿼리하면 다음과 같은 이점을 얻을 
수 있습니다. 
* Amazon RDS for MySQL DB 인스턴스의 성능에 영향을 주지 않고 보고서에 대한 쿼리를 
실행할 수 있습니다. DB 인스턴스에서 S3 버킷으로 데이터를 내보내고 Athena 를 사용하여 
버킷의 데이터를 쿼리할 수 있습니다. 이렇게 하면 DB 인스턴스에서 쿼리를 실행하는 
오버헤드와 경합을 피할 수 있습니다. 
* 보고서에 대한 쿼리를 실행하는 비용과 복잡성을 줄일 수 있습니다. 추가 요금이 
발생하고 유지 관리가 필요한 읽기 전용 복제본이나 DB 인스턴스의 백업을 생성할 필요가 
없습니다. 또한 운영 오버헤드를 증가시키는 추가 워크로드를 수용하기 위해 DB 
인스턴스의 크기를 조정할 필요가 없습니다. 
* Amazon S3 및 Athena 의 확장성과 유연성을 활용할 수 있습니다. 용량이나 성능 제한에 
대한 걱정 없이 S3 에 대량의 데이터를 저장하고 Athena 로 쿼리할 수 있습니다. 또한 
다양한 형식, 압축 방법 및 파티셔닝 체계를 사용하여 데이터 스토리지 및 쿼리 성능을 
최적화할 수 있습니다. 
Q654 
한 회사는 최근 웹 애플리케이션을 AWS 클라우드로 마이그레이션했습니다. 이 회사는 
Amazon EC2 인스턴스를 사용하여 여러 프로세스를 실행하여 애플리케이션을 호스팅합니다. 
프로세스에는 정적 콘텐츠를 제공하는 Apache 웹 서버가 포함됩니다. Apache 웹 서버는 
사용자 세션을 위해 로컬 Redis 서버를 사용하는 PHP 애플리케이션에 요청합니다. 
회사는 가용성이 높고 AWS 관리형 솔루션을 사용하도록 아키텍처를 재설계하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Elastic Beanstalk 를 사용하여 정적 콘텐츠와 PHP 애플리케이션을 호스팅하십시오. 
EC2 인스턴스를 퍼블릭 서브넷에 배포하도록 Elastic Beanstalk 를 구성합니다. 공용 IP 
주소를 할당합니다. 
B. AWS Lambda 를 사용하여 정적 콘텐츠와 PHP 애플리케이션을 호스팅합니다. Amazon 
API Gateway REST API 를 사용하여 Lambda 함수에 대한 요청을 프록시합니다. 도메인 
이름에 응답하도록 API 게이트웨이 CORS 구성을 설정합니다. 세션 정보를 처리하도록 
Redis 용 Amazon ElastiCache 를 구성합니다. 
C. EC2 인스턴스에 백엔드 코드를 유지합니다. 다중 AZ 가 활성화된 Redis 용 Amazon 
ElastiCache 클러스터를 생성합니다. 클러스터 모드에서 Redis 용 ElastiCache 클러스터를 
구성합니다. 프런트엔드 리소스를 Amazon S3 에 복사합니다. EC2 인스턴스를 참조하도록 
백엔드 코드를 구성합니다. 
D. Amazon S3 엔드포인트를 사용하여 Amazon CloudFront 배포를 정적 콘텐츠를 
호스팅하도록 구성된 S3 버킷으로 구성합니다. PHP 애플리케이션에 대해 AWS Fargate 
작업을 실행하는 Amazon Elastic Container Service(Amazon ECS) 서비스를 대상으로 하는 
Application Load Balancer 를 구성합니다. 여러 가용 영역에서 실행되는 Redis 용 Amazon 
ElastiCache 클러스터를 사용하도록 PHP 애플리케이션을 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/128008-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q655 
회사는 대상 그룹이 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 웹 
애플리케이션을 실행합니다. 회사는 더 나은 사용자 경험을 위해 세션 선호도(고정 세션)와 
함께 작동하도록 애플리케이션을 설계했습니다. 
애플리케이션은 인터넷을 통해 공개적으로 엔드포인트로 사용할 수 있어야 합니다. 추가 
보안을 위해 엔드포인트에 WAF 를 적용해야 합니다. 세션 선호도(고정 세션)는 
엔드포인트에서 구성되어야 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 공용 Network Load Balancer 를 생성합니다. 적용 대상 그룹을 지정합니다. 
B. 게이트웨이 로드 밸런서를 생성합니다. 적용 대상 그룹을 지정합니다. 
C. 공개 Application Load Balancer 를 생성합니다. 적용 대상 그룹을 지정합니다. 
D. 두 번째 대상 그룹을 생성합니다. EC2 인스턴스에 탄력적 IP 주소를 추가합니다. 
E. AWS WAF 에서 웹 ACL 을 생성합니다. 웹 ACL 을 엔드포인트와 연결합니다. 
Answer: C, E 
https://www.examtopics.com/discussions/amazon/view/128009-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q656 
한 회사에서 역사적 사건의 이미지를 저장하는 웹사이트를 운영하고 있습니다. 웹사이트 
사용자는 이미지 속 사건이 발생한 연도를 기준으로 이미지를 검색하고 볼 수 있는 기능이 
필요합니다. 평균적으로 사용자는 각 이미지를 1 년에 한두 번만 요청합니다. 회사는 
가용성이 높은 이미지를 원합니다. 
이미지를 저장하고 사용자에게 전달하는 솔루션입니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Block Store(Amazon EBS)에 이미지를 저장합니다. Amazon EC2 에서 
실행되는 웹 서버를 사용하십시오. 
B. Amazon Elastic File System(Amazon EFS)에 이미지를 저장합니다. Amazon EC2 에서 
실행되는 웹 서버를 사용하십시오. 
C. Amazon S3 Standard 에 이미지를 저장합니다. S3 Standard 를 사용하면 정적 웹사이트를 
통해 이미지를 직접 전달할 수 있습니다. 
D. Amazon S3 Standard-InfrequentAccess(S3 Standard-IA)에 이미지를 저장합니다. S3 
Standard-IA 를 사용하면 정적 웹 사이트를 통해 이미지를 직접 전달할 수 있습니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/127135-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q657 
회사는 여러 사업부에서 사용하는 AWS Organizations 의 조직에 여러 AWS 계정을 가지고 
있습니다. 이 회사는 전 세계에 여러 개의 사무실을 두고 있습니다. 회사는 새로운 사무실 
CIDR 범위를 허용하거나 조직 전체에서 이전 CIDR 범위를 제거하기 위해 보안 그룹 
규칙을 업데이트해야 합니다. 회사는 CIDR 범위 업데이트에 필요한 관리 오버헤드를 
최소화하기 위해 보안 그룹 규칙 관리를 중앙 집중화하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 조직의 마스터 계정에 VPC 보안 그룹을 생성합니다. CIDR 범위 업데이트가 필요한 경우 
보안 그룹을 업데이트하십시오. 
B. CIDR 목록이 포함된 VPC 고객 관리형 접두사 목록을 생성합니다. AWS Resource 
Access Manager(AWS RAM)를 사용하여 조직 전체에서 접두사 목록을 공유합니다. 조직 
전체의 보안 그룹에서 접두사 목록을 사용합니다. 
C. AWS 관리형 접두사 목록을 생성합니다. AWS Security Hub 정책을 사용하여 조직 전체에 
보안 그룹 업데이트를 적용합니다. CIDR 범위가 변경되면 AWS Lambda 함수를 사용하여 
접두사 목록을 자동으로 업데이트합니다. 
D. 중앙 관리 AWS 계정에 보안 그룹을 생성합니다. 전체 조직에 대한 AWS Firewall 
Manager 공통 보안 그룹 정책을 생성합니다. 이전에 생성된 보안 그룹을 정책의 기본 
그룹으로 선택합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/127524-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q658 
회사는 온프레미스 NAS(Network Attached Storage) 시스템을 사용하여 HPC(고성능 컴퓨팅) 
워크로드에 파일 공유를 제공합니다. 회사는 지연 시간에 민감한 HPC 워크로드와 
스토리지를 AWS 클라우드로 마이그레이션하려고 합니다. 회사는 파일 시스템에서 NFS 및 
SMB 다중 프로토콜 액세스를 제공할 수 있어야 합니다. 
가장 짧은 대기 시간으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) 
A. 컴퓨팅 최적화 EC2 인스턴스를 클러스터 배치 그룹에 배포합니다. 
B. 컴퓨팅 최적화 EC2 인스턴스를 파티션 배치 그룹에 배포합니다. 
C. EC2 인스턴스를 Amazon FSx for Lustre 파일 시스템에 연결합니다. 
D. EC2 인스턴스를 Amazon FSx for OpenZFS 파일 시스템에 연결합니다. 
E. EC2 인스턴스를 NetApp ONTAP 파일 시스템용 Amazon FSx 에 연결합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/126797-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
클러스터 배치 그룹은 네트워크 지연 시간을 최소화하기 위해 서로 가깝게 배치되는 단일 
가용 영역 내 EC2 인스턴스의 논리적 그룹입니다. 이는 높은 네트워크 성능이 요구되는 
대기 시간에 민감한 HPC 워크로드에 적합합니다. 컴퓨팅 최적화 EC2 인스턴스는 vCPU 대 
메모리 비율이 높은 인스턴스 유형으로, 컴퓨팅 집약적인 애플리케이션에 이상적입니다. 
NetApp ONTAP 용 Amazon FSx 는 파일 시스템에서 NFS 및 SMB 다중 프로토콜 액세스는 
물론 데이터 중복 제거, 압축, 씬 프로비저닝, 스냅샷과 같은 기능을 제공하는 완전관리형 
서비스입니다. 이 솔루션은 AWS 의 짧은 지연 시간 네트워크 및 스토리지 성능을 
활용하므로 가장 짧은 지연 시간으로 요구 사항을 충족합니다. 
Q659 
한 회사에서 데이터 센터를 이전하고 2 주 이내에 50TB 의 데이터를 AWS 로 안전하게 
전송하려고 합니다. 기존 데이터 센터에는 90% 활용되는 AWS 에 대한 Site-to-Site VPN 
연결이 있습니다. 
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 어떤 AWS 서비스를 사용해야 
합니까? 
A. VPC 엔드포인트가 있는 AWS DataSync 
B. AWS 다이렉트 커넥트 
C. AWS Snowball Edge 스토리지 최적화 
D. AWS 스토리지 게이트웨이 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/128067-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q660 
회사는 Auto Scaling 그룹의 Amazon EC2 온디맨드 인스턴스에서 애플리케이션을 
호스팅합니다. 신청 피크 시간은 매일 같은 시간에 발생합니다. 애플리케이션 사용자는 
피크 시간이 시작될 때 애플리케이션 성능이 느려진다고 보고합니다. 애플리케이션은 
일반적으로 피크 시간이 시작된 후 2~3 시간 후에 실행됩니다. 회사는 피크 시간대가 
시작될 때 애플리케이션이 제대로 작동하는지 확인하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 트래픽을 인스턴스에 적절하게 분산하도록 Application Load Balancer 를 구성합니다. 
B. 메모리 사용률을 기반으로 새 인스턴스를 시작하도록 Auto Scaling 그룹에 대한 동적 
조정 정책을 구성합니다. 
C. CPU 사용률을 기반으로 새 인스턴스를 시작하도록 Auto Scaling 그룹에 대한 동적 조정 
정책을 구성합니다. 
D. 피크 시간 전에 새 인스턴스를 시작하도록 Auto Scaling 그룹에 대한 예약된 조정 
정책을 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/126994-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q661 
회사는 회사의 Amazon RDS 데이터베이스에 연결되는 애플리케이션을 AWS 에서 
실행합니다. 애플리케이션은 주말과 연중 피크 시간대에 확장됩니다. 회사는 
데이터베이스에 연결하는 애플리케이션에 대해 데이터베이스를 보다 효과적으로 확장하려고 
합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 데이터베이스에 대한 대상 그룹 구성과 함께 연결 풀링과 함께 Amazon DynamoDB 를 
사용하십시오. DynamoDB 엔드포인트를 사용하도록 애플리케이션을 변경합니다. 
B. 데이터베이스의 대상 그룹과 함께 Amazon RDS Proxy 를 사용하십시오. RDS Proxy 
엔드포인트를 사용하도록 애플리케이션을 변경합니다. 
C. Amazon EC2 에서 실행되는 사용자 지정 프록시를 데이터베이스의 중개자로 사용합니다. 
사용자 정의 프록시 엔드포인트를 사용하도록 애플리케이션을 변경하십시오. 
D. AWS Lambda 함수를 사용하여 데이터베이스에 대한 대상 그룹 구성과 함께 연결 풀링을 
제공합니다. Lambda 함수를 사용하도록 애플리케이션을 변경합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/127729-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon RDS 프록시는 Amazon Relational Database Service(RDS)를 위한 완전 관리형 
고가용성 데이터베이스 프록시로, 애플리케이션의 확장성과 데이터베이스 오류에 대한 
복원력 및 보안을 더욱 강화합니다. RDS Proxy 를 사용하면 애플리케이션이 데이터베이스와 
설정된 연결을 풀링하고 공유할 수 있어 데이터베이스 효율성과 애플리케이션 확장성이 
향상됩니다. 또한 RDS Proxy 는 Aurora 및 RDS 데이터베이스의 장애 조치 시간을 최대 
66%까지 줄이고 데이터베이스 액세스를 위한 IAM 인증 및 Secrets Manager 통합을 
지원합니다. 코드 변경 없이 대부분의 애플리케이션에 대해 RDS Proxy 를 활성화할 수 
있습니다. 
Q662 
회사는 AWS Cost Explorer 를 사용하여 AWS 비용을 모니터링합니다. 회사는 Amazon 
Elastic Block Store(Amazon EBS) 스토리지 및 스냅샷 비용이 매달 증가한다는 사실을 
알아냈습니다. 그러나 회사는 매달 EBS 스토리지를 추가로 구매하지 않습니다. 회사는 
현재 스토리지 사용량에 맞게 월별 비용을 최적화하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon CloudWatch Logs 의 로그를 사용하여 Amazon EBS 의 스토리지 활용도를 
모니터링하십시오. Amazon EBS 탄력적 볼륨을 사용하여 EBS 볼륨의 크기를 줄입니다. 
B. 사용자 정의 스크립트를 사용하여 공간 사용량을 모니터링합니다. Amazon EBS 탄력적 
볼륨을 사용하여 EBS 볼륨의 크기를 줄입니다. 
C. 만료되거나 사용되지 않은 모든 스냅샷을 삭제하여 스냅샷 비용을 줄입니다. 
D. 중요하지 않은 스냅샷을 모두 삭제합니다. Amazon Data Lifecycle Manager 를 사용하여 
회사의 스냅샷 정책 요구 사항에 따라 스냅샷을 생성하고 관리합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/126865-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q663 
한 회사가 AWS 에서 새로운 애플리케이션을 개발하고 있습니다. 애플리케이션은 Amazon 
Elastic Container Service(Amazon ECS) 클러스터, 애플리케이션용 자산이 포함된 Amazon 
S3 버킷, 애플리케이션용 데이터 세트가 포함된 MySQL 용 Amazon RDS 데이터베이스로 
구성됩니다. 데이터 세트에는 민감한 정보가 포함되어 있습니다. 회사는 ECS 클러스터만 
RDS for MySQL 데이터베이스의 데이터와 S3 버킷의 데이터에 액세스할 수 있도록 하려고 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 새로운 AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성하여 S3 버킷과 
RDS for MySQL 데이터베이스를 모두 암호화합니다. KMS 키 정책에 ECS 작업 실행 역할에 
대한 암호화 및 암호 해독 권한이 포함되어 있는지 확인하십시오. 
B. AWS KMS(AWS Key Management Service) AWS 관리형 키를 생성하여 S3 버킷과 RDS 
for MySQL 데이터베이스를 모두 암호화합니다. S3 버킷 정책이 ECS 작업 실행 역할을 
사용자로 지정하는지 확인하세요. 
C. 버킷 액세스를 ECS 작업 실행 역할로 제한하는 S3 버킷 정책을 생성합니다. MySQL 용 
Amazon RDS 에 대한 VPC 엔드포인트를 생성합니다. ECS 클러스터가 작업을 생성할 
서브넷에서만 액세스를 허용하도록 RDS for MySQL 보안 그룹을 업데이트합니다. 
D. Amazon RDS for MySQL 에 대한 VPC 엔드포인트를 생성합니다. ECS 클러스터가 작업을 
생성할 서브넷에서만 액세스를 허용하도록 RDS for MySQL 보안 그룹을 업데이트합니다. 
Amazon S3 용 VPC 엔드포인트를 생성합니다. S3 VPC 엔드포인트에서만 액세스를 
허용하도록 S3 버킷 정책을 업데이트합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/126798-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q664 
회사에는 온프레미스에서 실행되는 웹 애플리케이션이 있습니다. 피크 시간 동안 
애플리케이션에 대기 시간 문제가 발생합니다. 지연 문제는 매달 두 번씩 발생합니다. 대기 
시간 문제가 시작되면 애플리케이션의 CPU 사용률이 즉시 정상 수치의 10 배로 
증가합니다. 
회사는 지연 시간을 개선하기 위해 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 
또한 회사는 애플리케이션 수요가 증가하면 애플리케이션을 자동으로 확장하려고 합니다. 
회사는 애플리케이션 배포를 위해 AWS Elastic Beanstalk 를 사용할 예정입니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 무제한 모드에서 성능 순간 확장이 가능한 인스턴스를 사용하도록 Elastic Beanstalk 
환경을 구성합니다. 요청에 따라 확장되도록 환경을 구성합니다. 
B. 컴퓨팅 최적화 인스턴스를 사용하도록 Elastic Beanstalk 환경을 구성합니다. 요청에 
따라 확장되도록 환경을 구성합니다. 
C. 컴퓨팅 최적화 인스턴스를 사용하도록 Elastic Beanstalk 환경을 구성합니다. 일정에 
따라 확장되도록 환경을 구성합니다. 
D. 무제한 모드에서 성능 순간 확장이 가능한 인스턴스를 사용하도록 Elastic Beanstalk 
환경을 구성합니다. 예측 지표를 확장하도록 환경을 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/126800-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q665 
회사는 전 세계에 고객을 두고 있습니다. 회사는 자동화를 사용하여 시스템과 네트워크 
인프라를 보호하기를 원합니다. 회사의 보안 팀은 인프라에 대한 모든 증분 변경 사항을 
추적하고 감사할 수 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Organizations 를 사용하여 인프라를 설정하십시오. AWS Config 를 사용하여 변경 
사항을 추적하세요. 
B. AWS CloudFormation 을 사용하여 인프라를 설정하십시오. AWS Config 를 사용하여 변경 
사항을 추적하세요. 
C. AWS Organizations 를 사용하여 인프라를 설정합니다. AWS Service Catalog 를 사용하여 
변경 사항을 추적합니다. 
D. AWS CloudFormation 을 사용하여 인프라를 설정합니다. AWS Service Catalog 를 
사용하여 변경 사항을 추적합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/128070-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q666 
한 스타트업 회사가 Amazon EC2 인스턴스에서 고객을 위한 웹 사이트를 호스팅하고 
있습니다. 웹사이트는 상태 비저장 Python 애플리케이션과 MySQL 데이터베이스로 
구성됩니다. 웹사이트는 소량의 트래픽만을 제공합니다. 회사는 인스턴스의 안정성에 대해 
우려하고 있으며 가용성이 높은 아키텍처로 마이그레이션해야 합니다. 회사는 애플리케이션 
코드를 수정할 수 없습니다. 
웹 사이트의 고가용성을 달성하기 위해 솔루션 아키텍트가 취해야 하는 작업 조합은 
무엇입니까? (2 개 선택) 
A. 사용 중인 각 가용 영역에 인터넷 게이트웨이를 프로비저닝합니다. 
B. 데이터베이스를 MySQL 다중 AZ DB 인스턴스용 Amazon RDS 로 마이그레이션합니다. 
C. 데이터베이스를 Amazon DynamoDB 로 마이그레이션하고 DynamoDB Auto Scaling 을 
활성화합니다. 
D. AWS DataSync 를 사용하여 여러 EC2 인스턴스에서 데이터베이스 데이터를 
동기화합니다. 
E. 두 개의 가용 영역에 분산된 EC2 인스턴스의 Auto Scaling 그룹에 트래픽을 분산시키기 
위해 Application Load Balancer 를 생성합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/128269-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
웹사이트의 고가용성을 달성하려면 두 가지 주요 작업을 수행해야 합니다. 
Amazon RDS for MySQL Multi-AZ: 데이터베이스를 RDS for MySQL Multi-AZ 배포로 
마이그레이션하면 데이터베이스가 고가용성이 됩니다. Multi-AZ 는 기본 데이터베이스에서 
다른 가용 영역의 대기 복제본으로 자동 장애 조치를 제공하여 AZ 장애가 발생하더라도 
데이터베이스 가용성을 보장합니다. 
애플리케이션 로드 밸런서 및 자동 확장: EC2 인스턴스 앞에 애플리케이션 로드 
밸런서(ALB)를 배포하면 트래픽이 인스턴스 전체에 고르게 분산됩니다. 여러 가용 영역에서 
EC2 인스턴스를 실행하도록 자동 확장 그룹을 구성하면 한 인스턴스 또는 한 AZ 가 사용 
불가능해지더라도 애플리케이션은 계속 사용할 수 있습니다. 이 설정은 내결함성을 
강화하고 안정성을 개선합니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(AZ 당 인터넷 게이트웨이): 인터넷 게이트웨이는 지역 전체 리소스이므로 가용 
영역별로 프로비저닝할 필요가 없습니다. 이 옵션은 고가용성에 기여하지 않습니다. 
옵션 C(DynamoDB + 자동 스케일링): DynamoDB 는 MySQL 에서 전환하기 위해 
애플리케이션 코드를 변경해야 하지만, 질문의 제약에 따라 불가능합니다. 
옵션 D(DataSync): AWS DataSync 는 데이터 전송 및 동기화에 사용되며, 데이터베이스의 
고가용성을 달성하는 데 사용되지 않습니다. 
Q667 
한 회사가 다년간의 마이그레이션 프로젝트 중에 데이터와 애플리케이션을 AWS 로 
이전하고 있습니다. 회사는 회사의 AWS 리전과 회사의 온프레미스 위치에서 Amazon S3 의 
데이터에 안전하게 액세스하려고 합니다. 데이터가 인터넷을 통과해서는 안 됩니다. 회사는 
해당 지역과 온프레미스 위치 간에 AWS Direct Connect 연결을 설정했습니다. 어떤 
솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 용 게이트웨이 엔드포인트를 생성합니다. 게이트웨이 엔드포인트를 사용하여 
지역 및 온프레미스 위치의 데이터에 안전하게 액세스하세요. 
B. AWS Transit Gateway 에 게이트웨이를 생성하여 리전 및 온프레미스 위치에서 Amazon 
S3 에 안전하게 액세스합니다. 
C. Amazon S3 용 인터페이스 엔드포인트를 생성합니다. 인터페이스 엔드포인트를 사용하여 
지역 및 온프레미스 위치의 데이터에 안전하게 액세스하세요. 
D. AWS Key Management Service(AWS KMS) 키를 사용하여 지역 및 온프레미스 위치에서 
데이터에 안전하게 액세스합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/126802-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q668 
한 회사가 AWS Organizations 에 새 조직을 만들었습니다. 조직에는 회사 개발팀에 대한 
여러 계정이 있습니다. 개발팀 구성원은 AWS IAM Identity Center(AWS Single Sign-On)를 
사용하여 계정에 액세스합니다. 회사의 각 애플리케이션에 대해 개발 팀은 미리 정의된 
애플리케이션 이름을 사용하여 생성된 리소스에 태그를 지정해야 합니다. 
솔루션 설계자는 애플리케이션 이름 태그에 승인된 값이 있는 경우에만 개발 팀이 리소스를 
생성할 수 있는 기능을 제공하는 솔루션을 설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 생성할 리소스에 대해 애플리케이션 이름 태그를 지정하도록 요구하는 조건부 허용 
정책이 있는 IAM 그룹을 생성합니다. 
B. 애플리케이션 이름 태그가 있는 모든 리소스에 대해 거부 정책이 있는 교차 계정 역할을 
생성합니다. 
C. AWS 리소스 그룹에서 리소스 그룹을 생성하여 태그가 모든 계정의 모든 리소스에 
적용되는지 확인합니다. 
D. 허용된 애플리케이션 이름 목록이 있는 조직에서 태그 정책을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/127661-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q669 
한 회사가 PostgreSQL 용 Amazon RDS 에서 데이터베이스를 실행합니다. 회사는 30 일마다 
비밀번호를 교체하여 마스터 사용자 비밀번호를 관리하는 안전한 솔루션을 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon EventBridge 를 사용하여 30 일마다 암호를 교체하도록 사용자 지정 AWS 
Lambda 함수를 예약하십시오. 
B. AWS CLI 에서 수정-db-instance 명령을 사용하여 비밀번호를 변경합니다. 
C. AWS Secrets Manager 를 PostgreSQL 용 Amazon RDS 와 통합하여 암호 교체를 
자동화합니다. 
D. AWS Systems Manager Parameter Store 를 PostgreSQL 용 Amazon RDS 와 통합하여 
암호 교체를 자동화합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/127660-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q670 
회사에서는 Amazon DynamoDB 테이블을 사용하는 애플리케이션에 대한 테스트를 
수행합니다. 테스트는 일주일에 한 번 4 시간 동안 진행됩니다. 회사는 테스트 중에 
애플리케이션이 매초 테이블에 대해 수행하는 읽기 및 쓰기 작업 수를 알고 있습니다. 
회사는 현재 다른 사용 사례에 DynamoDB 를 사용하지 않습니다. 솔루션 설계자는 테이블 
비용을 최적화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 주문형 모드를 선택하세요. 읽기 및 쓰기 용량 단위를 적절하게 업데이트합니다. 
B. 프로비저닝 모드를 선택합니다. 읽기 및 쓰기 용량 단위를 적절하게 업데이트합니다. 
C. 1 년 기간 동안 DynamoDB 예약 용량을 구매합니다. 
D. 3 년 기간 동안 DynamoDB 예약 용량을 구매하세요. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/129711-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q671 
회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 AWS 비용에 대해 
정기적인 재무 평가를 수행합니다. 회사는 최근 비정상적인 지출을 확인했습니다. 회사는 
비정상적인 지출을 방지하기 위한 솔루션이 필요합니다. 솔루션은 비용을 모니터링하고 
비정상적인 지출이 발생할 경우 책임 있는 이해관계자에게 알려야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 지출이 없는 예산을 생성하려면 AWS Budgets 템플릿을 사용하십시오. 
B. AWS Billing and Cost Management 콘솔에서 AWS 비용 이상 탐지 모니터를 생성합니다. 
C. 현재 실행 중인 워크로드 가격 세부 정보에 대한 AWS 가격 계산기 추정치를 
생성합니다. 
D. Amazon CloudWatch 를 사용하여 비용을 모니터링하고 비정상적인 지출을 식별합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/129712-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 비용을 모니터링하고 비정상적인 지출이 발생할 경우 책임 있는 
이해관계자에게 알릴 수 있습니다. AWS Billing and Cost Management 콘솔에서 AWS 비용 
이상 탐지 모니터를 생성함으로써 회사는 비정상적인 지출을 자동으로 탐지하고 경고하는 
기계 학습 서비스를 사용할 수 있습니다. 경고 임계값, 알림 기본 설정 및 근본 원인 
분석을 구성함으로써 회사는 비정상적인 지출을 방지하고 그 출처를 식별할 수 있습니다. 
Q672 
마케팅 회사는 마케팅 캠페인을 통해 Amazon S3 에서 대량의 새로운 클릭스트림 데이터를 
받습니다. 회사는 Amazon S3의 클릭스트림 데이터를 신속하게 분석해야 합니다. 그런 다음 
회사는 데이터 파이프라인에서 데이터를 추가로 처리할지 여부를 결정해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Spark 카탈로그에 외부 테이블을 생성합니다. 데이터를 쿼리하도록 AWS Glue 에서 
작업을 구성합니다. 
B. 데이터를 크롤링하도록 AWS Glue 크롤러를 구성합니다. 데이터를 쿼리하도록 Amazon 
Athena 를 구성합니다. 
C. Hive 메타스토어에 외부 테이블을 생성합니다. 데이터를 쿼리하도록 Amazon EMR 에서 
Spark 작업을 구성합니다. 
D. 데이터를 크롤링하도록 AWS Glue 크롤러를 구성합니다. SQL 을 사용하여 데이터를 
쿼리하도록 Amazon Kinesis Data Analytics 를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/129713-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS Glue Crawler: AWS Glue 는 분석을 위한 데이터를 쉽게 준비하고 로드할 수 있게 
해주는 완전 관리형 ETL(추출, 변환, 로드) 서비스입니다. Glue 크롤러는 Amazon S3 에서 
새로운 데이터와 스키마를 자동으로 검색할 수 있으므로 데이터 카탈로그를 최신 상태로 
쉽게 유지할 수 있습니다. 
* Crawling the Data: 
* 클릭스트림 데이터가 포함된 S3 버킷을 스캔하도록 AWS Glue 크롤러를 설정합니다. 
* 크롤러는 자동으로 스키마를 감지하고 AWS Glue 데이터 카탈로그에서 테이블을 
생성/업데이트합니다. 
* Amazon Athena: 
* Athena 는 표준 SQL 을 사용하여 Amazon S3 의 데이터를 쉽게 분석할 수 있는 대화형 
쿼리 서비스입니다. 
* Glue 크롤러에 의해 데이터 카탈로그가 업데이트되면 Athena 를 사용하여 S3 에서 직접 
클릭스트림 데이터를 쿼리합니다. 
* 운영 효율성: 이 솔루션은 완전 관리형 서비스를 활용하여 운영 오버헤드를 줄입니다. 
Glue 크롤러는 데이터 카탈로그 작성을 자동화하고 Athena 는 인프라를 설정하거나 관리할 
필요 없이 빠른 데이터 분석을 위한 서버리스, 쿼리당 지불 모델을 제공합니다. 
Q673 
한 회사는 데이터 센터에서 SMB 파일 서버를 운영하고 있습니다. 파일서버는 회사가 자주 
접속하는 대용량 파일을 파일 생성일로부터 최대 7일까지 저장합니다. 7일이 지나면 회사는 
최대 24 시간의 검색 시간으로 파일에 액세스할 수 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS DataSync 를 사용하여 SMB 파일 서버에서 AWS 로 7 일보다 오래된 데이터를 
복사합니다. 
B. 회사의 저장 공간을 늘리려면 Amazon S3 파일 게이트웨이를 생성하십시오. 7 일 후에 
데이터를 S3 Glacier Deep Archive 로 전환하는 S3 수명 주기 정책을 생성합니다. 
C. 회사의 저장 공간을 늘리기 위해 Amazon FSx 파일 게이트웨이를 생성합니다. 7 일 후에 
데이터를 전환하는 Amazon S3 수명 주기 정책을 생성합니다. 
D. 각 사용자에 대해 Amazon S3 에 대한 액세스를 구성합니다. 7 일 후에 데이터를 S3 
Glacier 유연한 검색으로 전환하는 S3 수명 주기 정책을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/129714-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon S3 파일 게이트웨이는 네트워크 파일 공유로 표시되는 Amazon S3 에 파일 기반 
인터페이스를 제공하는 서비스입니다. SMB 와 같은 표준 파일 스토리지 프로토콜을 통해 
Amazon S3 객체를 저장하고 검색할 수 있습니다. S3 파일 게이트웨이는 짧은 액세스 
지연을 위해 자주 액세스하는 데이터를 로컬로 캐시할 수도 있습니다. S3 수명 주기 정책은 
수명 주기 전반에 걸쳐 객체 관리를 자동화하는 규칙을 정의할 수 있는 기능입니다. S3 
수명 주기 정책을 사용하면 객체의 수명과 액세스 패턴에 따라 객체를 다양한 스토리지 
클래스로 전환할 수 있습니다. S3 Glacier Deep Archive 는 검색 시간이 12 시간 또는 
48 시간으로 가장 저렴한 장기 데이터 보관 비용을 제공하는 스토리지 클래스입니다. 이 
솔루션은 회사가 SMB 파일 액세스를 통해 S3 에 대용량 파일을 저장하고, 비용 절감 및 
규정 준수를 위해 7 일 후에 파일을 S3 Glacier Deep Archive 로 이동할 수 있도록 하므로 
요구 사항을 충족합니다. 
Q674 
한 회사가 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 
애플리케이션은 PostgreSQL DB 인스턴스용 Amazon RDS 에서 실행되는 데이터베이스를 
사용합니다. 트래픽이 증가하면 애플리케이션 성능이 느려집니다. 트래픽이 많은 기간 동안 
데이터베이스에 읽기 로드가 많이 발생합니다. 
이러한 성능 문제를 해결하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까? (2 개 
선택) 
A. DB 인스턴스에 대해 Auto Scaling 을 활성화합니다. 
B. DB 인스턴스에 대한 읽기 전용 복제본을 생성합니다. 읽기 트래픽을 읽기 전용 
복제본으로 보내도록 애플리케이션을 구성합니다. 
C. DB 인스턴스를 다중 AZ DB 인스턴스 배포로 변환합니다. 대기 DB 인스턴스에 읽기 
트래픽을 보내도록 애플리케이션을 구성합니다. 
D. Amazon ElastiCache 클러스터를 생성합니다. ElastiCache 클러스터에서 쿼리 결과를 
캐시하도록 애플리케이션을 구성합니다. 
E. EC2 인스턴스가 DB 인스턴스와 동일한 가용 영역에 프로비저닝되도록 Auto Scaling 
그룹 서브넷을 구성합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/129716-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q675 
회사는 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS) 볼륨을 
사용하여 애플리케이션을 실행합니다. 회사는 규정 준수 요구 사항을 충족하기 위해 매일 
각 EBS 볼륨에 대해 하나의 스냅샷을 생성합니다. 회사는 EBS 볼륨 스냅샷이 실수로 
삭제되는 것을 방지하는 아키텍처를 구현하려고 합니다. 솔루션은 스토리지 관리자 
사용자의 관리 권한을 변경해서는 안 됩니다. 
최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 스냅샷 삭제 권한이 있는 IAM 역할을 생성합니다. 새 EC2 인스턴스에 역할을 
연결합니다. 스냅샷을 삭제하려면 새 EC2 인스턴스에서 AWS CLI 를 사용하세요. 
B. 스냅샷 삭제를 거부하는 IAM 정책을 생성합니다. 스토리지 관리자 사용자에게 정책을 
연결합니다. 
C. 스냅샷에 태그를 추가합니다. 태그가 있는 EBS 스냅샷에 대해 휴지통에 보관 규칙을 
만듭니다. 
D. 삭제를 방지하기 위해 EBS 스냅샷을 잠급니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/129717-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
EBS 스냅샷은 데이터를 복원하거나 새 볼륨을 생성하는 데 사용할 수 있는 EBS 볼륨의 
특정 시점 백업입니다. EBS 스냅샷 잠금이라는 기능을 사용하여 실수로 삭제되는 것을 
방지하기 위해 EBS 스냅샷을 잠글 수 있습니다. 스냅샷이 잠겨 있으면 잠금이 해제될 
때까지 루트 사용자를 포함한 어떤 사용자도 삭제할 수 없습니다. 잠금 정책은 스냅샷을 
삭제할 수 있는 보존 기간을 지정할 수도 있습니다. 이 솔루션은 코드 개발이나 정책 
변경이 필요하지 않으므로 최소한의 관리 노력으로 요구 사항을 충족합니다. 
Q676 
회사의 애플리케이션은 Network Load Balancer, Auto Scaling 그룹, Amazon EC2 인스턴스 
및 Amazon VPC 에 배포된 데이터베이스를 사용합니다. 이 회사는 Amazon VPC 에서 거의 
실시간으로 네트워크 인터페이스를 오가는 트래픽에 대한 정보를 캡처하려고 합니다. 
회사는 분석을 위해 Amazon OpenSearch Service 에 정보를 보내려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon CloudWatch Logs 에 로그 그룹을 생성합니다. 로그 데이터를 로그 그룹으로 
보내도록 VPC 흐름 로그를 구성합니다. Amazon Kinesis Data Streams 를 사용하여 로그 
그룹의 로그를 OpenSearch Service 로 스트리밍합니다. 
B. Amazon CloudWatch Logs 에 로그 그룹을 생성합니다. 로그 데이터를 로그 그룹으로 
보내도록 VPC 흐름 로그를 구성합니다. Amazon Kinesis Data Firehose 를 사용하여 로그 
그룹의 로그를 OpenSearch Service 로 스트리밍합니다. 
C. AWS CloudTrail 에서 추적을 생성합니다. 로그 데이터를 추적으로 보내도록 VPC 흐름 
로그를 구성합니다. Amazon Kinesis Data Streams 를 사용하여 트레일의 로그를 
OpenSearch Service 로 스트리밍합니다. 
D. AWS CloudTrail 에서 추적을 생성합니다. 로그 데이터를 추적으로 보내도록 VPC 흐름 
로그를 구성합니다. Amazon Kinesis Data Firehose 를 사용하여 트레일의 로그를 
OpenSearch Service 로 스트리밍합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/129718-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q677 
한 회사가 프로덕션 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터에서 실행될 
애플리케이션을 개발하고 있습니다. EKS 클러스터에는 온디맨드 인스턴스로 프로비저닝되는 
관리형 노드 그룹이 있습니다. 
회사에는 개발 작업을 위한 전용 EKS 클러스터가 필요합니다. 회사는 애플리케이션의 
복원력을 테스트하기 위해 개발 클러스터를 자주 사용하지 않습니다. EKS 클러스터는 모든 
노드를 관리해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 스팟 인스턴스만 포함하는 관리형 노드 그룹을 생성합니다. 
B. 두 개의 관리형 노드 그룹을 생성합니다. 온디맨드 인스턴스로 하나의 노드 그룹을 
프로비저닝합니다. 스팟 인스턴스로 두 번째 노드 그룹을 프로비저닝합니다. 
C. 스팟 인스턴스를 사용하는 시작 구성이 있는 Auto Scaling 그룹을 생성합니다. EKS 
클러스터에 노드를 추가하도록 사용자 데이터를 구성합니다. 
D. 온디맨드 인스턴스만 포함하는 관리형 노드 그룹을 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/129827-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q678 
회사는 민감한 데이터를 Amazon S3 에 저장합니다. 솔루션 설계자는 암호화 솔루션을 
만들어야 합니다. 회사는 암호화해야 하는 모든 데이터에 대해 최소한의 노력으로 암호화 
키를 생성, 순환 및 비활성화할 수 있는 사용자의 능력을 완전히 제어해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 관리형 암호화 키(SSE-S3)와 함께 기본 서버 측 암호화를 사용하여 민감한 
데이터를 저장합니다. 
B. AWS Key Management Service(AWS KMS)를 사용하여 고객 관리형 키를 생성합니다. 
AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하여 S3 객체를 암호화하려면 새 키를 
사용합니다. 
C. AWS Key Management Service(AWS KMS)를 사용하여 AWS 관리형 키를 생성합니다. 
AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하여 S3 객체를 암호화하려면 새 키를 
사용합니다. 
D. S3 객체를 Amazon EC2 인스턴스로 다운로드합니다. 고객 관리 키를 사용하여 객체를 
암호화합니다. 암호화된 객체를 Amazon S3 에 다시 업로드합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/129719-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q679 
회사에서 온프레미스 가상 머신(VM)을 AWS 에 백업하려고 합니다. 회사의 백업 솔루션은 
온프레미스 백업을 Amazon S3 버킷에 객체로 내보냅니다. S3 백업은 30 일 동안 
보관되어야 하며 30 일 후에 자동으로 삭제되어야 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3 개 선택) 
A. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다. 
B. 객체 버전 관리가 활성화된 S3 버킷을 생성합니다. 
C. 객체의 기본 보존 기간을 30 일로 구성합니다. 
D. 30 일 동안 객체를 보호하도록 S3 수명 주기 정책을 구성합니다. 
E. 30 일 후에 객체가 만료되도록 S3 수명 주기 정책을 구성합니다. 
F. 30 일 보존 기간으로 개체에 태그를 지정하도록 백업 솔루션을 구성합니다. 
Answer: A, C, E 
https://www.examtopics.com/discussions/amazon/view/129721-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q680 
솔루션 아키텍트는 Amazon S3 버킷의 파일을 Amazon Elastic File System(Amazon EFS) 
파일 시스템과 다른 S3 버킷으로 복사해야 합니다. 파일은 계속해서 복사되어야 합니다. 새 
파일은 원본 S3 버킷에 지속적으로 추가됩니다. 복사된 파일은 원본 파일이 변경된 
경우에만 덮어써야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 대상 S3 버킷과 EFS 파일 시스템 모두에 대한 AWS DataSync 위치를 생성합니다. 
대상 S3 버킷 및 EFS 파일 시스템에 대한 작업을 생성합니다. 변경된 데이터만 전송하도록 
전송 모드를 설정하세요. 
B. AWS Lambda 함수를 생성합니다. 파일 시스템을 함수에 마운트합니다. Amazon S3 에서 
파일이 생성되고 변경될 때 함수를 호출하도록 S3 이벤트 알림을 설정합니다. 파일 
시스템과 대상 S3 버킷에 파일을 복사하는 기능을 구성합니다. 
C. 대상 S3 버킷과 EFS 파일 시스템 모두에 대한 AWS DataSync 위치를 생성합니다. 
대상 S3 버킷 및 EFS 파일 시스템에 대한 작업을 생성합니다. 모든 데이터를 전송하려면 
전송 모드를 설정하세요. 
D. 파일 시스템과 동일한 VPC 에서 Amazon EC2 인스턴스를 시작합니다. 파일 시스템을 
마운트합니다. 원본 S3 버킷에서 변경된 모든 객체를 대상 S3 버킷 및 탑재된 파일 
시스템과 정기적으로 동기화하는 스크립트를 만듭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/129722-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS DataSync 는 AWS 스토리지 서비스와 온프레미스 스토리지 시스템 간에 대량의 
데이터를 쉽게 이동할 수 있게 해주는 서비스입니다. AWS DataSync 는 S3 버킷에서 EFS 
파일 시스템 및 다른 S3 버킷으로 파일을 지속적으로 복사할 수 있을 뿐만 아니라 
소스에서 변경된 파일만 덮어쓸 수 있습니다. 이 솔루션은 코드 개발이나 수동 개입이 
필요하지 않으므로 최소한의 운영 오버헤드로 요구 사항을 충족합니다. 
Q681 
회사는 Amazon EC2 인스턴스를 사용하고 Amazon Elastic Block Store(Amazon EBS) 
볼륨에 데이터를 저장합니다. 회사는 AWS Key Management Service(AWS KMS)를 사용하여 
모든 저장 데이터가 암호화되었는지 확인해야 합니다. 회사는 암호화 키의 순환을 제어할 
수 있어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 고객 관리형 키를 생성합니다. 키를 사용하여 EBS 볼륨을 암호화합니다. 
B. AWS 관리형 키를 사용하여 EBS 볼륨을 암호화합니다. 키를 사용하여 자동 키 순환을 
구성합니다. 
C. 가져온 키 자료를 사용하여 외부 KMS 키를 생성합니다. 키를 사용하여 EBS 볼륨을 
암호화합니다. 
D. AWS 소유 키를 사용하여 EBS 볼륨을 암호화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/129723-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
최소한의 운영 오버헤드로 키 로테이션을 제어해야 하는 요구 사항을 충족하려면 AWS 
KMS에서 고객 관리 키(CMK)를 만드는 것이 최적의 솔루션입니다. CMK를 사용하면 사용자 
지정 키 로테이션 정책을 정의하여 매년 자동 키 로테이션을 활성화하는 것을 포함하여 키 
수명 주기를 제어할 수 있습니다. 
주요 AWS 기능: 
* 사용자 지정 키 관리: 고객 관리 키를 사용하면 키 정책, 수명 주기를 제어하고 규정 
준수를 위해 키 로테이션을 활성화할 수 있습니다. 
* 최소 운영 오버헤드: 고객 관리 키를 사용하면 암호화 관리가 간소화되고 AWS 관리 또는 
소유 키보다 더 많은 유연성을 제공합니다. 
* AWS 설명서: AWS Well-Architected Framework 는 키 제어 및 유연성이 필요한 환경에 
고객 관리 키를 권장합니다. 
Q682 
회사에는 Amazon EC2 인스턴스에 저장된 데이터 암호화를 적용하기 위한 솔루션이 
필요합니다. 솔루션은 비준수 리소스를 자동으로 식별하고 결과에 대해 준수 정책을 
시행해야 합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 사용자가 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨만 생성하도록 
허용하는 IAM 정책을 사용하십시오. AWS Config 및 AWS Systems Manager 를 사용하여 
암호화되지 않은 EBS 볼륨의 감지 및 수정을 자동화합니다. 
B. AWS Key Management Service(AWS KMS)를 사용하여 암호화된 Amazon Elastic Block 
Store(Amazon EBS) 볼륨에 대한 액세스를 관리합니다. AWS Lambda 및 Amazon 
EventBridge 를 사용하여 암호화되지 않은 EBS 볼륨의 감지 및 수정을 자동화합니다. 
C. Amazon Macie 를 사용하여 암호화되지 않은 Amazon Elastic Block Store(Amazon EBS) 
볼륨을 감지합니다. AWS 시스템 관리자 자동화 규칙을 사용하여 기존 및 신규 EBS 볼륨을 
자동으로 암호화합니다. 
D. Amazon Inspector 를 사용하여 암호화되지 않은 Amazon Elastic Block Store(Amazon 
EBS) 볼륨을 감지합니다. AWS 시스템 관리자 자동화 규칙을 사용하여 기존 및 신규 EBS 
볼륨을 자동으로 암호화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/129724-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q683 
한 회사가 다중 계층 온프레미스 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 
애플리케이션은 단일 노드 MySQL 데이터베이스와 다중 노드 웹 계층으로 구성됩니다. 
회사는 마이그레이션 중에 애플리케이션 변경을 최소화해야 합니다. 회사는 마이그레이션 
후 애플리케이션 복원성을 개선하려고 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 웹 계층을 Application Load Balancer 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 
인스턴스로 마이그레이션합니다. 
B. 데이터베이스를 Network Load Balancer 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 
인스턴스로 마이그레이션합니다. 
C. 데이터베이스를 Amazon RDS 다중 AZ 배포로 마이그레이션합니다. 
D. 웹 계층을 AWS Lambda 함수로 마이그레이션합니다. 
E. 데이터베이스를 Amazon DynamoDB 테이블로 마이그레이션합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/129725-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Auto Scaling 그룹은 유사한 특성을 공유하고 수요에 따라 자동으로 확장 또는 축소될 수 
있는 EC2 인스턴스 모음입니다. Auto Scaling 그룹은 여러 가용 영역의 여러 대상에 수신 
트래픽을 분산시키는 Elastic Load Balancing 로드 밸런서의 일종인 Application Load 
Balancer 뒤에 배치될 수 있습니다. 이 솔루션은 고가용성, 확장성 및 내결함성을 제공하여 
웹 계층의 복원성을 향상시킵니다. Amazon RDS 다중 AZ 배포는 기본 데이터베이스 
인스턴스를 자동으로 생성하고 다른 가용 영역에 있는 대기 인스턴스에 데이터를 
동기식으로 복제하는 구성입니다. 오류가 발생하면 Amazon RDS 는 수동 개입 없이 
자동으로 대기 인스턴스로 장애 조치됩니다. 이 솔루션은 데이터 중복성, 백업 지원 및 
가용성을 제공하여 데이터베이스 계층의 복원성을 향상시킵니다. 이 단계 조합은 
마이그레이션 중에 애플리케이션을 최소한으로 변경하여 요구 사항을 충족합니다. 
Q684 
회사는 웹 애플리케이션을 온프레미스에서 AWS 로 마이그레이션하려고 합니다. 이 회사는 
eu-central-1 지역 근처에 위치하고 있습니다. 규정으로 인해 회사는 eu-central-1 에서 
일부 애플리케이션을 시작할 수 없습니다. 회사는 한 자릿수 밀리초의 지연 시간을 
달성하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. eu-central-1 에 애플리케이션을 배포합니다. 회사의 VPC 를 eu-central-1 에서 Amazon 
CloudFront 의 엣지 위치로 확장합니다. 
B. 회사의 VPC 를 eu-central-1 에서 선택한 로컬 영역으로 확장하여 AWS 로컬 영역에 
애플리케이션을 배포합니다. 
C. eu-central-1 에 애플리케이션을 배포합니다. 회사의 VPC 를 eu-central-1 에서 Amazon 
CloudFront 의 지역 엣지 캐시로 확장합니다. 
D. 회사의 VPC 를 eu-central-1 에서 선택한 Wavelength Zone 으로 확장하여 AWS 
Wavelength Zone 에 애플리케이션을 배포합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/129726-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q685 
한 회사의 전자 상거래 웹 사이트에는 예측할 수 없는 트래픽이 있으며 AWS Lambda 
기능을 사용하여 PostgreSQL DB 인스턴스용 프라이빗 Amazon RDS 에 직접 액세스합니다. 
회사는 예측 가능한 데이터베이스 성능을 유지하고 Lambda 호출이 너무 많은 연결로 인해 
데이터베이스에 과부하가 걸리지 않도록 하려고 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. RDS 사용자 지정 끝점에서 클라이언트 드라이버를 가리킵니다. VPC 내부에 Lambda 
함수를 배포합니다. 
B. RDS 프록시 엔드포인트에서 클라이언트 드라이버를 가리킵니다. VPC 내부에 Lambda 
함수를 배포합니다. 
C. RDS 사용자 지정 엔드포인트에서 클라이언트 드라이버를 가리킵니다. VPC 외부에 
Lambda 함수를 배포합니다. 
D. RDS 프록시 엔드포인트에서 클라이언트 드라이버를 가리킵니다. VPC 외부에 Lambda 
함수를 배포합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133297-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
예측 가능한 데이터베이스 성능을 유지하고 Lambda 호출이 너무 많은 연결로 인해 
데이터베이스에 과부하를 주지 않도록 하려면 솔루션 설계자는 RDS 프록시 
엔드포인트에서 클라이언트 드라이버를 가리키고 VPC 내부에 Lambda 함수를 배포해야 
합니다. RDS 프록시는 애플리케이션이 데이터베이스에 대한 연결을 공유할 수 있도록 하여 
데이터베이스 가용성과 확장성을 향상시키는 완전 관리형 데이터베이스 프록시입니다. RDS 
프록시를 사용하면 Lambda 함수는 호출할 때마다 새 연결을 생성하는 대신 기존 연결을 
재사용하여 연결 오버헤드와 지연 시간을 줄일 수 있습니다. VPC 내부에 Lambda 함수를 
배포하면 퍼블릭 인터넷에 노출하지 않고도 프라이빗 RDS DB 인스턴스에 안전하고 
효율적으로 액세스할 수 있습니다. 참조: 
AWS Lambda 와 함께 Amazon RDS 프록시 사용 VPC 의 리소스에 액세스하도록 Lambda 
함수를 구성합니다. 
Q686 
회사에서 애플리케이션을 만들고 있습니다. 회사는 여러 온프레미스 위치에 애플리케이션 
테스트의 데이터를 저장합니다. 
회사는 온프레미스 위치를 AWS 클라우드의 AWS 지역에 있는 VPC 에 연결해야 합니다. 
내년에는 계정과 VPC 수가 증가할 예정입니다. 네트워크 아키텍처는 새로운 연결 관리를 
단순화해야 하며 확장 기능을 제공해야 합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. VPC 간에 피어링 연결을 생성합니다. VPC 와 온프레미스 위치 간에 VPN 연결을 
생성합니다. 
B. Amazon EC2 인스턴스를 시작합니다. 인스턴스에는 VPN 연결을 사용하여 모든 VPC 와 
온프레미스 위치를 연결하는 VPN 소프트웨어를 포함합니다. 
C. 전송 게이트웨이를 생성합니다. VPC 연결을 위한 VPC 연결을 생성합니다. 온프레미스 
연결을 위한 VPN 연결을 만듭니다. 
D. 온프레미스 위치와 중앙 VPC 간에 AWS Direct Connect 연결을 생성합니다. 피어링 
연결을 사용하여 중앙 VPC 를 다른 VPC 에 연결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132844-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
전송 게이트웨이는 중앙 집중식 및 확장 가능한 방식으로 VPC 와 온프레미스 네트워크를 
연결할 수 있는 네트워크 전송 허브입니다. VPC 연결을 생성하여 Transit Gateway 에 
연결하고, VPN 연결을 생성하여 인터넷을 통해 온프레미스 네트워크를 Transit Gateway 에 
연결할 수 있습니다. 전송 게이트웨이는 연결된 네트워크 간의 라우터 역할을 하며 필요한 
피어링 또는 VPN 연결 수를 줄여 새 연결 관리를 단순화합니다. Transit Gateway 라우팅 
테이블을 사용하여 연결된 네트워크 간의 트래픽 라우팅을 제어할 수도 있습니다. 전송 
게이트웨이를 생성하고 VPC 및 VPN 연결을 사용하면 최소한의 관리 오버헤드로 회사의 
요구 사항을 충족할 수 있습니다. 
Q687 
AWS 를 사용하는 회사에는 매달 제조 프로세스에 필요한 리소스를 예측하는 솔루션이 
필요합니다. 솔루션은 현재 Amazon S3 버킷에 저장된 기록 값을 사용해야 합니다. 회사는 
기계 학습(ML) 경험이 없으며 교육 및 예측에 관리형 서비스를 사용하려고 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. Amazon SageMaker 모델을 배포합니다. 추론을 위해 SageMaker 엔드포인트를 
생성합니다. 
B. Amazon SageMaker 를 사용하여 S3 버킷의 기록 데이터를 사용하여 모델을 교육합니다. 
C. Amazon SageMaker 엔드포인트를 사용하여 입력을 기반으로 예측을 생성하는 함수 
URL 로 AWS Lambda 함수를 구성합니다. 
D. Amazon Forecast 예측기를 사용하여 입력을 기반으로 예측을 생성하는 함수 URL 로 
AWS Lambda 함수를 구성합니다. 
E. S3 버킷의 기록 데이터를 사용하여 Amazon Forsecast 예측기를 교육합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/132845-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
D, E?? 
Q688 
회사는 AWS Organizations 에서 AWS 계정을 관리합니다. AWS IAM Identity Center(AWS 
Single Sign-On) 및 AWS Control Tower 가 계정에 대해 구성됩니다. 회사는 모든 계정에 
걸쳐 여러 사용자 권한을 관리하려고 합니다. 
권한은 여러 IAM 사용자가 사용하며 개발자 팀과 관리자 팀 간에 분배되어야 합니다. 각 
팀에는 서로 다른 권한이 필요합니다. 회사는 두 팀 모두에 고용된 신규 사용자를 포함하는 
솔루션을 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 각 계정에 대해 IAM Identity Center 에서 개별 사용자를 생성합니다. IAM Identity 
Center 에서 별도의 개발자 및 관리자 그룹을 생성합니다. 사용자를 적절한 그룹에 
할당합니다. 세분화된 권한을 설정하려면 각 그룹에 대한 사용자 지정 IAM 정책을 
생성하세요. 
B. 각 계정에 대해 IAM ID 센터에서 개별 사용자를 생성합니다. IAM Identity Center 에서 
별도의 개발자 및 관리자 그룹을 생성합니다. 사용자를 적절한 그룹에 할당합니다. 
세분화된 권한을 위해 필요에 따라 각 사용자에게 AWS 관리형 IAM 정책을 연결합니다. 
C. IAM Identity Center 에서 개별 사용자를 생성합니다. IAM Identity Center 에서 새로운 
개발자 및 관리자 그룹을 생성합니다. 각 그룹에 적합한 IAM 정책을 포함하는 새 권한 
세트를 생성합니다. 적절한 계정에 새 그룹을 할당합니다. 새 그룹에 새 권한 집합을 
할당합니다. 새로운 사용자가 고용되면 적절한 그룹에 추가하십시오. 
D. IAM Identity Center 에서 개별 사용자를 생성합니다. 각 사용자에 대한 적절한 IAM 
정책을 포함하는 새 권한 세트를 생성합니다. 사용자를 적절한 계정에 할당합니다. 특정 
계정 내에서 사용자에게 추가 IAM 권한을 부여합니다. 새로운 사용자가 고용되면 IAM 
Identity Center 에 추가하고 계정에 할당합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132847-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 IAM Identity Center 및 AWS Control Tower 의 기능을 활용하여 모든 계정에 
걸쳐 여러 사용자 권한을 중앙에서 관리하므로 최소한의 운영 오버헤드로 요구 사항을 
충족합니다. 새로운 그룹과 권한 집합을 생성함으로써 회사는 역할과 책임에 따라 개발자 
및 관리자 팀에 세분화된 권한을 할당할 수 있습니다. 권한 집합은 조직 수준의 그룹에 
적용되므로 조직의 모든 계정에 자동으로 상속됩니다. 새로운 사용자가 고용되면 회사는 
IAM ID 센터의 적절한 그룹에 해당 사용자를 추가하기만 하면 자동으로 해당 그룹에 할당된 
권한을 얻게 됩니다. 이를 통해 사용자 관리가 단순화되고 각 사용자에게 개별적으로 
권한을 할당하는 수동 작업이 줄어듭니다. 
Q689 
한 회사에서 Amazon Elastic Block Store(Amazon EBS) 볼륨 암호화 전략을 표준화하려고 
합니다. 또한 회사는 볼륨 암호화 검사를 수행하는 데 필요한 비용과 구성 노력을 
최소화하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. EBS 볼륨을 설명하고 EBS 볼륨이 암호화되었는지 확인하는 API 호출을 작성합니다. 
Amazon EventBridge 를 사용하여 API 호출을 실행하도록 AWS Lambda 함수를 예약합니다. 
B. EBS 볼륨을 설명하고 EBS 볼륨이 암호화되었는지 확인하는 API 호출을 작성합니다. 
AWS Fargate 작업에서 API 호출을 실행합니다. 
C. EBS 볼륨에서 태그를 사용해야 하는 AWS Identity and Access Management(IAM) 정책을 
생성합니다. 적절하게 태그가 지정되지 않은 리소스를 표시하려면 AWS Cost Explorer 를 
사용하십시오. 태그가 지정되지 않은 리소스를 수동으로 암호화합니다. 
D. Amazon EBS 에 대한 AWS Config 규칙을 생성하여 볼륨이 암호화되었는지 평가하고 
암호화되지 않은 경우 볼륨에 플래그를 지정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132849-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Config 는 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있는 서비스입니다. Config 
규칙을 만들면 최소한의 비용과 구성 노력으로 Amazon EBS 볼륨이 암호화되었는지 
자동으로 확인하고 암호화되지 않은 볼륨을 플래그 지정할 수 있습니다. 
AWS Config 규칙: AWS Config 는 미리 정의된 또는 사용자 지정 기준에 대해 리소스의 
준수 여부를 자동으로 확인하는 데 사용할 수 있는 관리형 규칙을 제공합니다. 이 경우 
EBS 볼륨을 평가하고 암호화되었는지 확인하는 규칙을 만듭니다. 볼륨이 암호화되지 않은 
경우 규칙에서 플래그를 지정하여 시정 조치를 취할 수 있습니다. 
운영 오버헤드: 이 방법은 규칙이 적용되면 EBS 볼륨의 준수 여부를 지속적으로 
모니터링하고 수동 검사나 사용자 지정 스크립팅이 필요하지 않으므로 운영 오버헤드를 
크게 줄입니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(API 호출 및 EventBridge 가 있는 Lambda): 이 방법은 작동할 수 있지만 사용자 
지정 코드를 작성하고 유지 관리해야 하므로 관리형 AWS Config 규칙을 사용하는 것보다 
운영 오버헤드가 증가합니다. 
옵션 B(Fargate 에서 API 호출): Fargate 에서 API 호출을 실행하는 것은 더 간단하고 
관리되는 솔루션을 제공하는 AWS Config 를 사용하는 것보다 더 복잡하고 비용이 많이 
듭니다. 
옵션 C(Cost Explorer 가 있는 IAM 정책): 이 옵션은 암호화 준수를 직접 적용하지 않고 
수동 개입이 필요하므로 효율성이 떨어지고 오류가 발생하기 쉽습니다. 
Q690 
한 회사는 정기적으로 GB 크기의 파일을 Amazon S3 에 업로드합니다. 회사는 파일을 
업로드한 후 Amazon EC2 스팟 인스턴스 집합을 사용하여 파일 형식을 트랜스코딩합니다. 
회사는 온프레미스 데이터 센터에서 Amazon S3 로 데이터를 업로드할 때와 Amazon 
S3 에서 EC2 인스턴스로 데이터를 다운로드할 때 처리량을 확장해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? (2 개 선택) 
A. S3 버킷에 직접 액세스하는 대신 S3 버킷 액세스 포인트를 사용하십시오. 
B. 파일을 여러 S3 버킷에 업로드합니다. 
C. S3 멀티파트 업로드를 사용합니다. 
D. 객체의 여러 바이트 범위를 병렬로 가져옵니다. 
E. 파일을 업로드할 때 각 개체에 임의의 접두사를 추가합니다. 
Answer: C, D 
https://www.examtopics.com/discussions/amazon/view/132852-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q691 
솔루션 설계자는 여러 가용 영역에 배포되는 웹 애플리케이션용 공유 스토리지 솔루션을 
설계하고 있습니다. 웹 애플리케이션은 Auto Scaling 그룹에 있는 Amazon EC2 
인스턴스에서 실행됩니다. 회사는 내용을 수시로 변경할 계획입니다. 솔루션은 변경사항이 
발생하는 즉시 새 콘텐츠를 반환하는 강력한 일관성을 가져야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) 
A. 개별 EC2 인스턴스에 탑재된 AWS Storage Gateway 볼륨 게이트웨이 iSCSI(Internet 
Small Computer Systems Interface) 블록 스토리지를 사용하십시오. 
B. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 개별 EC2 
인스턴스에 EFS 파일 시스템을 탑재합니다. 
C. 공유 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 개별 EC2 
인스턴스에 EBS 볼륨을 탑재합니다. 
D. AWS DataSync 를 사용하여 Auto Scaling 그룹의 EC2 호스트 간에 데이터를 지속적으로 
동기화합니다. 
E. 웹 콘텐츠를 저장할 Amazon S3 버킷을 생성합니다. Cache-Control 헤더의 
메타데이터를 no-cache 로 설정합니다. Amazon CloudFront 를 사용하여 콘텐츠를 
제공합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/132853-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이러한 옵션은 여러 가용 영역에 걸쳐 배포되고 강력한 일관성이 필요한 웹 애플리케이션을 
위한 공유 스토리지 솔루션을 설계하는 데 가장 적합한 방법입니다. 
옵션 B 는 Amazon Elastic File System(Amazon EFS)을 서로 다른 가용 영역의 여러 EC2 
인스턴스에 탑재할 수 있는 공유 파일 시스템으로 사용합니다. Amazon EFS 는 파일 기반 
워크로드에 대한 고가용성, 내구성, 확장성 및 성능을 제공합니다. 또한 강력한 일관성을 
지원합니다. 즉, 파일 시스템에 대한 모든 변경 사항이 모든 클라이언트에 즉시 표시됩니다. 
옵션 E 는 Amazon S3 를 웹 콘텐츠를 저장하고 콘텐츠 전송 네트워크(CDN)인 Amazon 
CloudFront 를 통해 제공할 수 있는 공유 객체 저장소로 사용합니다. Amazon S3 는 객체 
기반 워크로드에 대한 고가용성, 내구성, 확장성 및 성능을 제공합니다. 또한 쓰기 후 읽기 
및 목록 작업에 대한 강력한 일관성을 지원합니다. 즉, 개체에 대한 모든 변경 사항이 모든 
클라이언트에 즉시 표시됩니다. Cache-Control 헤더의 메타데이터를 nocache 로 설정하면 
웹 콘텐츠가 브라우저나 CDN 엣지 위치에서 캐시되는 것을 방지하여 항상 최신 콘텐츠가 
사용자에게 제공되도록 할 수 있습니다. 
Q692 
한 회사가 Application Load Balancer 를 사용하여 3 개 AWS 리전에 애플리케이션을 
배포하고 있습니다. Amazon Route 53 은 이러한 지역 간에 트래픽을 분산하는 데 
사용됩니다. 
솔루션 아키텍트는 MOST 고성능 경험을 제공하기 위해 어떤 Route 53 구성을 사용해야 
합니까? 
A. 대기 시간 정책이 포함된 A 레코드를 생성합니다. 
B. 지리적 위치 정책을 사용하여 A 레코드를 만듭니다. 
C. 장애 조치 정책을 사용하여 CNAME 레코드를 생성합니다. 
D. 지리 근접 정책을 사용하여 CNAME 레코드를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132854-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q693 
회사에는 내장형 NoSQL 데이터베이스가 포함된 웹 애플리케이션이 있습니다. 
애플리케이션은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 
실행됩니다. 인스턴스는 단일 가용 영역의 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 
최근 트래픽이 증가함에 따라 애플리케이션의 가용성이 높아야 하고 데이터베이스가 최종 
일관성을 유지해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. ALB 를 Network Load Balancer 로 교체합니다. EC2 인스턴스의 복제 서비스를 통해 
내장형 NoSQL 데이터베이스를 유지 관리합니다. 
B. ALB 를 Network Load Balancer 로 교체합니다. AWS Database Migration Service(AWS 
DMS)를 사용하여 내장형 NoSQL 데이터베이스를 Amazon DynamoDB 로 
마이그레이션합니다. 
C. 3 개의 가용 영역에서 EC2 인스턴스를 사용하도록 Auto Scaling 그룹을 수정합니다. EC2 
인스턴스의 복제 서비스를 통해 내장형 NoSQL 데이터베이스를 유지 관리합니다. 
D. 세 개의 가용 영역에서 EC2 인스턴스를 사용하도록 Auto Scaling 그룹을 수정합니다. 
AWS Database Migration Service(AWS DMS)를 사용하여 내장형 NoSQL 데이터베이스를 
Amazon DynamoDB 로 마이그레이션합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132855-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 최소한의 운영 오버헤드로 고가용성 및 최종 일관성 요구 사항을 충족합니다. 
3 개의 가용 영역에서 EC2 인스턴스를 사용하도록 Auto Scaling 그룹을 수정하면 웹 
애플리케이션이 트래픽 증가를 처리하고 1 개 또는 2 개의 가용 영역의 장애를 허용할 수 
있습니다. 내장된 NoSQL 데이터베이스를 Amazon DynamoDB 로 마이그레이션함으로써 
회사는 최종 일관성을 지원하는 확장 가능하고 안정적인 완전 관리형 NoSQL 데이터베이스 
서비스의 이점을 누릴 수 있습니다. AWS Database Migration Service(AWS DMS)는 관계형 
데이터베이스, 데이터 웨어하우스, NoSQL 데이터베이스 및 기타 유형의 데이터 저장소를 
쉽게 마이그레이션할 수 있게 해주는 클라우드 서비스입니다. AWS DMS 는 가동 중지 
시간을 최소화하고 데이터 손실 없이 내장형 NoSQL 데이터베이스를 Amazon 
DynamoDB 로 마이그레이션할 수 있습니다. 
Q694 
한 회사가 AWS 에서 쇼핑 애플리케이션을 구축하고 있습니다. 애플리케이션은 매달 한 
번씩 변경되고 트래픽 양에 따라 확장되어야 하는 카탈로그를 제공합니다. 회사는 
애플리케이션의 대기 시간이 최소화되기를 원합니다. 각 사용자 장바구니의 데이터는 
가용성이 높아야 합니다. 사용자의 연결이 끊어졌다가 다시 연결되더라도 사용자 세션 
데이터를 사용할 수 있어야 합니다. 
장바구니 데이터가 항상 보존되도록 솔루션 설계자는 무엇을 해야 합니까? 
A. Amazon Aurora 의 카탈로그에 액세스하기 위해 고정 세션 기능(세션 선호도)을 
활성화하도록 Application Load Balancer 를 구성합니다. 
B. Amazon DynamoDB 의 카탈로그 데이터와 사용자 세션의 장바구니 데이터를 캐시하도록 
Redis 용 Amazon ElastiCache 를 구성합니다. 
C. Amazon DynamoDB 의 카탈로그 데이터와 사용자 세션의 장바구니 데이터를 캐시하도록 
Amazon OpenSearch Service 를 구성합니다. 
D. 카탈로그 및 장바구니를 위한 Amazon Elastic Block Store(Amazon EBS) 스토리지로 
Amazon EC2 인스턴스를 구성합니다. 자동 스냅샷을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132857-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
장바구니 데이터가 항상 보존되도록 하려면 솔루션 설계자는 Amazon DynamoDB 의 
카탈로그 데이터와 사용자 세션의 장바구니 데이터를 캐시하도록 Redis 용 Amazon 
ElastiCache 를 구성해야 합니다. 이 솔루션에는 다음과 같은 이점이 있습니다. 
Redis 용 ElastiCache 는 인터넷 규모의 실시간 애플리케이션을 지원하기 위해 밀리초 
미만의 지연 시간을 제공하는 초고속 인 메모리 데이터 스토어이므로 애플리케이션에서 
가능한 가장 낮은 지연 시간을 제공합니다. 
Redis 용 ElastiCache 는 클러스터에 더 많은 노드나 샤드를 추가하여 수평적 확장을 
지원하고 노드 유형을 변경하여 수직적 확장을 지원하므로 트래픽 볼륨에 따라 확장됩니다. 
Redis 용 ElastiCache 는 여러 가용 영역에 걸친 복제와 기본 노드 장애 발생 시 자동 장애 
조치를 지원하므로 가용성이 높습니다 3. 
Redis 용 ElastiCache 는 스냅샷 또는 AOF(추가 전용 파일) 지속성을 사용하여 지속적이고 
내구성 있는 방식으로 사용자 로그인 정보, 장바구니 콘텐츠 등의 세션 데이터를 저장할 수 
있으므로 사용자의 연결이 끊겼다가 다시 연결되더라도 사용자 세션 데이터를 보존합니다. . 
참조: 
1: https://aws.amazon.com/elasticache/redis/ 
2: https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Scaling.html 
3: https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.html 
4: https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/backups.html 
Q695 
한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS)에 배포될 마이크로서비스 기반 
애플리케이션을 구축하고 있습니다. 마이크로서비스는 서로 상호 작용합니다. 회사는 향후 
성능 문제를 식별하기 위해 애플리케이션을 관찰할 수 있는지 확인하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon ElastiCache 를 사용하여 마이크로서비스로 전송되는 요청 수를 줄이도록 
애플리케이션을 구성합니다. 
B. EKS 클러스터에서 지표를 수집하도록 Amazon CloudWatch Container Insights 를 
구성합니다. 마이크로서비스 간 요청을 추적하도록 AWS X-Ray 를 구성합니다. 
C. API 호출을 검토하도록 AWS CloudTrail 을 구성합니다. Amazon QuickSight 대시보드를 
구축하여 마이크로서비스 상호 작용을 관찰하세요. 
D. AWS Trusted Advisor 를 사용하여 애플리케이션 성능을 이해하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132858-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션을 사용하면 회사가 Amazon EKS 에서 마이크로서비스 기반 애플리케이션의 
성능과 동작을 관찰할 수 있으므로 요구 사항을 충족합니다. Amazon CloudWatch Container 
Insights 는 컨테이너화된 애플리케이션 및 마이크로서비스에서 지표와 로그를 수집, 집계 
및 요약하는 기능입니다. Container Insights 는 Amazon EKS 및 Kubernetes 와 통합되어 
클러스터, 노드, 포드, 작업 및 서비스 수준에서 지표를 제공합니다. Container Insights 를 
사용하면 EKS 클러스터의 CPU, 메모리, 디스크 및 네트워크 사용률을 모니터링하고 병목 
현상, 지연 시간 급증 및 기타 문제를 식별할 수 있습니다. AWS X-Ray 는 애플리케이션이 
제공하는 요청에 대한 데이터를 수집하고, 해당 데이터를 보고, 필터링하고, 통찰력을 얻는 
데 사용할 수 있는 도구를 제공하는 서비스입니다. XRay 는 Amazon EKS 및 Kubernetes 와 
통합되어 마이크로서비스가 다운스트림 AWS 리소스, 마이크로서비스, 데이터베이스 및 웹 
API 에 보내는 요청을 추적합니다. X-Ray 를 사용하면 오류, 장애, 성능 문제의 근본 원인을 
분석하고 애플리케이션의 서비스 맵을 시각화할 수 있습니다. 
Q696 
기업은 고객에게 데이터에 대한 안전한 액세스를 제공해야 합니다. 회사는 고객 데이터를 
처리하고 결과를 Amazon S3 버킷에 저장합니다. 
모든 데이터에는 강력한 규정과 보안 요구 사항이 적용됩니다. 저장된 데이터는 
암호화되어야 합니다. 각 고객은 AWS 계정의 데이터에만 액세스할 수 있어야 합니다. 회사 
직원은 데이터에 접근할 수 없어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 각 고객에 대해 AWS Certificate Manager(ACM) 인증서를 프로비저닝합니다. 클라이언트 
측 데이터를 암호화합니다. 개인 인증서 정책에서 고객이 제공하는 IAM 역할을 제외한 
모든 보안 주체의 인증서에 대한 액세스를 거부합니다. 
B. 각 고객에 대해 별도의 AWS Key Management Service(AWS KMS) 키를 제공합니다. 
서버측 데이터를 암호화합니다. S3 버킷 정책에서 고객이 제공하는 IAM 역할을 제외한 모든 
보안 주체에 대한 데이터 암호 해독을 거부합니다. 
C. 각 고객에 대해 별도의 AWS Key Management Service(AWS KMS) 키를 
프로비저닝합니다. 서버측 데이터를 암호화합니다. 각 KMS 키 정책에서 고객이 제공하는 
IAM 역할을 제외한 모든 보안 주체에 대한 데이터 암호 해독을 거부합니다. 
D. 각 고객에 대해 AWS Certificate Manager(ACM) 인증서를 프로비저닝합니다. 클라이언트 
측 데이터를 암호화합니다. 공인 인증서 정책에서 고객이 제공하는 IAM 역할을 제외한 
모든 보안 주체의 인증서에 대한 액세스를 거부합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132859-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
올바른 솔루션은 각 고객에 대해 별도의 AWS KMS 키를 프로비저닝하고 서버 측에서 
데이터를 암호화하는 것입니다. 이러한 방식으로 회사는 S3 암호화 기능을 사용하여 저장 
중인 데이터를 보호하고 암호화 키에 대한 제어권을 고객에게 위임할 수 있습니다. 그러면 
고객은 자신의 IAM 역할을 사용하여 데이터에 액세스하고 암호를 해독할 수 있습니다. 
회사 직원은 KMS 주요 정책에 따라 승인되지 않았기 때문에 데이터에 액세스할 수 
없습니다. 다른 옵션은 다음과 같은 이유로 올바르지 않습니다. 
옵션 A 와 D 는 ACM 인증서를 사용하여 클라이언트 측 데이터를 암호화합니다. 이는 
암호화 프로세스에 복잡성과 오버헤드를 추가하므로 S3 암호화에 권장되지 않습니다. 
게다가 회사는 각 고객에 대한 인증서와 정책을 관리해야 하는데 이는 확장 가능하고 
안전하지 않습니다. 
옵션 B 는 각 고객에 대해 별도의 KMS 키를 사용하지만 S3 버킷 정책을 사용하여 암호 
해독 액세스를 제어합니다. 버킷 정책은 개별 객체가 아닌 전체 버킷에 적용되므로 이는 
안전한 솔루션이 아닙니다. 따라서 고객은 버킷 콘텐츠 나열 권한이 있는 경우 서로의 
데이터에 액세스하고 암호를 해독할 수 있습니다. 또한 버킷 정책은 KMS 키 정책을 
재정의합니다. 이는 회사 직원이 KMS 키를 사용할 권한이 있는 경우 데이터에 액세스할 수 
있음을 의미합니다. 
Q697 
솔루션 아키텍트는 2 개의 퍼블릭 서브넷과 2 개의 프라이빗 서브넷을 포함하는 VPC 를 
생성합니다. 기업 보안 의무에 따라 솔루션 설계자는 프라이빗 서브넷에서 모든 Amazon 
EC2 인스턴스를 시작해야 합니다. 그러나 솔루션 아키텍트가 프라이빗 서브넷의 포트 80 
및 443 에서 웹 서버를 실행하는 EC2 인스턴스를 시작하면 외부 인터넷 트래픽이 서버에 
연결할 수 없습니다. 
이 문제를 해결하려면 솔루션 아키텍트가 무엇을 해야 합니까? 
A. EC2 인스턴스를 프라이빗 서브넷의 Auto Scaling 그룹에 연결합니다. 웹 사이트의 DNS 
레코드가 Auto Scaling 그룹 식별자로 확인되는지 확인하세요. 
B. 퍼블릭 서브넷에서 인터넷 연결 Application Load Balancer(ALB)를 프로비저닝합니다. 
웹 사이트의 DNS 레코드가 ALB 로 확인되도록 AL 과 연결된 대상 그룹에 EC2 인스턴스를 
추가합니다. 
C. 프라이빗 서브넷에서 NAT 게이트웨이를 시작합니다. NAT 게이트웨이에 기본 경로를 
추가하려면 프라이빗 서브넷의 라우팅 테이블을 업데이트하세요. NAT 게이트웨이에 공용 
탄력적 IP 주소를 연결합니다. 
D. EC2 인스턴스에 연결된 보안 그룹이 포트 80 의 HTTP 트래픽과 포트 443 의 HTTPS 
트래픽을 허용하는지 확인하십시오. 웹 사이트의 DNS 레코드가 EC2 인스턴스의 퍼블릭 IP 
주소로 확인되는지 확인하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132860-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Application Load Balancer(ALB)는 여러 가용 영역 1 에서 EC2 인스턴스, 컨테이너, Lambda 
함수, IP 주소 등 여러 대상에 수신 애플리케이션 트래픽을 분산시키는 Elastic Load 
Balancer(ELB) 유형입니다. ALB 는 인터넷 연결이거나 내부일 수 있습니다. 인터넷 연결 
ALB 에는 클라이언트가 인터넷을 통해 요청을 보내는 데 사용할 수 있는 공용 DNS 이름이 
있습니다. 내부 ALB 에는 클라이언트가 VPC 내에서 요청을 보내는 데 사용할 수 있는 
프라이빗 DNS 이름이 있습니다. 이 솔루션은 다음과 같은 이유로 질문의 요구 사항을 
충족합니다. 
ALB 가 이러한 포트에서 요청을 수신하고 프라이빗 서브넷의 EC2 인스턴스로 전달하므로 
외부 인터넷 트래픽이 포트 80 및 443 의 웹 서버에 연결할 수 있습니다. 
EC2 인스턴스는 프라이빗 서브넷에서 시작되고 퍼블릭 IP 주소나 인터넷 게이트웨이에 
대한 경로가 없으므로 기업 보안 규정을 위반하지 않습니다. 
ALB 는 로드 밸런싱, 상태 확인, 확장 및 보안 작업을 처리하는 완전 관리형 서비스이므로 
운영 오버헤드가 줄어듭니다. 
Q698 
한 회사가 AWS Fargate 클러스터를 사용하여 Amazon Elastic Kubernetes Service(Amazon 
EKS)에 새 애플리케이션을 배포하고 있습니다. 애플리케이션에는 데이터 지속성을 위한 
스토리지 솔루션이 필요합니다. 솔루션은 가용성이 높고 내결함성이 있어야 합니다. 또한 
솔루션은 여러 애플리케이션 컨테이너 간에 공유되어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EKS 작업자 노드가 배치된 동일한 가용 영역에 Amazon Elastic Block Store(Amazon 
EBS) 볼륨을 생성합니다. EKS 클러스터의 StorageClass 객체에 볼륨을 등록합니다. EBS 
다중 연결을 사용하여 컨테이너 간에 데이터를 공유합니다. 
B. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. EKS 클러스터의 
StorageClass 객체에 파일 시스템을 등록합니다. 모든 컨테이너에 동일한 파일 시스템을 
사용합니다. 
C. Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. EKS 클러스터의 
StorageClass 객체에 볼륨을 등록합니다. 모든 용기에 동일한 용량을 사용하십시오. 
D. EKS 작업자 노드가 배치된 동일한 가용 영역에 Amazon Elastic File System(Amazon 
EFS) 파일 시스템을 생성합니다. EKS 클러스터의 StorageClass 객체에 파일 시스템을 
등록합니다. 파일 시스템 간에 데이터를 동기화하는 AWS Lambda 함수를 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132861-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon EFS 는 여러 컨테이너 간에 공유할 수 있는 탄력적이고 확장 가능한 완전관리형 
파일 시스템입니다. 여러 가용 영역에 걸쳐 데이터를 복제하여 고가용성과 내결함성을 
제공합니다. Amazon EFS 는 Amazon EKS 및 AWS Fargate 와 호환되며 EKS 클러스터의 
StorageClass 객체에 등록할 수 있습니다. Amazon EBS 볼륨은 AWS Fargate 에서 지원되지 
않으며 EBS 다중 연결을 사용하지 않고는 여러 컨테이너 간에 공유할 수 없습니다. 이는 
제한 사항과 성능에 영향을 미칩니다. 또한 EBS 다중 연결에서는 볼륨이 작업자 노드와 
동일한 가용 영역에 있어야 하므로 가용성과 내결함성이 줄어듭니다. AWS Lambda 를 
사용하여 여러 EFS 파일 시스템 간에 데이터를 동기화하는 것은 불필요하고 복잡하며 
오류가 발생하기 쉽습니다. 
Q699 
회사에는 로컬 데이터 센터에 Docker 컨테이너를 사용하는 애플리케이션이 있습니다. 
애플리케이션은 호스트의 볼륨에 영구 데이터를 저장하는 컨테이너 호스트에서 실행됩니다. 
컨테이너 인스턴스는 저장된 영구 데이터를 사용합니다. 
회사는 서버나 스토리지 인프라를 관리하고 싶지 않기 때문에 애플리케이션을 완전 관리형 
서비스로 이동하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 자체 관리형 노드와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 
사용하십시오. Amazon EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 
볼륨을 생성합니다. EBS 볼륨을 컨테이너에 탑재된 영구 볼륨으로 사용합니다. 
B. AWS Fargate 시작 유형과 함께 Amazon Elastic Container Service(Amazon ECS)를 
사용하십시오. Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. EFS 볼륨을 
컨테이너에 탑재된 영구 스토리지 볼륨으로 추가합니다. 
C. AWS Fargate 시작 유형과 함께 Amazon Elastic Container Service(Amazon ECS)를 
사용하십시오. Amazon S3 버킷을 생성합니다. S3 버킷을 컨테이너에 탑재된 영구 스토리지 
볼륨으로 매핑합니다. 
D. Amazon EC2 시작 유형과 함께 Amazon Elastic Container Service(Amazon ECS)를 
사용하십시오. Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. EFS 볼륨을 
컨테이너에 탑재된 영구 스토리지 볼륨으로 추가합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132862-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션을 사용하면 회사가 서버나 스토리지 인프라를 관리하지 않고도 애플리케이션을 
완전 관리형 서비스로 이동할 수 있으므로 요구 사항을 충족합니다. AWS Fargate 는 
Amazon ECS 작업을 실행하는 컨테이너용 서버리스 컴퓨팅 엔진입니다. Fargate 를 
사용하면 회사는 컨테이너를 실행하기 위해 가상 머신 클러스터를 프로비저닝, 구성 또는 
확장할 필요가 없습니다. Amazon EFS 는 여러 컨테이너에서 동시에 액세스할 수 있는 
완전관리형 파일 시스템입니다. EFS 를 사용하면 회사는 스토리지 용량을 프로비저닝하고 
관리할 필요가 없습니다. EFS 는 파일 시스템을 빠르고 쉽게 생성하고 구성할 수 있는 
간단한 인터페이스를 제공합니다. 회사는 EFS 볼륨을 컨테이너에 탑재된 영구 스토리지 
볼륨으로 사용하여 영구 데이터를 저장할 수 있습니다. 회사에서는 EFS 탑재 도우미를 
사용하여 탑재 프로세스를 단순화할 수도 있습니다. 
Q700 
한 게임 회사가 여러 AWS 리전에서 새로운 인터넷 연결 애플리케이션을 출시하려고 
합니다. 애플리케이션은 통신을 위해 TCP 및 UDP 프로토콜을 사용합니다. 회사는 글로벌 
사용자에게 고가용성과 최소 대기 시간을 제공해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 조치 조합을 취해야 합니까? (2 개 
선택) 
A. 각 리전의 애플리케이션 앞에 내부 Network Load Balancer 를 생성합니다. 
B. 각 지역의 애플리케이션 앞에 외부 Application Load Balancer 를 생성합니다. 
C. AWS Global Accelerator 액셀러레이터를 생성하여 각 리전의 로드 밸런서로 트래픽을 
라우팅합니다. 
D. 지리적 위치 라우팅 정책을 사용하여 트래픽을 분산하도록 Amazon Route 53 을 
구성합니다. 
E. 트래픽을 처리하고 각 지역의 애플리케이션에 대한 요청을 라우팅하도록 Amazon 
CloudFront 를 구성합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/132863-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q701 
한 도시에서는 ALB(Application Load Balancer) 뒤에 Amazon EC2 인스턴스에서 실행되는 
웹 애플리케이션을 배포했습니다. 애플리케이션 사용자는 산발적인 성능을 보고했는데, 
이는 무작위 IP 주소에서 발생하는 DDoS 공격과 관련된 것으로 보입니다. 도시에는 구성 
변경을 최소화하고 DDoS 소스에 대한 감사 추적을 제공하는 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. ALB 에서 AWS WAF 웹 ACL 을 활성화하고 알 수 없는 소스의 트래픽을 차단하는 규칙을 
구성합니다. 
B. Amazon Inspector 를 구독하세요. AWS DDoS 대응 팀(DRT)을 참여시켜 완화 제어 
기능을 서비스에 통합하십시오. 
C. AWS Shield Advanced 를 구독하세요. AWS DDoS 대응 팀(DRT)을 참여시켜 완화 제어 
기능을 서비스에 통합하십시오. 
D. 애플리케이션에 대한 Amazon CloudFront 배포를 생성하고 ALB 를 오리진으로 
설정합니다. 배포에서 AWS WAF 웹 ACL 을 활성화하고 알 수 없는 소스의 트래픽을 
차단하는 규칙을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132865-exam-aws-certified-sol
utions-architect-associate-saa-c03 
설명: 
임의 IP 주소에서 발생하는 DDoS 공격으로부터 웹 애플리케이션을 보호하려면 솔루션 
아키텍트가 AWS Shield Advanced 를 구독하고 AWS DDoS 대응 팀(DRT)과 협력하여 완화 
제어 기능을 서비스에 통합해야 합니다. AWS Shield Advanced 는 DRT 의 연중무휴 지원 및 
대응을 통해 대규모의 정교한 DDoS 공격에 대한 보호를 제공하는 관리형 서비스입니다. 
DRT 는 도시에서 AWS WAF 규칙, 속도 기반 규칙 및 네트워크 ACL 과 같은 사전 및 사후 
보호 장치를 구성하여 악성 트래픽을 차단하고 애플리케이션의 복원력을 향상시키는 데 
도움을 줄 수 있습니다. 
또한 이 서비스는 자세한 공격 보고서와 Amazon CloudWatch 지표를 통해 DDoS 소스에 
대한 감사 추적을 제공합니다. 
Q702 
한 회사는 최근 해양 조사에서 얻은 200TB 의 데이터를 AWS Snowball Edge Storage 
Optimized 디바이스에 복사합니다. 이 회사는 석유 및 가스 매장지를 찾기 위해 AWS 에 
호스팅되는 고성능 컴퓨팅(HPC) 클러스터를 보유하고 있습니다. 솔루션 아키텍트는 
Snowball Edge Storage Optimized 디바이스의 데이터에 대한 일관된 밀리초 미만의 지연 
시간과 높은 처리량 액세스를 클러스터에 제공해야 합니다. 회사는 디바이스를 AWS 로 
다시 보내고 있습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 버킷을 생성합니다. 데이터를 S3 버킷으로 가져옵니다. S3 버킷을 
사용하도록 AWS Storage Gateway 파일 게이트웨이를 구성합니다. HPC 클러스터 
인스턴스에서 파일 게이트웨이에 액세스합니다. 
B. Amazon S3 버킷을 생성합니다. 데이터를 S3 버킷으로 가져옵니다. Lustre 파일 시스템용 
Amazon FSx 를 구성하고 이를 S3 버킷과 통합합니다. HPC 클러스터 인스턴스에서 FSx for 
Lustre 파일 시스템에 액세스합니다. 
C. Amazon S3 버킷과 Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 
데이터를 S3 버킷으로 가져옵니다. S3 버킷의 데이터를 EFS 파일 시스템에 복사합니다. 
HPC 클러스터 인스턴스에서 EFS 파일 시스템에 액세스합니다. 
D. Lustre 파일 시스템용 Amazon FSx 를 생성합니다. 데이터를 FSx for Lustre 파일 
시스템으로 직접 가져옵니다. HPC 클러스터 인스턴스에서 FSx for Lustre 파일 시스템에 
액세스합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132866-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
D?? 
Q703 
한 회사의 온프레미스 데이터 센터에 소량의 데이터를 Amazon S3 에 정기적으로 백업해야 
하는 NFS 서버가 있습니다. 
이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까? 
A. 온프레미스 서버의 데이터를 Amazon S3 에 복사하도록 AWS Glue 를 설정합니다. 
B. 온프레미스 서버에 AWS DataSync 에이전트를 설정하고 데이터를 Amazon S3 에 
동기화합니다. 
C. AWS Transfer for SFTP 를 사용하여 SFTP 동기화를 설정하여 온프레미스에서 Amazon 
S3 로 데이터를 동기화합니다. 
D. 온프레미스 데이터 센터와 VPC 간에 AWS Direct Connect 연결을 설정하고 데이터를 
Amazon S3 에 복사합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132867-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS DataSync 는 온프레미스 스토리지와 AWS 스토리지 서비스 간에 대량의 데이터를 
온라인으로 쉽게 이동할 수 있게 해주는 서비스입니다. AWS DataSync 는 특별히 구축된 
네트워크 프로토콜을 사용하고 데이터 전송을 병렬화하여 오픈 소스 도구보다 최대 10 배 
빠른 속도로 데이터를 전송할 수 있습니다. AWS DataSync 는 암호화, 데이터 무결성 확인 
및 대역폭 최적화도 처리합니다. AWS DataSync 를 사용하려면 사용자는 NFS 서버에 
연결하고 데이터를 Amazon S3 에 동기화하는 온프레미스 서버에 DataSync 에이전트를 
배포해야 합니다. 사용자는 정기적 또는 일회성 동기화 작업을 예약하고 전송 진행 상황과 
상태를 모니터링할 수 있습니다. 
다른 옵션은 비용 효율적이지 않거나 사용 사례에 적합하지 않기 때문에 올바르지 않습니다. 
온프레미스 서버에서 Amazon S3 로 데이터를 복사하도록 AWS Glue 를 설정하는 것은 비용 
효율적이지 않습니다. AWS Glue 는 단순 작업이 아닌 추출, 변환 및 로드(ETL) 작업에 주로 
사용되는 서버리스 데이터 통합 서비스이기 때문입니다. 데이터 백업. 온프레미스에서 
Amazon S3 로 데이터를 동기화하기 위해 AWS Transfer for SFTP 를 사용하여 SFTP 
동기화를 설정하는 것은 비용 효율적이지 않습니다. 왜냐하면 AWS Transfer for SFTP 는 
교환에 더 적합한 SFTP 프로토콜을 사용하여 안전한 파일 전송을 제공하는 완전관리형 
서비스이기 때문입니다. 데이터를 백업하는 것보다 제3자에게 데이터를 제공하는 것입니다. 
온프레미스 데이터 센터와 VPC 간에 AWS Direct Connect 연결을 설정하고 Amazon S3 에 
데이터를 복사하는 것은 비용 효율적이지 않습니다. 왜냐하면 AWS Direct Connect 는 
AWS 와 온프레미스 위치 간의 전용 네트워크 연결이기 때문입니다. 초기 비용이 높고 추가 
구성이 필요합니다. 
Q704 
온라인 비디오 게임 회사는 게임 서버에 대해 매우 낮은 대기 시간을 유지해야 합니다. 
게임 서버는 Amazon EC2 인스턴스에서 실행됩니다. 회사에는 초당 수백만 건의 UDP 
인터넷 트래픽 요청을 처리할 수 있는 솔루션이 필요합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 인터넷 트래픽에 필요한 프로토콜과 포트로 Application Load Balancer 를 구성합니다. 
EC2 인스턴스를 대상으로 지정합니다. 
B. 인터넷 트래픽을 위한 게이트웨이 로드 밸런서를 구성합니다. EC2 인스턴스를 대상으로 
지정합니다. 
C. 인터넷 트래픽에 필요한 프로토콜과 포트로 Network Load Balancer 를 구성합니다. EC2 
인스턴스를 대상으로 지정합니다. 
D. 별도의 AWS 지역에 있는 EC2 인스턴스에서 동일한 게임 서버 세트를 시작합니다. 
인터넷 트래픽을 두 EC2 인스턴스 세트로 라우팅합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132868-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
온라인 비디오 게임 회사를 위한 가장 비용 효율적인 솔루션은 인터넷 트래픽에 필요한 
프로토콜과 포트로 Network Load Balancer 를 구성하고 EC2 인스턴스를 대상으로 지정하는 
것입니다. 이 솔루션을 통해 회사는 매우 짧은 대기 시간과 고성능으로 초당 수백만 개의 
UDP 요청을 처리할 수 있습니다. 
Network Load Balancer 는 연결 수준(계층 4)에서 작동하고 IP 프로토콜 데이터를 기반으로 
Amazon VPC 내의 대상(EC2 인스턴스, 마이크로서비스 또는 컨테이너)으로 트래픽을 
라우팅하는 Elastic Load Balancing 의 한 유형입니다. Network Load Balancer 는 매우 짧은 
대기 시간으로 높은 처리량을 유지하면서 초당 수백만 개의 요청을 처리할 수 있으므로 
TCP 및 UDP 트래픽의 로드 밸런싱에 이상적입니다. 또한 Network Load Balancer 는 
백엔드 애플리케이션에 대한 클라이언트의 소스 IP 주소를 보존하므로 로깅이나 보안 
목적으로 유용할 수 있습니다. 
Q705 
회사는 VPC 에서 3 티어 애플리케이션을 실행합니다. 데이터베이스 계층은 MySQL DB 
인스턴스용 Amazon RDS 를 사용합니다. 
이 회사는 RDS for MySQL DB 인스턴스를 Amazon Aurora PostgreSQL DB 클러스터로 
마이그레이션할 계획입니다. 회사에는 새 데이터베이스로 마이그레이션하는 동안 발생하는 
데이터 변경 사항을 복제하는 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. AWS Database Migration Service(AWS DMS) 스키마 변환을 사용하여 데이터베이스 
객체를 변환합니다. 
B. AWS DMS(AWS Database Migration Service) 스키마 변환을 사용하여 RDS for MySQL DB 
인스턴스에 Aurora PostgreSQL 읽기 전용 복제본을 생성합니다. 
C. RDS for MySQL DB 인스턴스에 대한 Aurora MySQL 읽기 전용 복제본을 구성합니다. 
D. 변경 데이터 캡처(CDC)를 사용하여 AWS Database Migration Service(AWS DMS) 작업을 
정의하여 데이터를 마이그레이션합니다. 
E. 복제 지연 시간이 0 일 때 Aurora PostgreSQL 읽기 전용 복제본을 독립형 Aurora 
PostgreSQL DB 클러스터로 승격합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/132870-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q706 
회사는 여러 가용 영역에 배포된 Amazon RDS 인스턴스에서 실행되는 데이터베이스를 
호스팅합니다. 회사는 정기적으로 데이터베이스에 대해 스크립트를 실행하여 
데이터베이스에 추가된 새 항목을 보고합니다. 데이터베이스에 대해 실행되는 스크립트는 
중요한 애플리케이션의 성능에 부정적인 영향을 미칩니다. 회사는 최소한의 비용으로 
애플리케이션 성능을 향상시켜야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 활성 연결이 가장 적은 인스턴스를 식별하는 기능을 스크립트에 추가하십시오. 해당 
인스턴스에서 읽어 전체 새 항목을 보고하도록 스크립트를 구성합니다. 
B. 데이터베이스의 읽기 전용 복제본을 생성합니다. 총 새 항목을 보고하기 위해 읽기 전용 
복제본만 쿼리하도록 스크립트를 구성합니다. 
C. 하루가 끝날 때마다 데이터베이스의 해당 날짜의 새 항목을 수동으로 내보내도록 개발 
팀에 지시합니다. 
D. Amazon ElastiCache 를 사용하여 스크립트가 데이터베이스에 대해 실행하는 일반 쿼리를 
캐시합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133216-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
읽기 전용 복제본은 읽기 전용 쿼리를 지원하는 기본 데이터베이스의 복사본입니다. 읽기 
전용 복제본을 생성하면 기본 데이터베이스에서 읽기 워크로드를 오프로드하고 성능을 
향상시킬 수 있습니다. 
스크립트는 기본 데이터베이스를 사용하는 중요한 애플리케이션에 영향을 주지 않고 읽기 
전용 복제본을 쿼리할 수 있습니다. 또한 이 솔루션은 스크립트를 수정하거나 데이터를 
수동으로 내보내거나 캐시 클러스터를 관리할 필요가 없으므로 운영 오버헤드가 가장 
적습니다. 
Q707 
회사는 ALB(Application Load Balancer)를 사용하여 애플리케이션을 인터넷에 제공하고 
있습니다. 회사는 애플리케이션 전체에서 비정상적인 트래픽 액세스 패턴을 발견합니다. 
솔루션 설계자는 회사가 이러한 이상 현상을 더 잘 이해할 수 있도록 인프라에 대한 
가시성을 향상해야 합니다. 
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까? 
A. Amazon Athena 에서 AWS CloudTrail 로그용 테이블을 생성합니다. 관련 정보에 대한 
쿼리를 만듭니다. 
B. Amazon S3 에 대한 ALB 액세스 로깅을 활성화합니다. Amazon Athena 에서 테이블을 
생성하고 로그를 쿼리합니다. 
C. Amazon S3 에 대한 ALB 액세스 로깅을 활성화합니다. 텍스트 편집기에서 각 파일을 
열고 각 줄에서 관련 정보를 검색하세요. 
D. 전용 Amazon EC2 인스턴스에서 Amazon EMR 을 사용하여 ALB 에 직접 쿼리하여 
트래픽 액세스 로그 정보를 얻습니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132874-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션을 사용하면 회사가 ALB 액세스 로깅 및 Amazon Athena 를 사용하여 인프라에 
대한 가시성을 향상할 수 있으므로 요구 사항을 충족합니다. ALB 액세스 로깅은 
클라이언트의 IP 주소, 요청 경로, 응답 코드, 대기 시간 등 로드 밸런서로 전송된 요청에 
대한 자세한 정보를 캡처하는 기능입니다. Amazon S3 에 대한 ALB 액세스 로깅을 
활성화함으로써 회사는 액세스 로그를 S3 버킷에 압축 파일로 저장할 수 있습니다. 
Amazon Athena 는 표준 SQL 을 사용하여 Amazon S3 의 데이터를 쉽게 분석할 수 있게 
해주는 대화형 쿼리 서비스입니다. Amazon Athena 에 액세스 로그용 테이블을 생성하면 
회사는 로그를 쿼리하고 몇 초 안에 결과를 얻을 수 있습니다. 이를 통해 회사는 
애플리케이션 전체의 비정상적인 트래픽 액세스 패턴을 더 잘 이해할 수 있습니다. 
Q708 
회사에서 AWS 환경에서 NAT 게이트웨이를 사용하려고 합니다. 프라이빗 서브넷에 있는 
회사의 Amazon EC2 인스턴스는 NAT 게이트웨이를 통해 퍼블릭 인터넷에 연결할 수 
있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. EC2 인스턴스와 동일한 프라이빗 서브넷에 퍼블릭 NAT 게이트웨이를 생성합니다. 
B. EC2 인스턴스와 동일한 프라이빗 서브넷에 프라이빗 NAT 게이트웨이를 생성합니다. 
C. EC2 인스턴스와 동일한 VPC 의 퍼블릭 서브넷에 퍼블릭 NAT 게이트웨이를 생성합니다. 
D. EC2 인스턴스와 동일한 VPC 의 퍼블릭 서브넷에 프라이빗 NAT 게이트웨이를 
생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132875-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
퍼블릭 NAT 게이트웨이를 사용하면 프라이빗 서브넷의 인스턴스가 아웃바운드 트래픽을 
인터넷으로 보내는 동시에 인터넷이 인스턴스와의 연결을 시작하는 것을 방지할 수 
있습니다. 퍼블릭 NAT 게이트웨이에는 탄력적 IP 주소와 VPC 용 인터넷 게이트웨이에 대한 
경로가 필요합니다. 프라이빗 NAT 게이트웨이를 사용하면 프라이빗 서브넷의 인스턴스가 
전송 게이트웨이 또는 가상 프라이빗 게이트웨이를 통해 다른 VPC 또는 온프레미스 
네트워크에 연결할 수 있습니다. 프라이빗 NAT 게이트웨이에는 탄력적 IP 주소나 인터넷 
게이트웨이가 필요하지 않습니다. 
사설 및 공용 NAT 게이트웨이 모두 인스턴스의 소스 사설 IPv4 주소를 NAT 게이트웨이의 
사설 IPv4 주소에 매핑하지만, 공용 NAT 게이트웨이의 경우 인터넷 게이트웨이가 공용 
NAT 게이트웨이의 사설 IPv4 주소를 NAT 게이트웨이와 연결된 탄력적 IP 주소에 
매핑합니다. 
공용 NAT 게이트웨이이든 개인 NAT 게이트웨이이든 관계없이 인스턴스에 응답 트래픽을 
보낼 때 NAT 게이트웨이는 주소를 원래 소스 IP 주소로 다시 변환합니다. 
EC2 인스턴스와 동일한 사설 서브넷에 공용 NAT 게이트웨이를 만드는 것(옵션 A)은 NAT 
게이트웨이에 인터넷 게이트웨이에 대한 경로가 없으므로 올바른 해결책이 아닙니다. 
EC2 인스턴스(옵션 B)와 동일한 프라이빗 서브넷에 프라이빗 NAT 게이트웨이를 생성하는 
것도 유효한 솔루션이 아닙니다. 인스턴스가 프라이빗 NAT 게이트웨이를 통해 인터넷에 
액세스할 수 없기 때문입니다. EC2 인스턴스와 동일한 VPC 의 퍼블릭 서브넷에 프라이빗 
NAT 게이트웨이를 생성하는 것(옵션 D)도 유효한 솔루션이 아닙니다. 인터넷 게이트웨이가 
프라이빗 NAT 게이트웨이에서 트래픽을 삭제하기 때문입니다. 
따라서 유일한 유효한 솔루션은 EC2 인스턴스와 동일한 VPC 의 퍼블릭 서브넷에 퍼블릭 
NAT 게이트웨이를 생성하는 것입니다(옵션 C). 이렇게 하면 인스턴스가 퍼블릭 NAT 
게이트웨이 및 인터넷 게이트웨이를 통해 인터넷에 액세스할 수 있습니다. 
Q709 
회사는 AWS Organizations 에 조직을 가지고 있습니다. 이 회사는 루트 조직 단위(OU)에 
있는 4 개의 AWS 계정에서 Amazon EC2 인스턴스를 실행합니다. 비프로덕션 계정 3 개와 
프로덕션 계정 1 개가 있습니다. 회사는 사용자가 비프로덕션 계정에서 특정 크기의 EC2 
인스턴스를 시작하는 것을 금지하려고 합니다. 회사는 금지된 유형을 사용하는 시작 
인스턴스에 대한 액세스를 거부하기 위해 서비스 제어 정책(SCP)을 만들었습니다. 
SCP 를 배포하는 솔루션은 이러한 요구 사항을 충족합니까? (2 개 선택) 
A. SCP 를 조직의 루트 OU 에 연결합니다. 
B. 세 개의 비생산 조직 구성원 계정에 SCP 를 연결합니다. 
C. SCP 를 조직 마스터 계정에 연결합니다. 
D. 프로덕션 계정에 대한 OU 를 생성합니다. SCP 를 OU 에 연결합니다. 프로덕션 구성원 
계정을 새 OU 로 이동합니다. 
E. 필요한 계정에 대한 OU 를 생성합니다. SCP 를 OU 에 연결합니다. 비프로덕션 구성원 
계정을 새 OU 로 이동합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/132876-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
SCP 는 조직의 권한을 관리하는 데 사용할 수 있는 조직 정책 유형입니다. SCP 는 조직의 
모든 계정에 사용 가능한 최대 권한에 대한 중앙 제어를 제공합니다. SCP 는 귀하의 계정이 
조직의 액세스 제어 지침을 준수하도록 보장하는 데 도움이 됩니다. 
특정 계정 집합에 SCP 를 적용하려면 해당 계정에 대한 OU 를 생성하고 SCP 를 OU 에 
연결해야 합니다. 이렇게 하면 SCP 는 해당 OU 의 멤버 계정에만 영향을 미치고 조직의 
다른 계정에는 영향을 미치지 않습니다. SCP 를 루트 OU 에 연결하면 프로덕션 계정을 
포함하여 조직의 모든 계정에 적용되지만 이는 원하는 결과가 아닙니다. SCP 를 마스터 
계정에 연결하면 아무런 효과가 없습니다. SCP 는 마스터 계정의 사용자나 역할에 영향을 
미치지 않기 때문입니다. 
따라서 SCP 를 배포하는 가장 좋은 솔루션은 B 와 E 입니다. 옵션 B 는 SCP 를 세 개의 
비프로덕션 계정에 직접 연결하는 반면, 옵션 E 는 비프로덕션 계정에 대해 별도의 OU 를 
생성하고 SCP 를 OU 에 연결합니다. 두 옵션 모두 비프로덕션 계정에서 EC2 인스턴스 
유형을 제한하는 동일한 결과를 얻을 수 있지만, 나중에 적용할 계정이나 정책이 더 많은 
경우 옵션 E 가 더 확장성과 관리가 용이할 수 있습니다. 
Q710 
Amazon EC2 인스턴스에 호스팅된 회사 웹 사이트는 Amazon S3 에 저장된 분류된 
데이터를 처리합니다. 보안 문제로 인해 회사에서는 EC2 리소스와 Amazon S3 간에 
비공개적이고 안전한 연결이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. VPC 엔드포인트에서의 액세스를 허용하도록 S3 버킷 정책을 설정하십시오. 
B. S3 버킷에 대한 읽기-쓰기 액세스 권한을 부여하도록 IAM 정책을 설정합니다. 
C. 프라이빗 서브넷 외부의 리소스에 액세스하기 위해 NAT 게이트웨이를 설정합니다. 
D. S3 버킷에 액세스하기 위한 액세스 키 ID 와 보안 액세스 키를 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/133462-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
이 솔루션은 다음 요구 사항을 충족합니다. 
EC2 인스턴스가 공용 인터넷을 사용하지 않고도 S3 버킷에 액세스할 수 있으므로 
비공개적이고 안전합니다. VPC 엔드포인트는 동일한 리전 내에서 VPC 와 다른 AWS 
서비스(예: S3) 간에 프라이빗 연결을 생성할 수 있게 해주는 게이트웨이입니다. S3 용 VPC 
엔드포인트는 VPC 의 프라이빗 IP 주소를 사용하여 S3 버킷 및 객체에 대한 안전하고 
직접적인 액세스를 제공합니다. 또한 VPC 엔드포인트 정책과 S3 버킷 정책을 사용하여 
엔드포인트, IAM 사용자, IAM 역할 또는 소스 IP 주소를 기반으로 S3 리소스에 대한 
액세스를 제어할 수 있습니다. 
추가 AWS 서비스, 게이트웨이 또는 NAT 장치가 필요하지 않으므로 간단하고 확장 
가능합니다. 
S3 용 VPC 엔드포인트는 네트워크 트래픽에 따라 자동으로 확장되는 완전관리형 
서비스입니다. 
VPC 콘솔에서 몇 번의 클릭이나 간단한 API 호출을 통해 S3 용 VPC 엔드포인트를 생성할 
수 있습니다. 
동일한 VPC 엔드포인트를 사용하여 동일한 리전에 있는 여러 S3 버킷에 액세스할 수도 
있습니다. 
Q711 
전자상거래 회사가 AWS 에서 애플리케이션을 실행합니다. 애플리케이션은 기본 
데이터베이스에 대해 다중 AZ 모드의 Amazon Aurora PostgreSQL 클러스터를 사용합니다. 
최근 판촉 캠페인 중에 애플리케이션에 과도한 읽기 로드 및 쓰기 로드가 발생했습니다. 
사용자가 애플리케이션에 액세스하려고 할 때 시간 초과 문제가 발생했습니다. 
솔루션 아키텍트는 애플리케이션 아키텍처의 확장성과 가용성을 높여야 합니다. 
가동 중지 시간을 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Aurora 클러스터를 소스로 포함하는 Amazon EventBridge 규칙을 생성하십시오. Aurora 
클러스터의 상태 변경 이벤트를 기록하는 AWS Lambda 함수를 생성합니다. EventBridge 
규칙의 대상으로 Lambda 함수를 추가합니다. 장애 조치할 추가 리더 노드를 추가합니다. 
B. Aurora 클러스터를 수정하고 ZDR(제로 다운타임 재시작) 기능을 활성화하십시오. 
클러스터에서 데이터베이스 활동 스트림을 사용하여 클러스터 상태를 추적합니다. 
C. Aurora 클러스터에 추가 리더 인스턴스를 추가합니다. Aurora 클러스터에 대한 Amazon 
RDS 프록시 대상 그룹을 생성합니다. 
D. Redis 캐시용 Amazon ElastiCache 를 생성합니다. Write-around 방식의 AWS Database 
Migration Service(AWS DMS)를 사용하여 Aurora 클러스터에서 Redis 로 데이터를 
복제합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132882-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 최소한의 다운타임으로 확장성 및 고가용성 요구 사항을 직접 해결합니다. 
추가 리더 인스턴스: Aurora 클러스터에 더 많은 리더 인스턴스를 추가하면 읽기 부하가 
분산되어 많은 읽기 트래픽에서 애플리케이션 성능이 향상됩니다. Aurora 리더 인스턴스는 
작성자 인스턴스에서 데이터를 자동으로 복제하여 읽기 작업을 확장할 수 있습니다. 
Amazon RDS 프록시: RDS 프록시는 데이터베이스 연결을 보다 효율적으로 관리하고 연결 
풀을 제공하여 데이터베이스 가용성을 개선합니다. 이를 통해 최대 부하 시 Aurora 
클러스터의 오버헤드가 줄어들어 애플리케이션 코드를 변경하지 않고도 성능과 가용성이 
더욱 향상됩니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(EventBridge 및 Lambda): 이는 성능 및 가용성 문제를 직접 해결하지 않습니다. 
상태 변경 사항을 로깅하고 장애 이벤트 시 리더 노드를 추가해도 사전 확장성이 제공되지 
않습니다. 
옵션 B(제로 다운타임 재시작 및 활동 스트림): 제로 다운타임 재시작(ZDR)은 유지 관리 
중 다운타임을 최소화하는 데 유용하지만 확장성을 직접 개선하지는 않습니다. 
데이터베이스 활동 스트림은 성능 향상보다는 보안 모니터링에 더 적합합니다. 
옵션 D(Redis 용 ElastiCache): 캐싱 계층을 추가하면 읽기 성능에 도움이 되지만 복잡성이 
발생하고 추가 리더 인스턴스가 부하를 처리할 수 있는 경우에는 필요하지 않을 수 
있습니다. 
Q712 
한 회사가 AWS 에서 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 회사의 기존 
데이터 센터와 회사의 VPC 간의 VPN 연결을 사용합니다. 
이 회사는 DNS 서비스로 Amazon Route 53 을 사용합니다. 애플리케이션은 프라이빗 DNS 
레코드를 사용하여 VPC 에서 온프레미스 서비스와 통신해야 합니다. 
가장 안전한 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Route 53 Resolver 아웃바운드 엔드포인트를 생성합니다. 해석기 규칙을 만듭니다. 
해석기 규칙을 VPC 와 연결합니다. 
B. Route 53 Resolver 인바운드 엔드포인트를 생성합니다. 해석기 규칙을 만듭니다. 해석기 
규칙을 VPC 와 연결합니다. 
C. Route 53 프라이빗 호스팅 영역을 생성합니다. 프라이빗 호스팅 영역을 VPC 와 
연결합니다. 
D. Route 53 퍼블릭 호스팅 영역을 생성합니다. 서비스 통신을 허용하려면 각 서비스에 
대한 레코드를 만듭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132883-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
가장 안전한 방식으로 웹 애플리케이션의 요구 사항을 충족하려면 회사는 Route 53 
Resolver 아웃바운드 엔드포인트를 생성하고, 확인자 규칙을 생성하고, 확인자 규칙을 
VPC 와 연결해야 합니다. 이 솔루션을 사용하면 애플리케이션이 프라이빗 DNS 레코드를 
사용하여 VPC 의 온프레미스 서비스와 통신할 수 있습니다. Route 53 Resolver 는 
온프레미스 네트워크와 AWS VPC 간의 DNS 확인을 가능하게 하는 서비스입니다. 
아웃바운드 엔드포인트는 확인자가 VPC 에서 온프레미스 네트워크의 확인자로 DNS 쿼리를 
전달하는 데 사용하는 IP 주소 집합입니다. 확인자 규칙은 확인자가 규칙에 지정한 IP 
주소로 DNS 쿼리를 전달하는 도메인 이름을 지정하는 규칙입니다. 아웃바운드 
엔드포인트와 확인자 규칙을 생성하고 이를 VPC 와 연결함으로써 회사는 프라이빗 DNS 
레코드를 사용하여 온프레미스 서비스에 대한 DNS 쿼리를 안전하게 확인할 수 있습니다. 
다른 옵션은 요구 사항을 충족하지 않거나 안전하지 않기 때문에 올바르지 않습니다. Route 
53 Resolver 인바운드 엔드포인트 생성, 해석기 규칙 생성 및 해석기 규칙을 VPC 와 
연결하는 것은 올바르지 않습니다. 왜냐하면 이 솔루션은 온프레미스 네트워크의 DNS 
쿼리가 VPC 의 리소스에 액세스하도록 허용하고 그 반대의 경우는 허용하지 않기 
때문입니다. 인바운드 엔드포인트는 확인자가 온프레미스 네트워크의 확인자로부터 DNS 
쿼리를 수신하는 데 사용하는 IP 주소 집합입니다. Route 53 프라이빗 호스팅 영역을 
생성하고 이를 VPC 와 연결하는 것은 올바르지 않습니다. 이 솔루션은 동일한 호스팅 
영역과 연결된 VPC 또는 다른 VPC 내의 리소스에 대해서만 DNS 확인을 허용하기 
때문입니다. 
프라이빗 호스팅 영역은 하나 이상의 VPC 에서만 액세스할 수 있는 DNS 레코드의 
컨테이너입니다. Route 53 퍼블릭 호스팅 영역을 생성하고 서비스 통신을 허용하기 위해 각 
서비스에 대한 레코드를 생성하는 것은 올바르지 않습니다. 이 솔루션은 온프레미스 
서비스를 안전하지 않은 퍼블릭 인터넷에 노출시키기 때문입니다. 퍼블릭 호스팅 영역은 
인터넷 어디에서나 액세스할 수 있는 DNS 레코드의 컨테이너입니다. 
Q713 
us-east-1 지역에서 사진 호스팅 서비스를 운영하는 회사가 있습니다. 이 서비스를 통해 
여러 국가의 사용자가 사진을 업로드하고 볼 수 있습니다. 일부 사진은 몇 달 동안 많이 
조회되지만 다른 사진은 일주일 미만 동안 조회됩니다. 이 애플리케이션에서는 각 사진당 
최대 20MB 까지 업로드할 수 있습니다. 이 서비스는 사진 메타데이터를 사용하여 각 
사용자에게 표시할 사진을 결정합니다. 
가장 비용 효율적으로 적절한 사용자 액세스를 제공하는 솔루션은 무엇입니까? 
A. Amazon DynamoDB 에 사진을 저장합니다. DynamoDB Accelerator(DAX)를 켜서 자주 
보는 항목을 캐시합니다. 
B. Amazon S3 Intelligent-Tiering 스토리지 클래스에 사진을 저장합니다. 사진 메타데이터와 
해당 S3 위치를 DynamoDB 에 저장합니다. 
C. Amazon S3 Standard 스토리지 클래스에 사진을 저장합니다. 30 일이 지난 사진을 S3 
Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스로 이동하도록 S3 수명 주기 
정책을 설정합니다. 메타데이터를 추적하려면 객체 태그를 사용하세요. 
D. Amazon S3 Glacier 스토리지 클래스에 사진을 저장합니다. 30 일이 지난 사진을 S3 
Glacier Deep Archive 스토리지 클래스로 이동하도록 S3 수명 주기 정책을 설정합니다. 
사진 메타데이터와 해당 S3 위치를 Amazon OpenSearch Service 에 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132885-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 성능에 영향을 주거나 운영 오버헤드 없이 액세스 패턴이 변경될 때 데이터를 
가장 비용 효율적인 액세스 계층으로 이동하여 스토리지 비용을 자동으로 최적화하는 
Amazon S3 Intelligent-Tiering 스토리지 클래스를 사용하기 때문에 가장 비용 효율적으로 
적절한 사용자 액세스를 제공합니다 1 . 이 스토리지 클래스는 몇 달 또는 일주일 미만 동안 
많이 본 사진과 같이 알 수 없거나 변화하거나 예측할 수 없는 액세스 패턴이 있는 
데이터에 이상적입니다. 사진 메타데이터와 해당 S3 위치를 DynamoDB 에 저장함으로써 
애플리케이션은 각 사용자에 대한 관련 사진을 신속하게 쿼리하고 검색할 수 있습니다. 
DynamoDB 는 키-값 및 문서 데이터 모델을 지원하는 빠르고 확장 가능하며 완전 관리형 
NoSQL 데이터베이스 서비스입니다. 
Q714 
한 회사는 Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스에서 고가용성 웹 
애플리케이션을 실행합니다. 회사는 Amazon CloudWatch 지표를 사용합니다. 
웹 애플리케이션에 대한 트래픽이 증가함에 따라 일부 EC2 인스턴스는 많은 미해결 
요청으로 인해 과부하가 발생합니다. CloudWatch 지표는 처리된 요청 수와 일부 EC2 
인스턴스로부터 응답을 수신하는 시간이 모두 다른 EC2 인스턴스에 비해 높다는 것을 
보여줍니다. 회사는 이미 과부하된 EC2 인스턴스에 새 요청이 전달되는 것을 원하지 
않습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. RequestCountPerTarget 및 ActiveConnectionCount CloudWatch 지표를 기반으로 하는 
라운드 로빈 라우팅 알고리즘을 사용하십시오. 
B. RequestCountPerTarget 및 ActiveConnectionCount CloudWatch 지표를 기반으로 최소 
미해결 요청 알고리즘을 사용합니다. 
C. RequestCount 및 TargetResponseTime CloudWatch 지표를 기반으로 라운드 로빈 
라우팅 알고리즘을 사용합니다. 
D. RequestCount 및 TargetResponseTime CloudWatch 지표를 기반으로 최소 미해결 요청 
알고리즘을 사용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132887-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
LOR(최소 미결 요청) 알고리즘은 들어오는 요청을 미결 요청이 가장 적은 대상에 
분산시키는 로드 밸런싱 알고리즘입니다. 이는 단일 대상의 과부하를 방지하고 웹 
애플리케이션의 전반적인 성능과 가용성을 향상시키는 데 도움이 됩니다. LOR 알고리즘은 
RequestCount 및 TargetResponseTime CloudWatch 지표를 사용하여 미해결 요청 수와 각 
대상의 응답 시간을 결정할 수 있습니다. 이러한 지표는 각 대상에서 처리된 요청 수와 
요청이 로드 밸런서를 떠난 후 로드 밸런서가 대상의 응답을 수신할 때까지 경과된 시간을 
각각 측정합니다. LOR 알고리즘은 이러한 메트릭을 사용하여 사용량이 적고 응답성이 높은 
대상으로 새 요청을 라우팅하고 이미 과부하되었거나 느린 대상으로 요청을 보내는 것을 
방지할 수 있습니다. 이 솔루션은 회사의 요구 사항을 충족합니다. 
Q715 
회사는 Amazon EC2, AWS Fargate 및 AWS Lambda 를 사용하여 회사의 AWS 계정에서 
여러 워크로드를 실행합니다. 회사는 Compute Savings Plan 을 최대한 활용하기를 원합니다. 
회사는 Compute Savings Plans 적용 범위가 줄어들면 알림을 받기를 원합니다. 
가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS 예산을 사용하여 Savings Plans 에 대한 일일 예산을 생성합니다. 적절한 이메일 
메시지 수신자에게 알림을 보내려면 적용 범위 임계값으로 예산을 구성하십시오. 
B. Savings Plans 에 대한 적용 범위 보고서를 실행하는 Lambda 함수를 생성합니다. 
Amazon Simple Email Service(Amazon SES)를 사용하여 해당 이메일 메시지 수신자에게 
보고서를 이메일로 보냅니다. 
C. Savings Plans 예산에 대한 AWS 예산 보고서를 생성합니다. 빈도를 매일로 설정하세요. 
D. Savings Plans 알림 구독을 만듭니다. 모든 알림 옵션을 활성화합니다. 알림을 받으려면 
이메일 주소를 입력하세요. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132888-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q716 
한 회사가 AWS 에서 실시간 데이터 수집 솔루션을 실행하고 있습니다. 이 솔루션은 최신 
버전의 Amazon Managed Streaming for Apache Kafka(Amazon MSK)로 구성됩니다. 이 
솔루션은 3 개의 가용 영역에 걸쳐 프라이빗 서브넷의 VPC 에 배포됩니다. 
솔루션 설계자는 인터넷을 통해 공개적으로 사용할 수 있도록 데이터 수집 솔루션을 
재설계해야 합니다. 전송 중인 데이터도 암호화되어야 합니다. 
가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 기존 VPC 에서 퍼블릭 서브넷을 구성합니다. 퍼블릭 서브넷에 MSK 클러스터를 
배포합니다. 상호 TLS 인증을 활성화하려면 MSK 클러스터 보안 설정을 업데이트하세요. 
B. 퍼블릭 서브넷이 있는 새 VPC 를 생성합니다. 퍼블릭 서브넷에 MSK 클러스터를 
배포합니다. 상호 TLS 인증을 활성화하려면 MSK 클러스터 보안 설정을 업데이트하세요. 
C. 프라이빗 서브넷을 사용하는 ALB(Application Load Balancer)를 배포합니다. HTTPS 
프로토콜에 대한 VPC CIDR 블록의 인바운드 트래픽을 허용하도록 ALB 보안 그룹 인바운드 
규칙을 구성합니다. 
D. 프라이빗 서브넷을 사용하는 NLB(Network Load Balancer)를 배포합니다. 인터넷을 통한 
HTTPS 통신을 위해 NLB 수신기를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132889-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
가장 운영 효율성이 뛰어나며 요구 사항을 충족하는 솔루션은 기존 VPC 에 퍼블릭 
서브넷을 구성하고 퍼블릭 서브넷에 MSK 클러스터를 배포하는 것입니다. 이 솔루션을 
사용하면 새 VPC 를 생성하거나 로드 밸런서를 배포하지 않고도 인터넷을 통해 데이터 
수집 솔루션을 공개적으로 사용할 수 있습니다. 또한 이 솔루션은 상호 TLS 인증을 
활성화하여 전송 중인 데이터가 암호화되도록 보장합니다. 이를 위해서는 클라이언트와 
서버 모두 확인을 위해 인증서를 제시해야 합니다. 이 솔루션은 Apache Kafka 2.6.0 이상 
버전을 실행하는 클러스터에서 사용할 수 있는 Amazon MSK 의 퍼블릭 액세스 기능을 
활용합니다. 
다른 솔루션은 불필요한 리소스를 생성하거나 전송 중인 데이터를 암호화하지 않기 때문에 
첫 번째 솔루션만큼 효율적이지 않습니다. 퍼블릭 서브넷이 있는 새 VPC 를 생성하면 
네트워크 리소스 및 라우팅 관리에 추가 비용과 복잡성이 발생합니다. ALB 또는 NLB 를 
배포하면 데이터 수집 솔루션에 더 많은 비용과 대기 시간이 추가됩니다. 또한 ALB 또는 
NLB 는 추가 단계와 유지 관리가 필요한 HTTPS 리스너 및 인증서로 구성되지 않는 한 
전송 중인 데이터를 자체적으로 암호화하지 않습니다. 따라서 이러한 솔루션은 주어진 요구 
사항에 최적이 아닙니다. 
Q717 
회사에서 온프레미스 레거시 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 
애플리케이션은 온프레미스 ERP(전사적 자원 관리) 시스템에서 고객 주문 파일을 
수집합니다. 그런 다음 애플리케이션은 파일을 SFTP 서버에 업로드합니다. 애플리케이션은 
매시간 주문 파일을 확인하는 예약된 작업을 사용합니다. 
회사에는 이미 온프레미스 네트워크에 연결된 AWS 계정이 있습니다. AWS 의 새로운 
애플리케이션은 기존 ERP 시스템과의 통합을 지원해야 합니다. 새로운 애플리케이션은 
안전하고 탄력적이어야 하며 SFTP 프로토콜을 사용하여 ERP 시스템의 주문을 즉시 
처리해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 두 개의 가용 영역에 AWS Transfer Family SFTP 인터넷 연결 서버를 생성합니다. 
Amazon S3 스토리지를 사용하세요. 주문 파일을 처리하는 AWS Lambda 함수를 
생성합니다. S3 이벤트 알림을 사용하여 s3:ObjectCreated:* 이벤트를 Lambda 함수로 
보냅니다. 
B. 하나의 가용 영역에 AWS Transfer Family SFTP 인터넷 연결 서버를 생성합니다. 
Amazon Elastic File System(Amazon EFS) 스토리지를 사용합니다. 주문 파일을 처리하는 
AWS Lambda 함수를 생성합니다. Transfer Family 관리형 워크플로를 사용하여 Lambda 
함수를 호출합니다. 
C. 두 개의 가용 영역에 AWS Transfer Family SFTP 내부 서버를 생성합니다. Amazon 
Elastic File System(Amazon EFS) 스토리지를 사용합니다. 주문 파일을 처리하기 위해 AWS 
Step Functions 상태 머신을 생성합니다. Amazon EventBridge Scheduler 를 사용하면 상태 
시스템을 호출하여 Amazon EFS 에서 주문 파일을 주기적으로 확인할 수 있습니다. 
D. 두 개의 가용 영역에 AWS Transfer Family SFTP 내부 서버를 생성합니다. Amazon S3 
스토리지를 사용하세요. 주문 파일을 처리하는 AWS Lambda 함수를 생성합니다. Transfer 
Family 관리형 워크플로를 사용하여 Lambda 함수를 호출합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132890-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 다음 구성 요소와 기능을 사용하므로 요구 사항을 충족합니다. 
AWS Transfer Family SFTP 내부 서버: 이를 통해 애플리케이션은 프라이빗 연결을 통해 
SFTP 프로토콜을 사용하여 온프레미스 ERP 시스템에서 AWS 로 주문 파일을 안전하게 
전송할 수 있습니다. 내부 서버는 고가용성과 내결함성을 위해 두 개의 가용 영역에 
배포됩니다. 
Amazon S3 스토리지: 주문 파일을 위한 확장 가능하고 내구성이 뛰어나며 비용 효과적인 
객체 스토리지를 제공합니다. Amazon S3 는 또한 데이터 보호 및 규정 준수를 위한 수명 
주기 정책 및 버전 관리는 물론 저장 및 전송 중 암호화도 지원합니다. 
AWS Lambda 기능: 이를 통해 애플리케이션은 서버를 프로비저닝하거나 관리하지 않고도 
서버리스 방식으로 주문 파일을 처리할 수 있습니다. Lambda 함수는 데이터 검증, 구문 
분석 또는 강화와 같은 주문 파일에 대한 사용자 지정 논리 또는 변환을 수행할 수 
있습니다. 
Transfer Family 관리형 워크플로: 파일이 SFTP 서버에 업로드되자마자 Lambda 함수를 
트리거하여 파일 처리 작업의 조정을 단순화합니다. 관리형 워크플로는 오류 처리, 재시도 
정책 및 로깅 기능도 제공합니다. 
Q718 
회사의 애플리케이션은 Apache Hadoop 및 Apache Spark 를 사용하여 온프레미스에서 
데이터를 처리합니다. 기존 인프라는 확장이 불가능하고 관리가 복잡합니다. 
솔루션 설계자는 운영 복잡성을 줄이는 확장 가능한 솔루션을 설계해야 합니다. 솔루션은 
온프레미스에서 데이터 처리를 유지해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Site-to-Site VPN 을 사용하여 온프레미스 Hadoop 분산 파일 시스템(HDFS) 데이터 
및 애플리케이션에 액세스하십시오. Amazon EMR 클러스터를 사용하여 데이터를 
처리합니다. 
B. AWS DataSync 를 사용하여 온프레미스 Hadoop 분산 파일 시스템(HDFS) 클러스터에 
연결합니다. 데이터를 처리할 Amazon EMR 클러스터를 생성합니다. 
C. Apache Hadoop 애플리케이션과 Apache Spark 애플리케이션을 AWS Outposts 의 
Amazon EMR 클러스터로 마이그레이션합니다. EMR 클러스터를 사용하여 데이터를 
처리합니다. 
D. AWS Snowball 장치를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. 
데이터를 처리할 Amazon EMR 클러스터를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132891-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q719 
한 회사가 온프레미스 스토리지에서 AWS 로 대량의 데이터를 마이그레이션하고 있습니다. 
동일한 AWS 리전에 있는 Windows, Mac 및 Linux 기반 Amazon EC2 인스턴스는 SMB 및 
NFS 스토리지 프로토콜을 사용하여 데이터에 액세스합니다. 회사는 정기적으로 데이터의 
일부에 액세스합니다. 회사는 나머지 데이터에 드물게 액세스합니다. 
회사는 데이터를 호스팅하기 위한 솔루션을 설계해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EFS Intelligent-Tiering 을 사용하는 Amazon Elastic File System(Amazon EFS) 볼륨을 
생성합니다. AWS DataSync 를 사용하여 데이터를 EFS 볼륨으로 마이그레이션합니다. 
B. ONTAP 인스턴스용 Amazon FSx 를 생성합니다. 자동 계층화 정책을 사용하는 루트 
볼륨이 있는 FSx for ONTAP 파일 시스템을 생성합니다. 데이터를 FSx for ONTAP 볼륨으로 
마이그레이션합니다. 
C. S3 Intelligent-Tiering 을 사용하는 Amazon S3 버킷을 생성합니다. AWS Storage Gateway 
Amazon S3 파일 게이트웨이를 사용하여 데이터를 S3 버킷으로 마이그레이션합니다. 
D. OpenZFS 파일 시스템용 Amazon FSx 를 생성합니다. 데이터를 새 볼륨으로 
마이그레이션합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132892-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q720 
한 제조 회사가 AWS 에서 보고서 생성 애플리케이션을 실행하고 있습니다. 애플리케이션은 
약 20 분 안에 각 보고서를 생성합니다. 애플리케이션은 단일 Amazon EC2 인스턴스에서 
실행되는 모놀리스로 구축되었습니다. 애플리케이션에는 긴밀하게 결합된 모듈을 자주 
업데이트해야 합니다. 회사에서 새로운 기능을 추가하면 애플리케이션을 유지 관리하기가 
복잡해집니다. 
회사에서 소프트웨어 모듈을 패치할 때마다 애플리케이션에 가동 중지 시간이 발생합니다. 
보고서 생성은 중단된 후에 처음부터 다시 시작되어야 합니다. 회사는 애플리케이션이 
유연하고 확장 가능하며 점진적으로 개선될 수 있도록 애플리케이션을 재설계하려고 합니다. 
회사는 애플리케이션 가동 중지 시간을 최소화하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Lambda 에서 최대 프로비저닝 동시성을 갖춘 단일 함수로 애플리케이션을 
실행합니다. 
B. 스팟 집합 기본 할당 전략을 사용하여 Amazon EC2 스팟 인스턴스에서 애플리케이션을 
마이크로서비스로 실행합니다. 
C. 서비스 자동 조정을 통해 Amazon Elastic Container Service(Amazon ECS)에서 
애플리케이션을 마이크로서비스로 실행합니다. 
D. 일괄 배포 전략을 사용하여 AWS Elastic Beanstalk 에서 애플리케이션을 단일 
애플리케이션 환경으로 실행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132893-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
요구 사항을 충족하는 솔루션은 Amazon Elastic Container Service(Amazon ECS)에서 
서비스 자동 확장 기능을 갖춘 마이크로서비스로 애플리케이션을 실행하는 것입니다. 이 
솔루션을 사용하면 애플리케이션을 유연하고 확장 가능하며 점진적으로 개선할 수 있을 
뿐만 아니라 애플리케이션 가동 중지 시간도 최소화할 수 있습니다. 모놀리식 
애플리케이션을 마이크로서비스로 분할함으로써 회사는 전체 애플리케이션에 영향을 주지 
않고 모듈을 분리하고 독립적으로 업데이트할 수 있습니다. Amazon ECS 에서 
마이크로서비스를 실행함으로써 회사는 이식성, 효율성, 격리와 같은 컨테이너화의 이점을 
활용할 수 있습니다. 서비스 자동 확장을 활성화함으로써 회사는 수요에 따라 각 
마이크로서비스에 대해 실행되는 컨테이너 수를 조정하여 최적의 성능과 비용을 보장할 수 
있습니다. 또한 Amazon ECS 는 업데이트 중 가동 중지 시간을 줄이거나 없앨 수 있는 롤링 
업데이트 또는 블루/그린 배포와 같은 다양한 배포 전략을 지원합니다. 
다른 솔루션은 요구 사항을 충족하지 않거나 새로운 문제를 야기하기 때문에 첫 번째 
솔루션만큼 효과적이지 않습니다. 최대 동시성 프로비저닝을 통해 AWS Lambda 에서 
애플리케이션을 단일 함수로 실행하면 모놀리스를 마이크로서비스로 분해하지도 않고 유지 
관리의 복잡성을 줄여주지도 않기 때문에 요구 사항을 충족하지 못합니다. 또한 Lambda 
함수는 실행 시간(15 분), 메모리 크기(10GB) 및 동시성 할당량에 의해 제한되는데, 이는 
보고서 생성 애플리케이션에 충분하지 않을 수 있습니다. 스팟 집합 기본 할당 전략을 
사용하여 Amazon EC2 스팟 인스턴스에서 마이크로서비스로 애플리케이션을 실행하면 현물 
가격 변동으로 인해 중단될 위험이 있으므로 요구 사항을 충족하지 못합니다. 스팟 
인스턴스는 가용성이나 안정성이 보장되지 않으며 AWS 에서 언제든지 2 분 경고 후 회수할 
수 있습니다. 
이로 인해 보고서 생성이 실패하거나 처음부터 다시 시작될 수 있습니다. 한꺼번에 배포 
전략을 사용하는 단일 애플리케이션 환경으로 AWS Elastic Beanstalk 에서 애플리케이션을 
실행하면 모놀리스를 마이크로서비스로 분해하지도 않고 애플리케이션 가동 중지 시간을 
최소화하지도 않기 때문에 요구 사항을 충족하지 못합니다. 일괄 배포 전략은 업데이트를 
모든 인스턴스에 동시에 배포하므로 애플리케이션이 잠시 중단됩니다. 
Q721 
한 회사는 대규모 웹 애플리케이션을 서버리스 마이크로서비스 아키텍처로 재설계하려고 
합니다. 애플리케이션은 Amazon EC2 인스턴스를 사용하며 Python 으로 작성되었습니다. 
회사는 마이크로서비스로 테스트하기 위해 웹 애플리케이션의 한 구성 요소를 선택했습니다. 
구성 요소는 초당 수백 개의 요청을 지원합니다. 회사는 Python 을 지원하는 AWS 
솔루션에서 마이크로서비스를 생성하고 테스트하려고 합니다. 또한 솔루션은 자동으로 
확장되어야 하며 최소한의 인프라와 최소한의 운영 지원이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 최신 Amazon Linux 운영 체제를 실행하는 EC2 인스턴스의 자동 확장 기능이 있는 스팟 
집합을 사용하십시오. 
B. 고가용성이 구성된 AWS Elastic Beanstalk 웹 서버 환경을 사용하십시오. 
C. Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다. 자체 관리형 EC2 
인스턴스의 Auto Scaling 그룹을 시작합니다. 
D. 사용자 정의 개발 코드를 실행하는 AWS Lambda 함수를 사용하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132894-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Lambda 는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 
서버리스 컴퓨팅 서비스입니다. Lambda 를 사용하여 Python 또는 기타 지원되는 언어로 
작성된 마이크로서비스를 생성하고 테스트할 수 있습니다. Lambda 는 초당 요청 수를 
처리하기 위해 자동으로 확장됩니다. 사용한 컴퓨팅 시간에 대해서만 비용을 지불하면 
됩니다. 또한 Lambda 는 Amazon API Gateway, Amazon S3, Amazon DynamoDB 및 
Amazon SQS 와 같은 다른 AWS 서비스와 통합되어 이벤트 기반 아키텍처를 활성화합니다. 
Lambda 는 서버, 운영 체제, 패치 또는 확장 정책을 관리할 필요가 없으므로 인프라와 
운영 오버헤드가 최소화됩니다. 
다른 옵션은 서버리스 솔루션이 아니며 더 많은 인프라와 운영 지원이 필요합니다. 또한 
초당 요청 수를 처리하기 위해 자동으로 확장되지 않습니다. 스팟 집합은 저렴한 가격으로 
여유 용량으로 실행되는 EC2 인스턴스 모음입니다. 그러나 스팟 인스턴스는 언제든지 
AWS 에 의해 중단될 수 있으며, 이는 마이크로서비스의 가용성과 성능에 영향을 미칠 수 
있습니다. AWS Elastic Beanstalk 는 EC2 인스턴스에서 웹 애플리케이션의 배포 및 관리를 
자동화하는 서비스입니다. 그러나 기본 EC2 인스턴스와 로드 밸런서는 여전히 프로비저닝, 
구성 및 모니터링해야 합니다. Amazon EKS 는 AWS 에서 Kubernetes 를 실행하는 
서비스입니다. 그러나 Kubernetes 클러스터와 노드를 구성하는 EC2 인스턴스를 생성, 구성 
및 관리해야 합니다. 또한 Kubernetes 소프트웨어 및 도구를 설치하고 업데이트해야 
합니다. 
Q722 
회사에는 온프레미스 위치에서 AWS 계정으로 AWS Direct Connect 연결이 있습니다. AWS 
계정에는 동일한 AWS 리전에 30 개의 서로 다른 VPC 가 있습니다. VPC 는 프라이빗 
VIF(가상 인터페이스)를 사용합니다. 각 VPC 에는 회사가 관리하는 다른 네트워크와 겹치지 
않는 CIDR 블록이 있습니다. 
회사는 네트워킹 아키텍처를 중앙에서 관리하는 동시에 각 VPC 가 다른 모든 VPC 및 
온프레미스 네트워크와 계속 통신할 수 있기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 전송 게이트웨이를 생성하고 Direct Connect 연결을 새 전송 VIF 와 연결합니다. Transit 
Gateway 의 경로 전파 기능을 켭니다. 
B. Direct Connect 게이트웨이를 생성합니다. 새 게이트웨이를 사용하려면 프라이빗 VIF 를 
다시 생성합니다. 새로운 가상 프라이빗 게이트웨이를 생성하여 각 VPC 를 연결합니다. 
C. 전송 VP 를 생성합니다. 전송 VPC 에 대한 Direct Connect 연결을 생성합니다. 리전의 
다른 모든 VPC 간에 피어링 연결을 생성합니다. 라우팅 테이블을 업데이트합니다. 
D. 온프레미스에서 각 VPC 로 AWS Site-to-Site VPN 연결을 생성합니다. 각 연결에 대해 
두 VPN 터널이 모두 작동 중인지 확인하세요. 경로 전파 기능을 켭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132895-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q723 
회사에 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. EC2 인스턴스는 
관련 정책이 있는 IAM 역할을 사용하여 Amazon RDS 데이터베이스에 연결합니다. 회사는 
AWS Systems Manager 를 사용하여 실행 중인 애플리케이션을 중단하지 않고 EC2 
인스턴스를 패치하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 새로운 IAM 역할을 생성합니다. AmazonSSMManagedInstanceCore 정책을 새 IAM 
역할에 연결합니다. 새 IAM 역할을 EC2 인스턴스와 기존 IAM 역할에 연결합니다. 
B. IAM 사용자를 생성합니다. AmazonSSMManagedInstanceCore 정책을 IAM 사용자에게 
연결합니다. IAM 사용자를 사용하여 EC2 인스턴스를 관리하도록 Systems Manager 를 
구성합니다. 
C. Systems Manager 에서 기본 호스트 구성 관리를 활성화하여 EC2 인스턴스를 
관리합니다. 
D. 기존 IAM 역할에서 기존 정책을 제거합니다. 기존 IAM 역할에 
AmazonSSMManagedInstanceCore 정책을 추가합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132900-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
회사 요구 사항에 가장 적합한 솔루션은 Systems Manager 에서 기본 호스트 구성 관리를 
활성화하여 EC2 인스턴스를 관리하는 것입니다. 이 솔루션을 사용하면 회사는 실행 중인 
애플리케이션을 중단하지 않고 IAM 역할이나 사용자를 수동으로 생성하거나 수정하지 
않고도 EC2 인스턴스를 패치할 수 있습니다. 
기본 호스트 구성 관리는 Systems Manager 가 EC2 인스턴스를 관리형 인스턴스로 자동 
관리할 수 있게 해주는 AWS Systems Manager 의 기능입니다. 관리형 인스턴스는 Systems 
Manager 와 함께 사용하도록 구성된 EC2 인스턴스입니다. Systems Manager 로 인스턴스를 
관리하면 다음과 같은 이점이 있습니다. 
Session Manager 를 사용하여 EC2 인스턴스에 안전하게 연결하세요. 
패치 관리자를 사용하여 자동화된 패치 스캔을 수행합니다. 
Systems Manager 인벤토리를 사용하여 인스턴스에 대한 자세한 정보를 확인하세요. 
Fleet Manager 를 사용하여 인스턴스를 추적하고 관리하세요. 
SSM 에이전트를 자동으로 최신 상태로 유지합니다. 
기본 호스트 구성 관리를 사용하면 IAM 인스턴스 프로필을 수동으로 생성하지 않고도 EC2 
인스턴스를 관리할 수 있습니다. 대신, 기본 호스트 구성 관리는 기본 IAM 역할을 생성하고 
적용하여 Systems Manager 가 활성화된 리전 및 계정의 모든 인스턴스를 관리할 수 있는 
권한을 갖도록 합니다. 제공된 권한이 사용 사례에 충분하지 않은 경우 기본 IAM 역할을 
수정하거나 사용자 지정 역할로 대체할 수 있습니다. 
다른 옵션은 운영 오버헤드가 더 많거나 요구 사항을 충족하지 않기 때문에 올바르지 
않습니다. 새 IAM 역할을 생성하고, AmazonSSMManagedInstanceCore 정책을 새 IAM 
역할에 연결하고, 새 IAM 역할과 기존 IAM 역할을 EC2 인스턴스에 연결하는 것은 
올바르지 않습니다. 이 솔루션에는 IAM 역할을 수동으로 생성 및 관리해야 하므로 
복잡하고 솔루션 비용. AmazonSSMManagedInstanceCore 정책은 Systems Manager 핵심 
기능에 대한 권한을 부여하는 관리형 정책입니다. IAM 사용자를 생성하고, 
AmazonSSMManagedInstanceCore 정책을 IAM 사용자에게 연결하고, IAM 사용자를 
사용하여 EC2 인스턴스를 관리하도록 Systems Manager 를 구성하는 것은 올바르지 
않습니다. 이 솔루션에는 IAM 사용자를 수동으로 생성 및 관리해야 하므로 복잡성과 
비용이 추가되기 때문입니다. 해결책. IAM 사용자는 단일 개인 또는 애플리케이션에 대한 
특정 권한을 가진 AWS 계정 내의 자격 증명입니다. 기존 IAM 역할에서 기존 정책을 
제거하고 AmazonSSMManagedInstanceCore 정책을 기존 IAM 역할에 추가하는 것은 
올바르지 않습니다. 이 솔루션은 RDS 데이터베이스에 액세스하기 위해 기존 정책을 
사용하는 실행 중인 애플리케이션을 중단시킬 수 있기 때문입니다. IAM 역할은 서비스 또는 
엔터티에 대한 특정 권한이 있는 AWS 계정 내의 자격 증명입니다. 
Q724 
한 회사는 Amazon Elastic Kubernetes Service(Amazon EKS)와 Kubernetes 수평형 포드 
자동 크기 조정기를 사용하여 컨테이너 애플리케이션을 실행합니다. 작업량이 하루 종일 
일정하지 않습니다. 솔루션 설계자는 기존 노드가 클러스터의 최대 용량에 도달해도 노드 
수가 자동으로 확장되지 않아 성능 문제가 발생한다는 사실을 알아냈습니다. 
최소한의 관리 오버헤드로 이 문제를 해결할 수 있는 솔루션은 무엇입니까? 
A. 메모리 사용량을 추적하여 노드를 확장합니다. 
B. Kubernetes Cluster Autoscaler 를 사용하여 클러스터의 노드 수를 관리합니다. 
C. AWS Lambda 함수를 사용하여 EKS 클러스터의 크기를 자동으로 조정합니다. 
D. Amazon EC2 Auto Scaling 그룹을 사용하여 워크로드를 분산합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132902-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q725 
한 회사는 매달 약 300TB 의 Amazon S3 Standard 스토리지를 유지 관리합니다. S3 객체의 
크기는 일반적으로 약 50GB 이며 글로벌 애플리케이션에 의해 멀티파트 업로드로 자주 
교체됩니다. S3 객체의 수와 크기는 일정하게 유지되지만 회사의 S3 스토리지 비용은 매달 
증가하고 있습니다. 
이 상황에서 솔루션 설계자는 어떻게 비용을 절감해야 합니까? 
A. 멀티파트 업로드에서 Amazon S3 Transfer Acceleration 으로 전환합니다. 
B. 불완전한 멀티파트 업로드를 삭제하는 S3 수명 주기 정책을 활성화합니다. 
C. 객체가 너무 빨리 보관되지 않도록 S3 인벤토리를 구성합니다. 
D. Amazon S3 에 저장되는 객체 수를 줄이도록 Amazon CloudFront 를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132904-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 이러한 상황에서 S3 스토리지 비용을 줄이는 가장 비용 효율적인 방법입니다. 
불완전한 멀티파트 업로드는 애플리케이션에 의해 완료되지 않거나 중단된 객체의 
일부입니다. 저장 공간을 소비하며 삭제될 때까지 요금이 부과됩니다. 불완전한 멀티파트 
업로드를 삭제하는 S3 수명 주기 정책을 활성화하면 지정된 기간(예: 1 일)이 지나면 
자동으로 제거하고 스토리지 공간을 확보할 수 있습니다. 이렇게 하면 S3 스토리지 비용이 
절감되고 불필요한 재시도나 오류를 방지하여 애플리케이션 성능도 향상됩니다. 
옵션 A 는 올바르지 않습니다. 멀티파트 업로드에서 Amazon S3 Transfer Acceleration 으로 
전환해도 S3 스토리지 비용이 줄어들지 않기 때문입니다. Amazon S3 Transfer 
Acceleration 은 AWS 엣지 네트워크를 사용하여 S3 와 더 빠른 데이터 전송을 가능하게 
하는 기능입니다. 장거리에 걸쳐 큰 개체의 업로드 속도를 향상시키는 데 유용하지만 저장 
공간이나 요금에는 영향을 미치지 않습니다. 실제로 해당 기능을 사용하기 위해 데이터 
전송 수수료를 추가하면 비용이 증가할 수 있습니다. 
객체가 너무 빨리 보관되는 것을 방지하도록 S3 인벤토리를 구성해도 S3 스토리지 비용이 
줄어들지 않기 때문에 옵션 C 는 올바르지 않습니다. Amazon S3 인벤토리는 S3 버킷의 
객체 및 해당 메타데이터에 대한 보고서를 제공하는 기능입니다. S3 객체를 관리하고 
감사하는 데 유용하지만 저장 공간이나 요금에는 영향을 미치지 않습니다. 실제로 인벤토리 
보고서를 위한 추가 S3 개체를 생성하면 비용이 증가할 수 있습니다. 
Amazon S3 에 저장된 객체 수를 줄이도록 Amazon CloudFront 를 구성해도 S3 스토리지 
비용이 줄어들지 않으므로 옵션 D 는 올바르지 않습니다. Amazon CloudFront 는 더 빠르고 
짧은 지연 시간 액세스를 위해 S3 객체를 엣지 로케이션에 배포하는 콘텐츠 전송 
네트워크(CDN)입니다. S3 객체의 다운로드 속도와 가용성을 향상시키는 데 유용하지만 
저장 공간이나 요금에는 영향을 미치지 않습니다. 실제로 서비스 이용에 따른 데이터 전송 
수수료를 추가하면 비용이 증가할 수 있습니다. 
Q726 
한 회사에서 모바일 장치용 멀티플레이어 게임을 배포했습니다. 이 게임에는 위도와 경도를 
기반으로 플레이어의 실시간 위치 추적이 필요합니다. 게임의 데이터 저장소는 신속한 
업데이트와 위치 검색을 지원해야 합니다. 
이 게임은 읽기 전용 복제본이 있는 PostgreSQL DB 인스턴스용 Amazon RDS 를 사용하여 
위치 데이터를 저장합니다. 사용량이 가장 많은 기간에는 데이터베이스가 업데이트를 읽고 
쓰는 데 필요한 성능을 유지할 수 없습니다. 게임의 사용자 기반이 빠르게 증가하고 
있습니다. 
데이터 계층의 성능을 향상하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 기존 DB 인스턴스의 스냅샷을 찍습니다. 다중 AZ 가 활성화된 스냅샷을 복원합니다. 
B. OpenSearch 대시보드를 사용하여 Amazon RDS 에서 Amazon OpenSearch Service 로 
마이그레이션합니다. 
C. 기존 DB 인스턴스 앞에 Amazon DynamoDB Accelerator(DAX)를 배포합니다. DAX 를 
사용하도록 게임을 수정합니다. 
D. 기존 DB 인스턴스 앞에 Redis 용 Amazon ElastiCache 클러스터를 배포합니다. Redis 를 
사용하도록 게임을 수정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132906-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
데이터 계층의 성능을 향상시키는 솔루션은 기존 DB 인스턴스 앞에 Redis 용 Amazon 
ElastiCache 클러스터를 배포하고 Redis 를 사용하도록 게임을 수정하는 것입니다. Redis 는 
지리공간 데이터 유형과 명령을 지원하는 메모리 내 데이터 저장소이므로 이 솔루션을 
사용하면 게임에서 빠르고 확장 가능한 방식으로 플레이어의 위치 데이터를 저장하고 
검색할 수 있습니다. Redis 용 ElastiCache 를 사용하면 게임에서 빈도가 높은 업데이트 및 
위치 데이터 쿼리에 최적화되지 않은 PostgreSQL DB 인스턴스용 RDS 의 로드를 줄일 수 
있습니다. Redis 용 ElastiCache 는 증가하는 게임 사용자 기반을 처리하기 위해 복제, 샤딩 
및 자동 크기 조정도 지원합니다. 
다른 솔루션은 성능을 향상시키지 않거나 지리공간 데이터를 지원하지 않거나 캐싱을 
활용하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. 기존 DB 인스턴스의 
스냅샷을 생성하고 다중 AZ 가 활성화된 상태로 복원하면 데이터 계층의 성능이 향상되지 
않습니다. 이는 높은 가용성과 내구성만 제공할 뿐 확장성이나 짧은 지연 시간은 제공하지 
않기 때문입니다. OpenSearch Dashboards 를 사용하여 Amazon RDS 에서 Amazon 
OpenSearch Service 로 마이그레이션해도 데이터 계층의 성능은 향상되지 않습니다. 
OpenSearch Service 는 주로 실시간 위치 추적이 아닌 전체 텍스트 검색 및 분석을 위해 
설계되었기 때문입니다. OpenSearch 서비스는 Redis 와 달리 기본적으로 지리공간 데이터 
유형 및 명령을 지원하지 않습니다. 기존 DB 인스턴스 앞에 Amazon DynamoDB 
Accelerator(DAX)를 배포하고 DAX 를 사용하도록 게임을 수정해도 데이터 계층의 성능은 
향상되지 않습니다. 왜냐하면 DAX 는 PostgreSQL 용 RDS 가 아닌 DynamoDB 하고만 
호환되기 때문입니다. DAX 는 지리공간 데이터 유형 및 명령도 지원하지 않습니다. 
Q727 
회사는 회사 AWS 계정의 Amazon DynamoDB 테이블에 중요한 데이터를 저장합니다. IT 
관리자가 실수로 DynamoDB 테이블을 삭제했습니다. 삭제로 인해 상당한 데이터 손실이 
발생하고 회사 운영이 중단되었습니다. 회사는 앞으로 이러한 유형의 중단을 방지하기를 
원합니다. 
최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS CloudTrail 에서 추적을 구성합니다. 삭제 작업에 대한 Amazon EventBridge 규칙을 
생성합니다. 삭제된 DynamoDB 테이블을 자동으로 복원하는 AWS Lambda 함수를 
생성합니다. 
B. DynamoDB 테이블에 대한 백업 및 복원 계획을 생성합니다. DynamoDB 테이블을 
수동으로 복구합니다. 
C. DynamoDB 테이블에 대한 삭제 방지를 구성합니다. 
D. DynamoDB 테이블에서 특정 시점 복구를 활성화합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132907-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
삭제 방지는 실수로 테이블이 삭제되는 것을 방지하는 DynamoDB 의 기능입니다. 삭제 
방지가 활성화되면 먼저 명시적으로 비활성화하지 않는 한 테이블을 삭제할 수 없습니다. 
이를 통해 보안 계층이 추가되고 데이터 손실 및 운영 중단 위험이 줄어듭니다. 삭제 
방지는 AWS Management Console, AWS CLI 또는 DynamoDB API 를 사용하여 쉽게 활성화 
및 비활성화할 수 있습니다. 이 솔루션은 추가 리소스나 서비스를 생성, 관리 또는 호출할 
필요가 없으므로 운영 오버헤드가 가장 적습니다. 
Q728 
회사에 스토리지 용량이 부족한 온프레미스 데이터 센터가 있습니다. 회사는 대역폭 비용을 
최소화하면서 스토리지 인프라를 AWS 로 마이그레이션하려고 합니다. 솔루션은 추가 비용 
없이 데이터를 즉시 검색할 수 있어야 합니다. 
이러한 요구 사항을 어떻게 충족할 수 있습니까? 
A. Amazon S3 Glacier Vault 를 배포하고 빠른 검색을 활성화합니다. 워크로드에 대해 
프로비저닝된 검색 용량을 활성화합니다. 
B. 캐시된 볼륨을 사용하여 AWS Storage Gateway 를 배포합니다. Storage Gateway 를 
사용하면 자주 액세스하는 데이터 하위 집합의 복사본을 로컬에 보관하면서 Amazon S3 에 
데이터를 저장할 수 있습니다. 
C. 저장된 볼륨을 사용하여 AWS Storage Gateway 를 배포하여 데이터를 로컬에 저장합니다. 
Storage Gateway 를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3 에 비동기식으로 
백업합니다. 
D. AWS Direct Connect 를 배포하여 온프레미스 데이터 센터에 연결합니다. 데이터를 
로컬에 저장하도록 AWS Storage Gateway 를 구성합니다. Storage Gateway 를 사용하여 
데이터의 특정 시점 스냅샷을 Amazon S3 에 비동기식으로 백업합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132910-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q729 
회사는 여러 가용 영역에 걸쳐 VPC 에서 3 계층 웹 애플리케이션을 실행합니다. Amazon 
EC2 인스턴스는 애플리케이션 계층에 대한 Auto Scaling 그룹에서 실행됩니다. 
회사는 각 리소스의 일일 및 주간 기록 워크로드 추세를 분석하는 자동화된 확장 계획을 
수립해야 합니다. 구성은 활용도의 예측 및 실시간 변화에 따라 리소스를 적절하게 
확장해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 확장 전략을 권장해야 합니까? 
A. EC2 인스턴스의 평균 CPU 사용률을 기준으로 단계 조정을 통해 동적 조정을 
구현합니다. 
B. 예측 및 확장을 위해 예측 확장을 활성화합니다. 대상 추적을 사용하여 동적 조정 구성 
C. 웹 애플리케이션의 트래픽 패턴을 기반으로 자동화된 예약 조정 작업을 생성합니다. 
D. 간단한 확장 정책을 설정합니다. EC2 인스턴스 시작 시간을 기준으로 휴지 기간을 
늘립니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132911-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션을 사용하면 회사에서 예측적 조정과 동적 조정을 모두 사용하여 Auto Scaling 
그룹의 용량을 최적화할 수 있으므로 요구 사항을 충족합니다. 예측 확장은 기계 학습을 
사용하여 기록 데이터를 분석하고 향후 트래픽 패턴을 예측합니다. 그런 다음 예측된 변경 
사항에 앞서 그룹의 원하는 용량을 조정합니다. 동적 조정은 목표 추적을 사용하여 지정된 
지표(예: CPU 사용률)를 목표 값으로 유지합니다. 메트릭을 대상에 가깝게 유지하기 위해 
필요에 따라 그룹을 확장하거나 축소합니다. 
두 가지 확장 방법을 모두 사용함으로써 회사는 예측된 활용도 변화와 실시간 활용도 
변화에 모두 대응하는 더 빠르고 간단하며 정확한 확장의 이점을 누릴 수 있습니다. 
Q730 
패키지 배송 회사에는 Amazon EC2 인스턴스와 Amazon Aurora MySQL DB 클러스터를 
사용하는 애플리케이션이 있습니다. 애플리케이션이 대중화되면서 EC2 인스턴스 사용량은 
약간만 증가합니다. DB 클러스터 사용량이 훨씬 빠른 속도로 증가합니다. 
회사에서는 단기간 동안 DB 클러스터 사용량을 줄이는 읽기 전용 복제본을 추가합니다. 
그러나 부하가 계속 증가합니다. DB 클러스터 사용량을 증가시키는 작업은 모두 전송 세부 
사항과 관련된 반복 읽기 명령문입니다. 회사에서는 DB 클러스터에 대한 반복 읽기의 
영향을 완화해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 애플리케이션과 DB 클러스터 사이에 Redis 용 Amazon ElastiCache 클러스터를 
구현합니다. 
B. DB 클러스터에 추가 읽기 전용 복제본을 추가합니다. 
C. Aurora 읽기 전용 복제본을 위한 Aurora Auto Scaling 을 구성합니다. 
D. 여러 개의 라이터 인스턴스를 갖도록 DB 클러스터를 수정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132913-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q731 
한 회사에 Amazon DynamoDB 테이블을 저장용으로 사용하는 애플리케이션이 있습니다. 
솔루션 설계자는 테이블에 대한 많은 요청이 최신 데이터를 반환하지 않는다는 것을 
발견했습니다. 회사 사용자는 데이터베이스 성능과 관련된 다른 문제를 보고하지 
않았습니다. 지연 시간이 허용 가능한 범위 내에 있습니다. 
솔루션 설계자는 어떤 디자인 변경을 권장해야 합니까? 
A. 테이블에 읽기 전용 복제본을 추가합니다. 
B. 글로벌 보조 인덱스(GSI)를 사용합니다. 
C. 테이블에 대해 강력하게 일관된 읽기를 요청합니다. 
D. 테이블에 대한 최종적 일관된 읽기를 요청합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132914-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
회사의 애플리케이션에 가장 적합한 디자인 변경은 테이블에 대해 강력하고 일관된 읽기를 
요청하는 것입니다. 이렇게 변경하면 테이블에 대한 요청이 모든 이전 쓰기 작업의 
업데이트를 반영하여 최신 데이터를 반환하게 됩니다. 
Amazon DynamoDB 는 원활한 확장성과 함께 빠르고 예측 가능한 성능을 제공하는 완전 
관리형 NoSQL 데이터베이스 서비스입니다. DynamoDB 는 최종적 일관된 읽기와 강력한 
일관된 읽기라는 두 가지 유형의 읽기 일관성을 지원합니다. 기본적으로 DynamoDB 는 
사용자가 달리 지정하지 않는 한 최종적 일관된 읽기를 사용합니다. 
최종 일관성 읽기는 최근 완료된 쓰기 작업의 결과를 반영하지 않을 수 있는 읽기입니다. 
모든 복제본에 데이터를 전파하는 데 지연이 발생하기 때문에 응답에 변경 사항이 포함되지 
않을 수 있습니다. 사용자가 잠시 후에 읽기 요청을 반복하면 응답은 업데이트된 데이터를 
반환해야 합니다. 최종 일관성 읽기는 최신 데이터가 필요하지 않거나 최종 일관성을 
허용할 수 있는 애플리케이션에 적합합니다. Strongly Consistency 읽기는 읽기 전에 
성공적인 응답을 받은 모든 쓰기를 반영하는 결과를 반환하는 읽기입니다. 사용자는 
GetItem, Query 또는 Scan 과 같은 읽기 작업에서 ConsistencyRead 매개 변수를 true 로 
설정하여 강력한 일관된 읽기를 요청할 수 있습니다. 강력한 일관된 읽기는 최신 데이터가 
필요하거나 최종 일관성을 허용할 수 없는 애플리케이션에 적합합니다. 
다른 옵션은 읽기 일관성 문제를 해결하지 않거나 사용 사례와 관련이 없기 때문에 
올바르지 않습니다. 이 옵션은 DynamoDB 에서 지원되지 않으므로 테이블에 읽기 전용 
복제본을 추가하는 것은 올바르지 않습니다. 읽기 복제본은 읽기 전용 트래픽을 제공하고 
가용성과 성능을 향상시킬 수 있는 기본 데이터베이스 인스턴스의 복사본입니다. 읽기 전용 
복제본은 Amazon RDS 또는 Amazon Aurora 와 같은 일부 관계형 데이터베이스 서비스에 
사용할 수 있지만 DynamoDB2 에는 사용할 수 없습니다. GSI(Global Secondary Index)를 
사용하는 것은 올바르지 않습니다. 이 옵션은 읽기 일관성과 관련이 없기 때문입니다. 
GSI 는 기본 테이블의 것과 다른 파티션 키와 선택적 정렬 키가 있는 인덱스입니다. GSI 를 
사용하면 사용자는 최종 일관성을 유지하면서 다양한 방식으로 데이터를 쿼리할 수 
있습니다. 테이블에 대한 최종적 일관된 읽기 요청은 올바르지 않습니다. 이 옵션은 이미 
DynamoDB 의 기본 동작이고 최신 데이터를 반환하지 않는 요청 문제를 해결하지 못하기 
때문입니다. 
Q732 
한 회사가 Amazon RDS 데이터베이스를 사용하여 Amazon EC2 인스턴스에 애플리케이션을 
배포했습니다. 회사는 최소 권한 원칙을 사용하여 데이터베이스 액세스 자격 증명을 
구성했습니다. 회사의 보안 팀은 SQL 주입 및 기타 웹 기반 공격으로부터 애플리케이션과 
데이터베이스를 보호하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 보안 그룹과 네트워크 ACL 을 사용하여 데이터베이스와 애플리케이션 서버를 
보호하십시오. 
B. AWS WAF 를 사용하여 애플리케이션을 보호하십시오. RDS 매개변수 그룹을 사용하여 
보안 설정을 구성합니다. 
C. AWS 네트워크 방화벽을 사용하여 애플리케이션과 데이터베이스를 보호하십시오. 
D. 다양한 기능을 위해 애플리케이션 코드에서 다양한 데이터베이스 계정을 사용합니다. 
데이터베이스 사용자에게 과도한 권한을 부여하지 마십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132915-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS WAF 는 애플리케이션 가용성에 영향을 미치거나 보안을 손상시키거나 과도한 
리소스를 소비할 수 있는 일반적인 웹 공격으로부터 웹 애플리케이션을 보호하는 데 도움이 
되는 웹 애플리케이션 방화벽입니다. AWS WAF 를 통해 사용자는 사용자 정의 가능한 웹 
보안 규칙을 기반으로 웹 요청을 차단, 허용 또는 계산하는 규칙을 생성할 수 있습니다. 
생성할 수 있는 규칙 유형 중 하나는 사용자가 허용하거나 차단할 IP 주소 또는 IP 주소 
범위 목록을 지정할 수 있는 SQL 삽입 규칙입니다. AWS WAF 를 사용하여 애플리케이션을 
보호함으로써 회사는 SQL 주입 및 기타 웹 기반 공격이 애플리케이션과 데이터베이스에 
도달하는 것을 방지할 수 있습니다. 
RDS 파라미터 그룹은 데이터베이스 인스턴스 작동 방식을 정의하는 파라미터 모음입니다. 
사용자는 매개변수 그룹의 매개변수를 수정하여 데이터베이스의 동작과 성능을 변경할 수 
있습니다. RDS 매개변수 그룹을 사용하여 보안 설정을 구성함으로써 회사는 원격 루트 
로그인 비활성화, SSL 연결 요구, 최대 연결 수 제한과 같은 모범 사례를 적용할 수 
있습니다. 
다른 옵션은 SQL 주입 및 기타 웹 기반 공격으로부터 애플리케이션과 데이터베이스를 
효과적으로 보호하지 못하기 때문에 올바르지 않습니다. 보안 그룹과 네트워크 ACL 을 
사용하여 데이터베이스와 애플리케이션 서버를 보호하는 것만으로는 충분하지 않습니다. 
왜냐하면 애플리케이션 계층이 아닌 네트워크 계층에서만 트래픽을 필터링하기 때문입니다. 
AWS 네트워크 방화벽을 사용하여 애플리케이션과 데이터베이스를 보호할 필요는 없습니다. 
이는 개별 애플리케이션이나 데이터베이스가 아닌 VPC 에 대한 네트워크 보호를 제공하는 
상태 저장 방화벽 서비스이기 때문입니다. 서로 다른 기능을 위해 애플리케이션 코드에서 
서로 다른 데이터베이스 계정을 사용하는 것은 좋은 습관이지만 SQL 주입 공격이 
애플리케이션 코드의 취약점을 악용하는 것을 방지할 수는 없습니다. 
Q733 
전자 상거래 회사는 AWS Organizations 의 조직에 속한 AWS 계정에서 애플리케이션을 
실행합니다. 애플리케이션은 모든 계정의 Amazon Aurora PostgreSQL 데이터베이스에서 
실행됩니다. 회사는 악의적인 활동을 방지해야 하며 데이터베이스에 대한 비정상적으로 
실패하거나 불완전한 로그인 시도를 식별해야 합니다. 
어떤 솔루션이 운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족합니까? 
A. 서비스 제어 정책(SCP)을 조직의 루트에 연결하여 실패한 로그인 시도를 식별합니다. 
B. 조직의 회원 계정에 대해 Amazon GuardDuty 에서 Amazon RDS 보호 기능을 
활성화합니다. 
C. Amazon CloudWatch Logs 의 로그 그룹에 Aurora 일반 로그를 게시합니다. 로그 
데이터를 중앙 Amazon S3 버킷으로 내보냅니다. 
D. AWS CloudTrail 의 모든 Aurora PostgreSQL 데이터베이스 이벤트를 중앙 Amazon S3 
버킷에 게시합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132916-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q734 
회사에는 회사 데이터 센터에서 us-east-1 지역의 VPC 까지 AWS Direct Connect 연결이 
있습니다. 이 회사는 최근 온프레미스 데이터 센터와 eu-west-2 지역 간에 여러 개의 
VPC 와 Direct Connect 연결을 갖춘 회사를 인수했습니다. 회사와 회사의 VPC 에 대한 
CIDR 블록은 중복되지 않습니다. 회사에서는 두 지역과 데이터 센터 간의 연결이 
필요합니다. 회사에는 운영 오버헤드를 줄이면서 확장 가능한 솔루션이 필요합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. us-east-1 의 VPC 와 eu-west-2 의 VPC 간에 리전 간 VPC 피어링을 설정합니다. 
B. us-east-1 의 Direct Connect 연결에서 eu-west-2 의 VPC 로 프라이빗 가상 
인터페이스를 생성합니다. 
C. Amazon EC2 에서 호스팅하는 완전히 메시된 VPN 네트워크에 VPN 어플라이언스를 
설정합니다. AWS VPN CloudHub 를 사용하여 데이터 센터와 각 VPC 간에 데이터를 보내고 
받습니다. 
D. 기존 Direct Connect 연결을 Direct Connect 게이트웨이에 연결합니다. 각 리전에 있는 
VPC 의 가상 프라이빗 게이트웨이에서 Direct Connect 게이트웨이로 트래픽을 
라우팅합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132920-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 회사가 단일 Direct Connect 연결을 사용하여 Direct Connect 게이트웨이를 
통해 다양한 지역의 여러 VPC 에 연결할 수 있도록 허용하므로 요구 사항을 충족합니다. 
Direct Connect 게이트웨이는 온프레미스 네트워크를 AWS 중국 리전을 제외한 모든 AWS 
리전의 VPC 에 연결할 수 있게 해주는 전 세계적으로 사용 가능한 리소스입니다. Direct 
Connect 게이트웨이를 각 리전의 전송 게이트웨이 또는 가상 프라이빗 게이트웨이와 
연결할 수 있습니다. VPC 의 가상 프라이빗 게이트웨이에서 Direct Connect 게이트웨이로 
트래픽을 라우팅하면 VPC 에 대한 리전 간 및 온프레미스 연결을 활성화할 수 있습니다. 이 
솔루션은 추가 연결을 생성하지 않고도 Direct Connect 게이트웨이에 다양한 리전의 더 
많은 VPC 를 추가할 수 있기 때문에 확장 가능합니다. 또한 이 솔루션은 여러 VPN 
어플라이언스, VPN 연결 또는 VPC 피어링 연결을 관리할 필요가 없기 때문에 운영 
오버헤드를 줄여줍니다. 
Q735 
한 회사에서 점수 업데이트를 백엔드 프로세서로 스트리밍한 다음 결과를 리더보드에 
게시하는 모바일 게임을 개발하고 있습니다. 솔루션 설계자는 대규모 트래픽 급증을 
처리하고, 모바일 게임 업데이트를 수신 순서대로 처리하고, 처리된 업데이트를 고가용성 
데이터베이스에 저장할 수 있는 솔루션을 설계해야 합니다. 또한 회사는 솔루션을 유지하는 
데 필요한 관리 오버헤드를 최소화하려고 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon Kinesis Data Streams 에 점수 업데이트를 푸시합니다. AWS Lambda 를 사용하여 
Kinesis Data Streams 의 업데이트를 처리합니다. 처리된 업데이트를 Amazon DynamoDB 에 
저장합니다. 
B. Amazon Kinesis Data Streams 에 점수 업데이트를 푸시합니다. Auto Scaling 용으로 
설정된 Amazon EC2 인스턴스 집합으로 업데이트를 처리합니다. 처리된 업데이트를 
Amazon Redshift 에 저장합니다. 
C. Amazon Simple 알림 서비스(Amazon SNS) 주제에 점수 업데이트를 푸시합니다. 
업데이트를 처리하려면 SNS 주제에 대한 AWS Lambda 함수를 구독하세요. Amazon 
EC2 에서 실행되는 SQL 데이터베이스에 처리된 업데이트를 저장합니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열에 점수 업데이트를 푸시합니다. 
Auto Scaling 이 포함된 Amazon EC2 인스턴스 집합을 사용하여 SQS 대기열의 업데이트를 
처리합니다. 처리된 업데이트를 Amazon RDS 다중 AZ DB 인스턴스에 저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132922-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Kinesis Data Streams 는 스트리밍 데이터를 실시간으로 수집, 버퍼링 및 처리할 수 
있는 확장 가능하고 안정적인 서비스입니다. 대규모 트래픽 급증을 처리하고 들어오는 
데이터 레코드의 순서를 보존할 수 있습니다. AWS Lambda 는 인프라 관리 없이 Kinesis 
Data Streams 의 데이터 스트림을 처리할 수 있는 서버리스 컴퓨팅 서비스입니다. 또한 
데이터 스트림의 처리량에 맞게 자동으로 확장할 수도 있습니다. 
Amazon DynamoDB 는 Lambda 에서 처리된 업데이트를 저장할 수 있는 완전 관리형, 
고가용성, 빠른 NoSQL 데이터베이스입니다. 또한 높은 쓰기 처리량을 처리하고 일관된 
성능을 제공할 수 있습니다. 
솔루션 아키텍트는 이러한 서비스를 사용하여 최소한의 운영 오버헤드로 회사의 요구 
사항을 충족하는 솔루션을 설계할 수 있습니다. 
Q736 
회사에는 us-west-2 지역에 애플리케이션이 배포된 여러 AWS 계정이 있습니다. 
애플리케이션 로그는 각 계정의 Amazon S3 버킷 내에 저장됩니다. 회사는 단일 S3 버킷을 
사용하는 중앙 집중식 로그 분석 솔루션을 구축하려고 합니다. 로그는 us-west-2 를 
벗어나면 안 되며, 회사는 최소한의 운영 오버헤드를 원합니다. 
이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까? 
A. 애플리케이션 S3 버킷 중 하나에서 중앙 집중식 S3 버킷으로 객체를 복사하는 S3 수명 
주기 정책을 생성합니다. 
B. S3 동일 리전 복제를 사용하여 S3 버킷의 로그를 us-west-2 의 다른 S3 버킷으로 
복제합니다. 로그 분석을 위해 이 S3 버킷을 사용하세요. 
C. 매일 PutObject API 작업을 사용하여 버킷의 전체 콘텐츠를 us-west-2 의 다른 S3 
버킷에 복사하는 스크립트를 작성합니다. 로그 분석을 위해 이 S3 버킷을 사용하세요. 
D. 로그가 S3 버킷(s3:ObjectCreated:* 이벤트)으로 전달될 때마다 트리거되는 AWS 
Lambda 함수를 이러한 계정에 작성합니다. us-west-2 의 다른 S3 버킷에 로그를 
복사합니다. 로그 분석을 위해 이 S3 버킷을 사용하세요. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132923-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 다음 요구 사항을 충족합니다. 
복제된 객체의 저장 및 데이터 전송에 대해서만 비용을 청구하고 추가 AWS 서비스나 
사용자 지정 스크립트가 필요하지 않으므로 비용 효율적입니다. S3 동일 리전 복제(SRR)는 
동일한 AWS 리전 내의 S3 버킷에 객체를 자동으로 복제하는 기능입니다. SRR 을 사용하면 
분석 및 감사를 위해 여러 소스의 로그를 단일 대상으로 집계할 수 있습니다. SRR 은 또한 
소스 객체의 메타데이터, 암호화 및 액세스 제어를 보존합니다. 
수동 개입이나 예약이 필요하지 않으므로 운영상 효율적입니다. SRR 은 객체가 원본 버킷에 
업로드되는 즉시 복제하여 대상 버킷에 항상 최신 로그 데이터가 있는지 확인합니다. 
SRR 은 또한 소스 객체의 업데이트나 삭제를 처리하여 대상 버킷을 동기화 상태로 
유지합니다. S3 콘솔에서 몇 번의 클릭이나 간단한 API 호출을 통해 SRR 을 활성화할 수 
있습니다. 
로그가 us-west-2 리전을 벗어나는 것을 허용하지 않으므로 안전합니다. SRR 은 동일한 
AWS 리전 내의 객체만 복제하므로 데이터 주권 및 규정 준수 요구 사항이 충족됩니다. 
SRR 은 또한 AWS KMS 또는 S3 관리형 키를 사용한 서버 측 암호화 또는 클라이언트 측 
암호화를 사용하여 소스 및 대상 객체의 암호화를 지원합니다. 
Q737 
한 회사에 전 세계 학생들에게 주문형 교육 비디오를 제공하는 애플리케이션이 있습니다. 
또한 이 애플리케이션을 사용하면 승인된 콘텐츠 개발자가 비디오를 업로드할 수 있습니다. 
데이터는 us-east-2 리전의 Amazon S3 버킷에 저장됩니다. 
회사는 eu-west-2 리전에 S3 버킷을, ap-southeast-1 리전에 S3 버킷을 생성했습니다. 
회사는 데이터를 새로운 S3 버킷에 복제하려고 합니다. 회사는 eu-west-2 및 
ap-southeast-1 근처에서 비디오를 업로드하는 개발자와 비디오를 스트리밍하는 학생의 
대기 시간을 최소화해야 합니다. 
애플리케이션을 가장 적게 변경하여 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? 
(2 개 선택) 
A. us-east-2 S3 버킷에서 eu-west-2 S3 버킷으로 단방향 복제를 구성합니다. us-east-2 
S3 버킷에서 ap-southeast-1 S3 버킷으로의 단방향 복제를 구성합니다. 
B. us-east-2 S3 버킷에서 eu-west-2 S3 버킷으로 단방향 복제를 구성합니다. eu-west-2 
S3 버킷에서 ap-southeast-1 S3 버킷으로의 단방향 복제를 구성합니다. 
C. 세 지역 모두에 있는 S3 버킷 간에 양방향(양방향) 복제를 구성합니다. 
D. S3 다중 지역 액세스 포인트를 생성합니다. 비디오 스트리밍을 위해 다중 지역 액세스 
포인트의 Amazon 리소스 이름(ARN)을 사용하도록 애플리케이션을 수정합니다. 비디오 
업로드용 애플리케이션을 수정하지 마십시오. 
E. S3 다중 지역 액세스 포인트를 생성합니다. 비디오 스트리밍 및 업로드를 위해 다중 
지역 액세스 포인트의 Amazon 리소스 이름(ARN)을 사용하도록 애플리케이션을 
수정합니다. 
Answer: C, E 
https://www.examtopics.com/discussions/amazon/view/132924-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q738 
회사에 새로운 모바일 앱이 있습니다. 세계 어디에서나 사용자는 자신이 선택한 주제에 
대한 지역 뉴스를 볼 수 있습니다. 사용자는 앱 내부에서 사진과 비디오를 게시할 수도 
있습니다. 
사용자는 콘텐츠가 게시된 후 처음 몇 분 안에 콘텐츠에 액세스하는 경우가 많습니다. 
새로운 콘텐츠가 이전 콘텐츠를 빠르게 대체한 다음 이전 콘텐츠는 사라집니다. 뉴스의 
지역적 특성은 사용자가 뉴스가 업로드되는 AWS 지역 내에서 콘텐츠의 90%를 소비한다는 
것을 의미합니다. 
콘텐츠 업로드에 가장 짧은 지연 시간을 제공하여 사용자 경험을 최적화하는 솔루션은 
무엇입니까? 
A. Amazon S3 에 콘텐츠를 업로드하고 저장합니다. 업로드에는 Amazon CloudFront 를 
사용하십시오. 
B. Amazon S3 에 콘텐츠를 업로드하고 저장합니다. 업로드에는 S3 Transfer Acceleration 을 
사용하세요. 
C. 사용자에게 가장 가까운 지역의 Amazon EC2 인스턴스에 콘텐츠를 업로드합니다. 
데이터를 Amazon S3 에 복사합니다. 
D. 사용자에게 가장 가까운 지역의 Amazon S3 에 콘텐츠를 업로드하고 저장합니다. 
Amazon CloudFront 의 여러 배포판을 사용하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132925-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
콘텐츠 업로드에 대한 지연 시간을 최소화하여 사용자 경험을 최적화하는 가장 적합한 
솔루션은 Amazon S3 에 콘텐츠를 업로드 및 저장하고 업로드에 S3 Transfer Acceleration 을 
사용하는 것입니다. 이 솔루션을 통해 회사는 AWS 글로벌 네트워크와 엣지 로케이션을 
활용하여 사용자와 S3 버킷 간의 데이터 전송 속도를 높일 수 있습니다. 
Amazon S3 는 모든 유형의 데이터에 대해 확장 가능하고 내구성이 뛰어나며 가용성이 높은 
객체 스토리지를 제공하는 스토리지 서비스입니다. Amazon S3 를 사용하면 사용자는 웹 
어디에서나 데이터를 저장하고 검색할 수 있으며 암호화, 버전 관리, 수명 주기 관리 및 
복제와 같은 다양한 기능을 제공합니다. 
S3 Transfer Acceleration 은 사용자가 S3 버킷과 더 빠르게 데이터를 주고받는 데 도움이 
되는 Amazon S3 의 기능입니다. S3 Transfer Acceleration 은 최적화된 네트워크 경로와 
Amazon 의 백본 네트워크를 사용하여 데이터 전송 속도를 가속화하는 방식으로 작동합니다. 
사용자는 버킷에 대해 S3 Transfer Acceleration 을 활성화하고 
<bucket>.s3-accelerate.amazonaws.com 과 같은 고유한 URL 을 사용하여 버킷에 
액세스할 수 있습니다. 
다른 옵션은 가장 낮은 대기 시간을 제공하지 않거나 사용 사례에 적합하지 않기 때문에 
올바르지 않습니다. Amazon S3 에 콘텐츠를 업로드 및 저장하고 업로드에 Amazon 
CloudFront 를 사용하는 것은 올바르지 않습니다. 이 솔루션은 업로드 최적화가 아니라 
다운로드 최적화를 위해 설계되었기 때문입니다. Amazon CloudFront 는 사용자가 짧은 지연 
시간과 높은 전송 속도로 콘텐츠를 전 세계에 배포할 수 있도록 지원하는 콘텐츠 전송 
네트워크(CDN)입니다. CloudFront 는 전 세계 엣지 로케이션에서 콘텐츠를 캐싱하는 
방식으로 작동하므로 사용자는 어디에서나 빠르고 쉽게 콘텐츠에 액세스할 수 있습니다 3. 
사용자에게 가장 가까운 지역의 Amazon EC2 인스턴스에 콘텐츠를 업로드하고 Amazon 
S3 에 데이터를 복사하는 것은 프로세스에 불필요한 복잡성과 비용을 추가하므로 올바르지 
않습니다. Amazon EC2 는 클라우드에서 확장 가능하고 안전한 가상 서버를 제공하는 
컴퓨팅 서비스입니다. 사용자는 필요에 따라 EC2 인스턴스를 시작, 중지 또는 종료할 수 
있으며 다양한 인스턴스 유형, 운영 체제 및 구성 중에서 선택할 수 있습니다 4. 사용자에게 
가장 가까운 지역의 Amazon S3 에 콘텐츠를 업로드하고 저장하며 Amazon CloudFront 의 
여러 배포를 사용하는 것은 사용 사례에 비해 비용 효율적이거나 효율적이지 않기 때문에 
올바르지 않습니다. 위에서 언급했듯이 Amazon CloudFront 는 사용자가 짧은 지연 시간과 
높은 전송 속도로 콘텐츠를 전 세계에 배포할 수 있도록 지원하는 CDN 입니다. 그러나 각 
지역에 대해 여러 CloudFront 배포를 생성하면 추가 비용과 관리 오버헤드가 발생하고 
콘텐츠의 90%가 업로드된 동일한 지역 내에서 소비되므로 필요하지 않습니다. 
Q739 
한 회사가 서버리스 아키텍처를 사용하는 새로운 애플리케이션을 구축하고 있습니다. 
아키텍처는 수신 요청을 관리하기 위한 Amazon API Gateway REST API 와 AWS Lambda 
함수로 구성됩니다. 
회사는 처리를 위해 API Gateway REST API 에서 받은 메시지를 여러 대상 Lambda 함수로 
보낼 수 있는 서비스를 추가하려고 합니다. 서비스는 대상 Lambda 함수에 필요한 
메시지만 수신할 수 있는 기능을 제공하는 메시지 필터링을 제공해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. API Gateway REST API 의 요청을 Amazon Simple Notification Service(Amazon SNS) 
주제로 보냅니다. Amazon Simple Queue Service(Amazon SQS) 대기열을 SNS 주제에 
등록합니다. 다양한 SQS 대기열을 폴링하도록 대상 Lambda 함수를 구성합니다. 
B. API Gateway REST API 의 요청을 Amazon EventBridge 로 보냅니다. 대상 Lambda 
함수를 호출하도록 EventBridge 를 구성합니다. 
C. API Gateway REST API 의 요청을 Apache Kafka 용 Amazon Managed Streaming(Amazon 
MSK)으로 보냅니다. 대상 Lambda 함수에 메시지를 게시하도록 Amazon MSK 를 
구성합니다. 
D. API Gateway REST API 의 요청을 여러 Amazon Simple Queue Service(Amazon SQS) 
대기열로 보냅니다. 다양한 SQS 대기열을 폴링하도록 대상 Lambda 함수를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132929-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q740 
한 회사는 수백만 개의 보관 파일을 Amazon S3 로 마이그레이션했습니다. 솔루션 설계자는 
고객이 제공한 키를 사용하여 모든 보관 데이터를 암호화하는 솔루션을 구현해야 합니다. 
솔루션은 암호화되지 않은 기존 개체와 향후 개체를 암호화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 인벤토리 보고서를 필터링하여 암호화되지 않은 객체 목록을 생성합니다. 
고객 제공 키(SSE-C)를 사용한 서버 측 암호화를 통해 목록의 객체를 암호화하도록 S3 
배치 작업 작업을 구성합니다. 고객 제공 키(SSE-C)로 서버 측 암호화를 사용하도록 S3 
기본 암호화 기능을 구성합니다. 
B. S3 Storage Lens 지표를 사용하여 암호화되지 않은 S3 버킷을 식별합니다. AWS KMS 
키(SSE-KMS)로 서버 측 암호화를 사용하도록 S3 기본 암호화 기능을 구성합니다. 
C. Amazon S3 에 대한 AWS 사용 보고서를 필터링하여 암호화되지 않은 객체 목록을 
생성합니다. AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화를 통해 목록의 객체를 
암호화하도록 AWS Batch 작업을 구성합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 
사용하도록 S3 기본 암호화 기능을 구성합니다. 
D. Amazon S3 에 대한 AWS 사용 보고서를 필터링하여 암호화되지 않은 객체 목록을 
생성합니다. 고객 제공 키(SSE-C)로 서버 측 암호화를 사용하도록 S3 기본 암호화 기능을 
구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132930-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q741 
회사의 도메인 이름 레코드를 호스팅하는 DNS 공급자가 AWS 에서 실행되는 웹 사이트의 
서비스 중단을 초래하는 중단을 겪고 있습니다. 회사는 보다 탄력적인 관리형 DNS 
서비스로 마이그레이션해야 하며 해당 서비스가 AWS 에서 실행되기를 원합니다. 
DNS 호스팅 서비스를 신속하게 마이그레이션하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 도메인 이름에 대한 Amazon Route 53 퍼블릭 호스팅 영역을 생성합니다. 이전 공급자가 
호스팅하는 도메인 레코드가 포함된 영역 파일을 가져옵니다. 
B. 도메인 이름에 대한 Amazon Route 53 프라이빗 호스팅 영역을 생성합니다. 이전 
공급자가 호스팅하는 도메인 레코드가 포함된 영역 파일을 가져옵니다. 
C. AWS 에서 Simple AD 디렉터리를 생성합니다. 도메인 레코드에 대해 DNS 공급자와 
Microsoft Active Directory 용 AWS Directory Service 간의 영역 전송을 활성화합니다. 
D. VPC 에 Amazon Route 53 Resolver 인바운드 엔드포인트를 생성합니다. 공급자의 DNS 가 
DNS 쿼리를 전달할 IP 주소를 지정합니다. 도메인에 대한 DNS 쿼리를 인바운드 
엔드포인트에 지정된 IP 주소로 전달하도록 공급자의 DNS 를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132931-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
DNS 호스팅 서비스를 AWS 의 보다 탄력적인 관리형 DNS 서비스로 마이그레이션하려면 
회사는 가용성과 확장성이 뛰어난 클라우드 DNS 웹 서비스인 Amazon Route 53 을 
사용해야 합니다. Route 53 은 회사의 도메인 이름에 대한 퍼블릭 DNS 레코드를 호스팅하고 
안정적이고 안전한 DNS 확인을 제공할 수 있습니다. DNS 호스팅 서비스를 신속하게 
마이그레이션하려면 회사는 도메인의 DNS 레코드에 대한 컨테이너인 Route 53 에서 도메인 
이름에 대한 퍼블릭 호스팅 영역을 생성해야 합니다. 그런 다음 회사는 이전 공급자가 
호스팅하는 도메인 레코드가 포함된 영역 파일(도메인에 대한 DNS 레코드를 정의하는 
텍스트 파일)을 가져와야 합니다. 이렇게 하면 회사는 수동으로 생성하지 않고도 기존 DNS 
레코드를 Route 53 으로 신속하게 전송할 수 있습니다. 영역 파일을 가져온 후 회사는 
Route 53 이 호스팅 영역에 할당하는 이름 서버를 사용하도록 도메인 등록 대행자를 
업데이트해야 합니다. 이렇게 하면 도메인 이름에 대한 DNS 쿼리가 Route 53 으로 
라우팅되고 가져온 레코드로 해결됩니다. 
Q742 
한 회사가 Amazon RDS 데이터베이스에 연결하는 애플리케이션을 AWS 에 구축하고 
있습니다. 회사는 애플리케이션 구성을 관리하고 데이터베이스 및 기타 서비스에 대한 자격 
증명을 안전하게 저장하고 검색하기를 원합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS AppConfig 를 사용하여 애플리케이션 구성을 저장하고 관리하십시오. AWS Secrets 
Manager 를 사용하여 자격 증명을 저장하고 검색합니다. 
B. AWS Lambda 를 사용하여 애플리케이션 구성을 저장하고 관리합니다. AWS Systems 
Manager Parameter Store 를 사용하여 자격 증명을 저장하고 검색합니다. 
C. 암호화된 애플리케이션 구성 파일을 사용합니다. 애플리케이션 구성을 위해 Amazon 
S3 에 파일을 저장합니다. 자격 증명을 저장하고 검색할 다른 S3 파일을 만듭니다. 
D. AWS AppConfig 를 사용하여 애플리케이션 구성을 저장하고 관리합니다. Amazon RDS 를 
사용하여 자격 증명을 저장하고 검색합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132932-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 최소한의 관리 오버헤드로 회사의 요구 사항을 충족하고 보안과 관리 용이성을 
보장합니다. 
AWS AppConfig: AWS AppConfig 는 안전하고 검증된 방식으로 애플리케이션 구성을 
관리하도록 설계된 서비스입니다. 애플리케이션의 성능이나 가용성에 영향을 미치지 않고 
안전하고 빠르게 구성을 배포할 수 있습니다. 
AWS Secrets Manager: AWS Secrets Manager 는 데이터베이스 및 기타 서비스의 자격 
증명을 관리, 검색 및 회전하도록 특별히 설계되었습니다. Amazon RDS 와 같은 AWS 
서비스와 완벽하게 통합되어 데이터베이스 자격 증명을 안전하게 저장하고 검색하는 데 
이상적인 솔루션입니다. Secrets Manager 는 또한 자격 증명의 자동 회전을 제공하여 운영 
부담을 줄입니다. 
다른 옵션은 왜 안 되나요?: 
옵션 B(AWS Lambda + Parameter Store): AWS Lambda 는 구성을 관리하는 데 사용할 수 
있고 AWS Systems Manager Parameter Store 는 자격 증명을 저장할 수 있지만, 이 방법은 
수동 설정이 더 많고 AppConfig 및 Secrets Manager 와 동일한 수준의 통합 관리 및 
보안을 제공하지 않습니다. 
옵션 C(암호화된 S3 구성 파일): S3 파일에 구성 및 자격 증명을 저장하면 수동 관리 및 
보안 고려 사항이 더 많아 관리 오버헤드가 증가합니다. 
옵션 D(자격 증명을 위한 AppConfig + RDS): RDS 는 애플리케이션 자격 증명을 저장하도록 
설계되지 않았습니다. 
데이터베이스 인스턴스와 해당 구성을 관리하는 데 더 적합합니다. 
Q743 
보안 요구 사항을 충족하려면 회사는 Amazon RDS MySQL DB 인스턴스와 통신하는 동안 
전송 중인 모든 애플리케이션 데이터를 암호화해야 합니다. 최근 보안 감사에서는 AWS Key 
Management Service(AWS KMS)를 사용하여 저장 데이터 암호화가 활성화되었지만 전송 
중인 데이터는 활성화되지 않은 것으로 나타났습니다. 
솔루션 설계자는 보안 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 데이터베이스에서 IAM 데이터베이스 인증을 활성화합니다. 
B. 자체 서명된 인증서를 제공합니다. RDS 인스턴스에 대한 모든 연결에 인증서를 
사용하십시오. 
C. RDS 인스턴스의 스냅샷을 찍습니다. 암호화가 활성화된 새 인스턴스로 스냅샷을 
복원합니다. 
D. AWS 에서 제공하는 루트 인증서를 다운로드합니다. RDS 인스턴스에 대한 모든 연결에 
인증서를 제공하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132933-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
보안 요구 사항을 충족하려면 솔루션 아키텍트는 AWS 에서 제공하는 루트 인증서를 
다운로드하고 RDS 인스턴스에 대한 모든 연결에 인증서를 제공해야 합니다. 이렇게 하면 
애플리케이션과 RDS 인스턴스 간에 전송되는 데이터에 대해 SSL/TLS 암호화가 
활성화됩니다. 
SSL/TLS 암호화는 클라이언트와 서버 간에 이동하는 데이터를 암호화하여 보안 계층을 
제공합니다. Amazon RDS 는 SSL 인증서를 생성하고 인스턴스가 프로비저닝되면 DB 
인스턴스에 인증서를 설치합니다. 애플리케이션은 AWS 가 제공한 루트 인증서를 사용하여 
DB 인스턴스의 신원을 확인하고 보안 연결을 설정할 수 있습니다. 
다른 옵션은 전송 중인 데이터에 대한 암호화를 활성화하지 않거나 사용 사례와 관련이 
없기 때문에 올바르지 않습니다. 데이터베이스에서 IAM 데이터베이스 인증을 활성화하는 
것은 올바르지 않습니다. 이 옵션은 암호화가 아닌 인증 방법만 제공하기 때문입니다. IAM 
데이터베이스 인증을 통해 사용자는 데이터베이스 사용자 이름과 암호를 사용하는 대신 
AWS Identity and Access Management(IAM) 사용자 및 역할을 사용하여 데이터베이스에 
액세스할 수 있습니다. 이 옵션은 안전하지 않거나 신뢰할 수 없기 때문에 자체 서명된 
인증서를 제공하는 것은 올바르지 않습니다. 자체 서명 인증서는 신뢰할 수 있는 인증 
기관(CA)이 아닌 이를 발급한 동일한 엔터티에 의해 서명된 인증서입니다. 자체 서명된 
인증서는 쉽게 위조되거나 손상될 수 있으며 대부분의 브라우저 및 애플리케이션에서 
인식되지 않습니다. 
RDS 인스턴스의 스냅샷을 찍어 암호화가 활성화된 새 인스턴스로 복원하는 것은 올바르지 
않습니다. 이 옵션은 전송 중 암호화가 아닌 유휴 암호화만 활성화하기 때문입니다. 미사용 
암호화는 디스크에 저장된 데이터를 보호하지만 클라이언트와 서버 간에 이동하는 데이터는 
보호하지 않습니다. 
Q744 
한 회사는 ELB(Elastic Load Balancing) 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 
실행될 새로운 웹 서비스를 설계하고 있습니다. 그러나 많은 웹 서비스 클라이언트는 
방화벽에서 승인된 IP 주소에만 접근할 수 있습니다. 
솔루션 아키텍트는 고객의 요구 사항을 충족하기 위해 무엇을 권장해야 합니까? 
A. 탄력적 IP 주소가 연결된 Network Load Balancer. 
B. 탄력적 IP 주소가 연결된 Application Load Balancer. 
C. 탄력적 IP 주소를 가리키는 Amazon Route 53 호스팅 영역의 A 레코드. 
D. 로드 밸런서 앞에서 프록시로 실행되는 퍼블릭 IP 주소가 있는 EC2 인스턴스. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132934-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Network Load Balancer 에는 사용하는 각 가용 영역에 대해 하나의 탄력적 IP 주소가 
할당될 수 있습니다. 이를 통해 클라이언트는 방화벽에서 승인될 수 있는 고정 IP 주소를 
사용하여 로드 밸런서에 연결할 수 있습니다. Application Load Balancer 에는 탄력적 IP 
주소를 할당할 수 없습니다. 탄력적 IP 주소를 가리키는 Amazon Route 53 호스팅 영역의 A 
레코드는 로드 밸런서가 여전히 웹 서비스에 전달되는 요청의 소스로 자체 IP 주소를 
사용하기 때문에 작동하지 않습니다. 로드 밸런서 앞에서 프록시로 실행되는 퍼블릭 IP 
주소가 있는 EC2 인스턴스는 불필요한 복잡성과 비용을 추가하며 Network Load 
Balancer 와 동일한 확장성과 가용성을 제공하지 않습니다. 
Q745 
회사에서 새로운 AWS 계정을 개설했습니다. 계정이 새로 프로비저닝되었으며 기본 설정이 
변경되지 않았습니다. 회사는 AWS 계정 루트 사용자의 보안을 우려하고 있습니다. 
루트 사용자를 보호하려면 어떻게 해야 합니까? 
A. 일상적인 관리 작업을 위해 IAM 사용자를 생성합니다. 루트 사용자를 비활성화합니다. 
B. 일상적인 관리 작업을 위한 IAM 사용자를 생성합니다. 루트 사용자에 대해 다단계 
인증을 활성화합니다. 
C. 루트 사용자에 대한 액세스 키를 생성합니다. AWS Management Console 대신 일일 
관리 작업에 액세스 키를 사용하세요. 
D. 최고 수석 솔루션 설계자에게 루트 사용자 자격 증명을 제공합니다. 솔루션 설계자가 
일상적인 관리 작업에 루트 사용자를 사용하도록 하세요. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132935-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 답변은 새 AWS 계정의 루트 사용자를 보호하기 위한 가장 안전하고 권장되는 
옵션입니다. 루트 사용자는 계정의 모든 AWS 서비스 및 리소스에 대한 완전한 액세스 
권한을 가진 자격 증명입니다. 계정을 만들 때 사용한 이메일 주소와 비밀번호로 
로그인하면 액세스됩니다. 루트 사용자 자격 증명을 무단 사용으로부터 보호하기 위해 
AWS 에서는 다음 모범 사례를 권장합니다. 
일상적인 관리 작업을 위한 IAM 사용자를 생성합니다. IAM 사용자는 AWS 리소스에 
액세스할 수 있는 특정 권한이 있는 계정에서 생성하는 자격 증명입니다. 귀하 자신과 
귀하의 계정에 액세스해야 하는 다른 사람들을 위해 개별 IAM 사용자를 생성할 수 
있습니다. 또한 일반적인 작업을 수행할 수 있는 권한을 부여하는 정책 세트가 있는 IAM 
그룹에 IAM 사용자를 할당할 수도 있습니다. 루트 사용자 대신 IAM 사용자를 사용하면 
최소 권한 원칙을 따르고 계정이 손상될 위험을 줄일 수 있습니다. 
루트 사용자에서 다중 요소 인증(MFA)을 활성화합니다. MFA 는 사용자가 비밀번호와 
자신만 액세스할 수 있는 장치의 코드라는 두 가지 정보를 제공하여 자신의 신원을 
증명하도록 요구하는 보안 기능입니다. 루트 사용자에 대해 MFA를 활성화하면 계정에 추가 
보호 계층을 추가하고 암호가 손상된 경우에도 무단 액세스를 방지할 수 있습니다. 
루트 사용자 계정으로 수행하는 작업을 제한하십시오. 계정 설정 변경, 계정 폐쇄, 통합 
결제 관리 등 루트 사용자 자격 증명이 필요한 작업에만 루트 사용자를 사용해야 합니다. 
루트 사용자 자격 증명이 필요한 작업의 전체 목록은 루트 사용자 자격 증명이 필요한 
작업을 참조하세요. 다른 모든 작업의 경우 적절한 권한이 있는 IAM 사용자 또는 역할을 
사용해야 합니다. 
Q746 
한 회사가 거의 실시간으로 스트리밍 데이터를 처리하는 애플리케이션을 배포하고 있습니다. 
회사는 워크로드에 Amazon EC2 인스턴스를 사용할 계획입니다. 네트워크 아키텍처는 노드 
간 가능한 최저 대기 시간을 제공하도록 구성 가능해야 합니다. 
이러한 요구 사항을 충족하는 네트워크 솔루션 조합은 무엇입니까? (2 개 선택) 
A. 각 EC2 인스턴스에서 향상된 네트워킹을 활성화하고 구성합니다. 
B. EC2 인스턴스를 별도의 계정으로 그룹화합니다. 
C. 클러스터 배치 그룹에서 EC2 인스턴스를 실행합니다. 
D. 각 EC2 인스턴스에 여러 탄력적 네트워크 인터페이스를 연결합니다. 
E. Amazon Elastic Block Store(Amazon EBS) 최적화 인스턴스 유형을 사용합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/132936-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q747 
한 금융 서비스 회사는 두 개의 데이터 센터를 폐쇄하고 100TB 가 넘는 데이터를 AWS 로 
마이그레이션하려고 합니다. 데이터는 하위 폴더의 깊은 계층에 저장된 수백만 개의 작은 
파일로 구성된 복잡한 디렉터리 구조를 가지고 있습니다. 대부분의 데이터는 비정형이며 
회사의 파일 스토리지는 여러 공급업체의 SMB 기반 스토리지 유형으로 구성됩니다. 회사는 
마이그레이션 후 데이터에 액세스하기 위해 애플리케이션을 변경하고 싶지 않습니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 
합니까? 
A. AWS Direct Connect 를 사용하여 데이터를 Amazon S3 로 마이그레이션하십시오. 
B. AWS DataSync 를 사용하여 데이터를 Amazon FSx for Lustre 로 마이그레이션합니다. 
C. AWS DataSync 를 사용하여 데이터를 Amazon FSx for Windows File Server 로 
마이그레이션합니다. 
D. AWS Direct Connect 를 사용하여 온프레미스 데이터 스토리지를 AWS Storage Gateway 
볼륨 게이트웨이로 마이그레이션합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132938-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS DataSync 는 인터넷이나 AWS Direct Connect 를 통해 온프레미스 스토리지 시스템과 
AWS 스토리지 서비스 간의 데이터 이동을 단순화, 자동화 및 가속화하는 데이터 전송 
서비스입니다. AWS DataSync 는 업계 표준 SMB(서버 메시지 블록) 프로토콜을 통해 
액세스할 수 있는 완전관리형 파일 시스템인 Amazon FSx for Windows File Server 로 
데이터를 전송할 수 있습니다. Windows 파일 서버용 Amazon FSx 는 Windows Server 를 
기반으로 구축되어 사용자 할당량, 최종 사용자 파일 복원, Microsoft Active Directory(AD) 
통합과 같은 광범위한 관리 기능을 제공합니다. 이 솔루션은 다음과 같은 이유로 질문의 
요구 사항을 충족합니다. 
AWS DataSync는 빠르고 효율적인 데이터 전송에 최적화되어 있으므로 합리적인 시간 내에 
100TB 이상의 데이터를 AWS 로 마이그레이션할 수 있습니다. 
AWS DataSync 는 파일 이름, 권한, 타임스탬프와 같은 복잡한 파일 구조와 메타데이터를 
처리할 수 있으므로 복잡한 디렉터리 구조와 하위 폴더의 심층 계층에 저장된 수백만 개의 
작은 파일을 보존할 수 있습니다. 
Amazon FSx for Windows File Server 는 회사의 온프레미스 파일 스토리지에서 사용하는 
것과 동일한 SMB 프로토콜 및 Windows Server 기능을 지원하므로 마이그레이션 후 
데이터에 액세스하기 위해 애플리케이션을 변경하지 않아도 됩니다. 
AWS DataSync 및 Amazon FSx for Windows File Server 는 데이터 전송 및 파일 시스템을 
설정, 구성 및 유지 관리하는 작업을 처리하는 완전 관리형 서비스이므로 운영 오버헤드를 
줄일 수 있습니다. 
Q748 
회사는 AWS Organizations 의 조직을 사용하여 애플리케이션이 포함된 AWS 계정을 
관리합니다. 회사는 조직 내에 전용 모니터링 회원 계정을 설정합니다. 회사는 Amazon 
CloudWatch 를 사용하여 계정 전체의 관측 가능성 데이터를 쿼리하고 시각화하려고 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 모니터링 계정에 대해 CloudWatch 교차 계정 관찰 기능을 활성화합니다. 모니터링 
계정에서 제공하는 AWS CloudFormation 템플릿을 각 AWS 계정에 배포하여 모니터링 
계정과 데이터를 공유합니다. 
B. 조직 루트 조직 단위(OU) 아래의 모니터링 계정에서 CloudWatch 에 대한 액세스를 
제공하도록 서비스 제어 정책(SCP)을 설정합니다. 
C. 모니터링 계정에 새 IAM 사용자를 구성합니다. 각 AWS 계정에서 계정의 CloudWatch 
데이터를 쿼리하고 시각화할 수 있도록 IAM 정책을 구성합니다. 새 IAM 사용자에게 새 IAM 
정책을 연결합니다. 
D. 모니터링 계정에 새 IAM 사용자를 생성합니다. 각 AWS 계정에서 교차 계정 IAM 정책을 
생성합니다. IAM 정책을 새 IAM 사용자에게 연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132939-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 모니터링 계정이 CloudWatch 를 사용하여 계정 전체에서 관찰 가능성 
데이터를 쿼리하고 시각화할 수 있도록 허용하므로 요구 사항을 충족합니다. CloudWatch 
교차 계정 관측 가능성은 중앙 모니터링 계정이 다른 계정에서 공유하는 관측 가능성 
데이터를 보고 상호 작용할 수 있도록 하는 기능입니다. 교차 계정 관측성을 활성화하려면 
모니터링 계정에서 공유할 데이터 유형(메트릭, 로그, 추적)과 연결할 원본 계정을 구성해야 
합니다. 원본 계정은 계정 ID, 조직 ID 또는 조직 경로로 지정할 수 있습니다. 모니터링 
계정과 데이터를 공유하려면 원본 계정이 모니터링 계정에서 제공하는 AWS 
CloudFormation 템플릿을 배포해야 합니다. 이 템플릿은 원본 계정과 모니터링 계정 간의 
링크를 나타내는 관찰 가능성 링크 리소스를 생성합니다. 또한 템플릿은 모니터링 계정의 
연결 지점을 나타내는 싱크 리소스를 만듭니다. 
원본 계정은 모니터링 계정의 싱크와 관찰 가능성 데이터를 공유할 수 있습니다. 그런 다음 
모니터링 계정은 CloudWatch 콘솔, API 또는 CLI 를 사용하여 계정 전체에서 관찰 가능성 
데이터를 검색, 분석 및 상호 연관시킬 수 있습니다. 
Q749 
회사의 웹사이트는 대중에게 제품을 판매하는 데 사용됩니다. 이 사이트는 ALB(Application 
Load Balancer) 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 
Amazon CloudFront 배포판도 있으며 AWS WAF 는 SQL 주입 공격으로부터 보호하는 데 
사용되고 있습니다. ALB 는 CloudFront 배포의 오리진입니다. 최근 보안 로그를 검토한 
결과, 해당 웹사이트에 대한 접근을 차단해야 할 외부 악성 IP 가 발견되었습니다. 
솔루션 설계자는 애플리케이션을 보호하기 위해 무엇을 해야 합니까? 
A. CloudFront 배포의 네트워크 ACL 을 수정하여 악성 IP 주소에 대한 거부 규칙을 
추가합니다. 
B. AWS WAF 구성을 수정하여 악성 IP 주소를 차단하는 IP 일치 조건을 추가합니다. 
C. ALB 뒤의 대상 그룹에 있는 EC2 인스턴스에 대한 네트워크 ACL 을 수정하여 악성 IP 
주소를 거부합니다. 
D. 악성 IP 주소를 거부하도록 ALB 뒤의 대상 그룹에 있는 EC2 인스턴스에 대한 보안 
그룹을 수정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132940-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS WAF 는 애플리케이션 가용성에 영향을 미치거나 보안을 손상시키거나 과도한 
리소스를 소비할 수 있는 일반적인 웹 공격으로부터 웹 애플리케이션을 보호하는 데 도움이 
되는 웹 애플리케이션 방화벽입니다. AWS WAF 를 통해 사용자는 사용자 정의 가능한 웹 
보안 규칙을 기반으로 웹 요청을 차단, 허용 또는 계산하는 규칙을 생성할 수 있습니다. 
생성할 수 있는 규칙 유형 중 하나는 사용자가 허용하거나 차단하려는 IP 주소 또는 IP 
주소 범위 목록을 지정할 수 있는 IP 일치 규칙입니다. 악의적인 IP 주소를 차단하는 IP 
일치 조건을 추가하도록 AWS WAF 의 구성을 수정함으로써 솔루션 아키텍트는 공격자가 
CloudFront 배포 및 ALB 를 통해 웹 사이트에 액세스하는 것을 방지할 수 있습니다. 
다른 옵션은 악성 IP 주소의 웹 사이트 액세스를 효과적으로 차단하지 못하기 때문에 
올바르지 않습니다. CloudFront 배포의 네트워크 ACL 또는 ALB 뒤의 대상 그룹에 있는 
EC2 인스턴스를 수정하는 것은 네트워크 ACL 이 상태 비저장이고 애플리케이션 계층에서 
트래픽을 평가하지 않기 때문에 작동하지 않습니다. 보안 그룹은 상태 저장형이고 로드 
밸런서 수준이 아닌 인스턴스 수준에서만 트래픽을 평가하기 때문에 ALB 뒤의 대상 그룹에 
있는 EC2 인스턴스에 대한 보안 그룹을 수정하면 작동하지 않습니다. 
Q750 
회사는 10 개의 AWS 계정을 포함하는 AWS Organizations 에 조직을 설정합니다. 솔루션 
설계자는 수천 명의 직원에게 계정에 대한 액세스를 제공하는 솔루션을 설계해야 합니다. 
회사에 기존 IdP(ID 공급자)가 있습니다. 회사는 AWS 인증에 기존 IdP 를 사용하려고 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 필요한 AWS 계정의 직원에 대한 IAM 사용자를 생성합니다. IAM 사용자를 기존 IdP 에 
연결합니다. IAM 사용자에 대한 연합 인증을 구성합니다. 
B. 기존 IdP 에서 동기화된 사용자 이메일 주소와 비밀번호를 사용하여 AWS 계정 루트 
사용자를 설정합니다. 
C. AWS IAM ID 센터(AWS Single Sign-On)를 구성합니다. IAM ID 센터를 기존 IdP 에 
연결합니다. 기존 IdP 에서 사용자 및 그룹을 프로비저닝합니다. 
D. AWS Resource Access Manager(AWS RAM)를 사용하여 기존 IdP 의 사용자와 AWS 
계정에 대한 액세스를 공유합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132941-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS IAM Identity Center: 
* IAM Identity Center 는 조직 내의 여러 AWS 계정에 대한 중앙 집중식 액세스 관리를 
제공하고 SAML 2.0 페더레이션을 통해 기존 ID 공급자(IdP)와 원활하게 통합됩니다. 
* 사용자는 기존 IdP 자격 증명을 사용하여 인증하고 각 계정에서 별도의 IAM 사용자를 
만들고 관리할 필요 없이 AWS 리소스에 액세스할 수 있습니다. 
* IAM Identity Center 는 또한 외부 IdP 에서 AWS 로 사용자와 그룹을 자동으로 동기화하여 
안전하고 관리되는 액세스를 보장할 수 있으므로 사용자 프로비저닝 및 프로비저닝 해제를 
간소화합니다. 
* 기존 IdP 와의 통합: 
* 이 솔루션은 SAML 을 사용하여 회사의 IdP 에 연결하도록 IAM Identity Center 를 구성하는 
것을 포함합니다. 
이 설정을 통해 직원은 기존 자격 증명으로 로그인하여 별도의 AWS 자격 증명을 관리하는 
복잡성을 줄일 수 있습니다. 
* 연결되면 IAM Identity Center 가 인증 및 권한을 처리하여 할당된 역할 및 권한에 따라 
사용자에게 AWS 계정에 대한 액세스 권한을 부여합니다. 
다른 옵션이 틀린 이유: 
* 옵션 A: 직원마다 별도의 IAM 사용자를 만드는 것은 확장성이나 효율이 없습니다. 여러 
AWS 계정에서 수천 명의 IAM 사용자를 관리하면 불필요한 복잡성과 운영 오버헤드가 
발생합니다. 
* 옵션 B: 동기화된 암호로 AWS 루트 사용자를 사용하는 것은 보안 위험이며 AWS 모범 
사례에 어긋납니다. 루트 계정은 일상적인 작업에 사용해서는 안 됩니다. 
* 옵션 D: AWS Resource Access Manager(RAM)는 계정 간에 AWS 리소스를 공유하는 데 
사용되며, 계정 간 사용자 액세스를 연합하는 데 사용되지 않습니다. 외부 IdP 를 통한 인증 
솔루션을 제공하지 않습니다. 
AWS 참조: 
* AWS IAM Identity Center 
* AWS IAM Identity Center 와 SAML 2.0 통합 
IAM Identity Center 를 설정하고 기존 IdP 에 연결하면 회사는 높은 수준의 운영 효율성과 
보안으로 여러 AWS 계정에서 수천 명의 직원에 대한 액세스를 효율적으로 관리할 수 
있습니다. 
따라서 옵션 C 가 최상의 솔루션입니다. 
Q751 
솔루션 아키텍트는 회사의 AWS 계정에 대한 AWS Identity and Access Management(IAM) 
인증 모델을 설계하고 있습니다. 회사는 AWS 계정의 AWS 서비스 및 리소스에 대한 전체 
액세스 권한을 갖도록 5 명의 특정 직원을 지정했습니다. 
솔루션 설계자는 지정된 5 명의 직원 각각에 대해 IAM 사용자를 생성하고 IAM 사용자 
그룹을 생성했습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. IAM 사용자 그룹에 AdministratorAccess 리소스 기반 정책을 연결합니다. 지정된 직원 
IAM 사용자 5 명을 각각 IAM 사용자 그룹에 배치합니다. 
B. SystemAdministrator 자격 증명 기반 정책을 IAM 사용자 그룹에 연결합니다. 지정된 
직원 IAM 사용자 5 명을 각각 IAM 사용자 그룹에 배치합니다. 
C. IAM 사용자 그룹에 AdministratorAccess 자격 증명 기반 정책을 연결합니다. 지정된 
직원 IAM 사용자 5 명을 각각 IAM 사용자 그룹에 배치합니다. 
D. SystemAdministrator 리소스 기반 정책을 IAM 사용자 그룹에 연결합니다. 지정된 직원 
IAM 사용자 5 명을 각각 IAM 사용자 그룹에 배치합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/133081-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 다음 구성 요소와 기능을 사용하므로 요구 사항을 충족합니다. 
AdministratorAccess 자격 증명 기반 정책: AWS 서비스 및 리소스에 대한 전체 액세스를 
제공하는 AWS 관리형 정책입니다. 이 정책을 IAM 사용자 그룹에 연결함으로써 솔루션 
아키텍트는 지정된 직원이 AWS 계정에서 모든 작업을 수행하는 데 필요한 권한을 부여할 
수 있습니다. 
IAM 사용자 그룹: 공통 권한을 공유하는 IAM 사용자의 모음입니다 2. 사용자 그룹을 만들고 
지정된 직원 5 명을 구성원으로 추가함으로써 솔루션 설계자는 권한 관리를 단순화하고 
인적 오류나 불일치의 위험을 줄일 수 있습니다. 
IAM 사용자: AWS 에서 지정된 직원을 나타내는 ID 입니다. 각 직원에 대한 IAM 사용자를 
생성하고 직원이 자신의 자격 증명으로 로그인하도록 요구함으로써 솔루션 설계자는 AWS 
계정의 보안과 책임성을 강화할 수 있습니다. 
Q752 
회사에는 가상 머신(VM)을 기반으로 하는 다중 계층 결제 처리 애플리케이션이 있습니다. 
계층 간의 통신은 정확히 1 회 전달을 보장하는 타사 미들웨어 솔루션을 통해 비동기적으로 
발생합니다. 
회사에는 최소한의 인프라 관리가 필요한 솔루션이 필요합니다. 솔루션은 애플리케이션 
메시징을 정확히 한 번만 전달하도록 보장해야 합니다. 
이러한 요구 사항을 충족하는 작업 조합은 무엇입니까? (2 개 선택) 
A. 아키텍처의 컴퓨팅 계층에 AWS Lambda 를 사용하십시오. 
B. 아키텍처의 컴퓨팅 계층에 Amazon EC2 인스턴스를 사용하십시오. 
C. 컴퓨팅 계층 사이의 메시징 구성 요소로 Amazon Simple 알림 서비스(Amazon SNS)를 
사용합니다. 
D. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 컴퓨팅 계층 간의 메시징 
구성 요소로 사용합니다. 
E. 아키텍처의 컴퓨팅 계층에 Amazon Elastic Kubemetes Service(Amazon EKS)를 기반으로 
하는 컨테이너를 사용합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/133405-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 최소한의 인프라 관리가 필요하고 애플리케이션 메시징에 대해 정확히 1 회 
전달을 보장하므로 요구 사항을 충족합니다. AWS Lambda 는 서버를 프로비저닝하거나 
관리하지 않고도 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스입니다. 사용한 컴퓨팅 
시간에 대해서만 비용을 지불하면 됩니다. Lambda 는 워크로드 크기에 따라 자동으로 
확장됩니다. Amazon SQS FIFO 대기열은 메시지가 전송된 순서대로 정확히 한 번만 
처리되도록 설계되었습니다. FIFO 대기열은 고가용성을 가지며 엄격한 선입선출 순서로 
메시지를 전달합니다. Amazon SQS 를 사용하여 마이크로서비스, 분산 시스템 및 서버리스 
애플리케이션을 분리하고 확장할 수 있습니다. 
Q753 
회사에는 온프레미스 파일 시스템이 SFTP 를 통해 매일 수신하는 보고서 파일을 분석하는 
야간 일괄 처리 루틴이 있습니다. 회사는 솔루션을 AWS 클라우드로 이전하려고 합니다. 
솔루션은 가용성과 복원력이 높아야 합니다. 또한 솔루션은 운영 노력을 최소화해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. SFTP 용 AWS 전송 및 스토리지용 Amazon Elastic File System(Amazon EFS) 파일 
시스템을 배포합니다. 예약된 조정 정책이 있는 Auto Scaling 그룹의 Amazon EC2 
인스턴스를 사용하여 배치 작업을 실행합니다. 
B. Linux 및 SFTP 서비스를 실행하는 Amazon EC2 인스턴스를 배포합니다. 저장에는 
Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용하십시오. 최소 인스턴스 수와 
원하는 인스턴스 수를 1 로 설정한 Auto Scaling 그룹을 사용합니다. 
C. Linux 및 SFTP 서비스를 실행하는 Amazon EC2 인스턴스를 배포합니다. 저장을 위해 
Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용합니다. 최소 인스턴스 수와 
원하는 인스턴스 수를 1 로 설정한 Auto Scaling 그룹을 사용합니다. 
D. SFTP 용 AWS 전송과 저장용 Amazon S3 버킷을 배포합니다. 처리를 위해 Amazon 
S3 에서 Amazon EC2 인스턴스로 배치 파일을 가져오도록 애플리케이션을 수정합니다. 
예약된 조정 정책이 있는 Auto Scaling 그룹의 EC2 인스턴스를 사용하여 일괄 작업을 
실행합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132944-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
고가용성, 성능, 보안 및 고정 IP 주소 요구 사항을 충족하는 솔루션은 Amazon CloudFront, 
ALB(Application Load Balancer), Amazon Route 53 및 AWS WAF 를 사용하는 것입니다. 이 
솔루션을 통해 회사는 엣지 로케이션에 콘텐츠를 캐시하고 각 엣지 로케이션에 고정 IP 
주소를 제공하는 CDN(콘텐츠 전송 네트워크) 서비스인 CloudFront 를 사용하여 HTTP 기반 
애플리케이션을 전 세계적으로 배포할 수 있습니다. 또한 회사는 Route 53 지연 시간 기반 
라우팅을 사용하여 각 지역에서 가장 가까운 ALB 로 요청을 라우팅하여 EC2 인스턴스 
전체에 로드 균형을 맞출 수 있습니다. 또한 회사는 정의된 조건에 따라 웹 요청을 허용, 
차단 또는 계산하는 규칙을 생성하여 일반적인 웹 공격으로부터 애플리케이션을 보호하기 
위해 CloudFront 배포에 AWS WAF 를 배포할 수도 있습니다. 다른 솔루션은 HTTP 기반 
애플리케이션을 지원하지 않는 NLB(Network Load Balancer)를 사용하거나 AWS Global 
Accelerator 보다 더 나은 성능과 보안을 제공하는 CloudFront 를 사용하지 않기 때문에 
모든 요구 사항을 충족하지 못합니다. 
Q754 
한 회사에는 여러 AWS 지역의 Amazon EC2 인스턴스에 배포된 HTTP 기반 
애플리케이션에 액세스하는 전 세계 사용자가 있습니다. 회사는 애플리케이션의 가용성과 
성능을 개선하려고 합니다. 또한 회사는 가용성에 영향을 미치거나, 보안을 손상시키거나, 
과도한 리소스를 소비할 수 있는 일반적인 웹 공격으로부터 애플리케이션을 보호하려고 
합니다. 고정 IP 주소가 필요합니다. 
이를 달성하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. 각 지역의 NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. NLB 에 AWS 
WAF 를 배포합니다. AWS Global Accelerator 를 사용하여 액셀러레이터를 생성하고 NLB 를 
엔드포인트로 등록합니다. 
B. 각 지역의 ALB(Application Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. ALB 에 
AWS WAF 를 배포합니다. AWS Global Accelerator 를 사용하여 액셀러레이터를 생성하고 
ALB 를 엔드포인트로 등록합니다. 
C. 각 지역의 NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. NLB 에 AWS 
WAF 를 배포합니다. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 요청을 NLB 로 
라우팅하는 오리진으로 Amazon CloudFront 배포를 생성합니다. 
D. 각 지역의 ALB(Application Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. Amazon 
Route 53 지연 시간 기반 라우팅을 사용하여 요청을 ALB 로 라우팅하는 오리진으로 
Amazon CloudFront 배포를 생성합니다. CloudFront 배포에 AWS WAF 를 배포합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132945-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q755 
회사의 데이터 플랫폼은 Amazon Aurora MySQL 데이터베이스를 사용합니다. 
데이터베이스에는 다양한 가용 영역에 걸쳐 여러 읽기 전용 복제본과 여러 DB 인스턴스가 
있습니다. 사용자들은 최근 데이터베이스에서 연결이 너무 많다는 오류를 보고했습니다. 
회사에서는 읽기 전용 복제본이 기본 작성자로 승격될 때 장애 조치 시간을 20% 
단축하려고 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 다중 AZ 클러스터 배포를 통해 Aurora 에서 Amazon RDS 로 전환합니다. 
B. Aurora 데이터베이스 앞에 Amazon RDS 프록시를 사용하십시오. 
C. 읽기 연결을 위해 DynamoDB Accelerator(DAX)를 사용하여 Amazon DynamoDB 로 
전환합니다. 
D. 재배치 기능이 있는 Amazon Redshift 로 전환합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132946-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명 
Amazon RDS Proxy 는 Amazon RDS 및 Aurora 데이터베이스를 위한 완전관리형 고가용성 
데이터베이스 프록시를 제공하는 서비스입니다. 이를 통해 데이터베이스 연결 풀링 및 공유, 
데이터베이스 로드 감소, 애플리케이션 확장성 및 가용성 향상이 가능합니다. 
Aurora 데이터베이스 앞에서 Amazon RDS Proxy 를 사용하면 다음과 같은 이점을 얻을 수 
있습니다. 
* 데이터베이스에 대한 연결 수를 줄이고 너무 많은 연결이 있음을 나타내는 오류를 피할 
수 있습니다. Amazon RDS Proxy 는 연결 관리 및 멀티플렉싱을 처리하므로 더 적은 수의 
데이터베이스 연결 및 리소스를 사용할 수 있습니다. 
* 읽기 복제본이 기본 작성자로 승격되면 장애 조치 시간을 20%까지 줄일 수 있습니다. 
Amazon RDS Proxy 는 애플리케이션 코드나 구성을 변경할 필요 없이 장애를 자동으로 
감지하고 새로운 기본 인스턴스로 트래픽을 라우팅합니다. 벤치마크 테스트에 따르면 
Amazon RDS Proxy 를 사용하면 장애 조치 시간이 66 초에서 53 초로 단축되어 20% 
향상되었습니다. 
* 데이터베이스 액세스의 보안 및 규정 준수를 향상시킬 수 있습니다. Amazon RDS 
Proxy 는 AWS Secrets Manager 및 AWS Identity and Access Management(IAM)와 통합되어 
데이터베이스 연결에 대한 안전하고 세분화된 인증 및 권한 부여를 지원합니다. 
Q756 
회사는 Amazon S3 에 텍스트 파일을 저장합니다. 텍스트 파일에는 고객 채팅 메시지, 날짜 
및 시간 정보, 고객 개인 식별 정보(PII)가 포함됩니다. 
회사에는 품질 관리를 위해 외부 서비스 제공업체에 대화 샘플을 제공하는 솔루션이 
필요합니다. 외부 서비스 제공자는 가장 최근 대화까지 샘플 대화를 무작위로 선택해야 
합니다. 회사는 고객 PII 를 외부 서비스 제공업체와 공유해서는 안 됩니다. 고객 대화 수가 
증가하면 솔루션도 확장되어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 객체 Lambda 액세스 포인트를 생성합니다. 함수가 파일을 읽을 때 PII 를 수정하는 
AWS Lambda 함수를 생성합니다. 외부 서비스 공급자에게 객체 Lambda 액세스 포인트에 
액세스하도록 지시합니다. 
B. 모든 새 파일을 정기적으로 읽고, 파일에서 PII 를 수정하고, 수정된 파일을 다른 S3 
버킷에 쓰는 Amazon EC2 인스턴스에 배치 프로세스를 만듭니다. PII 가 포함되지 않은 
버킷에 액세스하도록 외부 서비스 제공자에게 지시하십시오. 
B. 파일 목록을 표시하고, 파일에서 PII 를 수정하고, 외부 서비스 공급자가 PII 가 수정된 
파일의 새 버전을 다운로드할 수 있도록 하는 웹 애플리케이션을 Amazon EC2 인스턴스에 
생성합니다. 
D. Amazon DynamoDB 테이블을 생성합니다. PII 가 포함되지 않은 파일의 데이터만 읽는 
AWS Lambda 함수를 생성합니다. 새 파일이 Amazon S3 에 기록될 때 DynamoDB 
테이블에 PII 가 아닌 데이터를 저장하도록 Lambda 함수를 구성합니다. 외부 서비스 
공급자에게 DynamoDB 테이블에 대한 액세스 권한을 부여합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132947-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
올바른 해결책은 객체 Lambda 액세스 포인트와 함수가 파일을 읽을 때 PII 를 수정하는 
AWS Lambda 함수를 생성하는 것입니다. 이런 방식으로 회사는 복사본을 생성하거나 원본 
객체를 변경하지 않고도 S3 객체 Lambda 기능을 사용하여 S3 객체 콘텐츠를 즉시 수정할 
수 있습니다. 외부 서비스 공급자는 객체 Lambda 액세스 포인트에 액세스하고 파일의 
수정된 버전을 얻을 수 있습니다. 이 솔루션은 추가 저장, 처리 또는 동기화가 필요하지 
않으므로 운영 오버헤드가 가장 적습니다. 또한 이 솔루션은 고객 대화 수와 외부 서비스 
제공업체의 요구에 따라 자동으로 확장됩니다. 다른 옵션은 다음과 같은 이유로 올바르지 
않습니다. 
옵션 B 는 EC2 인스턴스에서 일괄 프로세스를 사용하여 파일을 읽고, 수정하고, 다른 S3 
버킷에 씁니다. 이 솔루션은 EC2 인스턴스, 배치 프로세스 및 추가 S3 버킷을 관리해야 
하므로 운영 오버헤드가 더 많습니다. 또한 원본 파일과 수정된 파일 사이에 지연 시간과 
불일치가 발생합니다. 
옵션 C 는 EC2 인스턴스에서 웹 애플리케이션을 사용하여 파일을 표시, 수정 및 
다운로드합니다. 이 솔루션은 EC2 인스턴스, 웹 애플리케이션 및 다운로드 프로세스를 
관리해야 하므로 운영 오버헤드가 더 많습니다. 또한 원본 파일을 웹 애플리케이션에 
노출하므로 PII 가 유출될 위험이 높아집니다. 
옵션 D 는 DynamoDB 테이블과 Lambda 함수를 사용하여 파일의 PII 가 아닌 데이터를 
저장합니다. 이 솔루션은 DynamoDB 테이블, Lambda 함수 및 데이터 변환을 관리해야 
하므로 운영 오버헤드가 더 많습니다. 또한 원본 파일의 형식과 구조를 변경하여 품질 관리 
프로세스에 영향을 미칠 수 있습니다. 
Q757 
회사는 Amazon EC2 인스턴스에서 레거시 시스템을 실행하고 있습니다. 애플리케이션 
코드는 수정할 수 없으며 시스템은 둘 이상의 인스턴스에서 실행될 수 없습니다. 솔루션 
설계자는 시스템 복구 시간을 향상시킬 수 있는 탄력적인 솔루션을 설계해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. EC2 인스턴스에 대한 종료 방지 기능을 활성화합니다. 
B. 다중 AZ 배포를 위해 EC2 인스턴스를 구성합니다. 
C. 장애 발생 시 EC2 인스턴스를 복구하기 위해 Amazon CloudWatch 경보를 생성합니다. 
D. 스토리지 중복성을 위해 RAID 구성을 사용하는 두 개의 Amazon Elastic Block 
Store(Amazon EBS) 볼륨으로 EC2 인스턴스를 시작합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/133082-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q758 
한 회사에서 컨테이너화된 애플리케이션 워크로드를 3 개의 가용 영역에 걸쳐 VPC 에 
배포하려고 합니다. 회사에는 가용 영역 전반에 걸쳐 가용성이 높은 솔루션이 필요합니다. 
솔루션을 사용하려면 애플리케이션을 최소한으로 변경해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Container Service(Amazon ECS)를 사용하세요. 대상 추적 조정을 
사용하도록 Amazon ECS 서비스 Auto Scaling 을 구성합니다. 최소 용량을 3 으로 
설정합니다. 가용 영역 속성을 사용하여 분산되도록 작업 배치 전략 유형을 설정합니다. 
B. Amazon Elastic Kubernetes Service(Amazon EKS) 자체 관리형 노드를 사용합니다. 대상 
추적 조정을 사용하도록 Application Auto Scaling 을 구성합니다. 최소 용량을 3 으로 
설정하세요. 
C. Amazon EC2 예약 인스턴스를 사용하십시오. 분산 배치 그룹에서 3 개의 EC2 
인스턴스를 시작합니다. 대상 추적 조정을 사용하도록 Auto Scaling 그룹을 구성합니다. 
최소 용량을 3 으로 설정하세요. 
D. AWS Lambda 함수를 사용하십시오. VPC 에 연결하도록 Lambda 함수를 구성합니다. 
Lambda 를 확장 가능한 대상으로 사용하도록 Application Auto Scaling 을 구성합니다. 최소 
용량을 3 으로 설정하세요. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132948-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 회사는 고가용성과 애플리케이션 변경을 최소화하면서 3 개의 가용 영역에 걸쳐 
컨테이너화된 애플리케이션 워크로드를 VPC 에 배포하려고 합니다. 최소한의 운영 
오버헤드로 이러한 요구 사항을 충족하는 솔루션은 다음과 같습니다. 
Amazon Elastic Container Service(Amazon ECS)를 사용하세요. Amazon ECS 는 AWS 에서 
컨테이너화된 애플리케이션을 실행하고 확장할 수 있는 완전관리형 컨테이너 
오케스트레이션 서비스입니다. Amazon ECS 를 사용하면 자체 클러스터 관리 인프라를 설치, 
운영 및 확장할 필요가 없습니다. Amazon ECS 는 VPC, ELB, CloudFormation, CloudWatch, 
IAM 등과 같은 다른 AWS 서비스와도 통합됩니다. 
대상 추적 조정을 사용하도록 Amazon ECS 서비스 Auto Scaling 을 구성합니다. Amazon 
ECS 서비스 Auto Scaling 을 사용하면 수요 또는 사용자 지정 지표를 기반으로 서비스의 
작업 수를 자동으로 조정할 수 있습니다. 목표 추적 조정은 지정된 지표를 목표 값으로 
유지하기 위해 서비스의 작업 수를 조정하는 정책 유형입니다. 예를 들어, 목표 추적 
조정을 사용하여 서비스에 대한 목표 CPU 사용률 또는 작업당 요청 수를 유지할 수 
있습니다. 
최소 용량을 3 으로 설정합니다. 이렇게 하면 서비스가 항상 3 개의 가용 영역에서 3 개 
이상의 작업을 실행하여 애플리케이션에 고가용성과 내결함성을 제공할 수 있습니다. 
가용 영역 속성을 사용하여 분산되도록 작업 배치 전략 유형을 설정합니다. 이렇게 하면 
작업이 클러스터의 가용 영역에 고르게 분산되어 서비스 가용성이 극대화됩니다. 
이 솔루션은 가용 영역 전반에 걸쳐 고가용성을 제공하고 애플리케이션 변경을 최소화하며 
자체 클러스터 인프라 관리에 따른 운영 오버헤드를 줄입니다. 
Q759 
미디어 회사는 Amazon S3 에 영화를 저장합니다. 각 영화는 크기가 1GB 에서 10GB 사이인 
단일 비디오 파일에 저장됩니다. 
회사는 사용자가 구매한 후 5 분 이내에 영화의 스트리밍 콘텐츠를 제공할 수 있어야 
합니다. 20 년이 넘은 영화보다 20 년 미만의 영화에 대한 수요가 더 높습니다. 회사는 
수요에 따라 호스팅 서비스 비용을 최소화하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 모든 미디어 콘텐츠를 Amazon S3 에 저장합니다. 영화에 대한 수요가 감소할 때 S3 
수명 주기 정책을 사용하여 미디어 데이터를 Infrequent Access 계층으로 이동합니다. 
B. S3 Standard 에 최신 영화 비디오 파일을 저장합니다. S3 Standard-infrequent Access(S3 
Standard-IA)에 오래된 영화 비디오 파일을 저장합니다. 사용자가 오래된 영화를 주문하면 
표준 검색을 사용하여 비디오 파일을 검색합니다. 
C. S3 Intelligent-Tiering 에 최신 영화 비디오 파일을 저장합니다. S3 Glacier 유연한 검색에 
오래된 영화 비디오 파일을 저장합니다. 사용자가 오래된 영화를 주문하면 빠른 검색을 
사용하여 비디오 파일을 검색합니다. 
D. S3 Standard 에 최신 영화 비디오 파일을 저장합니다. S3 Glacier 유연한 검색에 오래된 
영화 비디오 파일을 저장합니다. 사용자가 오래된 영화를 주문하면 대량 검색을 사용하여 
비디오 파일을 검색합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132949-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q760 
솔루션 아키텍트는 공급업체가 Docker 컨테이너 이미지로 제공하는 애플리케이션에 대한 
아키텍처를 설계해야 합니다. 컨테이너에는 임시 파일용으로 사용할 수 있는 50GB 의 
스토리지가 필요합니다. 인프라는 서버리스여야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 50GB 가 넘는 공간이 있는 Amazon S3 탑재 볼륨과 함께 Docker 컨테이너 이미지를 
사용하는 AWS Lambda 함수를 생성합니다. 
B. 50GB 가 넘는 공간을 가진 Amazon Elastic Block Store(Amazon EBS) 볼륨과 함께 
Docker 컨테이너 이미지를 사용하는 AWS Lambda 함수를 생성합니다. 
C. AWS Fargate 시작 유형을 사용하는 Amazon Elastic Container Service(Amazon ECS) 
클러스터를 생성합니다. Amazon Elastic File System(Amazon EFS) 볼륨을 사용하여 
컨테이너 이미지에 대한 작업 정의를 생성합니다. 해당 작업 정의를 사용하여 서비스를 
생성합니다. 
D. 50GB 가 넘는 공간을 가진 Amazon Elastic Block Store(Amazon EBS) 볼륨과 함께 
Amazon EC2 시작 유형을 사용하는 Amazon Elastic Container Service(Amazon ECS) 
클러스터를 생성합니다. 컨테이너 이미지에 대한 작업 정의를 생성합니다. 해당 작업 
정의를 사용하여 서비스를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132950-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Fargate 시작 유형은 기본 인프라를 관리할 필요 없이 Amazon ECS 에서 컨테이너를 
실행하는 서버리스 방식입니다. 컨테이너를 실행하는 데 필요한 리소스에 대해서만 비용을 
지불하면 AWS 가 클러스터의 프로비저닝, 확장 및 보안을 처리합니다. Amazon EFS 는 여러 
컨테이너에 탑재할 수 있고 높은 가용성과 내구성을 제공하는 탄력적이고 확장 가능한 완전 
관리형 파일 시스템입니다. AWS Fargate 및 Amazon EFS 를 사용하면 운영 오버헤드를 
최소화하면서 임시 파일에 사용할 수 있는 50GB 의 스토리지로 Docker 컨테이너 이미지를 
실행할 수 있습니다. 이 솔루션은 질문의 요구 사항을 충족합니다. 
Q761 
회사는 온프레미스 LDAP 디렉터리 서비스를 사용하여 AWS Management Console 에 
사용자를 인증해야 합니다. 디렉터리 서비스는 SAML(Security Assertion Markup 
Language)과 호환되지 않습니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS 와 온프레미스 LDAP 간에 AWS IAM Identity Center(AWS Single Sign-On)를 
활성화합니다. 
B. AWS 자격 증명을 사용하는 IAM 정책을 생성하고 정책을 LDAP 에 통합합니다. 
C. LDAP 자격 증명이 업데이트될 때마다 IAM 자격 증명을 교체하는 프로세스를 
설정합니다. 
D. AWS Security Token Service(AWS STS)를 사용하여 단기 자격 증명을 얻는 온프레미스 
사용자 지정 자격 증명 브로커 애플리케이션 또는 프로세스를 개발합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/133326-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
요구 사항을 충족하는 솔루션은 AWS Security Token Service(AWS STS)를 사용하여 단기 
자격 증명을 얻는 온프레미스 사용자 지정 자격 증명 브로커 애플리케이션 또는 프로세스를 
개발하는 것입니다. 이 솔루션을 사용하면 회사는 SAML 호환성 없이도 기존 LDAP 
디렉터리 서비스를 사용하여 AWS Management Console 에 사용자를 인증할 수 있습니다. 
사용자 지정 자격 증명 브로커 애플리케이션 또는 프로세스는 LDAP 디렉터리 서비스와 
AWS STS 간의 프록시 역할을 할 수 있으며 LDAP 속성 및 역할을 기반으로 사용자에 대한 
임시 보안 자격 증명을 요청할 수 있습니다. 그런 다음 사용자는 이러한 자격 증명을 
사용하여 자격 증명 브로커가 생성한 로그인 URL 을 통해 AWS Management Console 에 
액세스할 수 있습니다. 또한 이 솔루션은 지정된 기간 후에 만료되는 단기 자격 증명을 
사용하여 보안을 강화합니다. 
다른 솔루션은 SAML 호환성이 필요하거나 AWS Management Console 에 대한 액세스를 
제공하지 않기 때문에 요구 사항을 충족하지 않습니다. AWS 와 온프레미스 LDAP 간에 
AWS IAM Identity Center(AWS Single Sign-On)를 활성화하려면 SAML 2.0 을 지원하는 LDAP 
디렉터리 서비스가 필요하지만 이 시나리오에서는 그렇지 않습니다. AWS 자격 증명을 
사용하는 IAM 정책을 생성하고 정책을 LDAP 에 통합하면 AWS Management Console 에 
대한 액세스가 제공되지 않고 AWS API 에만 액세스할 수 있습니다. LDAP 자격 증명이 
업데이트될 때마다 IAM 자격 증명을 교체하는 프로세스를 설정하면 AWS Management 
콘솔에 대한 액세스가 제공되지 않고 AWS CLI 에만 액세스할 수 있습니다. 따라서 이러한 
솔루션은 주어진 요구 사항에 적합하지 않습니다. 
Q762 
회사는 Amazon EC2 인스턴스를 시작하기 위해 AWS 계정에 여러 Amazon 머신 
이미지(AMI)를 저장합니다. AMI 에는 회사 운영에 필요한 중요한 데이터와 구성이 포함되어 
있습니다. 회사는 실수로 삭제된 AMI 를 빠르고 효율적으로 복구하는 솔루션을 구현하려고 
합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AMI 의 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. 스냅샷을 별도의 
AWS 계정에 저장합니다. 
B. 모든 AMI 를 주기적으로 다른 AWS 계정에 복사합니다. 
C. 휴지통 보관규칙을 생성합니다. 
D. 교차 지역 복제 기능이 있는 Amazon S3 버킷에 AMI 를 업로드합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132951-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Snowball 은 보안 장치를 사용하여 AWS 클라우드 안팎으로 대량의 데이터를 전송하는 
페타바이트 규모의 데이터 전송 서비스입니다. Snowball 은 높은 네트워크 비용, 긴 전송 
시간, 보안 문제 등 대규모 데이터 전송과 관련된 일반적인 문제를 해결합니다. AWS 
Snowball 은 디바이스당 최대 80TB 의 데이터를 전송할 수 있으며, 마이그레이션 기한을 
맞추기 위해 여러 디바이스를 병렬로 사용할 수 있습니다. AWS Snowball 은 엑사바이트 
규모의 데이터 전송을 위해 설계된 AWS Snowmobile 이나 장거리의 빠른 전송에 최적화된 
Amazon S3 Transfer Acceleration 보다 비용 효율적입니다. Amazon S3 VPC 엔드포인트는 
업로드 속도를 높이지 않지만 VPC 와 S3 간의 안전한 비공개 연결만 제공합니다. 
Q763 
회사는 Amazon EC2 인스턴스를 시작하기 위해 AWS 계정에 여러 Amazon 머신 
이미지(AMI)를 저장합니다. AMI 에는 회사 운영에 필요한 중요한 데이터와 구성이 포함되어 
있습니다. 회사는 실수로 삭제된 AMI 를 빠르고 효율적으로 복구하는 솔루션을 구현하려고 
합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AMI 의 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. 스냅샷을 별도의 
AWS 계정에 저장합니다. 
B. 모든 AMI 를 주기적으로 다른 AWS 계정에 복사합니다. 
C. 휴지통 보관규칙을 생성합니다. 
D. 교차 지역 복제 기능이 있는 Amazon S3 버킷에 AMI 를 업로드합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132952-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
휴지통은 실수로 삭제된 Amazon EBS 스냅샷 및 EBS 지원 AMI 를 복원할 수 있는 데이터 
복구 기능입니다. 휴지통을 사용할 때 리소스가 삭제되면 해당 리소스는 영구적으로 
삭제되기 전에 지정한 기간 동안 휴지통에 보관됩니다. 보존 기간이 만료되기 전에 
언제든지 휴지통에서 리소스를 복원할 수 있습니다. 이 솔루션은 추가 리소스를 생성, 복사 
또는 업로드할 필요가 없으므로 운영 오버헤드가 가장 적습니다. 휴지통에서 AMI 에 대한 
태그와 권한을 관리할 수도 있습니다. 휴지통에 있는 AMI 에는 추가 비용이 발생하지 
않습니다. 
Q764 
회사는 3 계층 애플리케이션을 온프레미스에서 AWS 로 마이그레이션하려고 합니다. 웹 
계층과 애플리케이션 계층은 타사 VM(가상 머신)에서 실행됩니다. 데이터베이스 계층은 
MySQL 에서 실행됩니다. 
회사는 아키텍처를 최소한으로 변경하여 애플리케이션을 마이그레이션해야 합니다. 또한 
회사에는 데이터를 특정 시점으로 복원할 수 있는 데이터베이스 솔루션이 필요합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 웹 계층과 애플리케이션 계층을 프라이빗 서브넷의 Amazon EC2 인스턴스로 
마이그레이션합니다. 데이터베이스 계층을 프라이빗 서브넷의 MySQL 용 Amazon RDS 로 
마이그레이션합니다. 
B. 웹 계층을 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 애플리케이션 
계층을 프라이빗 서브넷의 EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 
프라이빗 서브넷의 Amazon Aurora MySQL 로 마이그레이션합니다. 
C. 웹 계층을 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 애플리케이션 
계층을 프라이빗 서브넷의 EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 
프라이빗 서브넷의 MySQL 용 Amazon RDS 로 마이그레이션합니다. 
D. 웹 계층과 애플리케이션 계층을 퍼블릭 서브넷의 Amazon EC2 인스턴스로 
마이그레이션합니다. 데이터베이스 계층을 퍼블릭 서브넷의 Amazon Aurora MySQL 로 
마이그레이션합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132954-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q765 
개발팀이 다른 회사와 협력하여 통합 제품을 만들고 있습니다. 다른 회사는 개발 팀의 
계정에 포함된 Amazon Simple Queue Service(Amazon SQS) 대기열에 액세스해야 합니다. 
다른 회사는 자신의 계정 권한을 포기하지 않고 대기열을 폴링하려고 합니다. 
솔루션 설계자는 SQS 대기열에 대한 액세스를 어떻게 제공해야 합니까? 
A. 다른 회사에 SQS 대기열에 대한 액세스를 제공하는 인스턴스 프로필을 생성합니다. 
B. SQS 대기열에 대한 다른 회사 액세스를 제공하는 IAM 정책을 생성합니다. 
C. SQS 대기열에 대한 다른 회사 액세스를 제공하는 SQS 액세스 정책을 만듭니다. 
D. 다른 회사에 SQS 대기열에 대한 액세스를 제공하는 Amazon Simple 알림 
서비스(Amazon SNS) 액세스 정책을 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132956-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
자체 계정 권한을 포기하지 않고 다른 회사에 SQS 대기열에 대한 액세스를 제공하려면 
솔루션 설계자는 SQS 대기열에 대한 다른 회사 액세스를 제공하는 SQS 액세스 정책을 
생성해야 합니다. SQS 액세스 정책은 대기열에 액세스할 수 있는 사람과 그들이 수행할 수 
있는 작업을 정의하는 리소스 기반 정책입니다. 정책은 상대 회사의 AWS 계정 ID 를 
주체로 지정하고 sqs:ReceiveMessage, sqs:DeleteMessage 및 sqs:GetQueueAttributes 와 
같은 작업에 대한 권한을 부여할 수 있습니다. 이렇게 하면 다른 회사가 역할을 맡거나 
교차 계정 액세스 키를 사용할 필요 없이 자체 자격 증명을 사용하여 대기열을 폴링할 수 
있습니다. 
Q766 
한 회사의 개발자는 최신 버전의 Amazon Linux 를 실행하는 회사의 Amazon EC2 
인스턴스에 대해 SSH 액세스를 얻을 수 있는 안전한 방법을 원합니다. 개발자는 원격으로 
회사 사무실에서 작업합니다. 
회사는 AWS 서비스를 솔루션의 일부로 사용하려고 합니다. EC2 인스턴스는 VPC 프라이빗 
서브넷에서 호스팅되며 퍼블릭 서브넷에 배포된 NAT 게이트웨이를 통해 인터넷에 
액세스합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하려면 솔루션 설계자가 무엇을 해야 
합니까? 
A. EC2 인스턴스와 동일한 서브넷에 배스천 호스트를 생성합니다. 개발자에게 
ec2:CreateVpnConnection IAM 권한을 부여합니다. 개발자가 EC2 인스턴스에 연결할 수 
있도록 EC2 Instance Connect 를 설치합니다. 
B. 회사 네트워크와 VPC 사이에 AWS Site-to-Site VPN 연결을 생성합니다. 개발자가 회사 
네트워크에 있을 때 Site-to-Site VPN 연결을 사용하여 EC2 인스턴스에 액세스하도록 
개발자에게 지시하십시오. 개발자에게 원격으로 작업할 때 액세스를 위해 다른 VPN 연결을 
설정하도록 지시하십시오. 
C. VPC 의 퍼블릭 서브넷에 배스천 호스트를 생성합니다. 개발자의 회사 및 원격 
네트워크의 연결 및 SSH 인증만 허용하도록 배스천 호스트의 보안 그룹과 SSH 키를 
구성합니다. 개발자에게 SSH 를 사용하여 배스천 호스트를 통해 연결하여 EC2 인스턴스에 
연결하도록 지시합니다. 
D. AmazonSSMManagedInstanceCore IAM 정책을 EC2 인스턴스와 연결된 IAM 역할에 
연결합니다. 개발자에게 AWS Systems Manager Session Manager 를 사용하여 EC2 
인스턴스에 액세스하도록 지시합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/132957-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Systems Manager Session Manager 는 SSH 키나 배스천 호스트를 사용하지 않고도 
EC2 인스턴스에 `안전하게 연결할 수 있게 해주는 서비스입니다. Session Manager 를 
사용하면 AWS Management Console, AWS CLI 또는 AWS SDK 를 통해 인스턴스에 
액세스할 수 있습니다. Session Manager 는 IAM 정책과 역할을 사용하여 누가 어떤 
인스턴스에 액세스할 수 있는지 제어합니다. AmazonSSMManagedlnstanceCore IAM 정책을 
EC2 인스턴스와 연결된 IAM 역할에 연결하면 Session Manager 서비스에 인스턴스에 대한 
작업을 수행하는 데 필요한 권한을 부여할 수 있습니다. 또한 개발자가 인스턴스에 대한 
세션을 시작할 수 있도록 허용하는 다른 IAM 정책을 개발자의 IAM 사용자 또는 역할에 
연결해야 합니다. Session Manager 는 Amazon Linux 2 및 기타 지원되는 Linux 배포판에 
기본적으로 설치되는 AWS Systems Manager 에이전트(SSM 에이전트)를 사용합니다. 또한 
Session Manager 는 클라이언트와 인스턴스 간의 모든 세션 데이터를 암호화하고 감사 
목적으로 세션 로그를 Amazon S3, Amazon CloudWatch Logs 또는 둘 다로 스트리밍합니다. 
이 솔루션은 배스천 호스트, VPN 연결 또는 NAT 게이트웨이와 같은 추가 리소스나 
서비스가 필요하지 않으므로 가장 비용 효율적입니다. 또한 SSH 키, 포트 열기 또는 
방화벽 규칙이 필요하지 않으므로 SSH 액세스의 보안 및 관리가 단순화됩니다. 
Q767 
한 제약회사에서 신약을 개발하고 있습니다. 지난 몇 달 동안 회사에서 생성되는 데이터의 
양이 기하급수적으로 증가했습니다. 회사의 연구원들은 최소한의 지연으로 즉시 사용할 수 
있도록 전체 데이터 세트의 하위 집합을 정기적으로 요구합니다. 그러나 전체 데이터 
세트에 매일 액세스할 필요는 없습니다. 현재 모든 데이터는 온프레미스 스토리지 어레이에 
상주하고 있으며 회사는 지속적인 자본 비용을 줄이고 싶어합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 스토리지 솔루션을 권장해야 
합니까? 
A. AWS DataSync 를 예약된 cron 작업으로 실행하여 지속적으로 데이터를 Amazon S3 
버킷으로 마이그레이션합니다. 
B. Amazon S3 버킷을 대상 스토리지로 사용하여 AWS Storage Gateway 파일 게이트웨이를 
배포합니다. 데이터를 Storage Gateway 어플라이언스로 마이그레이션합니다. 
C. Amazon S3 버킷을 대상 스토리지로 사용하여 캐시된 볼륨이 있는 AWS Storage 
Gateway 볼륨 게이트웨이를 배포합니다. 데이터를 Storage Gateway 어플라이언스로 
마이그레이션합니다. 
D. 온프레미스 환경에서 AWS 로 AWS Site-to-Site VPN 연결을 구성합니다. Amazon Elastic 
File System(Amazon EFS) 파일 시스템으로 데이터를 마이그레이션합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132996-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Storage Gateway 는 온프레미스 애플리케이션을 AWS 클라우드 스토리지와 원활하게 
통합할 수 있는 하이브리드 클라우드 스토리지 서비스입니다. 볼륨 게이트웨이는 
온프레미스 애플리케이션에 클라우드 지원 iSCSI 블록 스토리지 볼륨을 제공하는 스토리지 
게이트웨이 유형입니다. 볼륨 게이트웨이는 캐시 모드 또는 저장 모드에서 작동합니다. 
캐시 모드에서는 기본 데이터가 Amazon S3 에 저장되는 동시에 자주 액세스하는 데이터는 
짧은 지연 시간 액세스를 위해 캐시에 로컬로 보관됩니다. 저장 모드에서는 기본 데이터가 
로컬에 저장되고, 전체 데이터 세트를 온프레미스에서 짧은 지연 시간으로 액세스하는 
동시에 Amazon S3 에 비동기식으로 백업할 수 있습니다. 
제약 회사의 사용 사례에서는 캐시 모드가 다음 요구 사항을 충족하므로 가장 적합한 
옵션입니다. 
대부분의 데이터가 확장 가능하고 내구성이 뛰어나며 비용 효율적인 Amazon S3 에 
저장되므로 온프레미스 스토리지 인프라를 확장할 필요성이 줄어듭니다. 
이는 Storage Gateway 어플라이언스에 로컬로 캐시되므로 연구자가 정기적으로 필요로 
하는 데이터 하위 집합에 대한 짧은 대기 시간 액세스를 제공합니다. 
전체 데이터세트는 Amazon S3 에 저장되어 있고 요청 시 검색할 수 있으므로 매일 
액세스할 필요가 없습니다. 
이는 AWS 에 Amazon EBS 스냅샷으로 저장되는 AWS Backup 을 사용하여 볼륨의 특정 
시점 복사본을 만들 수 있으므로 유연한 데이터 보호 및 복구 옵션을 제공합니다. 
따라서 솔루션 설계자는 Amazon S3 버킷을 대상 스토리지로 사용하여 캐시된 볼륨이 있는 
AWS Storage Gateway 볼륨 게이트웨이를 배포하고 
Q768 
회사에는 Amazon EC2 인스턴스에서 실행되는 비즈니스에 중요한 애플리케이션이 있습니다. 
애플리케이션은 Amazon DynamoDB 테이블에 데이터를 저장합니다. 회사는 지난 24 시간 
내의 어느 시점으로든 테이블을 되돌릴 수 있어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 테이블에 대한 특정 시점 복구를 구성합니다. 
B. 테이블에 AWS Backup 을 사용하십시오. 
C. AWS Lambda 함수를 사용하여 매시간 테이블의 주문형 백업을 만듭니다. 
D. 테이블에서 스트림을 켜서 지난 24 시간 동안 테이블에 대한 모든 변경 사항에 대한 
로그를 캡처합니다. Amazon S3 버킷에 스트림 복사본을 저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/132960-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
DynamoDB 의 특정 시점 복구(PITR)는 지난 35 일 동안의 특정 시점으로 테이블 데이터를 
복원할 수 있는 기능입니다. PITR 은 프로덕션 테이블에 테스트 스크립트를 작성하거나 
사용자가 잘못된 명령을 실행하는 등 실수로 쓰기 또는 삭제 작업을 수행하지 않도록 
테이블을 보호하는 데 도움이 됩니다. PITR 은 사용하기 쉽고, 완벽하게 관리되며, 빠르고, 
확장 가능합니다. DynamoDB 콘솔에서 한 번의 클릭이나 간단한 API 호출을 통해 PITR 을 
활성화할 수 있습니다. 콘솔, AWS CLI 또는 DynamoDB API 를 사용하여 테이블을 새 
테이블로 복원할 수 있습니다. 
PITR 은 프로비저닝된 테이블 용량을 소비하지 않으며 프로덕션 애플리케이션의 성능이나 
가용성에 영향을 주지 않습니다. PITR 은 수동 백업 생성, 예약 또는 유지 관리가 필요하지 
않으므로 최소한의 운영 오버헤드로 회사의 요구 사항을 충족합니다. 또한 지난 24 시간 
내의 어느 시점으로든 테이블을 복원하기 위한 초당 세분성을 제공합니다. 
Q769 
한 회사가 Amazon S3 버킷에 파일을 업로드하는 데 사용되는 애플리케이션을 
호스팅합니다. 업로드되면 파일을 처리하여 메타데이터를 추출하는데, 이 작업에는 5 초도 
채 걸리지 않습니다. 업로드의 양과 빈도는 매 시간 몇 개의 파일부터 수백 개의 동시 
업로드까지 다양합니다. 회사는 솔루션 설계자에게 이러한 요구 사항을 충족할 수 있는 
비용 효율적인 아키텍처를 설계하도록 요청했습니다. 
솔루션 설계자는 무엇을 추천해야 합니까? 
A. S3 API 호출을 기록하도록 AWS CloudTrail 추적을 구성합니다. AWS AppSync 를 
사용하여 파일을 처리합니다. 
B. 파일을 처리하기 위해 AWS Lambda 함수를 호출하도록 S3 버킷 내에서 객체 생성 
이벤트 알림을 구성합니다. 
C. 데이터를 처리하고 Amazon S3 로 전송하도록 Amazon Kinesis Data Streams 를 
구성합니다. AWS Lambda 함수를 호출하여 파일을 처리합니다. 
D. Amazon S3 에 업로드된 파일을 처리하도록 Amazon Simple 알림 서비스(Amazon SNS) 
주제를 구성합니다. AWS Lambda 함수를 호출하여 파일을 처리합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/132997-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 S3 에 업로드된 파일을 처리하는 가장 비용 효율적이고 확장 가능한 방법입니다. 
AWS CloudTrail 은 API 호출을 기반으로 작업을 트리거하는 것이 아니라 API 호출을 
기록하는 데 사용됩니다. AWS AppSync 는 파일 처리가 아닌 GraphQL API 구축을 위한 
서비스입니다. Amazon Kinesis Data Streams 는 S3 로 데이터를 보내는 것이 아니라 
스트리밍 데이터를 수집하고 처리하는 데 사용됩니다. Amazon SNS 는 파일을 처리하는 
것이 아니라 구독자에게 이벤트를 알리는 데 사용할 수 있는 게시/구독 서비스입니다. 
Q770 
회사의 애플리케이션은 Amazon EC2 인스턴스에 배포되고 이벤트 기반 아키텍처에 AWS 
Lambda 기능을 사용합니다. 회사는 기능을 프로덕션에 배포하기 전에 다른 AWS 계정의 
비프로덕션 개발 환경을 사용하여 새로운 기능을 테스트합니다. 
프로덕션 인스턴스는 시간대가 다른 고객으로 인해 지속적인 사용량을 보여줍니다. 회사는 
평일 업무 시간에만 비프로덕션 인스턴스를 사용합니다. 회사는 주말에 비프로덕션 
인스턴스를 사용하지 않습니다. 회사는 AWS 에서 애플리케이션을 실행하는 데 드는 비용을 
최적화하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 프로덕션 인스턴스에는 온디맨드 인스턴스를 사용하십시오. 주말에만 비프로덕션 
인스턴스에 전용 호스트를 사용하세요. 
B. 프로덕션 인스턴스와 비프로덕션 인스턴스에 예약 인스턴스를 사용합니다. 사용하지 
않을 때는 비프로덕션 인스턴스를 종료합니다. 
C. 프로덕션 인스턴스에는 Compute Savings Plan 을 사용하십시오. 비프로덕션 
인스턴스에는 온디맨드 인스턴스를 사용합니다. 사용하지 않을 때는 비프로덕션 인스턴스를 
종료합니다. 
D. 프로덕션 인스턴스에는 전용 호스트를 사용하십시오. 비프로덕션 인스턴스에는 EC2 
Instance Savings Plans 를 사용하세요. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132998-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Compute Savings Plans 는 EC2 와 AWS Lambda 사용 모두에 상당한 절감(최대 66%)을 
제공하는 동시에 인스턴스 패밀리 유형, 크기, 심지어 지역에 대한 유연성을 허용하기 
때문에 프로덕션 인스턴스에 가장 유연하고 비용 효율적인 솔루션을 제공합니다. 
비프로덕션 인스턴스의 경우 On-Demand Instances 를 사용하면 인스턴스가 실행 중일 
때만 비용을 지불하고, 업무 시간 외에 종료하면 비용을 더욱 최적화할 수 있습니다. 
주요 AWS 기능: 
* Compute Savings Plans: 일관된 사용에 따라 절감을 제공하므로 부하가 안정적인 
프로덕션 환경에 이상적입니다. 
* On-Demand Instances: 간헐적으로 사용되는 비프로덕션 환경에 적합합니다. 
사용하지 않을 때 종료하면 불필요한 비용을 피할 수 있습니다. 
* AWS 설명서: AWS 의 비용 최적화 모범 사례에 따르면 프로덕션에는 Savings Plans 를 
사용하고 비프로덕션 환경에는 On-Demand Instances 를 아껴서 사용하면 최적의 비용 
절감 효과를 얻을 수 있습니다. 
Q771 
회사는 온프레미스 Oracle 관계형 데이터베이스에 데이터를 저장합니다. 회사는 분석을 
위해 Amazon Aurora PostgreSQL 에서 데이터를 사용할 수 있도록 해야 합니다. 회사는 
AWS Site-to-Site VPN 연결을 사용하여 온프레미스 네트워크를 AWS 에 연결합니다. 
회사는 Aurora PostgreSQL 로 마이그레이션하는 동안 소스 데이터베이스에 발생하는 변경 
사항을 캡처해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS SCT(AWS Schema Conversion Tool)를 사용하여 Oracle 스키마를 Aurora 
PostgreSQL 스키마로 변환합니다. AWS Database Migration Service(AWS DMS) 전체 로드 
마이그레이션 작업을 사용하여 데이터를 마이그레이션합니다. 
B. AWS DataSync 를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. Aurora 
PostgreSQL aws_s3 확장을 사용하여 S3 데이터를 Aurora PostgreSQL 로 가져옵니다. 
C. AWS Schema Conversion Tool(AWS SCT)을 사용하여 Oracle 스키마를 Aurora 
PostgreSQL 스키마로 변환합니다. AWS Database Migration Service(AWS DMS)를 사용하여 
기존 데이터를 마이그레이션하고 지속적인 변경 사항을 복제합니다. 
D. AWS Snowball 장치를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. 
Aurora PostgreSQL aws_s3 확장을 사용하여 S3 데이터를 Aurora PostgreSQL 로 
가져옵니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/132999-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
온프레미스 Oracle 데이터베이스에서 Amazon Aurora PostgreSQL 로 데이터를 
마이그레이션하는 경우 이 솔루션은 스키마 변환, 데이터 마이그레이션 및 진행 중인 
데이터 복제를 효과적으로 처리합니다. 
AWS 스키마 변환 도구(SCT): SCT 는 Oracle 데이터베이스 스키마를 Aurora PostgreSQL 과 
호환되는 형식으로 변환하는 데 사용됩니다. 이 도구는 데이터베이스 스키마와 저장 
프로시저와 같은 코드 객체를 대상 데이터베이스 엔진으로 자동으로 변환합니다. 
AWS 데이터베이스 마이그레이션 서비스(DMS): DMS 는 데이터 마이그레이션을 수행하는 데 
사용됩니다. 전체 로드 마이그레이션(초기 데이터 전송용)과 진행 중인 변경 사항의 
지속적인 복제(변경 데이터 캡처 또는 CDC)를 모두 지원합니다. 이를 통해 마이그레이션 
중에 Oracle 데이터베이스에 대한 모든 업데이트가 캡처되어 Aurora PostgreSQL 
데이터베이스에 적용되어 다운타임이 최소화됩니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(SCT + DMS 전체 로드만): 이 옵션은 진행 중인 변경 사항을 캡처하지 않으며, 이는 
데이터 일관성을 보장하기 위해 라이브 데이터베이스 마이그레이션에 필수적입니다. 
옵션 B(DataSync + S3): AWS DataSync 는 데이터베이스 마이그레이션보다는 파일 전송에 
더 적합하며, 지속적인 변경 복제를 지원하지 않습니다. 
옵션 D(Snowball + S3): Snowball 은 일반적으로 지속적인 동기화가 필요하지 않은 대규모 
데이터 전송에 사용되므로 지속적인 변경을 캡처해야 하는 이 시나리오에는 적합하지 
않습니다. 
Q772 
한 회사가 Docker 컨테이너를 사용하여 애플리케이션을 구축했으며 AWS 클라우드에서 
애플리케이션을 실행해야 합니다. 회사는 관리형 서비스를 사용하여 애플리케이션을 
호스팅하려고 합니다. 
솔루션은 개별 컨테이너 서비스에 대한 수요에 따라 적절하게 확장 및 축소되어야 합니다. 
또한 솔루션으로 인해 추가적인 운영 오버헤드나 관리해야 할 인프라가 발생해서는 안 
됩니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? (2 개 선택) 
A. AWS Fargate 와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용하십시오. 
B. AWS Fargate 와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하십시오. 
C. Amazon API Gateway API 를 프로비저닝합니다. API 를 AWS Lambda 에 연결하여 
컨테이너를 실행합니다. 
D. Amazon EC2 작업자 노드와 함께 Amazon Elastic Container Service(Amazon ECS)를 
사용하십시오. 
E. Amazon EC2 작업자 노드와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 
사용합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/133002-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이러한 옵션은 회사가 자동으로 확장되고 관리하는 데 인프라가 필요하지 않은 관리형 
서비스를 사용하여 AWS 클라우드에서 Docker 컨테이너로 애플리케이션을 실행할 수 있게 
해주기 때문에 최고의 솔루션입니다. AWS Fargate 를 사용하면 회사는 EC2 인스턴스 
클러스터를 프로비저닝, 구성 또는 확장할 필요 없이 컨테이너를 시작하고 실행할 수 
있습니다. Fargate 는 각 컨테이너에 적절한 양의 컴퓨팅 리소스를 할당하고 필요에 따라 
확장하거나 축소합니다. Amazon ECS 또는 Amazon EKS 를 사용하여 회사는 필요에 맞는 
컨테이너 오케스트레이션 플랫폼을 선택할 수 있습니다. Amazon ECS 는 다른 AWS 
서비스와 통합되고 컨테이너 배포 및 관리를 단순화하는 완전관리형 서비스입니다. Amazon 
EKS는 AWS에서 Kubernetes를 실행하고 기존 Kubernetes 도구 및 플러그인과의 호환성을 
제공하는 관리형 서비스입니다. 
C: Amazon API Gateway API 프로비저닝 API 를 AWS Lambda 에 연결하여 컨테이너를 
실행합니다. AWS Lambda 는 Docker 컨테이너 직접 실행을 지원하지 않기 때문에 이 
옵션은 실현 가능하지 않습니다. Lambda 함수는 다른 함수 및 리소스와 격리된 샌드박스 
환경에서 실행됩니다. Lambda 에서 Docker 컨테이너를 실행하려면 회사는 Docker API 를 
에뮬레이션하는 사용자 지정 런타임이나 래퍼 라이브러리를 사용해야 하며 이로 인해 
추가적인 복잡성과 오버헤드가 발생할 수 있습니다. 
D: Amazon EC2 작업자 노드와 함께 Amazon Elastic Container Service(Amazon ECS)를 
사용합니다. 
이 옵션은 회사가 컨테이너를 호스팅하는 EC2 인스턴스를 관리해야 하기 때문에 최적이 
아닙니다. 회사는 EC2 인스턴스를 프로비저닝, 구성, 확장, 패치 및 모니터링해야 하므로 
운영 오버헤드와 인프라 비용이 증가할 수 있습니다. 
E: Amazon EC2 작업자 노드와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 
사용하십시오. 
이 옵션은 회사가 컨테이너를 호스팅하는 EC2 인스턴스를 관리해야 하기 때문에 
이상적이지 않습니다. 회사는 EC2 인스턴스를 프로비저닝, 구성, 확장, 패치 및 
모니터링해야 하므로 운영 오버헤드와 인프라 비용이 증가할 수 있습니다. 
Q773 
전자상거래 회사에서 계절별 온라인 세일을 진행하고 있습니다. 이 회사는 여러 가용 
영역에 걸쳐 있는 Amazon EC2 인스턴스에서 웹 사이트를 호스팅합니다. 회사는 자사 
웹사이트에서 세일 기간 동안 급격한 트래픽 증가를 관리할 수 있기를 원합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 최대 트래픽 로드를 처리할 수 있을 만큼 큰 Auto Scaling 그룹을 생성합니다. Amazon 
EC2 인스턴스의 절반을 중지합니다. 트래픽이 증가하면 중지된 인스턴스를 사용하여 
확장하도록 Auto Scaling 그룹을 구성합니다. 
B. 웹 사이트에 대한 Auto Scaling 그룹을 생성합니다. 확장할 필요 없이 높은 트래픽 
볼륨을 처리할 수 있도록 Auto Scaling 그룹의 최소 크기를 설정합니다. 
C. Amazon CloudFront 및 Amazon ElastiCache 를 사용하여 Auto Scaling 그룹이 원본으로 
설정된 동적 콘텐츠를 캐시합니다. CloudFront 및 ElastiCache 를 채우는 데 필요한 
인스턴스로 Auto Scaling 그룹을 구성합니다. 캐시가 완전히 채워진 후 규모를 축소합니다. 
D. 트래픽 증가에 따라 확장되도록 Auto Scaling 그룹을 구성합니다. 사전 구성된 Amazon 
머신 이미지(AMI)에서 새 인스턴스를 시작하기 위한 시작 템플릿을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/133004-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q774 
솔루션 설계자는 보안 그룹이 0.0.0.0/0 의 SSH 를 허용하는 규칙을 포함할 수 없다고 
명시하는 회사의 규정 준수 정책에 대한 자동화된 솔루션을 제공해야 합니다. 정책을 
위반한 경우 회사에 통보해야 합니다. 가능한 한 빨리 해결책이 필요합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 
합니까? 
A. 0.0.0.0/0 주소에 열려 있는 SSH 에 대한 보안 그룹을 모니터링하고 이를 발견할 때마다 
알림을 생성하는 AWS Lambda 스크립트를 작성합니다. 
B. 제한된 SSH AWS Config 관리형 규칙을 활성화하고 비준수 규칙이 생성되면 Amazon 
Simple 알림 서비스(Amazon SNS) 알림을 생성합니다. 
C. 전 세계적으로 보안 그룹 및 네트워크 ACL 을 열 수 있는 권한이 있는 IAM 역할을 
생성합니다. 사용자가 역할을 맡을 때마다 알림을 생성하려면 Amazon Simple 알림 
서비스(Amazon SNS) 주제를 생성합니다. 
D. 관리자가 아닌 사용자가 보안 그룹을 생성하거나 편집하는 것을 방지하는 서비스 제어 
정책(SCP)을 구성합니다. 사용자가 관리자 권한이 필요한 규칙을 요청할 때 티켓팅 
시스템에 알림을 만듭니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133006-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
회사의 규정 준수 정책에 가장 적합한 솔루션은 제한된 SSH AWS Config 관리형 규칙을 
활성화하고 비준수 규칙이 생성될 때 Amazon Simple 알림 서비스(Amazon SNS) 알림을 
생성하는 것입니다. 이 솔루션은 사용자가 AWS 리소스의 구성을 평가, 감사 및 평가할 수 
있는 서비스인 AWS Config 에서 이미 사용 가능한 사전 정의된 규칙을 사용하기 때문에 
운영 오버헤드가 가장 적습니다. 제한된 SSH 규칙은 사용 중인 보안 그룹에 0.0.0.0/0 
주소에서 SSH 를 허용하는 인바운드 규칙이 있는지 확인하고 이를 비준수로 보고합니다. 
사용자는 규정을 준수하지 않는 변경 사항이 발생할 때 Amazon SNS 주제에 알림을 
보내도록 규칙을 구성하고 주제를 구독하여 이메일, SMS 또는 기타 방법을 통해 알림을 
받을 수 있습니다. 
다른 옵션은 운영 오버헤드가 더 많거나 요구 사항을 충족하지 않기 때문에 올바르지 
않습니다. 0.0.0.0/0 주소에 열려 있는 SSH 에 대한 보안 그룹을 모니터링하고 잘못된 
주소를 발견할 때마다 알림을 생성하는 AWS Lambda 스크립트를 작성하려면 사용자 지정 
코드 개발 및 유지 관리가 필요하므로 솔루션에 복잡성과 비용이 추가됩니다. 전역적으로 
보안 그룹 및 네트워크 ACL 을 열 수 있는 권한이 있는 IAM 역할을 생성하고 사용자가 
역할을 맡을 때마다 알림을 생성하는 Amazon SNS 주제를 생성하는 것은 올바르지 
않습니다. 이는 비준수 규칙 생성을 방지하거나 감지하지 못하기 때문입니다. 다른 사용자 
또는 역할과 관련이 있으며 정책을 위반할 수 있는 기존 규칙을 다루지 않습니다. 관리자가 
아닌 사용자가 보안 그룹을 생성하거나 편집하는 것을 방지하는 서비스 제어 정책(SCP)을 
구성하고, 사용자가 관리자 권한이 필요한 규칙을 요청할 때 티켓팅 시스템에서 알림을 
생성하는 것은 자동화된 솔루션을 제공하지 않기 때문에 올바르지 않습니다. 정책 집행 및 
통지를 위해 사용자의 유연성과 생산성을 제한할 수 있습니다. 
Q775 
Amazon EC2 작업자 노드와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 
사용합니다. 
회사에서 AWS 계정에 애플리케이션을 배포했습니다. 애플리케이션은 AWS Lambda 및 
Amazon Elastic Kubernetes Service(Amazon EKS)에서 실행되는 마이크로서비스로 
구성됩니다. 별도의 팀이 각 마이크로서비스를 지원합니다. 회사에는 여러 개의 AWS 
계정이 있으며 각 팀에 마이크로서비스에 대한 자체 계정을 제공하려고 합니다. 
솔루션 설계자는 HTTPS(포트 443)를 통해 서비스 간 통신을 제공하는 솔루션을 설계해야 
합니다. 또한 솔루션은 서비스 검색을 위한 서비스 레지스트리를 제공해야 합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 검사 VPC를 생성합니다. 검사 VPC에 AWS 네트워크 방화벽 방화벽을 배포합니다. 검사 
VPC 를 새 전송 게이트웨이에 연결합니다. VPC 간 트래픽을 검사 VPC 로 라우팅합니다. 
HTTPS 통신만 허용하도록 방화벽 규칙을 적용합니다. 
B. VPC Lattice 서비스 네트워크를 생성합니다. 마이크로서비스를 서비스 네트워크와 
연결합니다. 각 서비스에 대해 HTTPS 수신기를 정의합니다. 마이크로서비스 컴퓨팅 
리소스를 대상으로 등록합니다. 서비스와 통신해야 하는 VPC 를 식별합니다. 해당 VPC 를 
서비스 네트워크와 연결합니다. 
C. 각 마이크로서비스에 대한 HTTPS 리스너 및 대상 그룹을 사용하여 NLB(Network Load 
Balancer)를 생성합니다. 각 마이크로서비스에 대한 AWS PrivateLink 엔드포인트 서비스를 
생성합니다. 해당 마이크로서비스를 사용해야 하는 각 VPC 에 인터페이스 VPC 
엔드포인트를 생성합니다. 
D. 마이크로서비스가 포함된 VPC 간에 피어링 연결을 생성합니다. 클라이언트에 연결해야 
하는 각 서비스에 대한 접두사 목록을 만듭니다. 적절한 VPC 로 트래픽을 라우팅하는 
라우팅 테이블을 생성합니다. HTTPS 통신만 허용하는 보안 그룹을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133007-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q776 
한 회사에 Amazon RDS DB 인스턴스에서 대부분의 메타데이터를 읽는 모바일 게임이 
있습니다. 게임의 인기가 높아짐에 따라 개발자들은 게임의 메타데이터 로드 시간과 관련된 
속도 저하를 발견했습니다. 성능 지표는 단순히 데이터베이스를 확장하는 것만으로는 
도움이 되지 않음을 나타냅니다. 솔루션 설계자는 스냅샷, 복제 및 밀리초 미만의 응답 
시간 기능을 포함하는 모든 옵션을 탐색해야 합니다. 
이러한 문제를 해결하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. Aurora 복제본을 사용하여 데이터베이스를 Amazon Aurora 로 마이그레이션하십시오. 
B. 글로벌 테이블을 사용하여 데이터베이스를 Amazon DynamoDB 로 마이그레이션합니다. 
C. 데이터베이스 앞에 Redis 용 Amazon ElastiCache 계층을 추가합니다. 
D. 데이터베이스 앞에 Memcached 용 Amazon ElastiCache 계층을 추가합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/133008-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 데이터베이스를 마이그레이션하지 않고 게임의 메타데이터 로드 시간을 
향상시키는 가장 적합한 방법입니다. Redis 용 Amazon ElastiCache 는 읽기 집약적인 
워크로드에 대해 밀리초 미만의 지연 시간과 높은 처리량을 제공하는 완전 관리형 인 
메모리 데이터 스토어입니다. 
이를 RDS DB 인스턴스 앞의 캐싱 계층으로 사용하여 자주 액세스하는 메타데이터를 
저장하고 데이터베이스의 로드를 줄일 수 있습니다. 또한 스냅샷, 복제, 데이터 지속성과 
같은 Redis 기능을 활용하여 데이터 내구성과 가용성을 보장할 수도 있습니다. Redis 용 
ElastiCache 는 수요에 맞게 자동으로 확장되며 CloudFormation, CloudWatch, IAM 등의 
다른 AWS 서비스와 통합됩니다. 
Aurora 복제본을 사용하여 데이터베이스를 Amazon Aurora 로 마이그레이션하면 추가 
비용과 복잡성이 발생하므로 옵션 A 는 최적이 아닙니다. Amazon Aurora 는 MySQL 및 
PostgreSQL 과의 고성능, 가용성 및 호환성을 제공하는 관계형 데이터베이스 서비스입니다. 
Aurora 복제본은 읽기 용량을 확장하고 가용성을 향상시키는 데 사용할 수 있는 기본 
데이터베이스의 읽기 전용 복사본입니다. 그러나 데이터베이스를 Aurora 로 
마이그레이션하려면 애플리케이션 코드 수정, 호환성 테스트 및 데이터 마이그레이션 
수행이 필요합니다. 또한 Aurora 복제본은 Redis 용 ElastiCache 처럼 밀리초 미만의 응답 
시간을 제공하지 못할 수도 있습니다. 
글로벌 테이블이 있는 Amazon DynamoDB 로 데이터베이스를 마이그레이션하면 추가 
비용과 복잡성이 발생하므로 옵션 B 는 최적이 아닙니다. Amazon DynamoDB 는 모든 
규모에 대해 빠르고 유연한 데이터 액세스를 제공하는 NoSQL 데이터베이스 서비스입니다. 
글로벌 테이블은 고가용성 및 성능을 위해 여러 AWS 리전에 걸쳐 데이터를 복제할 수 
있는 DynamoDB 의 기능입니다. 그러나 데이터베이스를 DynamoDB 로 마이그레이션하려면 
데이터 모델 변경, 애플리케이션 코드 수정, 데이터 마이그레이션 수행이 필요합니다. 또한 
글로벌 테이블은 주로 지역 간 데이터 액세스 및 재해 복구에 사용되므로 게임의 
메타데이터에 필요하지 않을 수 있습니다. 
데이터베이스 앞에 Memcached 용 Amazon ElastiCache 계층을 추가하면 Redis 용 
ElastiCache 와 동일한 기능을 제공하지 않으므로 옵션 D 는 최적이 아닙니다. 
Memcached 용 Amazon ElastiCache 는 캐싱 워크로드에 높은 성능과 확장성을 제공하는 또 
다른 완전관리형 인메모리 데이터 스토어입니다. 그러나 Memcached 는 스냅샷, 복제 또는 
데이터 지속성을 지원하지 않습니다. 즉, 노드 오류 또는 캐시 제거 시 캐시된 데이터가 
손실될 수 있습니다. 또한 Memcached 는 Redis 만큼 다른 AWS 서비스와 통합되지 
않습니다. 따라서 이 시나리오에는 Redis 용 ElastiCache 가 더 나은 선택입니다. 
Q777 
회사는 다중 계정 AWS 설정을 위해 AWS Organizations 를 사용합니다. 회사의 보안 조직 
단위(OU)는 승인된 Amazon 머신 이미지(AMI)를 개발 OU 와 공유해야 합니다. AMI 는 AWS 
Key Management Service(AWS KMS) 암호화된 스냅샷을 사용하여 생성됩니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? (2 개 선택) 
A. 개발 팀의 OU Amazon 리소스 이름(ARN)을 AMI 의 시작 권한 목록에 추가합니다. 
B. AMI 의 시작 권한 목록에 조직 루트 Amazon 리소스 이름(ARN)을 추가합니다. 
C. 개발 팀의 OU 가 스냅샷을 해독하는 데 사용되는 AWS KMS 키를 사용할 수 있도록 키 
정책을 업데이트합니다. 
D. 개발 팀의 계정 Amazon 리소스 이름(ARN)을 AMI 의 시작 권한 목록에 추가합니다. 
E. AWS KMS 키를 다시 생성합니다. 조직 루트 Amazon 리소스 이름(ARN)이 AWS KMS 
키를 사용할 수 있도록 키 정책을 추가합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/133009-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q778 
한 데이터 분석 회사에는 전 세계적으로 분산된 80 개의 사무실이 있습니다. 각 사무실은 
1PB 의 데이터를 호스팅하고 1~2Gbps 의 인터넷 대역폭을 보유합니다. 
회사는 사무실에서 Amazon S3 로 대량의 데이터를 일회성 마이그레이션해야 합니다. 
회사는 4 주 이내에 마이그레이션을 완료해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 각 사무실에 새로운 10Gbps AWS Direct Connect 연결을 설정합니다. 데이터를 Amazon 
S3 로 전송합니다. 
B. 여러 AWS Snowball Edge 스토리지 최적화 장치를 사용하여 데이터를 Amazon S3 에 
저장하고 전송합니다. 
C. AWS Snowmobile 을 사용하여 데이터를 Amazon S3 에 저장하고 전송합니다. 
D. 데이터를 Amazon S3 로 전송하도록 AWS Storage Gateway 볼륨 게이트웨이를 
설정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133010-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q779 
회사에는 참조 데이터 세트가 포함된 Amazon Elastic File System(Amazon EFS) 파일 
시스템이 있습니다. 회사에는 데이터 세트를 읽어야 하는 Amazon EC2 인스턴스에 
애플리케이션이 있습니다. 그러나 애플리케이션은 데이터 세트를 변경할 수 없어야 합니다. 
회사는 IAM 액세스 제어를 사용하여 애플리케이션이 데이터 세트를 수정하거나 삭제하지 
못하도록 방지하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. EC2 인스턴스 내에서 읽기 전용 모드로 EFS 파일 시스템을 탑재합니다. 
B. EC2 인스턴스에 연결된 IAM 역할에 대한 elasticfilesystem:ClientWrite 작업을 거부하는 
EFS 파일 시스템에 대한 리소스 정책을 생성합니다. 
C. EFS 파일 시스템에서 elasticfilesystem:ClientWrite 작업을 거부하는 EFS 파일 시스템에 
대한 ID 정책을 생성합니다. 
D. 각 애플리케이션에 대한 EFS 액세스 포인트를 생성합니다. POSIX(Portable Operating 
System Interface) 파일 권한을 사용하여 루트 디렉터리의 파일에 대한 읽기 전용 액세스를 
허용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133011-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q780 
회사에서 회사의 AWS 계정에서 작업을 수행하기 위해 외부 공급업체를 고용했습니다. 
공급업체는 공급업체가 소유한 AWS 계정에 호스팅된 자동화 도구를 사용합니다. 
공급업체는 회사의 AWS 계정에 대한 IAM 액세스 권한이 없습니다. 회사는 공급업체에 
회사의 AWS 계정에 대한 액세스 권한을 부여해야 합니다. 
이러한 요구 사항을 가장 안전하게 충족하는 솔루션은 무엇입니까? 
A. 공급업체의 IAM 역할에 대한 액세스 권한을 위임하려면 회사 계정에 IAM 역할을 
생성하세요. 공급업체에 필요한 권한에 대한 역할에 적절한 IAM 정책을 연결합니다. 
B. 회사 계정에 비밀번호 복잡성 요구 사항을 충족하는 비밀번호를 사용하여 IAM 사용자를 
생성합니다. 공급업체가 요구하는 권한에 대해 적절한 IAM 정책을 사용자에게 연결합니다. 
C. 회사 계정에 IAM 그룹을 생성합니다. 공급업체 계정의 자동화 도구 IAM 사용자를 
그룹에 추가합니다. 공급업체에 필요한 권한에 대해 적절한 IAM 정책을 그룹에 연결합니다. 
D. 공급업체 계정을 허용하는 권한 경계가 있는 회사 계정에 IAM 사용자를 생성합니다. 
공급업체가 요구하는 권한에 대해 적절한 IAM 정책을 사용자에게 연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/133014-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q781 
한 회사가 AWS 클라우드에서 실험적인 워크로드를 실행하려고 합니다. 회사에는 클라우드 
지출에 대한 예산이 있습니다. 회사의 CFO 는 각 부서의 클라우드 지출 책임에 대해 
우려하고 있습니다. CFO 는 지출 임계값이 예산의 60%에 도달하면 알림을 받기를 
원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS 리소스의 비용 할당 태그를 사용하여 소유자에게 레이블을 지정합니다. AWS 
예산에서 사용 예산을 생성합니다. 지출이 예산의 60%를 초과할 때 알림을 받을 수 있도록 
경고 임계값을 추가합니다. 
B. AWS Cost Explorer 예측을 사용하여 리소스 소유자를 결정합니다. AWS 비용 이상 
탐지를 사용하면 지출이 예산의 60%를 초과할 때 경고 임계값 알림을 생성할 수 있습니다. 
C. AWS 리소스의 비용 할당 태그를 사용하여 소유자에게 레이블을 지정합니다. AWS 
Trusted Advisor 의 AWS Support API 를 사용하면 지출이 예산의 60%를 초과할 때 경고 
임계값 알림을 생성할 수 있습니다. 
D. AWS Cost Explorer 예측을 사용하여 리소스 소유자를 결정합니다. AWS 예산에서 사용 
예산을 생성합니다. 지출이 예산의 60%를 초과할 때 알림을 받을 수 있도록 경고 임계값을 
추가합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/133015-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 비용 할당 태그를 사용하여 여러 부서에 비용을 할당하고, 사용 예산을 
생성하여 지출 한도를 설정하고, 지출이 특정 수준에 도달하면 알림을 받을 수 있도록 경고 
임계값을 추가함으로써 회사가 클라우드 지출을 추적 및 관리할 수 있도록 허용하므로 요구 
사항을 충족합니다. 예산의 비율. 이러한 방식으로 회사는 실험적인 워크로드를 
모니터링하고 클라우드에 대한 과도한 지출을 피할 수 있습니다. 
Q782 
회사에서 AWS 에 내부 웹 애플리케이션을 배포하려고 합니다. 웹 애플리케이션은 회사 
사무실에서만 액세스할 수 있어야 합니다. 회사는 인터넷에서 웹 애플리케이션용 보안 
패치를 다운로드해야 합니다. 
회사는 VPC 를 생성하고 회사 사무실에 대한 AWS Site-to-Site VPN 연결을 구성했습니다. 
솔루션 설계자는 웹 애플리케이션을 위한 보안 아키텍처를 설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 퍼블릭 ALB(Application Load Balancer) 뒤에 있는 퍼블릭 서브넷의 Amazon EC2 
인스턴스에 웹 애플리케이션을 배포합니다. 인터넷 게이트웨이를 VPC 에 연결합니다. ALB 
보안 그룹의 인바운드 소스를 0.0.0.0/0 으로 설정합니다. 
B. 내부 ALB(Application Load Balancer) 뒤에 있는 프라이빗 서브넷의 Amazon EC2 
인스턴스에 웹 애플리케이션을 배포합니다. 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다. 
인터넷 게이트웨이를 VPC 에 연결합니다. ALB 보안 그룹의 인바운드 소스를 회사의 사무실 
네트워크 CIDR 블록으로 설정합니다. 
C. 내부 ALB(Application Load Balancer) 뒤에 있는 퍼블릭 서브넷의 Amazon EC2 
인스턴스에 웹 애플리케이션을 배포합니다. 프라이빗 서브넷에 NAT 게이트웨이를 
배포합니다. VPS 에 인터넷 게이트웨이를 연결합니다. ALB 보안 그룹의 아웃바운드 대상을 
회사 사무실 네트워크 CIDR 블록으로 설정합니다. 
D. 퍼블릭 ALB(Application Load Balancer) 뒤에 있는 프라이빗 서브넷의 Amazon EC2 
인스턴스에 웹 애플리케이션을 배포합니다. 인터넷 게이트웨이를 VPC 에 연결합니다. ALB 
보안 그룹의 아웃바운드 대상을 0.0.0.0/0 으로 설정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133016-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q783 
회사는 Amazon EC2 인스턴스에서 실행되는 사용자 지정 애플리케이션에서 회계 기록을 
유지 관리합니다. 회사는 애플리케이션 데이터의 개발 및 유지 관리를 위해 데이터를 AWS 
관리형 서비스로 마이그레이션해야 합니다. 솔루션에는 최소한의 운영 지원이 필요하고 
데이터 변경 사항에 대해 변경할 수 없고 암호화 방식으로 검증 가능한 로그를 제공해야 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 애플리케이션의 레코드를 Amazon Redshift 클러스터에 복사합니다. 
B. 애플리케이션의 레코드를 Amazon Neptune 클러스터에 복사합니다. 
C. 애플리케이션의 레코드를 Amazon Timestream 데이터베이스로 복사합니다. 
D. 애플리케이션의 레코드를 Amazon Quantum Ledger Database(Amazon QLDB) 원장에 
복사합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/133018-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q784 
회사의 마케팅 데이터는 여러 소스에서 Amazon S3 버킷으로 업로드됩니다. 일련의 데이터 
준비 작업은 보고를 위해 데이터를 집계합니다. 데이터 준비 작업은 정기적인 간격으로 
병렬로 실행되어야 합니다. 나중에 특정 순서로 몇 가지 작업을 실행해야 합니다. 
회사는 작업 오류 처리, 재시도 논리 및 상태 관리의 운영 오버헤드를 제거하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터가 S3 버킷에 업로드되는 즉시 AWS Lambda 함수를 사용하여 데이터를 
처리합니다. 정기적으로 예약된 간격으로 다른 Lambda 함수를 호출합니다. 
B. Amazon Athena 를 사용하여 데이터를 처리합니다. Amazon EventBridge Scheduler 를 
사용하여 정기적인 내부에서 Athena 를 호출합니다. 
C. AWS Glue DataBrew 를 사용하여 데이터를 처리합니다. AWS Step Functions 상태 
시스템을 사용하여 DataBrew 데이터 준비 작업을 실행합니다. 
D. AWS Data Pipeline 을 사용하여 데이터를 처리합니다. 자정에 한 번 데이터를 처리하도록 
데이터 파이프라인을 예약합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/133019-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Glue DataBrew 는 코드를 작성하지 않고도 데이터를 쉽게 정리, 정규화 및 변환할 수 
있는 시각적 데이터 준비 도구입니다. Amazon S3, Amazon Redshift 또는 기타 데이터 
소스에 저장된 데이터에 대해 데이터 준비 작업을 생성하고 실행할 수 있습니다. 
AWS Step Functions 는 여러 AWS 서비스를 서버리스 워크플로로 조정할 수 있는 
서비스입니다. Step Functions 를 사용하여 DataBrew 작업을 조정하고, 실행 순서 및 병렬 
처리를 정의하고, 오류 및 재시도를 처리하고, 워크플로 상태를 모니터링할 수 있습니다. 
AWS Glue DataBrew 및 AWS Step Functions 를 사용하면 코드를 작성하거나 서버를 
관리하거나 복잡한 종속성을 처리할 필요가 없으므로 최소한의 운영 오버헤드로 회사의 
요구 사항을 충족할 수 있습니다. 
Q785 
솔루션 아키텍트는 여러 가용 영역에 걸쳐 프라이빗 서브넷의 AWS Lambda 에서 실행되는 
결제 처리 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 여러 Lambda 함수를 
사용하고 매일 수백만 건의 트랜잭션을 처리합니다. 
아키텍처는 애플리케이션이 중복 결제를 처리하지 않도록 보장해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Lambda 를 사용하여 모든 지불 금액을 검색하십시오. Amazon S3 버킷에 지불 기한을 
게시합니다. 기한 지불을 처리하기 위해 다른 Lambda 함수를 호출하도록 이벤트 알림으로 
S3 버킷을 구성합니다. 
B. Lambda 를 사용하여 모든 지불 금액을 검색합니다. Amazon Simple Queue 
Service(Amazon SQS) 대기열에 지불 기한을 게시합니다. SQS 대기열을 폴링하고 기한 
지불을 처리하도록 다른 Lambda 함수를 구성합니다. 
C. Lambda 를 사용하여 모든 지불 금액을 검색합니다. Amazon Simple Queue 
Service(Amazon SQS) FIFO 대기열에 지불 기한을 게시합니다. FIFO 대기열을 폴링하고 
기한 지불을 처리하도록 다른 Lambda 함수를 구성합니다. 
D. Lambda 를 사용하여 모든 지불 금액을 검색합니다. Amazon DynamoDB 테이블에 지불 
기한을 저장합니다. 기한 지불을 처리하기 위해 다른 Lambda 함수를 호출하도록 
DynamoDB 테이블의 스트림을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/133021-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q786 
회사는 온프레미스 데이터 센터에서 여러 워크로드를 실행합니다. 회사의 데이터 센터는 
회사의 확장되는 비즈니스 요구 사항을 충족할 만큼 빠르게 확장할 수 없습니다. 회사는 
AWS 로의 마이그레이션을 계획하기 위해 온프레미스 서버 및 워크로드에 대한 사용량 및 
구성 데이터를 수집하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Migration Hub 에서 홈 AWS 리전을 설정합니다. AWS Systems Manager 를 사용하여 
온프레미스 서버에 대한 데이터를 수집합니다. 
B. AWS Migration Hub 에서 홈 AWS 지역을 설정합니다. AWS Application Discovery 
Service 를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다. 
C. AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 생성합니다. AWS 
Trusted Advisor 를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다. 
D. AWS SCT(AWS Schema Conversion Tool)를 사용하여 관련 템플릿을 생성합니다. AWS 
Database Migration Service(AWS DMS)를 사용하여 온프레미스 서버에 대한 데이터를 
수집합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133022-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
회사의 요구 사항에 가장 적합한 솔루션은 AWS Migration Hub 에서 홈 AWS 리전을 
설정하고 AWS Application Discovery Service 를 사용하여 온프레미스 서버에 대한 데이터를 
수집하는 것입니다. 이 솔루션을 통해 회사는 온프레미스 서버 및 워크로드의 사용량 및 
구성 데이터를 수집하고 AWS 로의 마이그레이션을 계획할 수 있습니다. 
AWS Migration Hub 는 마이그레이션 상태 정보를 단일 콘솔에 집계하여 마이그레이션 
추적을 단순화하고 가속화하는 서비스입니다. 사용자는 검색된 서버를 보고, 이를 
애플리케이션으로 그룹화하고, 홈 리전의 Migration Hub 콘솔에서 각 애플리케이션의 
마이그레이션 상태를 추적할 수 있습니다. 홈 리전은 마이그레이션하는 리전과 관계없이 
사용자가 마이그레이션 데이터를 저장하는 AWS 리전입니다. 
AWS Application Discovery Service 는 온프레미스 서버 및 데이터베이스에 대한 사용량 및 
구성 데이터를 수집하여 사용자가 AWS 로의 마이그레이션을 계획하는 데 도움을 주는 
서비스입니다. 
Application Discovery Service 는 AWS Migration Hub 와 통합되어 에이전트 없는 검색과 
에이전트 기반 검색이라는 두 가지 검색 수행 방법을 지원합니다. 가상 머신(VM) 및 
데이터베이스에 대한 정적 구성 데이터와 활용도 데이터를 수집하는 VMware vCenter 를 
통해 Application Discovery Service Agentless Collector 를 배포하여 에이전트 없는 검색을 
수행할 수 있습니다. 에이전트 기반 검색은 정적 구성 데이터, 상세한 시계열 시스템 성능 
정보, 인바운드 및 아웃바운드 네트워크 연결, 실행 중인 프로세스를 수집하는 AWS 
Application Discovery Agent 를 각 VM 및 물리적 서버에 배포하여 수행할 수 있습니다. 
다른 옵션은 요구 사항을 충족하지 않거나 사용 사례와 관련이 없기 때문에 올바르지 
않습니다. AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 생성하고 
AWS Trusted Advisor 를 사용하여 온프레미스 서버에 대한 데이터를 수집하는 것은 
올바르지 않습니다. 이 솔루션은 온프레미스 서버의 사용 및 구성 데이터를 수집하는 데 
적합하지 않기 때문입니다. 작업 부하. AWS SCT 는 사용자가 데이터베이스 스키마와 코드 
객체를 한 데이터베이스 엔진에서 다른 데이터베이스 엔진(예: Oracle 에서 
PostgreSQL 로)으로 변환하는 데 도움이 되는 도구입니다. AWS Trusted Advisor 는 비용 
최적화, 성능, 보안, 내결함성 및 서비스 제한에 대한 모범 사례 권장 사항을 제공하는 
서비스입니다. AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 
생성하고 AWS Database Migration Service(AWS DMS)를 사용하여 온프레미스 서버에 대한 
데이터를 수집하는 것은 올바르지 않습니다. 이 솔루션은 사용 및 구성 데이터를 수집하는 
데 적합하지 않기 때문입니다. 온프레미스 서버 및 워크로드. 위에서 언급한 것처럼 AWS 
SCT 는 사용자가 데이터베이스 스키마와 코드 객체를 한 데이터베이스 엔진에서 다른 
데이터베이스 엔진으로 변환하는 데 도움이 되는 도구입니다. AWS DMS 는 사용자가 가동 
중지 시간을 최소화하면서 관계형 데이터베이스, 비관계형 데이터베이스 및 기타 유형의 
데이터 스토어를 AWS 로 마이그레이션하는 데 도움이 되는 서비스입니다. 
Q787 
회사의 AWS Organizations 에는 모든 기능이 활성화된 조직이 있습니다. 회사는 기존 또는 
신규 AWS 계정의 모든 API 호출 및 로그인을 감사해야 한다고 요구합니다. 회사에서는 
추가 작업을 방지하고 비용을 최소화하기 위해 관리형 솔루션이 필요합니다. 또한 회사는 
AWS 계정이 AWS FSBP(Foundational Security Best Practices) 표준을 준수하지 않는 
경우도 알아야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 조직 마스터 계정에 AWS Control Tower 환경을 배포합니다. 환경에서 AWS Security 
Hub 및 AWS Control Tower Account Factory 를 활성화합니다. 
B. 전용 조직 회원 계정에 AWS Control Tower 환경을 배포합니다. 환경에서 AWS Security 
Hub 및 AWS Control Tower Account Factory 를 활성화합니다. 
C. AWS Managed Services(AMS) Accelerate 를 사용하여 다중 계정 랜딩 존(MALZ)을 
구축합니다. MALZ 의 셀프 서비스 프로비저닝 Amazon GuardDuty 에 RFC 를 제출하세요. 
D. AWS Managed Services(AMS) Accelerate 를 사용하여 MALZ(다중 계정 랜딩 존)를 
구축합니다. MALZ 의 셀프 서비스 프로비저닝 AWS Security Hub 에 RFC 를 제출하세요. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/133023-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q788 
한 회사는 Amazon S3 버킷에 Apache Parquet 형식으로 10TB 의 로그 파일을 
저장했습니다. 회사에서는 때때로 SQL 을 사용하여 로그 파일을 분석해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon Aurora MySQL 데이터베이스를 생성하십시오. AWS Database Migration 
Service(AWS DMS)를 사용하여 S3 버킷의 데이터를 Aurora 로 마이그레이션합니다. Aurora 
데이터베이스에 SQL 문을 발행합니다. 
B. Amazon Redshift 클러스터를 생성합니다. Redshift Spectrum 을 사용하여 S3 버킷의 
데이터에 대해 직접 SQL 문을 실행하세요. 
C. S3 버킷에서 테이블 메타데이터를 저장하고 검색하는 AWS Glue 크롤러를 생성합니다. 
Amazon Athena 를 사용하여 S3 버킷의 데이터에 대해 직접 SQL 문을 실행하세요. 
D. Amazon EMR 클러스터를 생성합니다. Apache Spark SQL 을 사용하여 S3 버킷의 
데이터에 대해 직접 SQL 문을 실행하세요. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/133024-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Glue 는 데이터를 크롤링, 분류 및 준비할 수 있는 서버리스 데이터 통합 
서비스입니다. 
분석을 위해. AWS Glue 는 데이터의 스키마와 파티셔닝을 자동으로 검색할 수 있습니다. 
S3 에 Apache Parquet 형식으로 저장되고 AWS Glue 데이터 카탈로그에 테이블을 
생성합니다. 
Amazon Athena 는 SQL 쿼리를 직접 실행할 수 있는 서버리스 대화형 쿼리 서비스입니다. 
데이터를 로드하거나 변환할 필요 없이 S3 에 데이터를 저장합니다. Athena 는 테이블을 
사용할 수 있습니다. 
AWS Glue 데이터 카탈로그의 메타데이터를 사용하여 S3 의 데이터를 쿼리합니다. AWS 
Glue 를 사용하여 
Athena, S3 의 로그 파일을 가장 비용 효율적으로 분석할 수 있습니다. 
크롤러와 쿼리에서 소비하는 리소스를 사용하므로 프로비저닝하거나 
서버나 클러스터를 관리합니다. 
Q789 
회사에는 AWS CloudFormation 스택이 명령문에 인라인 정책 또는 "*"를 포함하는 AWS 
Identity and Access Management(IAM) 리소스를 배포하지 못하도록 방지하는 솔루션이 
필요합니다. 또한 솔루션은 퍼블릭 IP 주소를 사용하는 Amazon EC2 인스턴스 배포를 
금지해야 합니다. 회사는 AWS Organizations 의 조직에서 AWS Control Tower 를 
활성화했습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Control Tower 사전 제어를 사용하여 퍼블릭 IP 주소 및 향상된 액세스 또는 "*"가 
포함된 인라인 정책이 포함된 EC2 인스턴스 배포를 차단합니다. 
B. AWS Control Tower 탐지 제어를 사용하여 퍼블릭 IP 주소 및 향상된 액세스 또는 "*"가 
포함된 인라인 정책을 사용하여 EC2 인스턴스의 배포를 차단합니다. 
C. AWS Config 를 사용하여 EC2 및 IAM 규정 준수에 대한 규칙을 생성합니다. 규정을 
준수하지 않는 리소스를 삭제하기 위해 AWS Systems Manager Session Manager 자동화를 
실행하도록 규칙을 구성합니다. 
D. 서비스 제어 정책(SCP)을 사용하여 조치로 인해 규정이 준수되지 않는 경우 EC2 
인스턴스 및 IAM 리소스에 대한 조치를 차단합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/133025-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q790 
AWS 클라우드에 호스팅되는 한 회사의 웹 애플리케이션이 최근 인기가 높아졌습니다. 웹 
애플리케이션은 현재 단일 퍼블릭 서브넷의 단일 Amazon EC2 인스턴스에 존재합니다. 웹 
애플리케이션은 증가하는 웹 트래픽의 수요를 충족하지 못했습니다. 
회사에는 웹 애플리케이션을 다시 작성하지 않고도 증가하는 사용자 요구를 충족할 수 있는 
고가용성과 확장성을 제공하는 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. EC2 인스턴스를 더 큰 컴퓨팅 최적화 인스턴스로 교체하십시오. 
B. 프라이빗 서브넷의 여러 가용 영역으로 Amazon EC2 Auto Scaling 을 구성합니다. 
C. 웹 요청을 처리하기 위해 퍼블릭 서브넷에 NAT 게이트웨이를 구성합니다. 
D. EC2 인스턴스를 더 큰 메모리 최적화 인스턴스로 교체합니다. 
E. 웹 트래픽을 분산시키기 위해 퍼블릭 서브넷에 Application Load Balancer 를 
구성합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/133027-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 두 단계는 웹 애플리케이션을 다시 작성하지 않고도 웹 애플리케이션에 대한 고가용성과 
확장성을 제공하므로 요구 사항을 충족합니다. Amazon EC2 Auto Scaling 을 사용하면 수요 
변화에 따라 EC2 인스턴스 수를 자동으로 조정할 수 있습니다. 프라이빗 서브넷의 여러 
가용 영역으로 Auto Scaling 을 구성하면 웹 애플리케이션이 격리된 내결함성 위치에 
분산되고 인스턴스가 인터넷에 직접 노출되지 않도록 할 수 있습니다. Application Load 
Balancer 는 애플리케이션 계층에서 작동하며 수신 웹 트래픽을 EC2 인스턴스, 컨테이너 
또는 Lambda 함수와 같은 여러 대상에 분산합니다. 퍼블릭 서브넷에서 Application Load 
Balancer 를 구성하면 웹 애플리케이션이 인터넷의 요청을 처리하고 프라이빗 서브넷의 
적절한 대상으로 라우팅할 수 있습니다. 
Q791 
회사에 환경 변수를 사용하는 AWS Lambda 함수가 있습니다. 회사는 개발자가 환경 변수를 
일반 텍스트로 보는 것을 원하지 않습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Lambda 함수를 사용하는 대신 Amazon EC2 인스턴스에 코드를 배포하십시오. 
B. AWS CloudHSM 을 사용하여 환경 변수를 저장하고 암호화하도록 Lambda 함수에 SSL 
암호화를 구성합니다. 
C. AWS Certificate Manager(ACM)에서 인증서를 생성합니다. 인증서를 사용하여 환경 
변수를 암호화하도록 Lambda 함수를 구성합니다. 
D. AWS Key Management Service(AWS KMS) 키를 생성합니다. KMS 키를 사용하여 환경 
변수를 저장하고 암호화하려면 Lambda 함수에서 암호화 도우미를 활성화하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/133030-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q792 
분석 회사는 Amazon VPC 를 사용하여 다중 계층 서비스를 실행합니다. 회사는 RESTful 
API 를 사용하여 수백만 명의 사용자에게 웹 분석 서비스를 제공하려고 합니다. API 에 
액세스하려면 인증 서비스를 사용하여 사용자를 확인해야 합니다. 
가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 사용자 인증을 위해 Amazon Cognito 사용자 풀을 구성합니다. Cognito 권한 부여자를 
사용하여 Amazon API Gateway REST API 를 구현합니다. 
B. 사용자 인증을 위해 Amazon Cognito 자격 증명 풀을 구성합니다. Cognito 권한 
부여자를 사용하여 Amazon API Gateway HTTP API 를 구현합니다. 
C. 사용자 인증을 처리하도록 AWS Lambda 함수를 구성합니다. Lambda 권한 부여자를 
사용하여 Amazon API Gateway REST API 를 구현합니다. 
D. 사용자 인증을 처리하도록 IAM 사용자를 구성합니다. IAM 권한 부여자를 사용하여 
Amazon API Gateway HTTP API 를 구현합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/133031-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 다음과 같은 이유로 최고의 운영 효율성으로 요구 사항을 충족합니다. 
Amazon Cognito 사용자 풀은 사용자 프로필을 저장 및 관리하고 사용자 가입, 로그인 및 
액세스 제어를 처리할 수 있는 안전하고 확장 가능한 사용자 디렉터리를 제공합니다. 
사용자 풀은 SAML 또는 OIDC 를 통해 소셜 ID 공급자 및 기업 ID 공급자와 통합할 수도 
있습니다. 사용자 풀은 사용자를 인증하고 API 요청을 승인하는 데 사용할 수 있는 
JWT(JSON 웹 토큰)를 발행할 수 있습니다. 
Amazon API Gateway REST API 를 사용하면 백엔드 서비스를 클라이언트에 노출하는 API 를 
생성하고 배포할 수 있습니다. REST API 는 Cognito 사용자 풀, IAM, Lambda 및 사용자 
지정 권한 부여자를 포함한 여러 권한 부여 메커니즘을 지원합니다. Cognito 권한 부여자는 
Cognito 사용자 풀을 자격 증명 소스로 사용하는 Lambda 권한 부여자의 유형입니다. 
클라이언트가 Cognito 권한 부여자로 구성된 REST API 메서드에 요청하면 API Gateway 는 
사용자 풀에서 발행한 JWT 를 확인하고 토큰의 클레임과 권한 부여자의 구성을 기반으로 
액세스 권한을 부여합니다. 
Cognito 권한 부여자와 함께 Cognito 사용자 풀 및 API 게이트웨이 REST API 를 사용하면 
웹 분석 서비스에 대해 높은 수준의 보안, 확장성 및 성능을 달성할 수 있습니다. 
또한 사용자 관리, 토큰 검증, 캐싱, 제한, 모니터링 등 Cognito 및 API Gateway 에 내장된 
기능을 직접 구현할 필요 없이 활용할 수도 있습니다. 이를 통해 솔루션의 운영 오버헤드와 
복잡성이 줄어듭니다. 
Q793 
한 회사에 고객을 위한 모바일 앱이 있습니다. 앱의 데이터는 민감하므로 저장 시 
암호화되어야 합니다. 회사는 AWS Key Management Service(AWS KMS)를 사용합니다. 
회사에는 실수로 KMS 키가 삭제되는 것을 방지하는 솔루션이 필요합니다. 솔루션은 
사용자가 KMS 키를 삭제하려고 할 때 Amazon Simple 알림 서비스(Amazon SNS)를 
사용하여 관리자에게 이메일 알림을 보내야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 사용자가 KMS 키를 삭제하려고 할 때 반응하는 Amazon EventBridge 규칙을 
생성하십시오. KMS 키 삭제를 취소하는 AWS Config 규칙을 구성합니다. EventBridge 
규칙의 대상으로 AWS Config 규칙을 추가합니다. 관리자에게 알리는 SNS 주제를 
생성합니다. 
B. KMS 키 삭제를 방지하기 위한 사용자 지정 논리가 있는 AWS Lambda 함수를 
생성합니다. 사용자가 KMS 키를 삭제하려고 할 때 활성화되는 Amazon CloudWatch 
경보를 생성합니다. DeleteKey 작업이 수행될 때 Lambda 함수를 호출하는 Amazon 
EventBridge 규칙을 생성합니다. SNS 주제를 생성합니다. 관리자에게 알리는 SNS 메시지를 
게시하도록 EventBridge 규칙을 구성합니다. 
C. KMS DeleteKey 작업이 수행될 때 반응하는 Amazon EventBridge 규칙을 생성합니다. 
AWS 시스템 관리자 자동화 Runbook 을 시작하도록 규칙을 구성합니다. KMS 키 삭제를 
취소하도록 Runbook 을 구성합니다. SNS 주제를 생성합니다. 관리자에게 알리는 SNS 
메시지를 게시하도록 EventBridge 규칙을 구성합니다. 
D. AWS CloudTrail 추적을 생성합니다. 새로운 Amazon CloudWatch 로그 그룹에 로그를 
전달하도록 추적을 구성합니다. CloudWatch 로그 그룹에 대한 지표 필터를 기반으로 
CloudWatch 경보를 생성합니다. KMS DeleteKey 작업이 수행될 때 Amazon SNS 를 
사용하여 관리자에게 알리도록 경보를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/133032-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 완벽하게 관리되고 확장 가능한 AWS 서비스를 사용하므로 최소한의 운영 
오버헤드로 요구 사항을 충족합니다. EventBridge 규칙은 AWS KMS API 에서 DeleteKey 
작업을 감지하고 미리 정의된 워크플로를 실행하여 키 삭제를 취소할 수 있는 Systems 
Manager Automation Runbook 을 트리거할 수 있습니다. EventBridge 규칙은 관리자에게 
이메일 알림을 보내는 주제에 SNS 메시지를 게시할 수도 있습니다. 이를 통해 회사는 KMS 
키가 실수로 삭제되는 것을 방지하고, 삭제 시도가 있을 경우 관리자에게 알릴 수 
있습니다. 
옵션 A 는 유효한 솔루션이 아닙니다. AWS Config 규칙은 KMS 키 삭제를 취소하는 것이 
아니라 AWS 리소스 구성을 평가하는 데 사용되기 때문입니다. 
옵션 B 는 운영 오버헤드를 추가하는 KMS 키 삭제를 방지하는 논리가 있는 사용자 지정 
Lambda 함수를 생성하고 유지해야 하기 때문에 유효한 솔루션이 아닙니다. 
옵션 D 는 관리자에게 삭제 키 작업을 알리기만 하고 취소하지는 않으므로 유효한 솔루션이 
아닙니다. 
Q794 
회사에서는 모바일 앱 사용을 추적하기 위해 보고서를 분석하고 생성하려고 합니다. 이 
앱은 인기가 높으며 글로벌 사용자 기반을 보유하고 있습니다. 회사는 맞춤형 보고서 작성 
프로그램을 사용하여 애플리케이션 사용량을 분석합니다. 
프로그램은 매월 마지막 주에 여러 보고서를 생성합니다. 프로그램은 각 보고서를 생성하는 
데 10 분 미만이 소요됩니다. 회사에서는 매월 마지막 주 외에 보고서를 생성하는 
프로그램을 거의 사용하지 않습니다. 회사는 보고서를 요청할 때 최소한의 시간에 보고서를 
생성하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon EC2 온디맨드 인스턴스를 사용하여 프로그램을 실행합니다. 보고서가 요청되면 
EC2 인스턴스를 시작하는 Amazon EventBridge 규칙을 생성합니다. 매월 마지막 주에 EC2 
인스턴스를 지속적으로 실행합니다. 
B. AWS Lambda 에서 프로그램을 실행합니다. 보고서가 요청될 때 Lambda 함수를 
실행하는 Amazon EventBridge 규칙을 생성합니다. 
C. Amazon Elastic Container Service(Amazon ECS)에서 프로그램을 실행합니다. 보고서가 
요청되면 프로그램을 실행하도록 Amazon ECS 를 예약합니다. 
D. Amazon EC2 스팟 인스턴스를 사용하여 프로그램을 실행합니다. 보고서가 요청되면 EC2 
인스턴스를 시작하는 Amazon EventBndge 규칙을 생성합니다. 매월 마지막 주에 EC2 
인스턴스를 지속적으로 실행합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133033-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 AWS Lambda 및 Amazon EventBridge 의 서버리스 및 이벤트 중심 기능을 
활용하므로 가장 비용 효율적으로 요구 사항을 충족합니다. AWS Lambda 를 사용하면 
서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있으며, 사용한 컴퓨팅 시간에 
대해서만 비용을 지불하면 됩니다. Amazon EventBridge 는 애플리케이션을 다양한 소스의 
데이터와 연결하고 해당 데이터를 AWS Lambda 와 같은 대상으로 라우팅할 수 있게 해주는 
서버리스 이벤트 버스 서비스입니다. Amazon EventBridge 를 사용하면 보고서가 요청될 때 
프로그램을 실행하도록 Lambda 함수를 트리거하는 규칙을 생성할 수 있으며, 매월 마지막 
주에 규칙이 실행되도록 예약할 수도 있습니다. 이렇게 하면 최소한의 시간에 보고서를 
생성하고 사용한 리소스에 대해서만 비용을 지불할 수 있습니다. 
Q795 
한 회사는 AWS 클라우드에서 긴밀하게 결합된 고성능 컴퓨팅(HPC) 환경을 설계하고 
있습니다. 회사는 네트워킹 및 스토리지를 위해 HPC 환경을 최적화하는 기능을 포함해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (2 개 선택) 
A. AWS Global Accelerator 에서 액셀러레이터를 생성합니다. 가속기에 대한 사용자 지정 
라우팅을 구성합니다. 
B. Lustre 파일 시스템용 Amazon FSx 를 생성합니다. 스크래치 스토리지로 파일 시스템을 
구성합니다. 
C. Amazon CloudFront 배포판을 생성합니다. 뷰어 프로토콜 정책을 HTTP 및 HTTPS 로 
구성합니다. 
D. Amazon EC2 인스턴스를 시작합니다. EFA(Elastic Fabric Adapter)를 인스턴스에 
연결합니다. 
E. 환경을 관리하기 위해 AWS Elastic Beanstalk 배포를 생성합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/133034-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 두 가지 솔루션은 네트워킹 및 스토리지에 맞게 HPC 환경을 최적화합니다. Amazon FSx 
for Lustre 는 컴퓨팅 워크로드를 위한 비용 효율적이고 고성능이며 확장 가능한 스토리지를 
제공하는 완전관리형 서비스입니다. 이는 HPC 및 기계 학습과 같이 빠른 스토리지가 
필요한 애플리케이션을 위해 설계된 세계에서 가장 인기 있는 고성능 파일 시스템인 
Lustre 를 기반으로 구축되었습니다. 스크래치 스토리지로 파일 시스템을 구성하면 밀리초 
미만의 대기 시간, 최대 수백 GB/s 의 처리량 및 수백만 IOPS 를 달성할 수 있습니다. 
스크래치 파일 시스템은 임시 저장 및 단기 데이터 처리에 이상적입니다. 파일 서버에 
장애가 발생하면 데이터가 복제되지 않으며 유지되지 않습니다. 자세한 내용은 Lustre 용 
Amazon FSx 를 참조하세요. 
EFA(Elastic Fabric Adapter)는 고객이 AWS 에서 높은 수준의 노드 간 통신이 필요한 
애플리케이션을 대규모로 실행할 수 있도록 지원하는 Amazon EC2 인스턴스용 네트워크 
인터페이스입니다. 맞춤형 운영 체제(OS) 우회 하드웨어 인터페이스는 HPC 및 기계 학습 
애플리케이션을 확장하는 데 중요한 인스턴스 간 통신 성능을 향상시킵니다. EFA 는 
인스턴스 간 통신을 위해 지연 시간이 낮고 지터가 낮은 채널을 제공하므로 긴밀하게 
결합된 HPC 또는 분산 기계 학습 애플리케이션을 수천 개의 코어로 확장할 수 있습니다. 
EFA 는 통신을 위해 대부분의 HPC 프로그래밍 모델에서 지원되는 libfabric 인터페이스와 
libfabric API 를 사용합니다. 자세한 내용은 탄력적 패브릭 어댑터를 참조하세요. 
다른 솔루션은 네트워킹 및 스토리지를 위한 HPC 환경을 최적화하는 데 적합하지 
않습니다. AWS Global Accelerator 는 AWS 글로벌 네트워크를 사용하여 퍼블릭 
애플리케이션의 가용성, 성능 및 보안을 향상시키는 데 도움이 되는 네트워킹 서비스입니다. 
이는 두 개의 전역 고정 공용 IP, 결정적 라우팅, 빠른 장애 조치(failover) 및 애플리케이션 
엔드포인트에 대한 에지에서의 TCP 종료를 제공합니다. 그러나 HPC 및 기계 학습 
애플리케이션에 필요한 OSbypass 기능이나 고성능 파일 시스템은 지원하지 않습니다. 
자세한 내용은 AWS Global Accelerator 를 참조하십시오. 
Amazon CloudFront 는 개발자 친화적인 환경 내에서 짧은 지연 시간과 높은 전송 속도로 
전 세계 고객에게 데이터, 비디오, 애플리케이션 및 API 를 안전하게 제공하는 CDN(콘텐츠 
전송 네트워크) 서비스입니다. CloudFront 는 Amazon S3, Amazon EC2, AWS Elemental 
Media Services, AWS Shield, AWS WAF 및 AWS Lambda@Edge 와 같은 AWS 서비스와 
통합됩니다. 그러나 CloudFront 는 높은 수준의 노드 간 통신과 빠른 스토리지가 필요한 
HPC 및 기계 학습 애플리케이션용으로 설계되지 않았습니다. 자세한 내용은 [Amazon 
CloudFront]를 참조하세요. 
AWS Elastic Beanstalk 는 Apache, Nginx, Passenger 와 같은 친숙한 서버에서 Java, .NET, 
PHP, Node.js, Python, Ruby, Go 및 Docker 로 개발된 웹 애플리케이션과 서비스를 
배포하고 확장하기 위한 사용하기 쉬운 서비스입니다. 및 IIS. 코드를 업로드하기만 하면 
Elastic Beanstalk 가 용량 프로비저닝, 로드 밸런싱, 자동 크기 조정부터 애플리케이션 상태 
모니터링까지 배포를 자동으로 처리합니다. 그러나 Elastic Beanstalk 는 OSbypass 기능과 
고성능 파일 시스템이 필요한 HPC 및 기계 학습 애플리케이션에 최적화되어 있지 
않습니다. 자세한 내용은 [AWS Elastic Beanstalk]를 참조하세요. 
Q796 
회사에는 원치 않는 콘텐츠가 포함된 사진이 회사의 웹 애플리케이션에 업로드되는 것을 
방지하는 솔루션이 필요합니다. 솔루션에는 기계 학습(ML) 모델 교육이 포함되어서는 안 
됩니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon SageMaker Autopilot 을 사용하여 모델을 생성하고 배포합니다. 새 사진이 
업로드될 때 웹 애플리케이션이 호출하는 실시간 엔드포인트를 만듭니다. 
B. Amazon Rekognition 을 사용하여 원치 않는 콘텐츠를 감지하는 AWS Lambda 함수를 
생성합니다. 새 사진이 업로드될 때 웹 애플리케이션이 호출하는 Lambda 함수 URL 을 
생성합니다. 
C. Amazon Comprehend 를 사용하여 원치 않는 콘텐츠를 감지하는 Amazon CloudFront 
함수를 생성합니다. 기능을 웹 애플리케이션과 연결합니다. 
D. Amazon Rekognition Video 를 사용하여 원치 않는 콘텐츠를 감지하는 AWS Lambda 
함수를 생성합니다. 새 사진이 업로드될 때 웹 애플리케이션이 호출하는 Lambda 함수 
URL 을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133035-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
요구 사항을 충족하는 솔루션은 Amazon Rekognition 을 사용하여 원치 않는 콘텐츠를 
감지하는 AWS Lambda 함수를 생성하고 새 사진이 업로드될 때 웹 애플리케이션이 
호출하는 Lambda 함수 URL 을 생성하는 것입니다. Amazon Rekognition 은 이미지 및 
비디오 분석을 위해 사전 훈련된 컴퓨터 비전 모델을 제공하는 완전 관리형 서비스이므로 
이 솔루션에는 기계 학습 모델 훈련이 포함되지 않습니다. Amazon Rekognition 은 
노골적이거나 외설적인 성인 콘텐츠, 폭력, 무기, 마약 등과 같은 원치 않는 콘텐츠를 
탐지할 수 있습니다. AWS Lambda 를 사용하여 회사는 웹 애플리케이션의 HTTP 요청에 
의해 트리거될 수 있는 서버리스 기능을 생성할 수 있습니다. Lambda 함수는 Amazon 
Rekognition API 를 사용하여 업로드된 사진을 분석하고 원치 않는 콘텐츠가 포함되어 
있는지 여부를 나타내는 응답을 반환할 수 있습니다. 
다른 솔루션은 기계 학습 모델 교육이 포함되거나 이미지 분석을 지원하지 않거나 사진 
작업을 수행하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. Amazon 
SageMaker Autopilot 을 사용하여 모델을 생성하고 배포하려면 기계 학습 모델을 훈련해야 
하는데, 이는 시나리오에 필요하지 않습니다. Amazon SageMaker Autopilot 은 사용자가 
제공한 데이터를 기반으로 분류 또는 회귀를 위한 최고의 기계 학습 모델을 자동으로 생성, 
교육 및 조정하는 서비스입니다. Amazon Comprehend 를 사용하여 원치 않는 콘텐츠를 
감지하는 Amazon CloudFront 함수를 생성하면 이미지 분석이 지원되지 않습니다. Amazon 
Comprehend 는 이미지가 아닌 텍스트를 분석하는 자연어 처리 서비스이기 때문입니다. 
Amazon Comprehend 는 언어, 감정, 항목, 주제 등과 같은 텍스트에서 통찰력과 관계를 
추출할 수 있습니다. Amazon Rekognition Video 를 사용하여 원치 않는 콘텐츠를 감지하는 
AWS Lambda 함수를 생성하는 것은 사진에서는 작동하지 않습니다. Amazon Rekognition 
Video 는 정적 이미지가 아닌 비디오 스트림을 분석하도록 설계되었기 때문입니다. Amazon 
Rekognition Video 는 비디오 스트림에서 활동, 객체, 얼굴, 유명인, 텍스트 등을 감지할 수 
있습니다. 
Q797 
한 회사는 AWS 를 사용하여 전자상거래 플랫폼을 운영합니다. 이 플랫폼은 회사 운영에 
매우 중요하며 트래픽과 거래량이 많습니다. 회사는 AWS 계정 루트 사용자 자격 증명을 
보호하기 위해 다중 요소 인증(MFA) 장치를 구성합니다. 회사는 MFA 디바이스가 분실된 
경우 루트 사용자 계정에 대한 액세스 권한을 잃지 않기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 회사가 MFA 디바이스를 분실한 경우 회사에서 로그인하는 데 사용할 수 있는 백업 
관리자 계정을 설정하십시오. 
B. 재해 시나리오를 처리하기 위해 루트 사용자 계정에 여러 MFA 장치를 추가합니다. 
C. 회사에서 루트 계정에 접근할 수 없는 경우 새로운 관리자 계정을 생성한다. 
D. 회사가 루트 계정에 접근할 수 없는 경우 다른 IAM 사용자에게 관리자 정책을 
연결합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133036-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q798 
한 소셜 미디어 회사가 사용자를 위한 보상 프로그램 웹사이트를 만들고 있습니다. 회사는 
이용자가 동영상을 제작하여 홈페이지에 업로드할 때 이용자에게 포인트를 부여합니다. 
사용자는 자신의 포인트를 회사 제휴 파트너의 선물이나 할인으로 교환할 수 있습니다. 
고유 ID 는 사용자를 식별합니다. 파트너는 이 ID 를 참조하여 사용자의 보상 자격을 
확인합니다. 
파트너는 회사가 사용자에게 포인트를 제공할 때 HTTP 엔드포인트를 통해 사용자 ID 에 
대한 알림을 받기를 원합니다. 매일 수백 개의 공급업체가 제휴 파트너가 되는 데 관심을 
갖고 있습니다. 회사는 확장 가능한 방식으로 신속하게 파트너를 추가할 수 있는 기능을 웹 
사이트에 제공하는 아키텍처를 설계하려고 합니다. 
최소한의 구현 노력으로 이러한 요구 사항을 충족할 수 있는 솔루션은 무엇입니까? 
A. 제휴 파트너 목록을 보관하려면 Amazon Timestream 데이터베이스를 생성하세요. 
목록을 읽으려면 AWS Lambda 함수를 구현하십시오. 회사에서 사용자에게 포인트를 제공할 
때 각 파트너에게 사용자 ID 를 보내도록 Lambda 기능을 구성합니다. 
B. Amazon Simple 알림 서비스(Amazon SNS) 주제를 생성합니다. 엔드포인트 프로토콜을 
선택하세요. 주제에 대한 파트너를 구독하십시오. 회사가 사용자에게 포인트를 제공할 때 
해당 주제에 사용자 ID 를 게시합니다. 
C. AWS Step Functions 상태 머신을 생성합니다. 모든 제휴 파트너에 대한 작업을 만듭니다. 
회사가 사용자에게 포인트를 제공할 때 사용자 ID 를 입력으로 사용하여 상태 머신을 
호출합니다. 
D. Amazon Kinesis Data Streams 에서 데이터 스트림을 생성합니다. 생산자 및 소비자 
애플리케이션을 구현합니다. 데이터 스트림에 제휴 파트너 목록을 저장합니다. 회사가 
이용자에게 포인트를 지급할 때 이용자 ID 를 발송합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/133037-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q799 
회사는 Amazon S3 버킷에 텍스트 파일로 저장된 레시피 레코드에서 재료 이름을 추출해야 
합니다. 웹 애플리케이션은 성분 이름을 사용하여 Amazon DynamoDB 테이블을 쿼리하고 
영양 점수를 결정합니다. 
애플리케이션은 식품 이외의 기록과 오류를 처리할 수 있습니다. 회사에는 이 솔루션을 
개발할 수 있는 머신러닝 지식을 갖춘 직원이 없습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. PutObject 요청이 발생할 때 S3 이벤트 알림을 사용하여 AWS Lambda 함수를 
호출하십시오. Amazon Comprehend 를 사용하여 객체를 분석하고 성분 이름을 추출하도록 
Lambda 함수를 프로그래밍합니다. Amazon Comprehend 출력을 DynamoDB 테이블에 
저장합니다. 
B. PutObject 요청이 발생할 때 Amazon EventBridge 규칙을 사용하여 AWS Lambda 
함수를 호출합니다. Amazon Forecast 를 사용하여 성분 이름을 추출함으로써 객체를 
분석하도록 Lambda 함수를 프로그래밍합니다. DynamoDB 테이블에 예측 결과를 
저장합니다. 
C. PutObject 요청이 발생할 때 S3 이벤트 알림을 사용하여 AWS Lambda 함수를 
호출합니다. Amazon Polly 를 사용하여 레시피 레코드의 오디오 녹음을 생성합니다. S3 
버킷에 오디오 파일을 저장합니다. Amazon Simple 알림 서비스(Amazon SNS)를 사용하여 
URL 을 직원에게 메시지로 전송합니다. 직원에게 오디오 파일을 듣고 영양 점수를 
계산하도록 지시합니다. DynamoDB 테이블에 성분 이름을 저장합니다. 
D. PutObject 요청이 발생할 때 Amazon EventBridge 규칙을 사용하여 AWS Lambda 
함수를 호출합니다. Amazon SageMaker 를 사용하여 객체를 분석하고 성분 이름을 
추출하도록 Lambda 함수를 프로그래밍합니다. SageMaker 엔드포인트의 추론 출력을 
DynamoDB 테이블에 저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/135257-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 다음 요구 사항을 충족합니다. 
사용량에 따라 요금이 부과되고 사전 프로비저닝이나 유지 관리가 필요하지 않은 서버리스 
구성 요소만 사용하므로 비용 효율적입니다. 
성능 저하나 수동 개입 없이 S3 버킷에 업로드되는 레시피 레코드 수에 관계없이 처리할 
수 있으므로 확장 가능합니다. 
기계 학습 지식이나 복잡한 데이터 처리 논리가 필요하지 않으므로 구현이 쉽습니다. 
Amazon Comprehend 는 텍스트 파일에서 성분과 같은 엔터티를 자동으로 추출할 수 있는 
자연어 처리 서비스입니다. Lambda 함수는 간단히 Comprehend API 를 호출하고 결과를 
DynamoDB 테이블에 저장할 수 있습니다. 
식품 이외의 기록과 오류를 우아하게 처리할 수 있으므로 신뢰할 수 있습니다. Amazon 
Comprehend 는 텍스트 파일의 언어와 도메인을 감지하고 적절한 응답을 반환할 수 
있습니다. Lambda 함수는 오류 처리 및 로깅 메커니즘을 구현하여 데이터 품질과 무결성을 
보장할 수도 있습니다. 
Q800 
회사는 회사의 기본 AWS 계정에 있는 VPC 에서 실행될 AWS Lambda 함수를 생성해야 
합니다. Lambda 함수는 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에 
저장하는 파일에 액세스해야 합니다. EFS 파일 시스템은 보조 AWS 계정에 있습니다. 
회사가 파일 시스템에 파일을 추가함에 따라 솔루션은 수요를 충족하도록 확장되어야 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 기본 계정에 새 EPS 파일 시스템을 생성합니다. AWS DataSync 를 사용하여 원본 EPS 
파일 시스템의 콘텐츠를 새 EPS 파일 시스템에 복사합니다. 
B. 기본 계정과 보조 계정에 있는 VPC 간에 VPC 피어링 연결을 생성합니다. 
C. 파일 시스템에 대해 구성된 마운트가 있는 보조 계정에서 두 번째 Lambda 함수를 
생성합니다. 기본 계정의 Lambda 함수를 사용하여 보조 계정의 Lambda 함수를 
호출합니다. 
D. 파일 시스템의 내용을 Lambda 계층으로 이동합니다. Lambda 계층 구성 
회사의 보조 계정이 Lambda 계층을 사용할 수 있도록 허용하는 권한입니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/135258-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 기본 계정의 Lambda 함수가 보조 계정의 EFS 파일 시스템에 액세스할 수 
있도록 허용하는 가장 비용 효율적이고 확장 가능한 방법입니다. VPC 피어링을 사용하면 
게이트웨이, VPN 연결 또는 전용 네트워크 연결 없이도 두 VPC 간의 프라이빗 연결이 
가능합니다. Lambda 함수는 VPC 피어링 연결을 사용하여 EFS 파일 시스템을 로컬 파일 
시스템으로 탑재하고 필요에 따라 파일에 액세스할 수 있습니다. 이 솔루션은 추가 데이터 
전송이나 저장 비용이 발생하지 않으며, 데이터를 복제하거나 이동하지 않고 기존 EFS 
파일 시스템을 활용합니다. 
옵션 A 는 새로운 EFS 파일 시스템을 생성하고 AWS DataSync 를 사용하여 원래 EFS 파일 
시스템에서 데이터를 복사해야 하기 때문에 비용 효율적이지 않습니다. 이로 인해 추가 
저장 및 데이터 전송 비용이 발생하고 파일에 대한 실시간 액세스가 제공되지 않습니다. 
옵션 C 는 보조 계정에 두 번째 Lambda 함수를 생성하고 기본 계정에서 이를 호출하기 
위한 교차 계정 권한을 구성해야 하기 때문에 확장 가능하지 않습니다. 이로 인해 솔루션에 
복잡성과 대기 시간이 추가되고 Lambda 호출 비용이 증가합니다. 
옵션 D 는 Lambda 계층이 대량의 데이터를 저장하거나 파일 시스템 액세스를 제공하도록 
설계되지 않았기 때문에 실현 가능하지 않습니다. Lambda 계층은 여러 Lambda 함수에서 
공통 코드나 라이브러리를 공유하는 데 사용됩니다. 
EFS 파일 시스템의 콘텐츠를 Lambda 계층으로 이동하면 계층의 크기 제한인 250MB 를 
초과하게 되며, Lambda 함수가 계층에 파일을 읽거나 쓸 수 없게 됩니다. 
Q801 
금융회사는 매우 민감한 데이터를 처리해야 합니다. 회사는 Amazon S3 버킷에 데이터를 
저장합니다. 회사는 데이터가 전송 중이거나 저장되어 있을 때 암호화되었는지 확인해야 
합니다. 회사는 AWS 클라우드 외부의 암호화 키를 관리해야 합니다. 어떤 솔루션이 이러한 
요구 사항을 충족합니까? 
A. AWS Key Management Service(AWS KMS) 고객 관리형 키를 사용하는 서버 측 
암호화(SSE)로 S3 버킷의 데이터를 암호화합니다. 
B. AWS Key Management Service(AWS KMS) AWS 관리형 키를 사용하는 서버 측 
암호화(SSE)로 S3 버킷의 데이터를 암호화합니다. 
C. 기본 서버 측 암호화(SSE)를 사용하여 S3 버킷의 데이터를 암호화합니다. 
D. S3 버킷에 데이터를 저장하기 전에 회사 데이터 센터의 데이터를 암호화하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/135259-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q802 
한 회사가 AWS 에서 결제 애플리케이션을 실행하려고 합니다. 애플리케이션은 모바일 
장치로부터 결제 알림을 받습니다. 결제 알림은 추가 처리를 위해 전송되기 전에 기본적인 
확인이 필요합니다. 백엔드 처리 애플리케이션은 장기간 실행되며 조정하려면 컴퓨팅 및 
메모리가 필요합니다. 회사는 인프라 관리를 원하지 않습니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Simple Queue Service(Amazon SQS) 대기열 생성 대기열을 Amazon 
EventBndge 규칙과 통합하여 모바일 장치에서 결제 알림을 수신합니다. 결제 알림을 
검증하고 백엔드 애플리케이션에 알림을 보내도록 규칙을 구성합니다. Amazon Elastic 
Kubernetes Service(Amazon EKS)에 백엔드 애플리케이션을 어디서나 배포합니다. 독립형 
클러스터를 만듭니다. 
B. Amazon API 게이트웨이 API 생성 API 를 AWS Step Functions 상태 머신과 통합하여 
모바일 장치에서 결제 알림 수신 상태 머신을 호출하여 결제 알림의 유효성을 검사하고 
백엔드 애플리케이션으로 알림을 전송합니다. Amazon Elastic Kubernetes Service(Amazon 
EKS)에 백엔드 애플리케이션을 배포합니다. 자체 관리형 노드로 EKS 클러스터를 
구성합니다. 
C. Amazon Simple Queue Service(Amazon SQS) 대기열 생성 대기열을 Amazon 
EventBridge 규칙과 통합하여 모바일 장치에서 결제 알림을 수신합니다. 결제 알림을 
검증하고 백엔드 애플리케이션에 알림을 보내도록 규칙을 구성합니다. Amazon EC2 스팟 
인스턴스에 백엔드 애플리케이션을 배포합니다. 기본 할당 전략으로 스팟 집합을 
구성합니다. 
D. Amazon API 게이트웨이 API 만들기 모바일 장치에서 결제 알림을 수신하기 위해 API 를 
AWS Lambda 와 통합하기 Lambda 함수를 호출하여 결제 알림의 유효성을 검사하고 
백엔드 애플리케이션으로 알림을 전송합니다. Amazon Elastic Container Service(Amazon 
ECS)에 백엔드 애플리케이션을 배포합니다. AWS Fargate 시작 유형으로 Amazon ECS 를 
구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/135260-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 회사가 운영 오버헤드와 인프라 관리를 최소화하면서 AWS 에서 결제 
애플리케이션을 실행할 수 있게 해주기 때문에 최고의 솔루션입니다. Amazon API 
Gateway 를 사용하면 회사는 안전하고 확장 가능한 API 를 생성하여 모바일 장치에서 결제 
알림을 받을 수 있습니다. AWS Lambda 를 사용하면 회사는 서버리스 기능을 실행하여 결제 
알림을 검증하고 이를 백엔드 애플리케이션으로 보낼 수 있습니다. Lambda 는 기능의 
프로비저닝, 확장 및 보안을 처리하여 운영 복잡성과 비용을 줄입니다. AWS Fargate와 함께 
Amazon ECS 를 사용함으로써 회사는 컴퓨팅 리소스를 자동으로 확장하고 관리하는 데 
EC2 인스턴스가 필요하지 않은 완전관리형 컨테이너 서비스에서 백엔드 애플리케이션을 
실행할 수 있습니다. Fargate 는 각 컨테이너에 적절한 양의 CPU 와 메모리를 할당하고 
필요에 따라 조정합니다. 
Q803 
솔루션 설계자는 회사를 위한 사용자 인증 솔루션을 설계하고 있습니다. 솔루션은 일관되지 
않은 지리적 위치 IP 주소 또는 장치에서 로그인하는 사용자에 대해 2 단계 인증을 
호출해야 합니다. 또한 솔루션은 수백만 명의 사용자를 수용할 수 있도록 확장할 수 있어야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 사용자 인증을 위해 Amazon Cognito 사용자 풀 구성 멀티 팩터 인증(MFA)으로 nsk 
기반 적응형 인증 기능을 활성화합니다. 
B. 사용자 인증을 위한 Amazon Cognito 자격 증명 풀 구성 다단계 인증(MFA)을 
활성화합니다. 
C. 사용자 인증을 위해 AWS Identity and Access Management(IAM) 사용자 구성 
AllowManageOwnUserMFA 작업을 허용하는 IAM 정책을 연결합니다. 
D. 사용자 인증을 위한 AWS IAM Identity Center(AWS Single Sign-On) 인증 구성 다단계 
인증(MFA)을 요구하도록 권한 세트를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/135472-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Cognito 사용자 풀은 사용자 인증 및 관리를 위한 안전하고 확장 가능한 사용자 
디렉터리를 제공합니다. 사용자 풀은 사용자 이름과 비밀번호, 이메일과 비밀번호, 
전화번호와 비밀번호, 소셜 ID 공급자 등 다양한 인증 방법을 지원합니다. 사용자 풀은 
또한 사용자에게 자격 증명 외에 확인 코드나 생체 인식 요소를 제공하도록 요구하여 보안 
계층을 추가하는 다중 요소 인증(MFA)도 지원합니다. 사용자 풀은 로그인 시도의 위험 
수준에 따라 인증 문제를 동적으로 조정하는 위험 기반 적응형 인증을 활성화할 수도 
있습니다. 예를 들어 사용자가 익숙하지 않은 장치나 위치에서 로그인을 시도하는 경우 
사용자 풀은 SMS 또는 이메일 확인 코드와 같은 더 강력한 인증 요소를 요구할 수 
있습니다. 이 기능은 무단 액세스로부터 사용자 계정을 보호하고 합법적인 사용자에 대한 
마찰을 줄이는 데 도움이 됩니다. 사용자 풀은 수백만 명의 사용자로 확장할 수 있으며 
Amazon SNS, Amazon SES, AWS Lambda 및 AWS KMS와 같은 다른 AWS 서비스와 통합할 
수 있습니다. 
Amazon Cognito 자격 증명 풀은 사용자 풀, 소셜 자격 증명 공급자, 기업 자격 증명 
공급자 등 여러 자격 증명 공급자의 자격 증명을 연합하는 방법을 제공합니다. 자격 증명 
풀을 사용하면 사용자는 권한이 제한된 임시 자격 증명으로 AWS 리소스에 액세스할 수 
있습니다. 자격 증명 풀은 MFA 또는 적응형 인증과 같은 사용자 인증이나 관리 기능을 
제공하지 않습니다. 따라서 선택지 B 는 올바르지 않습니다. 
AWS Identity and Access Management(IAM)는 AWS 리소스에 대한 액세스를 관리하는 데 
도움이 되는 서비스입니다. 
IAM 사용자는 AWS 와 상호 작용해야 하는 사람이나 애플리케이션을 나타내는 
엔터티입니다. IAM 사용자는 암호나 액세스 키를 사용하여 인증할 수 있습니다. IAM 
사용자는 IAM 정책에서 AllowManageOwnUserMFA 작업을 사용하여 자신의 계정에 대해 
MFA 를 활성화할 수도 있습니다. 그러나 IAM 사용자는 관리 목적으로 사용되므로 웹 또는 
모바일 애플리케이션에 대한 사용자 인증에는 적합하지 않습니다. IAM 사용자는 위험 
요소를 기반으로 한 적응형 인증도 지원하지 않습니다. 따라서 선택지 C 는 올바르지 
않습니다. 
AWS IAM Identity Center(AWS Single Sign-On)는 사용자가 단일 자격 증명 세트를 사용하여 
여러 AWS 계정 및 애플리케이션에 로그인할 수 있게 해주는 서비스입니다. AWS SSO 는 
AWS SSO 디렉터리, AWS Managed Microsoft AD, 외부 자격 증명 공급자 등 다양한 자격 
증명 소스를 지원합니다. 
AWS SSO 는 또한 각 사용자의 액세스 수준을 정의하는 권한 세트에서 구성할 수 있는 
사용자 인증을 위한 MFA 를 지원합니다. 그러나 AWS SSO 는 위험 요인에 따른 적응형 
인증을 지원하지 않습니다. 따라서 옵션 D 는 올바르지 않습니다. 
Q804 
회사에 Amazon S3 데이터 레이크가 있습니다. 회사에는 데이터 레이크의 데이터를 
변환하고 매일 데이터 웨어하우스에 로드하는 솔루션이 필요합니다. 데이터 웨어하우스에는 
MPP(대량 병렬 처리) 기능이 있어야 합니다. 그런 다음 데이터 분석가는 데이터에 대해 
SQL 명령을 사용하여 기계 학습(ML) 모델을 생성하고 교육해야 합니다. 솔루션은 가능한 
경우 서버리스 AWS 서비스를 사용해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 매일 Amazon EMR 작업을 실행하여 데이터를 변환하고 Amazon Redshift 에 데이터를 
로드합니다. Amazon Redshift ML 을 사용하여 ML 모델을 생성하고 교육합니다. 
B. 매일 Amazon EMR 작업을 실행하여 데이터를 변환하고 Amazon Aurora Serverless 에 
데이터를 로드합니다. Amazon Aurora ML 을 사용하여 ML 모델을 생성하고 훈련하십시오. 
C. 매일 AWS Glue 작업을 실행하여 데이터를 변환하고 Amazon Redshift Serverless 에 
데이터를 로드합니다. Amazon Redshift ML 을 사용하여 ML 모델을 생성하고 트램합니다. 
D. 매일 AWS Glue 작업을 실행하여 데이터를 변환하고 Amazon Athena 테이블에 데이터를 
로드합니다. Amazon Athena ML 을 사용하여 ML 모델을 생성하고 훈련합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/135261-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Glue 는 분석을 위해 데이터를 쉽게 준비하고 로드할 수 있게 해주는 완전 관리형 
ETL(추출, 변환 및 로드) 서비스입니다. AWS Glue 는 Amazon S3 에서 데이터를 자동으로 
검색하고 카탈로그화할 수 있으므로 SQL 을 사용하여 데이터를 쿼리하고 검색할 수 
있습니다. AWS Glue 는 또한 Apache Spark 및 Python 을 사용하여 서버리스 ETL 작업을 
실행하여 데이터를 Amazon Redshift, Amazon Athena 또는 Amazon Aurora 와 같은 다양한 
대상으로 변환하고 로드할 수 있습니다. AWS Glue 는 서버리스 서비스이므로 작업에 사용된 
리소스에 대해서만 비용을 지불하고 인프라를 프로비저닝하거나 관리할 필요가 없습니다. 
Amazon Redshift 는 표준 SQL 과 기존 비즈니스 인텔리전스(BI) 도구를 사용하여 데이터를 
분석할 수 있게 해주는 페타바이트 규모의 완전 관리형 데이터 웨어하우스 서비스입니다. 
Amazon Redshift 는 또한 MPP(대량 병렬 처리)를 지원합니다. 즉, 여러 노드에 쿼리를 
병렬로 배포하고 실행할 수 있어 빠른 성능과 확장성을 제공할 수 있습니다. Amazon 
Redshift Serverless 는 실행 중인 쿼리에 따라 쿼리 컴퓨팅 용량을 자동으로 확장하는 
새로운 옵션이므로 클러스터나 용량을 관리할 필요가 없습니다. 쿼리 처리 시간과 데이터가 
소비한 스토리지에 대해서만 비용을 지불하면 됩니다. 
Amazon Redshift ML 은 익숙한 SQL 명령을 사용하여 기계 학습(ML) 모델을 생성, 훈련 및 
배포할 수 있는 기능입니다. Amazon Redshift ML 은 데이터에 가장 적합한 모델과 
하이퍼파라미터를 자동으로 검색하고, ML 모델 구축, 교육 및 배포를 위한 포괄적인 도구 
세트를 제공하는 완전 관리형 서비스인 Amazon SageMaker 에 모델을 저장할 수 있습니다. 
그런 다음 SQL 함수를 사용하여 Amazon Redshift 의 데이터에 모델을 적용하고 예측을 
생성할 수 있습니다. 
AWS Glue, Amazon Redshift Serverless 및 Amazon Redshift ML 의 조합은 Amazon S3 
데이터 레이크의 데이터를 변환, 로드 및 분석하기 위한 서버리스, 확장 가능한 SQL 기반 
솔루션을 제공하므로 질문의 요구 사항을 충족합니다. 데이터에 대한 ML 모델을 생성하고 
훈련합니다. 
Amazon EMR 은 서버리스 서비스가 아니기 때문에 옵션 A 가 올바르지 않습니다. Amazon 
EMR 은 AWS 에서 Apache Spark, Apache Hadoop 및 기타 빅 데이터 프레임워크 실행을 
단순화하는 관리형 서비스입니다. Amazon EMR 을 사용하려면 ETL 작업을 실행하기 위해 
EC2 인스턴스 클러스터를 시작하고 구성해야 하므로 AWS Glue 에 비해 복잡성과 비용이 
추가됩니다. 
옵션 B 는 올바르지 않습니다. Amazon Aurora Serverless 는 데이터 웨어하우스 서비스가 
아니고 MPP 를 지원하지 않기 때문입니다. Amazon Aurora Serverless 는 MySQL 및 
PostgreSQL 과 호환되는 관계형 데이터베이스 서비스인 Amazon Aurora 를 위한 온디맨드 
자동 확장 구성입니다. Amazon Aurora Serverless 는 트래픽에 따라 데이터베이스 용량을 
자동으로 조정할 수 있지만 Amazon Redshift 처럼 여러 노드에 데이터와 쿼리를 
분산시키지는 않습니다. Amazon Aurora Serverless 는 분석 워크로드보다 트랜잭션 
워크로드에 더 적합합니다. 
옵션 D 는 올바르지 않습니다. Amazon Athena 는 데이터 웨어하우스 서비스가 아니고 
MPP 를 지원하지 않기 때문입니다. 
Amazon Athena 는 표준 SQL 을 사용하여 Amazon S3 의 데이터를 분석할 수 있는 대화형 
쿼리 서비스입니다. Amazon Athena 는 서버리스이므로 실행한 쿼리에 대해서만 비용을 
지불하고 데이터를 데이터베이스에 로드할 필요가 없습니다. 그러나 Amazon Athena 는 
Amazon Redshift 처럼 데이터를 열 형식으로 저장하거나, 데이터를 압축하거나, 쿼리 실행 
계획을 최적화하지 않습니다. Amazon Athena 는 복잡한 분석 및 ML 보다 임시 쿼리에 더 
적합합니다. 
Q805 
회사는 회사 로컬 데이터 센터의 Kubernetes 환경에서 컨테이너를 실행합니다. 회사는 
Amazon Elastic Kubernetes Service(Amazon EKS) 및 기타 AWS 관리 서비스를 사용하려고 
합니다. 데이터는 회사의 데이터 센터에 로컬로 유지되어야 하며 규정 준수를 유지하기 
위해 원격 사이트나 클라우드에 저장할 수 없습니다. 이러한 요구 사항을 충족하는 
솔루션은 무엇입니까? 
A. 회사의 데이터 센터에 AWS 로컬 영역을 배포합니다. 
B. 회사 데이터 센터에서 AWS Snowmobile 을 사용합니다. 
C. 회사 데이터 센터에 AWS Outposts 랙을 설치합니다. 
D. 데이터 센터에 AWS Snowball Edge Storage Optimized 노드를 설치합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/135262-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Outposts 는 일관된 하이브리드 경험을 위해 거의 모든 온프레미스 또는 엣지 위치에 
AWS 인프라 및 서비스를 제공하는 완전관리형 서비스입니다. AWS Outposts 는 AWS 및 
온프레미스에서 Kubernetes 를 쉽게 실행할 수 있게 해주는 관리형 서비스인 Amazon 
EKS 를 지원합니다. 회사 데이터 센터에 AWS Outposts 랙을 설치하면 회사는 Amazon EKS 
및 기타 AWS 관리 서비스를 사용하여 Kubernetes 환경에서 컨테이너를 실행하는 동시에 
데이터를 회사 데이터 센터에 로컬로 유지하고 규정 준수 요구 사항을 충족할 수 있습니다. 
또한 AWS Outposts 는 광범위한 AWS 서비스에 액세스할 수 있도록 로컬 AWS 리전에 
대한 원활한 연결을 제공합니다. 
AWS 로컬 영역은 회사의 데이터 센터가 아니라 최종 사용자에게 더 가까운 대도시 지역에 
배포되므로 옵션 A 는 유효한 솔루션이 아닙니다. AWS 로컬 영역은 AWS 가 소유, 관리 및 
운영하며 공용 인터넷과 로컬 AWS 리전에 대한 지연 시간이 짧은 액세스를 제공합니다. 
옵션 B 는 유효한 솔루션이 아닙니다. AWS Snowmobile 은 세미 트레일러 트럭이 끄는 
45 피트 길이의 견고한 운송 컨테이너를 사용하여 엑사바이트 규모의 데이터를 AWS 로 
전송하는 서비스이기 때문입니다. AWS Snowmobile 은 온프레미스에서 컨테이너나 AWS 
관리형 서비스를 실행하도록 설계되지 않았지만 대규모 데이터 마이그레이션을 위해 
설계되었습니다. 
옵션 D 는 유효한 솔루션이 아닙니다. AWS Snowball Edge Storage Optimized 는 데이터 
전송 및 엣지 컴퓨팅을 위해 80TB의 HDD 또는 210TB의 NVMe 스토리지 용량을 제공하는 
장치이기 때문입니다. AWS Snowball Edge Storage Optimized 는 Amazon EKS 또는 기타 
AWS 관리형 서비스를 지원하지 않으며 Kubernetes 환경에서 컨테이너를 실행하는 데 
적합하지 않습니다. 
Q806 
소셜 미디어 회사에는 데이터를 수집하고 처리하는 워크로드가 있습니다. 워크로드는 
온프레미스 NFS 스토리지에 데이터를 저장합니다. 데이터 저장소는 회사의 확장되는 
비즈니스 요구 사항을 충족할 만큼 빠르게 확장할 수 없습니다. 회사는 현재 데이터 
스토어를 AWS 로 마이그레이션하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. AWS Storage Gateway 볼륨 게이트웨이를 설정합니다. Amazon S3 수명 주기 정책을 
사용하여 데이터를 적절한 스토리지 클래스로 전환합니다. 
B. AWS Storage Gateway Amazon S3 파일 게이트웨이를 설정합니다. Amazon S3 수명 주기 
정책을 사용하여 데이터를 적절한 스토리지 클래스로 전환합니다. 
C. Amazon Elastic File System(Amazon EFS) Standard-Infrequent Access(Standard-IA) 
스토리지 클래스를 사용합니다. 빈번하지 않은 액세스 수명주기 정책을 활성화합니다. 
D. Amazon Elastic File System(Amazon EFS) One Zone-Infrequent Access(One Zone-IA) 
스토리지 클래스를 사용합니다. 빈번하지 않은 액세스 수명주기 정책을 활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/135263-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 회사가 기존 애플리케이션이나 워크플로를 변경하지 않고도 온프레미스 NFS 
데이터 스토어를 AWS 로 마이그레이션할 수 있도록 지원하므로 가장 비용 효율적으로 요구 
사항을 충족합니다. AWS Storage Gateway 는 온프레미스와 AWS 스토리지 간의 원활하고 
안전한 통합을 제공하는 하이브리드 클라우드 스토리지 서비스입니다. Amazon S3 파일 
게이트웨이는 지연 시간이 짧은 액세스를 위한 로컬 캐싱과 함께 Amazon S3 에 파일 
인터페이스를 제공하는 AWS Storage Gateway 유형입니다. Amazon S3 파일 게이트웨이를 
설정함으로써 회사는 NFS 와 같은 표준 파일 프로토콜을 사용하여 파일을 Amazon S3 에 
객체로 저장하고 검색할 수 있습니다. 또한 회사는 Amazon S3 수명 주기 정책을 사용하여 
액세스 빈도와 스토리지 비용에 따라 데이터를 적절한 스토리지 클래스로 자동 전환할 수도 
있습니다. 예를 들어 회사는 자주 액세스하는 데이터에는 S3 Standard 를 사용하고, 자주 
액세스하지 않는 데이터에는 S3 Standard-Infrequent Access(S3 Standard-IA) 또는 S3 One 
Zone-Infrequent Access(S3 One Zone-IA)를 사용하고, S3 Glacier 또는 S3 를 사용할 수 
있습니다. 장기 보관 데이터를 위한 Glacier Deep Archive. 
옵션 A 는 유효한 솔루션이 아닙니다. AWS Storage Gateway 볼륨 게이트웨이는 지연 
시간이 짧은 액세스를 위한 로컬 캐싱과 함께 Amazon S3 에 블록 인터페이스를 제공하는 
AWS Storage Gateway 유형이기 때문입니다. 볼륨 게이트웨이는 iSCSI 프로토콜을 
사용하여 EC2 인스턴스 또는 온프레미스 서버에 볼륨을 연결해야 하기 때문에 NFS 데이터 
저장소를 마이그레이션하는 데 적합하지 않습니다. Amazon Elastic File System(Amazon 
EFS)은 고가용성, 확장성 및 성능이 필요한 워크로드용으로 설계된 완전 관리형 탄력적 
NFS 파일 시스템이므로 옵션 C 는 유효한 솔루션이 아닙니다. Amazon EFS 
Standard-Infrequent Access(Standard-IA)는 자주 액세스하지 않는 파일에 최적화된 
Amazon EFS 내의 스토리지 클래스로, GB 당 가격은 더 낮고 액세스당 가격은 더 높습니다. 
NFS 데이터 스토어 마이그레이션을 위해 Amazon EFS Standard-IA 를 사용하는 것은 
액세스 비용이 더 많이 발생하고 수명 주기 관리를 활성화하기 위한 추가 구성이 
필요하므로 비용 효율적이지 않습니다. 
Amazon EFS One Zone-Infrequent Access(One Zone-IA)는 Amazon EFS 표준 또는 표준의 
가용성과 내구성이 필요하지 않고 자주 액세스하지 않는 파일에 최적화된 Amazon EFS 
내의 스토리지 클래스이기 때문에 옵션 D 는 유효한 솔루션이 아닙니다. IA. Amazon EFS 
One Zone-IA 는 단일 가용 영역에 데이터를 저장하므로 Amazon EFS Standard-IA 에 비해 
비용이 47% 절감되지만 가용 영역에 장애가 발생할 경우 데이터 손실 위험도 높아집니다. 
NFS 데이터 스토어 마이그레이션을 위해 Amazon EFS One Zone-IA 를 사용하는 것은 
액세스 비용이 더 많이 발생하고 수명 주기 관리를 활성화하기 위한 추가 구성이 
필요하므로 비용 효율적이지 않습니다. 또한 데이터의 가용성과 내구성이 손상될 수 
있습니다. 
Q807 
한 회사는 높은 동시성 AWS Lambda 함수를 사용하여 마케팅 이벤트 중에 메시지 
대기열에서 지속적으로 증가하는 메시지 수를 처리합니다. Lambda 함수는 CPU 집약적인 
코드를 사용하여 메시지를 처리합니다. 회사는 컴퓨팅 비용을 줄이고 고객의 서비스 대기 
시간을 유지하기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Lambda 함수에 대해 예약된 동시성을 구성합니다. Lambda 함수에 할당된 메모리를 
줄입니다. 
B. Lambda 함수에 대한 예약된 동시성을 구성합니다. AWS Compute Optimizer 권장 사항에 
따라 메모리를 늘리십시오. 
C. Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. Lambda 함수에 할당된 
메모리를 줄입니다. 
D. Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. AWS Compute Optimizer 권장 
사항에 따라 메모리를 늘리십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/135552-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
회사는 메시지 대기열에서 지속적으로 증가하는 메시지 수를 처리하는 Lambda 함수에 
대해 컴퓨팅 비용을 줄이고 서비스 지연 시간을 유지하려고 합니다. 
Lambda 함수는 CPU 집약적인 코드를 사용하여 메시지를 처리합니다. 이러한 요구 사항을 
충족하려면 솔루션 설계자는 다음 솔루션을 권장해야 합니다. 
Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. 프로비저닝된 동시성은 Lambda 
함수에 할당된 사전 초기화된 실행 환경의 수입니다. 
이러한 실행 환경은 들어오는 기능 요청에 즉시 응답하여 콜드 스타트 대기 시간을 
줄입니다. 프로비저닝된 동시성을 구성하면 Lambda 서비스의 동시성 한도 도달로 인한 
조절 오류를 방지하는 데도 도움이 됩니다. 
AWS Compute Optimizer 권장 사항에 따라 메모리를 늘리십시오. AWS Compute 
Optimizer 는 사용률 데이터를 기반으로 최적의 AWS 리소스 구성에 대한 권장 사항을 
제공하는 서비스입니다. Lambda 함수에 할당된 메모리를 늘려 CPU 성능을 높이고 CPU 
집약적인 코드의 성능을 향상시킬 수도 있습니다. AWS Compute Optimizer 는 워크로드 
특성 및 성능 목표를 기반으로 Lambda 함수에 대한 최적의 메모리 크기를 찾는 데 도움이 
됩니다. 
이 솔루션은 메모리 및 CPU 리소스의 불필요한 과잉 프로비저닝을 방지하여 컴퓨팅 
비용을 절감하고, 프로비저닝된 동시성 및 Lambda 함수에 대한 최적의 메모리 크기를 
사용하여 서비스 대기 시간을 유지합니다. 
Q808 
회사는 Amazon Elastic Container Service(Amazon ECS)에서 워크로드를 실행합니다. ECS 
작업 정의에서 사용하는 컨테이너 이미지는 CVE(Common Vulnerability and Exposures)를 
검사해야 합니다. 생성된 새 컨테이너 이미지도 스캔해야 합니다. 
워크로드를 가장 적게 변경하여 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Container Registry(Amazon ECR)를 프라이빗 이미지 리포지토리로 
사용하여 컨테이너 이미지를 저장하세요. ECR 기본 검사에 대한 푸시 필터 검사를 
지정합니다. 
B. 컨테이너 이미지를 Amazon S3 버킷에 저장합니다. Amazon Macie 를 사용하여 이미지를 
스캔합니다. S3 이벤트 알림을 사용하여 s3:ObjectCreated:Put 이벤트 유형이 있는 모든 
이벤트에 대해 Macie 스캔을 시작합니다. 
C. Amazon Elastic Kubernetes Service(Amazon EKS)에 워크로드를 배포합니다. Amazon 
Elastic Container Registry(Amazon ECR)를 프라이빗 이미지 리포지토리로 사용합니다. ECR 
강화 검사를 위해 푸시 필터에 대한 검사를 지정합니다. 
D. 버전 관리가 활성화된 Amazon S3 버킷에 컨테이너 이미지를 저장합니다. 
s3:ObjectCreated:* 이벤트에 대한 S3 이벤트 알림을 구성하여 AWS Lambda 함수를 
호출합니다. Amazon Inspector 스캔을 시작하도록 Lambda 함수를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/135473-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q809 
회사는 AWS Batch 작업을 사용하여 일일 판매 프로세스를 실행합니다. 회사에는 AWS 
Batch 작업이 성공할 때 타사 보고 애플리케이션을 호출하는 서버리스 솔루션이 
필요합니다. 보고 애플리케이션에는 사용자 이름과 비밀번호 인증을 사용하는 HTTP API 
인터페이스가 있습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 수신되는 AWS Batch 작업 SUCCEEDED 이벤트와 일치하도록 Amazon EventBridge 
규칙을 구성합니다. 사용자 이름과 비밀번호를 사용하여 타사 API 를 EventBridge API 
대상으로 구성합니다. API 대상을 EventBridge 규칙 대상으로 설정합니다. 
B. 수신되는 AWS Batch 작업 SUCCEEDED 이벤트와 일치하도록 Amazon EventBridge 
Scheduler 를 구성합니다. 사용자 이름과 암호를 사용하여 타사 API 를 호출하도록 AWS 
Lambda 함수를 구성합니다. Lambda 함수를 EventBridge 규칙 대상으로 설정합니다. 
C. Amazon API Gateway REST API 에 작업 SUCCEEDED 이벤트를 게시하도록 AWS Batch 
작업을 구성합니다. 사용자 이름과 비밀번호를 사용하여 타사 API 를 호출하도록 API 
Gateway REST API 에서 HTTP 프록시 통합을 구성합니다. 
D. Amazon API Gateway REST API 에 작업 SUCCEEDED 이벤트를 게시하도록 AWS Batch 
작업을 구성합니다. API Gateway REST API 에서 AWS Lambda 함수에 대한 프록시 통합을 
구성합니다. 사용자 이름과 암호를 사용하여 타사 API 를 호출하도록 Lambda 함수를 
구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/135695-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q810 
회사는 공급업체로부터 데이터를 수집하고 처리합니다. 공급업체는 공급업체 자체 AWS 
계정에 있는 MySQL 용 Amazon RDS 데이터베이스에 데이터를 저장합니다. 회사의 
VPC 에는 인터넷 게이트웨이, AWS Direct Connect 연결 또는 AWS Site-to-Site VPN 연결이 
없습니다. 회사는 공급업체 데이터베이스에 있는 데이터에 액세스해야 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 공급업체에 AWS Hosted Connection Direct Connect 프로그램에 등록하도록 지시합니다. 
VPC 피어링을 사용하여 회사의 VPC 와 공급업체의 VPC 를 연결합니다. 
B. 회사의 VPC와 공급업체의 VPC 간에 클라이언트 VPN 연결을 구성합니다. VPC 피어링을 
사용하여 회사의 VPC 와 공급업체의 VPC 를 연결합니다. 
C. 공급업체에 NLB(Network Load Balancer)를 생성하도록 지시합니다. MySQL 용 Amazon 
RDS 데이터베이스 앞에 NLB 를 배치합니다. AWS PrivateLink 를 사용하여 회사의 VPC 와 
공급업체의 VPC 를 통합합니다. 
D. AWS Transit Gateway 를 사용하여 회사의 VPC 와 공급업체의 VPC 를 통합합니다. VPC 
피어링을 사용하여 회사의 VPC 와 공급업체의 VPC 를 연결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/135264-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q811 
한 회사에서 Amazon Managed Grafana 를 시각화 도구로 설정하려고 합니다. 회사는 
Amazon RDS 데이터베이스의 데이터를 하나의 데이터 소스로 시각화하려고 합니다. 
회사에는 인터넷을 통해 데이터가 노출되지 않는 보안 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. VPC 없이 Amazon Managed Grafana 작업 공간을 생성합니다. RDS 데이터베이스에 
대한 퍼블릭 엔드포인트를 만듭니다. Amazon Managed Grafana 에서 퍼블릭 엔드포인트를 
데이터 소스로 구성합니다. 
B. VPC 에 Amazon Managed Grafana 작업 공간을 생성합니다. RDS 데이터베이스에 대한 
프라이빗 엔드포인트를 만듭니다. Amazon Managed Grafana 에서 프라이빗 엔드포인트를 
데이터 소스로 구성합니다. 
C. VPC 없이 Amazon Managed Grafana 작업 공간을 생성합니다. AWS PrivateLink 
엔드포인트를 생성하여 Amazon Managed Grafana 와 Amazon RDS 간의 연결을 설정합니다. 
Amazon Managed Grafana 에서 Amazon RDS 를 데이터 소스로 설정합니다. 
D. VPC 에서 Amazon Managed Grafana 작업 공간을 생성합니다. RDS 데이터베이스에 대한 
퍼블릭 엔드포인트를 만듭니다. Amazon Managed Grafana 에서 퍼블릭 엔드포인트를 데이터 
소스로 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/135697-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
C?? 
Q812 
한 회사가 Amazon S3 에서 데이터 레이크를 호스팅하고 있습니다. 데이터 레이크는 다양한 
데이터 소스에서 Apache Parquet 형식으로 데이터를 수집합니다. 회사는 수집된 데이터를 
준비하기 위해 여러 변환 단계를 사용합니다. 이 단계에는 이상 항목 필터링, 데이터를 
표준 날짜 및 시간 값으로 정규화, 분석을 위한 집계 생성이 포함됩니다. 
회사는 변환된 데이터를 데이터 분석가가 액세스하는 S3 버킷에 저장해야 합니다. 
회사에는 코드가 필요하지 않은 데이터 변환을 위해 사전 구축된 솔루션이 필요합니다. 
솔루션은 데이터 계보 및 데이터 프로파일링을 제공해야 합니다. 회사는 회사 전체의 
직원과 데이터 변환 단계를 공유해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터를 변환하도록 AWS Glue Studio 시각적 캔버스를 구성합니다. AWS Glue 작업을 
사용하여 변화 단계를 직원과 공유하세요. 
B. 데이터를 변환하도록 Amazon EMR Serverless 를 구성합니다. EMR Serveriess 작업을 
사용하여 직원과 변환 단계를 공유하십시오. 
C. 데이터를 변환하도록 AWS Glue DataBrew 를 구성합니다. DataBrew 레시피를 사용하여 
변환 단계를 직원과 공유하세요. 
D. 데이터용 Amazon Athena 테이블을 생성합니다. Athena SQL 쿼리를 작성하여 데이터를 
변환합니다. Athena SQL 쿼리를 직원과 공유하세요. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/135265-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
회사의 요구 사항에 가장 적합한 솔루션은 DataBrew 레시피를 사용하여 데이터를 변환하고 
변환 단계를 직원과 공유하도록 AWS Glue DataBrew 를 구성하는 것입니다. 이 솔루션은 
코드가 필요하지 않은 데이터 변환을 위해 사전 구축된 솔루션을 제공하고 데이터 계보 및 
데이터 프로파일링도 제공합니다. 회사는 DataBrew 레시피를 사용하여 회사 전체의 직원과 
데이터 변환 단계를 쉽게 공유할 수 있습니다. 
AWS Glue DataBrew 는 데이터 분석가와 데이터 과학자가 분석 또는 기계 학습을 위해 
데이터를 최대 80% 더 빠르게 정리하고 정규화할 수 있게 해주는 시각적 데이터 준비 
도구입니다. 사용자는 Amazon S3, Amazon RDS, Amazon Redshift, Amazon Aurora 또는 
Glue Data Catalog 와 같은 다양한 소스에서 데이터를 업로드하고 포인트 앤 클릭 
인터페이스를 사용하여 250 개 이상의 기본 제공 변환을 적용할 수 있습니다. 사용자는 각 
변환 단계의 결과를 미리 보고 이것이 데이터의 품질과 분포에 어떤 영향을 미치는지 
확인할 수도 있습니다. 
DataBrew 레시피는 하나 이상의 데이터세트에 적용할 수 있는 재사용 가능한 변환 단계 
세트입니다. 사용자는 처음부터 레시피를 생성하거나 DataBrew 레시피 라이브러리의 기존 
레시피를 사용할 수 있습니다. 사용자는 또한 AWS 계정 또는 조직 내의 다른 사용자 또는 
그룹과 레시피를 내보내거나 가져오거나 공유할 수도 있습니다. 
DataBrew 는 또한 사용자가 데이터 품질을 이해하고 개선하는 데 도움이 되는 데이터 계보 
및 데이터 프로파일링 기능을 제공합니다. 데이터 계보는 각 데이터세트의 소스와 대상, 
그리고 각 레시피 단계에서 데이터가 변환되는 방식을 보여줍니다. 데이터 프로파일링은 
열과 같은 각 데이터세트에 대한 다양한 통계 및 측정항목을 표시합니다. 
Q813 
솔루션 아키텍트는 ALB(Application Load Balancer) 뒤의 개별 대상 그룹에 있는 여러 
Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 사용자는 공개 웹사이트를 통해 
애플리케이션에 접근할 수 있습니다. 
솔루션 아키텍트는 엔지니어가 웹 사이트의 개발 버전을 사용하여 하나의 특정 개발 EC2 
인스턴스에 액세스하여 애플리케이션의 새로운 기능을 테스트할 수 있도록 허용하려고 
합니다. 솔루션 아키텍트는 Amazon Route 53 호스팅 영역을 사용하여 엔지니어에게 개발 
인스턴스에 대한 액세스 권한을 제공하려고 합니다. 개발 인스턴스가 교체되더라도 
솔루션은 자동으로 개발 인스턴스로 라우팅되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. ALB 에 값이 설정된 개발 웹 사이트에 대한 A 레코드를 생성합니다. 개발 웹 사이트에 
대한 요청을 개발 인스턴스가 포함된 대상 그룹에 전달하는 리스너 규칙을 ALB 에 
생성합니다. 
B. 퍼블릭 IP 주소를 사용하여 개발 인스턴스를 다시 생성합니다. 개발 인스턴스의 퍼블릭 
IP 주소로 설정된 값을 갖는 개발 웹 사이트에 대한 A 레코드를 생성합니다. 
C. ALB 에 값이 설정된 개발 웹 사이트에 대한 A 레코드를 생성합니다. ALB 에 리스너 
규칙을 생성하여 개발 웹 사이트에 대한 요청을 개발 인스턴스의 공용 IP 주소로 
리디렉션합니다. 
D. 모든 인스턴스를 동일한 대상 그룹에 배치합니다. 개발 웹 사이트에 대한 A 레코드를 
만듭니다. 값을 ALB 로 설정합니다. 개발 웹 사이트에 대한 요청을 대상 그룹에 전달하는 
리스너 규칙을 ALB 에 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/135726-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q814 
회사는 회사 데이터 센터의 Kubernetes 클러스터에서 컨테이너 애플리케이션을 실행합니다. 
애플리케이션은 AMQP(Advanced Message Queuing Protocol)를 사용하여 메시지 큐와 
통신합니다. 데이터 센터는 회사의 확장되는 비즈니스 요구 사항을 충족할 만큼 빠르게 
확장할 수 없습니다. 회사는 워크로드를 AWS 로 마이그레이션하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 컨테이너 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)로 
마이그레이션합니다. Amazon Simple Queue Service(Amazon SQS)를 사용하여 메시지를 
검색합니다. 
B. 컨테이너 애플리케이션을 Amazon Elastic Kubernetes Service(Amazon EKS)로 
마이그레이션합니다. Amazon MQ 를 사용하여 메시지를 검색합니다. 
C. 고가용성 Amazon EC2 인스턴스를 사용하여 애플리케이션을 실행합니다. Amazon MQ 를 
사용하여 메시지를 검색합니다. 
D. AWS Lambda 함수를 사용하여 애플리케이션을 실행합니다. Amazon Simple Queue 
Service(Amazon SQS)를 사용하여 메시지를 검색합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/135266-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 회사가 최소한의 변경으로 컨테이너 애플리케이션을 AWS 로 마이그레이션하고 
관리형 서비스를 활용하여 Kubernetes 클러스터와 메시지 대기열을 실행할 수 있게 해주기 
때문에 최고의 솔루션입니다. 
Amazon EKS 를 사용하여 회사는 기존 Kubernetes 도구 및 플러그인과 호환되는 완전 
관리형 Kubernetes 제어 플레인에서 컨테이너 애플리케이션을 실행할 수 있습니다. 
Amazon EKS 는 Kubernetes 클러스터의 프로비저닝, 확장, 패치 및 보안을 처리하여 운영 
오버헤드와 복잡성을 줄입니다. Amazon MQ 를 사용함으로써 회사는 AMQP 및 기타 널리 
사용되는 메시징 프로토콜을 지원하는 완전 관리형 메시지 브로커 서비스를 사용할 수 
있습니다. Amazon MQ 는 메시지 브로커의 관리, 유지 관리 및 확장을 처리하여 메시지의 
고가용성, 내구성 및 보안을 보장합니다. 
A: 컨테이너 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)로 
마이그레이션하세요. Amazon Simple Queue Service(Amazon SQS)를 사용하여 메시지를 
검색합니다. 이 옵션은 회사가 컨테이너 오케스트레이션 플랫폼을 Kubernetes 에서 ECS 로 
변경해야 하므로 최적이 아니며, 이로 인해 추가적인 복잡성과 위험이 발생할 수 있습니다. 
또한 회사에서는 메시징 프로토콜을 AMQP 에서 SQS 로 변경해야 하며, 이는 애플리케이션 
논리와 성능에도 영향을 미칠 수 있습니다. Amazon ECS 와 Amazon SQS 는 모두 
컨테이너와 메시지의 배포 및 관리를 단순화하는 완전 관리형 서비스이지만 기존 
애플리케이션 아키텍처 및 요구 사항과 호환되지 않을 수 있습니다. 
C: 고가용성 Amazon EC2 인스턴스를 사용하여 애플리케이션을 실행합니다. Amazon MQ 를 
사용하여 메시지를 검색합니다. 이 옵션은 회사가 컨테이너 애플리케이션을 호스팅하는 
EC2 인스턴스를 관리해야 하기 때문에 이상적이지 않습니다. 회사는 EC2 인스턴스를 
프로비저닝, 구성, 확장, 패치 및 모니터링해야 하므로 운영 오버헤드와 인프라 비용이 
증가할 수 있습니다. 또한 회사는 EC2 인스턴스에 Kubernetes 소프트웨어를 설치하고 유지 
관리해야 하므로 복잡성과 위험이 가중될 수도 있습니다. Amazon MQ 는 AMQP 및 기타 
널리 사용되는 메시징 프로토콜을 지원하는 완전 관리형 메시지 브로커 서비스이지만 
관리형 Kubernetes 서비스의 부족을 보완할 수는 없습니다. 
D: AWS Lambda 함수를 사용하여 애플리케이션을 실행합니다. Amazon Simple Queue 
Service(Amazon SQS)를 사용하여 메시지를 검색합니다. AWS Lambda 는 컨테이너 
애플리케이션 실행을 직접 지원하지 않기 때문에 이 옵션은 실현 가능하지 않습니다. 
Lambda 함수는 다른 함수 및 리소스와 격리된 샌드박스 환경에서 실행됩니다. 
Lambda 에서 컨테이너 애플리케이션을 실행하려면 회사는 사용자 지정 런타임이나 
컨테이너 API 를 에뮬레이트하는 래퍼 라이브러리를 사용해야 하므로 복잡성과 오버헤드가 
추가될 수 있습니다. 또한 Lambda 함수에는 사용 가능한 CPU, 메모리 및 런타임 측면에서 
제한이 있어 애플리케이션 요구 사항에 적합하지 않을 수 있습니다. Amazon SQS 는 비동기 
통신을 지원하는 완전 관리형 메시지 대기열 서비스이지만 AMQP 또는 기타 메시징 
프로토콜은 지원하지 않습니다. 
Q815 
한 온라인 게임 회사는 여러 AWS 리전의 NLB(Network Load Balancer) 뒤에 있는 Amazon 
EC2 인스턴스에서 플랫폼을 호스팅합니다. NLB 는 인터넷을 통해 요청을 대상으로 
라우팅할 수 있습니다. 회사는 글로벌 고객 기반의 엔드투엔드 로드 시간을 줄여 고객 
플레이 경험을 개선하고자 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 각 지역에 ALB(Application Load Balancer)를 생성하여 기존 NLB 를 대체합니다. 기존 
EC2 인스턴스를 각 지역의 ALB 대상으로 등록합니다. 
B. 동일한 가중치의 트래픽을 각 지역의 NLB 로 라우팅하도록 Amazon Route 53 을 
구성합니다. 
C. 회사의 대규모 고객 기반이 있는 다른 지역에 추가 NLB 및 EC2 인스턴스를 
생성합니다. 
D. AWS Global Accelerator 에서 표준 액셀러레이터를 생성합니다. 기존 NLB 를 대상 
엔드포인트로 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/135267-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 회사는 글로벌 고객 기반의 엔드투엔드 로드 시간을 단축하고자 합니다. AWS Global 
Accelerator 는 트래픽을 가장 가까운 AWS 에지 위치로 라우팅하여 지연 시간을 줄이는 
네트워크 최적화 서비스를 제공하여 전 세계에 분산된 고객의 사용자 경험을 개선합니다. 
자세한 설명: 
* AWS Global Accelerator: 
* Global Accelerator 는 AWS 의 글로벌 네트워크 인프라를 통해 트래픽을 라우팅하여 
애플리케이션의 성능을 개선합니다. 이렇게 하면 공용 인터넷을 사용하는 것에 비해 홉 
수와 지연 시간이 줄어듭니다. 
* Global Accelerator 는 표준 가속기를 만들고 기존 NLB 를 대상 엔드포인트로 구성하여 전 
세계 사용자의 트래픽이 가장 가까운 AWS 에지 위치로 라우팅된 다음 각 지역의 NLB 로 
최적화된 경로를 통해 라우팅되도록 합니다. 이렇게 하면 글로벌 고객의 엔드투엔드 로드 
시간이 크게 개선됩니다. 
* 다른 옵션은 왜 안 되나요?: 
* 옵션 A(NLB 대신 ALB): ALB 는 HTTP/HTTPS 트래픽을 위해 설계되었으며 7 계층 기능을 
제공하지만 글로벌 고객 기반의 지연 시간 문제는 해결하지 못합니다. 여기서 핵심 문제는 
지연이며, Global Accelerator 는 이를 해결하기 위해 특별히 설계되었습니다. 
* 옵션 B(Route 53 가중치 라우팅): Route 53 은 트래픽을 다른 지역으로 라우팅할 수 
있지만 네트워크 성능을 최적화하지는 않습니다. 지연을 개선하지 않고 엔드포인트 간 
트래픽을 분산할 뿐입니다. 
* 옵션 C(더 많은 지역에 추가 NLB): 이를 통해 지연을 개선할 수 있지만 여러 지역에 
인프라를 설정해야 합니다. Global Accelerator 는 AWS 의 기존 글로벌 네트워크를 활용하는 
더 간단하고 효율적인 솔루션입니다. 
AWS 참조: 
* AWS Global Accelerator 
기존 NLB 와 함께 AWS Global Accelerator 를 사용하면 회사는 글로벌 트래픽 라우팅을 
최적화하고 지연을 최소화하여 고객 경험을 개선할 수 있습니다. 따라서 옵션 D 가 
정답입니다. 
Q816 
회사에는 SFTP 를 사용하여 여러 공급업체로부터 재무 데이터를 수집하는 온프레미스 
애플리케이션이 있습니다. 회사는 AWS 클라우드로 마이그레이션하고 있습니다. 이 회사는 
Amazon S3 API 를 사용하여 공급업체로부터 파일을 업로드하는 애플리케이션을 
만들었습니다. 
일부 공급업체는 S3 API 를 지원하지 않는 레거시 애플리케이션에서 시스템을 실행합니다. 
공급업체는 SFTP 기반 애플리케이션을 계속 사용하여 데이터를 업로드하기를 원합니다. 
회사는 레거시 애플리케이션을 사용하는 공급업체의 요구에 맞게 관리형 서비스를 
사용하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS DMS(AWS Database Migration Service) 인스턴스를 생성하여 레거시 
애플리케이션을 사용하는 공급업체의 스토리지에서 Amazon S3 로 데이터를 복제합니다. 
AWS DMS 인스턴스에 액세스하기 위한 자격 증명을 공급업체에 제공합니다. 
B. 레거시 애플리케이션을 사용하는 공급업체를 위한 AWS Transfer Family 엔드포인트를 
생성합니다. 
C. SFTP 서버를 실행하도록 Amazon EC2 인스턴스를 구성합니다. 레거시 애플리케이션을 
사용하는 공급업체에 SFTP 서버를 사용하여 데이터를 업로드하도록 지시합니다. 
D. 레거시 애플리케이션을 사용하여 SMB 파일 공유에 파일을 업로드하는 공급업체를 위해 
Amazon S3 파일 게이트웨이를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/135268-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q817 
마케팅팀에서 다가오는 종합 스포츠 이벤트를 위한 캠페인을 구축하려고 합니다. 팀은 지난 
5 년간의 뉴스 보고서를 PDF 형식으로 보유하고 있습니다. 팀에는 뉴스 보도의 내용과 
정서에 대한 인사이트를 추출할 수 있는 솔루션이 필요합니다. 솔루션은 Amazon 
Textract 를 사용하여 뉴스 보도를 처리해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 분석을 위해 추출된 통찰력을 Amazon Athena 에 제공합니다. 추출된 통찰력과 분석을 
Amazon S3 버킷에 저장합니다. 
B. 추출된 통찰력을 Amazon DynamoDB 테이블에 저장합니다. Amazon SageMaker 를 
사용하여 감정 모델을 구축하십시오. 
C. 분석을 위해 추출된 통찰력을 Amazon Comprehend 에 제공합니다. 분석을 Amazon S3 
버킷에 저장합니다. 
D. 추출된 통찰력을 Amazon S3 버킷에 저장합니다. Amazon QuickSight 를 사용하여 
데이터를 시각화하고 분석합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/135269-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q818 
회사의 애플리케이션은 여러 가용 영역에 있는 Amazon EC2 인스턴스에서 실행됩니다. 
애플리케이션은 타사 애플리케이션에서 실시간 데이터를 수집해야 합니다. 회사에는 수집된 
원시 데이터를 Amazon S3 버킷에 배치하는 데이터 수집 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터 수집을 위해 Amazon Kinesis 데이터 스트림을 생성합니다. Kinesis 데이터 
스트림을 사용하기 위해 Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. S3 
버킷을 전송 스트림의 대상으로 지정합니다. 
B. AWS Database Migration Service(AWS DMS)에서 데이터베이스 마이그레이션 작업을 
생성합니다. EC2 인스턴스의 복제 인스턴스를 소스 엔드포인트로 지정합니다. S3 버킷을 
대상 엔드포인트로 지정합니다. 기존 데이터를 마이그레이션하고 지속적인 변경 사항을 
복제하도록 마이그레이션 유형을 설정합니다. 
C. EC2 인스턴스에서 AWS DataSync 에이전트를 생성하고 구성합니다. EC2 인스턴스에서 
S3 버킷으로 데이터를 전송하도록 DataSync 작업을 구성합니다. 
D. 데이터 수집을 위해 애플리케이션에 대한 AWS Direct Connect 연결을 생성합니다. 
Amazon Kinesis Data Firehose 전송 스트림을 생성하여 애플리케이션에서 직접 PUT 작업을 
사용합니다. S3 버킷을 전송 스트림의 대상으로 지정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/135270-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
요구 사항을 충족하는 솔루션은 데이터 수집을 위한 Amazon Kinesis 데이터 스트림을 
생성하고, Kinesis 데이터 스트림을 사용하기 위한 Amazon Kinesis Data Firehose 전송 
스트림을 생성하고, S3 버킷을 전송 스트림의 대상으로 지정하는 것입니다. 
이 솔루션을 사용하면 회사의 애플리케이션이 타사 애플리케이션에서 실시간 데이터를 
수집하고 수집된 원시 데이터를 S3 버킷에 배치할 수 있습니다. Amazon Kinesis 데이터 
스트림은 수십만 개의 소스에서 데이터를 캡처하고 저장할 수 있는 확장 가능하고 내구성이 
뛰어난 스트림입니다. Amazon Kinesis Data Firehose 는 스트리밍 데이터를 S3, Amazon 
Redshift, Amazon OpenSearch Service 및 Splunk 와 같은 대상으로 전달할 수 있는 
완전관리형 서비스입니다. Amazon Kinesis Data Firehose 는 데이터를 S3 에 전달하기 전에 
변환하고 압축할 수도 있습니다. 
다른 솔루션은 실시간 데이터 수집을 지원하지 않거나, 타사 애플리케이션과 작동하지 
않거나, S3 를 대상으로 사용하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. 
AWS Database Migration Service(AWS DMS)에서 데이터베이스 마이그레이션 작업을 
생성하면 실시간 데이터 수집이 지원되지 않습니다. AWS DMS 는 주로 스트리밍 데이터가 
아닌 관계형 데이터베이스 마이그레이션을 위해 설계되었기 때문입니다. 또한 AWS 
DMS 에서는 복제 인스턴스, 소스 엔드포인트 및 대상 엔드포인트가 특정 데이터베이스 
엔진 및 버전과 호환되어야 합니다. AWS DataSync 는 애플리케이션 간이 아닌 온프레미스 
스토리지 시스템과 AWS 스토리지 서비스 간에 데이터를 전송하는 서비스이므로 EC2 
인스턴스에서 AWS DataSync 에이전트를 생성하고 구성하는 것은 타사 애플리케이션에서 
작동하지 않습니다. 또한 AWS DataSync 에서는 소스 또는 대상 서버에 에이전트를 
설치해야 합니다. 데이터 수집을 위해 애플리케이션에 대한 AWS Direct Connect 연결을 
생성하면 S3 가 대상으로 사용되지 않습니다. AWS Direct Connect 는 애플리케이션과 
스토리지 서비스 간이 아니라 온프레미스와 AWS 간에 전용 네트워크 연결을 설정하는 
서비스이기 때문입니다. 
AWS Direct Connect 를 사용하려면 AWS Direct Connect 위치에 대한 물리적 연결도 
필요합니다. 
Q819 
회사의 애플리케이션이 여러 데이터 소스로부터 데이터를 수신하고 있습니다. 데이터의 
크기는 다양하며 시간이 지남에 따라 증가할 것으로 예상됩니다. 현재 최대 크기는 
700KB 입니다. 더 많은 데이터 소스가 추가됨에 따라 데이터 볼륨과 데이터 크기가 
계속해서 증가하고 있습니다. 
회사는 Amazon DynamoDB 를 애플리케이션의 기본 데이터베이스로 사용하기로 
결정했습니다. 솔루션 설계자는 대용량 데이터를 처리하는 솔루션을 식별해야 합니다. 
어떤 솔루션이 운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족합니까? 
A. DynamoDB 항목 크기 제한을 초과하는 데이터를 필터링하는 AWS Lambda 함수를 
생성하십시오. Amazon DocumentDB(MongoDB 호환) 데이터베이스에 더 큰 데이터를 
저장합니다. 
B. 대용량 데이터를 Amazon S3 버킷에 객체로 저장합니다. DynamoDB 테이블에서 
데이터의 S3 URL 을 가리키는 속성이 있는 항목을 생성합니다. 
C. 들어오는 모든 대용량 데이터를 동일한 파티션 키를 가진 항목 컬렉션으로 분할합니다. 
BatchWriteItem API 작업을 사용하여 단일 작업으로 DynamoDB 테이블에 데이터를 씁니다. 
D. gzip 압축을 사용하여 DynamoDB 테이블에 기록되는 대형 객체를 압축하는 AWS 
Lambda 함수를 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/135302-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q820 
회사는 온프레미스 데이터 센터의 레거시 애플리케이션을 AWS 로 마이그레이션하고 
있습니다. 이 애플리케이션은 하루 종일 다양한 반복 일정에 따라 1~20 분 동안 실행되는 
수백 개의 크론 작업에 의존합니다. 
회사는 최소한의 리팩토링으로 AWS 에서 크론 작업을 예약하고 실행할 수 있는 솔루션을 
원합니다. 솔루션은 향후 이벤트에 대한 응답으로 크론 작업 실행을 지원해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 크론 작업을 위한 컨테이너 이미지를 생성합니다. Amazon EventBridge Scheduler 를 
사용하여 반복 일정을 생성합니다. cron 작업 작업을 AWS Lambda 함수로 실행합니다. 
B. 크론 작업을 위한 컨테이너 이미지를 생성합니다. Amazon Elastic Container 
Service(Amazon ECS)에서 일정 정책과 함께 AWS Batch 를 사용하여 cron 작업을 
실행합니다. 
C. 크론 작업을 위한 컨테이너 이미지를 생성합니다. Amazon EventBridge Scheduler 를 
사용하여 반복 일정을 생성합니다. AWS Fargate 에서 cron 작업을 실행합니다. 
D. 크론 작업을 위한 컨테이너 이미지를 생성합니다. 대기 상태를 사용하여 지정된 시간에 
cron 작업을 실행하는 워크플로를 AWS Step Functions 에서 생성합니다. RunTask 작업을 
사용하여 AWS Fargate 에서 cron 작업을 실행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/135271-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 최소한의 리팩토링으로 AWS 에서 크론 작업을 실행하는 데 가장 적합하며, 
향후 이벤트에 대한 응답으로 작업을 실행할 가능성도 지원합니다. 
크론 작업용 컨테이너 이미지: 크론 작업을 컨테이너화하면 작업을 실행하는 데 필요한 
환경과 종속성을 패키징하여 다양한 환경에서 일관성과 배포 용이성을 보장할 수 있습니다. 
Amazon EventBridge Scheduler: EventBridge Scheduler 를 사용하면 특정 시간이나 
간격으로 작업(크론 작업 실행 등)을 트리거할 수 있는 반복 일정을 만들 수 있습니다. 
스케줄링에 대한 세부적인 제어를 제공하고 AWS 서비스와 완벽하게 통합됩니다. 
AWS Fargate: Fargate 는 EC2 인스턴스를 관리할 필요성을 없애는 컨테이너용 서버리스 
컴퓨팅 엔진입니다. 기본 인프라에 대해 걱정하지 않고 컨테이너를 실행할 수 있습니다. 
Fargate 는 작업 요구 사항에 따라 자동으로 확장되므로 크론 작업과 같이 기간이 다를 수 
있는 작업을 실행하는 데 이상적입니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(Lambda): AWS Lambda 는 단기 실행 크론 작업을 처리할 수 있지만 실행 기간(최대 
15 분) 측면에서 제한이 있으며 최대 20 분 동안 실행되는 작업에는 적합하지 않을 수 
있습니다. 
옵션 B(ECS 의 AWS Batch): AWS Batch 는 배치 처리 및 복잡한 작업 종속성 또는 
오케스트레이션이 필요한 워크로드에 더 적합하며, 이는 간단한 크론 작업에 필요한 것보다 
더 많을 수 있습니다. 
옵션 D(대기 상태가 있는 Step Functions): Step Functions 는 오케스트레이션 기능을 
제공하지만 
이 접근 방식은 EventBridge 를 사용하여 Fargate 에서 실행하는 간단한 스케줄링과 
비교했을 때 불필요한 복잡성과 오버헤드를 도입합니다. 
Q821 
회사에서 Salesforce 를 사용합니다. 회사는 분석을 위해 기존 데이터와 지속적인 데이터 
변경 사항을 Salesforce 에서 Amazon Redshift 로 로드해야 합니다. 회사는 데이터가 공용 
인터넷을 통해 이동하는 것을 원하지 않습니다. 
최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. VPC 에서 Salesforce 로 VPN 연결을 설정합니다. AWS Glue DataBrew 를 사용하여 
데이터를 전송합니다. 
B. VPC 에서 Salesforce 로 AWS Direct Connect 연결을 설정합니다. AWS Glue DataBrew 를 
사용하여 데이터를 전송합니다. 
C. VPC 에서 Salesforce 로의 AWS PrivateLink 연결을 생성합니다. Amazon AppFlow 를 
사용하여 데이터를 전송합니다. 
D. Salesforce 에 대한 VPC 피어링 연결을 만듭니다. Amazon AppFlow 를 사용하여 
데이터를 전송합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/136993-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q822 
한 회사는 최근 애플리케이션을 AWS 로 마이그레이션했습니다. 애플리케이션은 여러 가용 
영역에 걸쳐 Auto Scaling 그룹의 Amazon EC2 Linux 인스턴스에서 실행됩니다. 
애플리케이션은 EFS Standard-Infrequent Access 스토리지를 사용하는 Amazon Elastic File 
System(Amazon EFS) 파일 시스템에 데이터를 저장합니다. 응용 프로그램은 회사의 파일을 
색인화합니다. 인덱스는 Amazon RDS 데이터베이스에 저장됩니다. 
회사는 일부 애플리케이션 및 서비스 변경을 통해 스토리지 비용을 최적화해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Intelligent-Tiering 수명주기 정책을 사용하는 Amazon S3 버킷을 생성하십시오. 모든 
파일을 S3 버킷에 복사합니다. Amazon S3 API 를 사용하여 파일을 저장하고 검색하도록 
애플리케이션을 업데이트합니다. 
B. Windows 파일 서버 파일 공유용 Amazon FSx 를 배포합니다. CIFS 프로토콜을 사용하여 
파일을 저장하고 검색하도록 애플리케이션을 업데이트합니다. 
C. OpenZFS 파일 시스템 공유용 Amazon FSx 를 배포합니다. 새 탑재 지점을 사용하여 
파일을 저장하고 검색하도록 애플리케이션을 업데이트합니다. 
D. S3 Glacier 유연한 검색을 사용하는 Amazon S3 버킷을 생성합니다. 모든 파일을 S3 
버킷에 복사합니다. Amazon S3 API 를 사용하여 파일을 표준 검색으로 저장하고 검색하도록 
애플리케이션을 업데이트합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/137046-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
Q823 
한 로봇 회사가 의료 수술을 위한 솔루션을 설계하고 있습니다. 로봇은 고급 센서, 카메라 
및 AI 알고리즘을 사용하여 환경을 인식하고 수술을 완료합니다. 
회사에는 백엔드 서비스와의 원활한 통신을 보장할 AWS 클라우드의 공용 로드 밸런서가 
필요합니다. 로드 밸런서는 쿼리 문자열을 기반으로 트래픽을 다른 대상 그룹으로 라우팅할 
수 있어야 합니다. 트래픽도 암호화되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. ACM(AWS Certificate Manager)에서 첨부된 인증서와 함께 Network Load Balancer 를 
사용하십시오. 쿼리 매개변수 기반 라우팅을 사용합니다. 
B. 게이트웨이 로드 밸런서를 사용합니다. AWS Identity and Access Management(IAM)에서 
생성된 인증서를 가져옵니다. 인증서를 로드 밸런서에 연결합니다. HTTP 경로 기반 
라우팅을 사용합니다. 
C. ACM(AWS Certificate Manager)에서 첨부된 인증서와 함께 Application Load Balancer 를 
사용합니다. 쿼리 매개변수 기반 라우팅을 사용합니다. 
D. Network Load Balancer 를 사용하십시오. AWS Identity and Access Management(IAM)에서 
생성된 인증서를 가져옵니다. 인증서를 로드 밸런서에 연결합니다. 쿼리 매개변수 기반 
라우팅을 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/136955-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q824 
회사에는 단일 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 
애플리케이션은 동일한 EC2 인스턴스에서 실행되는 MySQL 데이터베이스를 사용합니다. 
회사에는 증가된 트래픽을 처리하기 위해 가용성이 높고 자동으로 확장 가능한 솔루션이 
필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Application Load Balancer 뒤의 Auto Scaling 그룹에서 실행되는 EC2 인스턴스에 
애플리케이션을 배포합니다. 여러 개의 MySQL 호환 노드가 있는 Amazon Redshift 
클러스터를 생성합니다. 
B. Application Load Balancer 뒤에 대상 그룹으로 구성된 EC2 인스턴스에 애플리케이션을 
배포합니다. 여러 인스턴스가 있는 MySQL 용 Amazon RDS 클러스터를 생성합니다. 
C. Application Load Balancer 뒤의 Auto Scaling 그룹에서 실행되는 EC2 인스턴스에 
애플리케이션을 배포합니다. 데이터베이스 계층을 위한 Amazon Aurora Serverless MySQL 
클러스터를 생성합니다. 
D. Application Load Balancer 뒤에 대상 그룹으로 구성된 EC2 인스턴스에 애플리케이션을 
배포합니다. MySQL 커넥터를 사용하는 Redis 용 Amazon ElastiCache 클러스터를 
생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/136804-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q825 
한 회사가 데이터를 Amazon S3 버킷으로 마이그레이션할 계획입니다. 데이터는 S3 버킷 
내에서 저장 시 암호화되어야 합니다. 암호화 키는 매년 자동으로 순환되어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 데이터를 S3 버킷으로 마이그레이션합니다. Amazon S3 관리형 키(SSE-S3)로 서버 측 
암호화를 사용합니다. SSE-S3 암호화 키의 내장 키 순환 동작을 사용합니다. 
B. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. 자동 키 순환을 
활성화합니다. 고객 관리형 KMS 키를 사용하도록 S3 버킷의 기본 암호화 동작을 
설정합니다. 데이터를 S3 버킷으로 마이그레이션합니다. 
C. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. 고객 관리형 
KMS 키를 사용하도록 S3 버킷의 기본 암호화 동작을 설정합니다. 데이터를 S3 버킷으로 
마이그레이션합니다. 매년 KMS 키를 수동으로 순환합니다. 
D. 고객 키 자료를 사용하여 데이터를 암호화합니다. 데이터를 S3 버킷으로 
마이그레이션합니다. 키 자료 없이 AWS Key Management Service(AWS KMS) 키를 
생성합니다. 고객 키 자료를 KMS 키로 가져옵니다. 자동 키 순환을 활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/136805-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q826 
회사는 회사가 관리하는 온프레미스 Microsoft Active Directory 의 애플리케이션을 AWS 로 
마이그레이션하고 있습니다. 회사는 여러 AWS 계정에 애플리케이션을 배포합니다. 회사는 
AWS Organizations 를 사용하여 계정을 중앙에서 관리합니다. 
회사의 보안 팀에는 회사의 모든 AWS 계정에 대한 Single Sign-On 솔루션이 필요합니다. 
회사는 온-프레미스 Active Directory 에 있는 사용자 및 그룹을 계속 관리해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Microsoft Active Directory 용 AWS Directory Service 에서 Enterprise Edition Active 
Directory 를 생성합니다. AWS IAM ID 센터의 ID 소스로 Active Directory 를 구성합니다. 
B. AWS IAM ID 센터를 활성화합니다. Microsoft Active Directory 용 AWS Directory Service 를 
사용하여 회사의 자체 관리형 Active Directory 를 IAM Identity Center 와 연결하도록 양방향 
포리스트 신뢰 관계를 구성합니다. 
C. AWS Directory Service 를 사용하여 회사의 자체 관리형 Active Directory 와 양방향 신뢰 
관계를 생성합니다. 
D. Amazon EC2 에 ID 공급자(IdP)를 배포합니다. IdP 를 AWS IAM Identity Center 내에서 
자격 증명 소스로 연결합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/136806-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q827 
한 회사가 Amazon Aurora PostgreSQL Serverless v2 클러스터에 애플리케이션을 배포할 
계획입니다. 애플리케이션은 많은 양의 트래픽을 수신하게 됩니다. 회사는 애플리케이션의 
로드가 증가함에 따라 클러스터의 스토리지 성능을 최적화하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Aurora Standard 스토리지 구성을 사용하도록 클러스터를 구성하십시오. 
B. 클러스터 스토리지 유형을 프로비저닝된 IOPS 로 구성합니다. 
C. 클러스터 저장소 유형을 범용으로 구성합니다. 
D. Aurora I/O 최적화 스토리지 구성을 사용하도록 클러스터를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/136807-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Aurora I/O 최적화: 이 스토리지 구성은 Aurora 데이터베이스에 일관된 고성능을 
제공하도록 설계되었습니다. IOPS 를 별도로 프로비저닝할 필요 없이 워크로드가 증가함에 
따라 IOPS 를 자동으로 확장합니다. 
* 비용 효율성: Aurora I/O-Optimized 를 사용하면 사용하는 스토리지와 I/O 에 대해서만 
비용을 지불하므로 I/O 수요가 다양하고 예측할 수 없는 애플리케이션을 위한 비용 
효율적인 솔루션이 됩니다. 
* 구현: 
* Aurora PostgreSQL Serverless v2 클러스터를 생성하는 동안 I/O 최적화 스토리지 구성을 
선택합니다. 
* 스토리지 시스템은 애플리케이션 로드에 따라 자동으로 확장 및 성능 최적화를 
처리합니다. 
* 운영 효율성: 이 구성은 수동 조정의 필요성을 줄이고 추가 관리 오버헤드 없이 최적의 
성능을 보장합니다. 
Q828 
AWS 를 기반으로 운영되는 한 금융 서비스 회사는 업계 표준을 충족하도록 보안 제어를 
설계했습니다. 업계 표준에는 NIST(National Institute of Standards and Technology) 및 PCI 
DSS(지불 카드 산업 데이터 보안 표준)가 포함됩니다. 
회사의 제 3 자 감사자는 설계된 통제가 구현되었고 올바르게 작동하고 있다는 증거가 
필요합니다. 이 회사는 AWS Organizations 의 단일 조직에 수백 개의 AWS 계정을 보유하고 
있습니다. 회사는 계정 전체의 현재 통제 상태를 모니터링해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 하나의 계정을 조직 마스터 계정에서 Amazon Inspector 위임 관리자 계정으로 
지정합니다. Inspector 를 Organizations 와 통합하여 모든 AWS 계정에서 리소스를 검색하고 
스캔합니다. NIST 및 PCI DSS 에 대한 Inspector 산업 표준을 활성화합니다. 
B. 하나의 계정을 조직 마스터 계정에서 Amazon GuardDuty 위임 관리자 계정으로 
지정합니다. 지정된 GuardDuty 관리자 계정에서 GuardDuty 를 활성화하여 모든 멤버 
계정을 보호합니다. NIST 및 PCI DSS 에 대한 GuardDuty 산업 표준을 활성화합니다. 
C. 조직 마스터 계정에서 AWS CloudTrail 조직 추적을 구성합니다. 하나의 계정을 규정 
준수 계정으로 지정합니다. 규정 준수 계정에서 NIST 및 PCI DSS 에 대한 CloudTrail 보안 
표준을 활성화합니다. 
D. 하나의 계정을 조직 마스터 계정에서 AWS Security Hub 위임 관리자 계정으로 
지정합니다. 지정된 Security Hub 관리자 계정에서 모든 회원 계정에 대해 Security Hub 를 
활성화합니다. NIST 및 PCI DSS 에 대한 Security Hub 표준을 활성화합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/136994-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q829 
한 회사는 Amazon S3 버킷을 데이터 레이크 스토리지 플랫폼으로 사용합니다. S3 버킷에는 
여러 팀과 수백 개의 애플리케이션에서 무작위로 액세스하는 엄청난 양의 데이터가 
포함되어 있습니다. 회사는 S3 스토리지 비용을 절감하고 자주 액세스하는 객체에 대한 
즉각적인 가용성을 제공하고자 합니다. 
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까? 
A. 객체를 S3 Intelligent-Tiering 스토리지 클래스로 전환하는 S3 수명 주기 규칙을 
생성합니다. 
B. Amazon S3 Glacier 에 객체를 저장합니다. S3 Select 를 사용하여 애플리케이션에 
데이터에 대한 액세스 권한을 제공합니다. 
C. S3 스토리지 클래스 분석의 데이터를 사용하여 객체를 S3 Standard-Infrequent 
Access(S3 Standard-IA) 스토리지 클래스로 자동 전환하는 S3 수명 주기 규칙을 
생성합니다. 
D. 객체를 S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스로 전환합니다. 
애플리케이션에서 객체에 액세스할 때 객체를 S3 Standard 스토리지 클래스로 전환하는 
AWS Lambda 함수를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/136995-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Amazon S3 Intelligent-Tiering: 이 스토리지 클래스는 액세스 패턴이 변경될 때 두 액세스 
계층(빈번 및 드물게) 간에 데이터를 자동으로 이동하여 비용을 최적화하도록 
설계되었습니다. 성능에 영향을 주거나 운영 오버헤드 없이 비용을 절감할 수 있습니다. 
* S3 수명 주기 규칙: S3 수명 주기 규칙을 생성함으로써 회사는 객체를 지능형 계층화 
스토리지 클래스로 자동 전환할 수 있습니다. 이렇게 하면 수동 개입이 필요하지 않으며 
객체가 액세스 패턴에 따라 가장 비용 효율적인 스토리지 계층으로 이동됩니다. 
* 운영 효율성: 지능형 계층화는 추가 관리가 필요하지 않으며 자주 액세스하는 개체에 
대한 즉각적인 가용성을 제공합니다. 이는 주어진 요구 사항에 대해 운영상 가장 효율적인 
솔루션을 제공합니다. 
Q830 
회사에는 5TB 의 데이터 세트가 있습니다. 데이터 세트는 1 백만 개의 사용자 프로필과 
1 천만 개의 연결로 구성됩니다. 사용자 프로필에는 다대다 관계와 같은 연결이 있습니다. 
회사에는 최대 5 개 수준까지 상호 연결을 찾기 위한 효율적인 성능 방법이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 버킷을 사용하여 데이터 세트를 저장하십시오. Amazon Athena 를 사용하여 
SQL JOIN 쿼리를 수행하여 연결을 찾습니다. 
B. Amazon Neptune 을 사용하여 에지 및 꼭짓점과 함께 데이터 세트를 저장합니다. 
데이터를 쿼리하여 연결을 찾습니다. 
C. Amazon S3 버킷을 사용하여 데이터세트를 저장합니다. Amazon QuickSight 를 사용하여 
연결을 시각화합니다. 
D. Amazon RDS 를 사용하여 여러 테이블이 포함된 데이터 세트를 저장합니다. SQL JOIN 
쿼리를 수행하여 연결을 찾습니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/136957-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q831 
회사에는 온프레미스 환경과 AWS 간의 보안 연결이 필요합니다. 이 연결에는 높은 
대역폭이 필요하지 않으며 소량의 트래픽을 처리합니다. 연결이 빨리 설정되어야 합니다. 
이러한 유형의 연결을 설정하는 가장 비용 효율적인 방법은 무엇입니까? 
A. 클라이언트 VPN 을 구현합니다. 
B. AWS Direct Connect 를 구현합니다. 
C. Amazon EC2 에 배스천 호스트를 구현합니다. 
D. AWS Site-to-Site VPN 연결을 구현합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/136997-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS Site-to-Site VPN: 온프레미스 환경과 AWS 간에 안전하고 암호화된 연결을 
제공합니다. 낮은 대역폭과 작은 트래픽 요구에 적합한 비용 효율적인 솔루션입니다. 
* 빠른 설치: 
* Site-to-Site VPN 은 AWS 측에 가상 프라이빗 게이트웨이를 구성하고 온프레미스 측에 
고객 게이트웨이를 구성하여 빠르게 설정할 수 있습니다. 
* 표준 IPsec 프로토콜을 사용하여 VPN 터널을 설정합니다. 
* 비용 효율성: 전용 물리적 연결과 높은 설정 비용이 필요한 AWS Direct Connect 에 비해 
Site-to-Site VPN 은 비용이 적게 들고 더 작은 트래픽 요구 사항에 맞게 구현하기가 더 
쉽습니다. 
Q832 
회사에 온프레미스 SFTP 파일 전송 솔루션이 있습니다. 이 회사는 파일 전송 솔루션을 
확장하고 Amazon S3 를 사용하여 비용을 최적화하기 위해 AWS 클라우드로 
마이그레이션하고 있습니다. 회사 직원은 온프레미스 Microsoft AD(Active Directory)에 대한 
자격 증명을 사용하여 새 솔루션에 액세스합니다. 회사는 현재의 인증 및 파일 액세스 
메커니즘을 유지하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. S3 파일 게이트웨이를 구성합니다. 기존 Active Directory 를 사용하여 인증하는 파일 
게이트웨이에 SMB 파일 공유를 생성합니다. 
B. SFTP 솔루션을 실행하기 위해 Amazon EC2 인스턴스로 Auto Scaling 그룹을 구성합니다. 
60% CPU 사용률로 확장되도록 그룹을 구성합니다. 
C. SFTP 엔드포인트를 사용하여 AWS Transfer Family 서버를 생성합니다. AWS 디렉터리 
서비스 옵션을 자격 증명 공급자로 선택합니다. AD Connector 를 사용하여 온프레미스 
Active Directory 를 연결합니다. 
D. AWS Transfer Family SFTP 엔드포인트를 생성합니다. 기존 Active Directory 에 연결하기 
위한 자격 증명 공급자로 AWS Directory Service 옵션을 사용하도록 엔드포인트를 
구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/136998-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS Transfer Family: 이 서비스는 SFTP, FTPS 및 FTP 프로토콜을 사용하여 Amazon S3 
내부 및 외부로 직접 파일을 전송할 수 있는 완전관리형 지원을 제공합니다. 
* SFTP 엔드포인트: 
* AWS Transfer Family 서버를 설정하고 파일 전송을 처리하도록 SFTP 엔드포인트를 
구성합니다. 
* 이 서비스는 확장 가능하고 관리되므로 EC2 인스턴스에서 SFTP 솔루션을 실행하는 것에 
비해 운영 오버헤드가 줄어듭니다. 
* Active Directory 와의 통합: 
* Transfer Family 서버의 ID 공급자로 AWS 디렉터리 서비스 옵션을 선택합니다. 
* AD Connector 를 사용하여 온프레미스 Active Directory 를 AWS 와 연결하면 직원이 기존 
AD 자격 증명을 사용하여 SFTP 서비스에 액세스할 수 있습니다. 
* 운영 효율성: 이 솔루션은 파일 전송 및 ID 관리 모두에 관리형 서비스를 활용하여 현재 
인증 메커니즘에 대한 변경을 최소화하고 운영 오버헤드를 줄입니다. 
Q833 
한 회사에서 이벤트 기반 주문 처리 시스템을 설계하고 있습니다. 각 주문은 주문이 생성된 
후 여러 검증 단계를 거쳐야 합니다. 멱등성 AWS Lambda 함수는 각 검증 단계를 
수행합니다. 각 검증 단계는 다른 검증 단계와 독립적입니다. 개별 검증 단계에는 주문 
이벤트 정보의 하위 집합만 필요합니다. 
회사는 각 검증 단계 Lambda 함수가 함수에 필요한 주문 이벤트의 정보에만 액세스할 수 
있도록 하려고 합니다. 주문 처리 시스템의 구성요소는 향후 비즈니스 변화를 수용할 수 
있도록 느슨하게 결합되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 각 검증 단계에 대해 Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 
주문 데이터를 각 검증 단계에 필요한 형식으로 변환하고 메시지를 적절한 SQS 대기열에 
게시하는 새로운 Lambda 함수를 생성합니다. 각 검증 단계 Lambda 함수를 해당 SQS 
대기열에 구독합니다. 
B. Amazon Simple 알림 서비스(Amazon SNS) 주제를 생성합니다. SNS 주제에 대한 검증 
단계 Lambda 함수를 구독합니다. 메시지 본문 필터링을 사용하여 구독한 각 Lambda 
함수에 필요한 데이터만 보냅니다. 
C. Amazon EventBridge 이벤트 버스를 생성합니다. 각 유효성(검증) 검사 단계에 대한 
이벤트 규칙을 만듭니다. 각 대상 검증 단계 Lambda 함수에 필요한 데이터만 보내도록 
입력 변환기를 구성합니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. SQS 대기열을 
구독하고 주문 데이터를 각 검증 단계에 필요한 형식으로 변환하는 새로운 Lambda 함수를 
생성합니다. 새로운 Lambda 함수를 사용하여 별도의 스레드에서 병렬로 검증 단계 
Lambda 함수의 동기식 호출을 수행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/137000-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q834 
한 회사가 3 티어 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 애플리케이션에는 
MySQL 데이터베이스가 필요합니다. 과거에는 애플리케이션 사용자가 새 항목을 생성할 때 
애플리케이션 성능이 좋지 않다고 보고했습니다. 이러한 성능 문제는 사용자가 근무 시간 
동안 애플리케이션에서 다양한 실시간 보고서를 생성함으로써 발생했습니다. 
AWS 로 이전하면 애플리케이션의 성능을 향상시키는 솔루션은 무엇입니까? 
A. 프로비저닝된 용량을 사용하여 데이터를 Amazon DynamoDB 테이블로 가져옵니다. 
보고서에 DynamoDB 를 사용하도록 애플리케이션을 리팩터링합니다. 
B. 컴퓨팅 최적화 Amazon EC2 인스턴스에 데이터베이스를 생성합니다. 컴퓨팅 리소스가 
온프레미스 데이터베이스를 초과하는지 확인하세요. 
C. 여러 읽기 전용 복제본이 있는 Amazon Aurora MySQL 다중 AZ DB 클러스터를 
생성합니다. 보고서에 리더 엔드포인트를 사용하도록 애플리케이션을 구성합니다. 
D. Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다. 클러스터의 백업 
인스턴스를 보고서의 엔드포인트로 사용하도록 애플리케이션을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/137842-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q835 
한 회사가 AWS Direct Connect 연결을 사용하여 안전한 온프레미스 네트워크를 AWS 
클라우드로 확장하고 있습니다. 온프레미스 네트워크에는 직접적인 인터넷 액세스가 
없습니다. 온프레미스 네트워크에서 실행되는 애플리케이션은 Amazon S3 버킷을 사용해야 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 퍼블릭 가상 인터페이스(VIF)를 생성합니다. 퍼블릭 VIF 를 통해 AWS 트래픽을 
라우팅합니다. 
B. VPC 와 NAT 게이트웨이를 생성합니다. 온프레미스 네트워크에서 NAT 게이트웨이로 
AWS 트래픽을 라우팅합니다. 
C. VPC 와 Amazon S3 인터페이스 엔드포인트를 생성합니다. 온프레미스 네트워크에서 S3 
인터페이스 엔드포인트로 AWS 트래픽을 라우팅합니다. 
D. 온프레미스 네트워크와 Direct Connect 사이에 VPC 피어링 연결을 생성합니다. 피어링 
연결을 통해 AWS 트래픽을 라우팅합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/137001-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q836 
회사는 단일 AWS 지역에서 Amazon EC2 인스턴스의 Auto Scaling 그룹을 사용하여 웹 
사이트를 제공합니다. 웹사이트에는 데이터베이스가 필요하지 않습니다. 
회사는 확장되고 있으며 회사의 엔지니어링 팀은 웹 사이트를 두 번째 지역에 배포합니다. 
회사는 성장을 수용하고 재해 복구 목적을 위해 두 지역 모두에 트래픽을 분산하려고 
합니다. 솔루션은 웹 사이트가 비정상인 지역의 트래픽을 제공해서는 안 됩니다. 
이러한 요구 사항을 충족하기 위해 회사는 어떤 정책이나 리소스를 사용해야 합니까? 
A. Amazon Route 53 단순 라우팅 정책 
B. Amazon Route 53 다중값 응답 라우팅 정책 
C. 두 지역의 EC2 인스턴스 ID 를 지정하는 대상 그룹이 있는 한 지역의 Application Load 
Balancer 
D. 두 지역의 EC2 인스턴스 IP 주소를 지정하는 대상 그룹이 있는 한 지역의 Application 
Load Balancer 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/137002-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Amazon Route 53 다중 값 응답 라우팅: 이 라우팅 정책을 사용하면 Route 53 이 DNS 
쿼리에 대한 응답으로 IP 주소와 같은 여러 값을 반환할 수 있습니다. 이는 여러 리소스에 
걸쳐 트래픽을 분산할 수 있으며 트래픽이 정상 인스턴스로만 라우팅되도록 하는 상태 
확인을 포함합니다. 
* 상태 점검: 
* 웹사이트 인스턴스의 상태를 모니터링하려면 각 지역에 대한 상태 확인을 구성하세요. 
* Route 53 은 DNS 응답에 정상 인스턴스만 포함하므로 트래픽이 비정상 리전으로 
라우팅되지 않습니다. 
* 부하 분산 및 재해 복구: 
* 다중값 응답 라우팅은 서로 다른 지역의 인스턴스 간 로드 균형을 맞추는 데 도움이 
됩니다. 
* 한 지역의 인스턴스가 비정상이 되면 Route 53 은 다른 지역의 정상 인스턴스로 트래픽을 
라우팅합니다. 
* 운영 단순성: 이 솔루션은 복잡한 구성이나 추가 리소스가 필요하지 않으므로 트래픽을 
분산하고 고가용성을 보장하는 간단하면서도 효과적인 방법입니다. 
Q837 
회사는 Amazon Elastic Block Store(Amazon EBS)가 지원하는 Amazon EC2 인스턴스에서 
애플리케이션을 실행합니다. EC2 인스턴스는 최신 Amazon Linux 릴리스를 실행합니다. 
회사 직원이 25GB 이상의 파일을 저장하고 검색할 때 애플리케이션에 가용성 문제가 
발생합니다. 회사에는 EC2 인스턴스 간에 파일을 전송할 필요가 없는 솔루션이 필요합니다. 
파일은 여러 EC2 인스턴스와 여러 가용 영역에서 사용할 수 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 모든 파일을 Amazon S3 버킷으로 마이그레이션합니다. 직원에게 S3 버킷의 파일에 
액세스하도록 지시합니다. 
B. 기존 EBS 볼륨의 스냅샷을 찍습니다. EC2 인스턴스 전반에 걸쳐 스냅샷을 EBS 
볼륨으로 탑재합니다. 직원에게 EC2 인스턴스의 파일에 액세스하도록 지시합니다. 
C. 모든 EC2 인스턴스에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 
탑재합니다. 직원에게 EC2 인스턴스의 파일에 액세스하도록 지시합니다. 
D. EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 인스턴스 스토어 볼륨을 
사용하는 AMI 에서 새 EC2 인스턴스를 구성합니다. 직원에게 EC2 인스턴스의 파일에 
액세스하도록 지시합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/137843-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
여러 EC2 인스턴스와 여러 가용 영역에 걸쳐 25GB 이상의 파일을 저장하고 액세스하려면 
Amazon Elastic File System(Amazon EFS)이 적합한 솔루션입니다. Amazon EFS 는 여러 
EC2 인스턴스에 동시에 탑재할 수 있는 간단하고 확장 가능하며 탄력적인 파일 시스템을 
제공합니다. Amazon EFS 는 한 지역 내의 여러 가용 영역에 데이터를 저장하여 고가용성과 
내구성을 지원합니다. 
Q838 
한 회사가 Amazon RDS 데이터베이스를 기반으로 하는 Amazon EC2 에서 매우 민감한 
애플리케이션을 실행하고 있습니다. 규정 준수 규정에 따라 모든 개인 식별 정보(PII)는 
저장 시 암호화되어야 합니다. 
인프라에 대한 변경 사항을 최소화하면서 이 요구 사항을 충족하기 위해 솔루션 설계자는 
어떤 솔루션을 권장해야 합니까? 
A. AWS Certificate Manager 를 배포하여 인증서를 생성합니다. 인증서를 사용하여 
데이터베이스 볼륨을 암호화합니다. 
B. AWS CloudHSM 을 배포하고, 암호화 키를 생성하고, 키를 사용하여 데이터베이스 볼륨을 
암호화합니다. 
C. AWS Key Management Service(AWS KMS)를 사용하여 SSL 암호화를 구성하여 
데이터베이스 볼륨을 암호화합니다. 
D. AWS KMS(AWS Key Management Service) 키를 사용하여 Amazon Elastic Block 
Store(Amazon EBS) 암호화 및 Amazon RDS 암호화를 구성하여 인스턴스 및 데이터베이스 
볼륨을 암호화합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/138289-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* EBS 암호화: 
* 기본 EBS 암호화: 새 EBS 볼륨에 대해 활성화할 수 있습니다. 
* AWS KMS 사용: AWS KMS 키를 지정하여 데이터 암호화 및 복호화를 투명하게 
처리합니다. 
* Amazon RDS 암호화: 
* RDS 암호화: AWS KMS 를 사용하여 RDS 인스턴스의 기본 스토리지를 암호화합니다. 
* 구성: RDS 인스턴스 생성 시 암호화를 활성화하거나 기존 인스턴스를 수정하여 암호화를 
활성화합니다. 
* 최소 변경 금액: 
* EBS 와 RDS 모두 AWS KMS 를 통한 원활한 암호화를 지원하므로 기존 인프라에 대한 
변경이 최소화됩니다. 
* 애플리케이션을 수정하지 않고도 규제 요구 사항을 준수할 수 있습니다. 
* 운영 효율성: EBS 와 RDS 모두에 AWS KMS 를 사용하면 암호화에 대한 일관되고 
관리되는 접근 방식이 보장되어 키 관리가 단순화되고 보안이 강화됩니다. 
Q839 
회사는 VPC 의 프라이빗 서브넷에서 AWS Lambda 함수를 실행합니다. 서브넷에는 Amazon 
EC2 NAT 인스턴스를 통해 인터넷으로 연결되는 기본 경로가 있습니다. Lambda 함수는 
입력 데이터를 처리하고 해당 출력을 Amazon S3 에 객체로 저장합니다. 
간헐적으로 NAT 인스턴스 네트워크의 트래픽 포화로 인해 객체를 업로드하려고 시도하는 
동안 Lambda 함수가 시간 초과됩니다. 회사는 인터넷을 통하지 않고 Amazon S3 에 
액세스하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. EC2 NAT 인스턴스를 AWS 관리형 NAT 게이트웨이로 교체합니다. 
B. VPC 의 EC2 NAT 인스턴스 크기를 네트워크에 최적화된 인스턴스 유형으로 늘립니다. 
C. VP에서 Amazon S3용 게이트웨이 엔드포인트 프로비저닝서브넷의 경로 테이블을 적절히 
업데이트합니다. 
D. 전송 게이트웨이를 프로비저닝합니다. Lambda 함수가 실행 중인 프라이빗 서브넷에 
전송 게이트웨이 연결을 배치합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/137712-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Amazon S3 용 게이트웨이 엔드포인트: Amazon S3 용 VPC 엔드포인트를 사용하면 인터넷 
게이트웨이, NAT 장치, VPN 연결 또는 AWS 없이도 VPC 를 Amazon S3 에 비공개로 연결할 
수 있습니다. 
직접 연결 연결. 
* 엔드포인트 프로비저닝: 
* VPC 대시보드로 이동합니다. 
* "엔드포인트"를 선택하고 새 엔드포인트를 생성합니다. 
* S3 의 서비스 이름(com.amazonaws.region.s3)을 선택합니다. 
* 적절한 VPC 와 서브넷을 선택합니다. 
* 새 엔드포인트를 포함하도록 서브넷의 라우팅 테이블을 조정합니다. 
* 라우팅 테이블 업데이트: S3 로 향하는 트래픽을 새로 생성된 엔드포인트로 전달하도록 
서브넷의 라우팅 테이블을 수정합니다. 이렇게 하면 S3 에 대한 트래픽이 NAT 인스턴스를 
통과하지 않고 포화된 네트워크를 방지하고 시간 초과를 방지할 수 있습니다. 
* 운영 효율성: 이 솔루션은 NAT 인스턴스에 대한 종속성을 제거하고 인터넷 트래픽을 
방지하여 운영 오버헤드를 최소화하여 보다 안정적이고 안전한 S3 상호 작용을 가능하게 
합니다. 
Q840 
전 세계에 기자를 보유하고 있는 한 언론사는 AWS 에서 방송 시스템을 호스팅하고 
있습니다. 기자는 방송 시스템에 생방송을 보냅니다. 기자들은 전화기의 소프트웨어를 
사용하여 RTMP(Real Time Messaging Protocol)를 통해 라이브 스트림을 보냅니다. 
솔루션 설계자는 보고자가 최고 품질의 스트림을 전송할 수 있는 기능을 제공하는 솔루션을 
설계해야 합니다. 솔루션은 브로드캐스트 시스템에 대한 가속화된 TCP 연결을 다시 
제공해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 사용해야 합니까? 
A. Amazon CloudFront 
B. AWS Global Accelerator 
C. AWS Client VPN 
D. Amazon EC2 인스턴스 및 AWS 탄력적 IP 주소 (Amazon EC2 instances and AWS 
Elastic IP addresses) 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/136812-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS Global Accelerator: 이 서비스는 애플리케이션에 대한 글로벌 고정 진입점을 
제공하고 AWS 글로벌 네트워크를 통해 애플리케이션에 대한 경로를 최적화하여 지연 
시간을 줄이고 성능을 향상시킵니다. 
* 가속화된 TCP 연결: 
* Global Accelerator 는 AWS 글로벌 네트워크를 사용하여 트래픽을 가장 가까운 엣지 
위치로 라우팅하여 라이브 스트림의 성능과 안정성을 향상시킵니다. 
* 애플리케이션에 대한 고정 진입점 역할을 하는 고정 IP 주소를 제공하여 DNS 관리를 
단순화합니다. 
* 고품질 스트림: 
* Global Accelerator 를 활용하면 리포터는 최고 품질과 짧은 지연 시간으로 라이브 
스트림을 보낼 수 있습니다. 
* 이 서비스는 트래픽을 가장 가까운 AWS 리전으로 자동으로 다시 라우팅하여 트래픽 
급증이나 장애가 발생하는 동안에도 일관된 성능을 보장합니다. 
* 운영 효율성: Global Accelerator 를 사용하면 네트워크 설정이 단순화되고 복잡한 구성 
없이 라이브 스트리밍에 최적화된 경로가 제공되므로 실시간 스트리밍 애플리케이션을 위한 
효율적인 솔루션이 됩니다. 
Q841 
한 회사는 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS)를 사용하여 
자체 관리형 데이터베이스를 실행합니다. 이 회사는 모든 EBS 볼륨에 걸쳐 350TB 의 
데이터를 보유하고 있습니다. 회사는 EBS 스냅샷을 매일 촬영하여 1 개월간 보관합니다. 
일일 변동률은 EBS 물량의 5%입니다. 
새로운 규정으로 인해 회사는 월별 스냅샷을 7 년 동안 보관해야 합니다. 회사는 새로운 
규정을 준수하고 관리 노력을 최소화하면서 데이터를 사용할 수 있도록 백업 전략을 
변경해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. EBS 스냅샷 표준 계층에 일일 스냅샷을 1 개월 동안 보관합니다. 보존 기간이 7 년인 
월별 스냅샷을 Amazon S3 Glacier Deep Archive 에 복사합니다. 
B. 현재 EBS 스냅샷 정책을 계속 유지합니다. 보존 기간이 7 년인 Amazon EBS 스냅샷 
아카이브로 월간 스냅샷을 이동하는 새 정책을 추가합니다. 
C. EBS 스냅샷 표준 계층에 일일 스냅샷을 1 개월 동안 보관합니다. 월별 스냅샷을 7 년 
동안 표준 계층에 유지합니다. 증분 스냅샷을 사용합니다. 
D. EBS 스냅샷 표준 계층에 일일 스냅샷을 보관합니다. EBS 다이렉트 API 를 사용하여 매달 
모든 EBS 볼륨의 스냅샷을 찍습니다. Infrequent Access 계층의 Amazon S3 버킷에 
스냅샷을 7 년 동안 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/137844-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
A?? 
Q842 
한 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에 영구 데이터를 
저장하는 여러 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 AWS 관리형 
서비스 솔루션을 사용하여 데이터를 다른 AWS 리전에 복제해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. EFS-EFS 백업 솔루션을 사용하여 데이터를 다른 지역의 EFS 파일 시스템에 
복제하십시오. 
B. 야간 스크립트를 실행하여 EFS 파일 시스템의 데이터를 Amazon S3 버킷으로 
복사합니다. S3 버킷에서 S3 교차 리전 복제를 활성화합니다. 
C. 다른 리전에 VPC 를 생성합니다. 지역 간 VPC 피어를 설정합니다. 야간 rsync 를 
실행하여 원래 리전의 데이터를 새 리전으로 복사합니다. 
D. AWS 백업을 사용하여 매일 백업을 수행하고 이를 다른 리전에 복제하는 규칙으로 백업 
계획을 생성합니다. 백업 계획에 EFS 파일 시스템 리소스를 할당합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/137845-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q843 
전자상거래 회사가 온프레미스 워크로드를 AWS 클라우드로 마이그레이션하고 있습니다. 
현재 워크로드는 웹 애플리케이션과 스토리지용 백엔드 Microsoft SQL 데이터베이스로 
구성됩니다. 
회사는 판촉 행사 기간 동안 많은 양의 고객을 기대합니다. AWS 클라우드의 새로운 
인프라는 가용성과 확장성이 높아야 합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 웹 애플리케이션을 Application Load Balancer 뒤에 있는 두 개의 가용 영역에 걸쳐 두 
개의 Amazon EC2 인스턴스로 마이그레이션합니다. 두 가용 영역 모두에 읽기 전용 
복제본이 있는 Microsoft SQL Server 용 Amazon RDS 로 데이터베이스를 
마이그레이션합니다. 
B. 웹 애플리케이션을 두 가용 영역 뒤에 있는 Auto Scaling 그룹에서 실행되는 Amazon 
EC2 인스턴스로 마이그레이션합니다. 
애플리케이션 로드 밸런서. 데이터베이스 복제를 통해 별도의 AWS 지역에 걸쳐 두 개의 
EC2 인스턴스로 데이터베이스를 마이그레이션합니다. 
C. 애플리케이션 뒤의 두 가용 영역에 걸쳐 Auto Scaling 그룹에서 실행되는 Amazon EC2 
인스턴스로 웹 애플리케이션을 마이그레이션합니다. 
로드 밸런서. 다중 AZ 배포를 통해 데이터베이스를 Amazon RDS 로 마이그레이션합니다. 
D. 웹 애플리케이션을 Application Load Balancer 뒤에 있는 3 개의 가용 영역에 걸쳐 
3 개의 Amazon EC2 인스턴스로 마이그레이션합니다. 3 개의 가용 영역에 걸쳐 
데이터베이스를 3 개의 EC2 인스턴스로 마이그레이션합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/138109-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q844 
회사에는 매일 수백 개의 파일을 생성하는 온프레미스 비즈니스 애플리케이션이 있습니다. 
이러한 파일은 SMB 파일 공유에 저장되며 애플리케이션 서버에 대한 지연 시간이 짧은 
연결이 필요합니다. 새로운 회사 정책에는 애플리케이션에서 생성된 모든 파일을 AWS 에 
복사해야 한다고 명시되어 있습니다. AWS 에 대한 VPN 연결이 이미 있습니다. 
애플리케이션 개발 팀은 애플리케이션을 AWS 로 이동하는 데 필요한 코드를 수정할 시간이 
없습니다. 
애플리케이션이 AWS 에 파일을 복사할 수 있도록 솔루션 아키텍트는 어떤 서비스를 
권장해야 합니까? 
A. Amazon Elastic File System (Amazon EFS) 
B. Amazon FSx for Windows File Server 
C. AWS Snowball 
D. AWS Storage Gateway 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/138083-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
. 
Q845 
한 회사에 직원이 15 명 있습니다. 회사는 직원 시작 날짜를 Amazon DynamoDB 테이블에 
저장합니다. 회사에서는 직원의 입사 기념일에 각 직원에게 이메일 메시지를 보내려고 
합니다. 
가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. DynamoDB 테이블을 스캔하고 Amazon Simple Notification Service (Amazon SNS)를 
사용하여 필요할 때 직원에게 이메일 메시지를 보내는 스크립트를 생성합니다. cron 작업을 
사용하여 Amazon EC2 인스턴스에서 매일 이 스크립트를 실행하세요. 
B. DynamoDB 테이블을 스캔하고 Amazon Simple Queue Service (Amazon SQS)를 
사용하여 필요할 때 직원에게 이메일 메시지를 보내는 스크립트를 만듭니다. cron 작업을 
사용하여 Amazon EC2 인스턴스에서 매일 이 스크립트를 실행하세요. 
C. DynamoDB 테이블을 스캔하고 Amazon Simple Notification Service (Amazon SNS)를 
사용하여 필요할 때 직원에게 이메일 메시지를 보내는 AWS Lambda 함수를 생성합니다. 이 
Lambda 함수가 매일 실행되도록 예약하세요. 
D. DynamoDB 테이블을 스캔하고 Amazon Simple Queue Service (Amazon SQS)를 
사용하여 필요할 때 직원에게 이메일 메시지를 보내는 AWS Lambda 함수를 생성합니다. 이 
Lambda 함수가 매일 실행되도록 예약하세요. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/139191-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 운영 효율성을 위한 AWS Lambda: 
* AWS Lambda 는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 
서버리스 컴퓨팅 서비스입니다. 호출 횟수에 따라 자동으로 확장되고 EC2 인스턴스를 유지 
관리하고 모니터링할 필요가 없으므로 EC2 에서 cron 작업을 실행하는 것보다 운영 
효율성이 훨씬 높습니다. 
* Lambda 를 사용하면 함수가 사용하는 컴퓨팅 시간에 대해서만 비용을 지불하면 됩니다. 
이는 DynamoDB 테이블을 스캔하고 하루에 한 번 이메일 메시지를 보내는 것과 같은 
가벼운 작업을 처리할 때 특히 유용합니다. 
* Amazon DynamoDB: 
* DynamoDB 는 확장성이 뛰어난 완전 관리형 NoSQL 데이터베이스입니다. 테이블에는 
직원 시작 날짜가 저장되고, 오늘이 근무 기념일인 직원을 찾기 위해 테이블을 스캔하는 
것은 가벼운 작업입니다. Lambda 는 데이터 구조에 따라 DynamoDB Scan API 또는 쿼리를 
사용하여 이 작업을 쉽게 수행할 수 있습니다. 
* 이메일 알림을 위한 Amazon SNS: 
* Amazon Simple Notification Service(SNS)는 이메일을 포함한 다양한 엔드포인트에 알림을 
보내는 것을 지원하는 완전 관리형 메시징 서비스입니다. SNS 는 팬아웃 메시징 패턴(여러 
수신자에게 동일한 메시지 보내기)을 처리할 수 있으므로 직원에게 이메일 메시지를 보내는 
데 적합합니다. 
* 이 시나리오에서 Lambda 는 근무 기념일이 있는 직원을 식별하면 SNS 를 사용하여 
이메일 알림을 효율적으로 보낼 수 있습니다. SNS 는 Lambda 와 완벽하게 통합되며 SNS 를 
통해 이메일을 보내는 것은 이러한 유형의 사용 사례에 대한 일반적인 패턴입니다. 
* 이벤트 스케줄링: 
* 이 일일 작업을 자동화하려면 Amazon EventBridge(이전 명칭 CloudWatch Events)를 
사용하여 Lambda 함수를 스케줄링할 수 있습니다. EventBridge 는 일일 스케줄(Cron 과 
유사한 스케줄링)로 Lambda 함수를 트리거할 수 있습니다. 이렇게 하면 EC2 인스턴스에서 
Cron 작업을 수동으로 설정하는 복잡성과 운영 오버헤드를 피할 수 있습니다. 
* EC2 나 SQS 가 아닌 이유는?: 
* 옵션 A 및 B 는 Amazon EC2 인스턴스에서 Cron 작업을 실행하는 것을 제안합니다. 이 
접근 방식은 EC2 인스턴스를 관리, 확장 및 패치해야 하므로 운영 오버헤드가 증가합니다. 
Lambda 는 자동으로 확장되고 서버 관리가 필요하지 않기 때문에 더 나은 선택입니다. 
* Amazon Simple Queue Service(SQS)는 분산 시스템을 분리하는 데 이상적이지만 이 
맥락에서는 필요하지 않습니다. 그 이유는 직원의 근무 기념일에 알림을 보내는 것이 
목표이기 때문입니다. 
SQS 는 이 간단한 사용 사례에 불필요한 복잡성을 더하는데, SNS 가 더 간단하고 효율적인 
솔루션이기 때문입니다. 
Q846 
회사의 애플리케이션이 Elastic Load Balancer 뒤의 Auto Scaling 그룹 내의 Amazon EC2 
인스턴스에서 실행되고 있습니다. 애플리케이션 기록을 토대로 회사에서는 매년 휴일 동안 
트래픽이 급증할 것으로 예상합니다. 솔루션 아키텍트는 Auto Scaling 그룹이 애플리케이션 
사용자에 대한 성능 영향을 최소화하기 위해 용량을 사전에 늘리도록 하는 전략을 설계해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. CPU 사용률이 90%를 초과하면 EC2 인스턴스를 확장하기 위해 Amazon CloudWatch 
경보를 생성합니다. 
B. 예상되는 최고 수요 기간 이전에 Auto Scaling 그룹을 확장하기 위해 반복 예약 작업을 
생성합니다. 
C. 피크 수요 기간 동안 Auto Scaling 그룹의 최소 및 최대 EC2 인스턴스 수를 늘립니다. 
D. Auto Scaling:EC2_INSTANCE_LAUNCH 이벤트가 있을 때 알림을 보내도록 Amazon 
Simple Notification Service (Amazon SNS) 알림을 구성합니다. 
Answer: B 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139063-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
. 
Q847 
한 회사는 데이터 계층으로 PostgreSQL 데이터베이스용 Amazon RDS 를 사용합니다. 
회사는 데이터베이스에 대한 비밀번호 교체를 구현해야 합니다. 
최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Secrets Manager 에 비밀번호를 저장하세요. 보안 비밀에 대한 자동 교체를 
활성화합니다. 
B. AWS Systems Manager Parameter Store 에 비밀번호를 저장합니다. 매개변수에 대한 
자동 회전을 활성화합니다. 
C. AWS Systems Manager Parameter Store 에 비밀번호를 저장합니다. 비밀번호를 교체하는 
AWS Lambda 함수를 작성합니다. 
D. AWS Key Management Service(AWS KMS)에 비밀번호를 저장합니다. 고객 마스터 
키(CMK)에서 자동 교체를 활성화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/138644-exam-aws-certified-sol
utions-architect-associate-saa-c03 
. 
Q848 
한 회사가 Oracle Database Enterprise Edition 에서 애플리케이션을 실행하고 있습니다. 
회사는 애플리케이션과 데이터베이스를 AWS 로 마이그레이션해야 합니다. 회사는 AWS 로 
마이그레이션하는 동안 BYOL(Bring Your Own License) 모델을 사용할 수 있습니다. 
애플리케이션은 권한 있는 액세스가 필요한 타사 데이터베이스 기능을 사용합니다. 
솔루션 설계자는 데이터베이스 마이그레이션을 위한 솔루션을 설계해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 기본 도구를 사용하여 데이터베이스를 Oracle 용 Amazon RDS 로 마이그레이션합니다. 
타사 기능을 AWS Lambda 로 대체합니다. 
B. 기본 도구를 사용하여 데이터베이스를 Oracle 용 Amazon RDS Custom 으로 
마이그레이션합니다. 타사 기능을 지원하도록 새 데이터베이스 설정을 사용자 정의합니다. 
C. AWS Database Migration Service (AWS DMS)를 사용하여 데이터베이스를 Amazon 
DynamoDB 로 마이그레이션합니다. 타사 기능을 지원하도록 새 데이터베이스 설정을 
사용자 정의합니다. 
D. AWS Database Migration Service (AWS DMS)를 사용하여 데이터베이스를 PostgreSQL 용 
Amazon RDS 로 마이그레이션합니다. 타사 기능에 대한 종속성을 제거하려면 애플리케이션 
코드를 다시 작성하세요. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/138645-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Oracle 용 Amazon RDS Custom: 이 서비스를 사용하면 기존 Oracle 데이터베이스 
라이선스를 가져올 수 있으며 데이터베이스 설정을 사용자 지정할 수 있는 유연성을 
제공하므로 권한 있는 액세스와 타사 데이터베이스 기능이 필요한 애플리케이션에 
적합합니다. 
* BYOL(기존 라이센스 가져오기): 
* RDS Custom 은 BYOL 모델을 지원하므로 기존 Oracle 라이선스를 사용하고 라이선스 
요구 사항을 준수할 수 있습니다. 
* 이는 기존 투자를 활용하고 마이그레이션 비용을 줄이는 데 도움이 됩니다. 
* 사용자 정의 및 타사 기능: 
* RDS Custom 을 사용하면 표준 RDS 인스턴스에 비해 데이터베이스 환경을 더욱 
심층적으로 사용자 지정할 수 있습니다. 
* 이를 통해 큰 변경 없이 애플리케이션이 의존하는 타사 기능을 지원할 수 있습니다. 
* 마이그레이션 프로세스: 
* Data Pump 또는 RMAN 과 같은 기본 Oracle 도구를 사용하여 데이터베이스를 RDS 
Custom 으로 마이그레이션합니다. 
* 타사 기능과의 호환성을 보장하기 위해 마이그레이션 후 데이터베이스 설정을 사용자 
정의합니다. 
Q849 
한 대규모 국제 대학이 모든 컴퓨팅 서비스를 AWS 클라우드에 배포했습니다. 이러한 
서비스에는 Amazon EC2, Amazon RDS 및 Amazon DynamoDB 가 포함됩니다. 이 대학은 
현재 인프라를 백업하기 위해 많은 사용자 정의 스크립트를 사용하고 있습니다. 그러나 
대학에서는 AWS 기본 옵션을 사용하여 관리를 중앙 집중화하고 데이터 백업을 최대한 
자동화하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Storage Gateway 테이프 게이트웨이 가상 테이프 라이브러리와 함께 타사 백업 
소프트웨어를 사용하십시오. 
B. AWS Backup 을 사용하여 사용 중인 서비스에 대한 모든 백업을 구성하고 
모니터링합니다. 
C. AWS Config 를 사용하여 일정에 따라 모든 데이터 소스의 스냅샷을 찍도록 수명 주기 
관리를 설정합니다. 
D. AWS 시스템 관리자 상태 관리자를 사용하여 백업 작업의 구성 및 모니터링을 
관리합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/137928-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q850 
한 회사는 보안 위험을 초래하는 리소스에 대한 정책을 식별하고 시행하기 위해 IT 인프라 
맵을 구축하려고 합니다. 회사의 보안팀은 IT 인프라 맵의 데이터를 쿼리하고 보안 위험을 
신속하게 식별할 수 있어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon RDS 를 사용하여 데이터를 저장하십시오. SQL 을 사용하여 데이터를 쿼리하여 
보안 위험을 식별합니다. 
B. Amazon Neptune 을 사용하여 데이터를 저장합니다. SPARQL 을 사용하여 데이터를 
쿼리하여 보안 위험을 식별합니다. 
C. Amazon Redshift 를 사용하여 데이터를 저장하십시오. SQL 을 사용하여 데이터를 
쿼리하여 보안 위험을 식별합니다. 
D. Amazon DynamoDB 를 사용하여 데이터를 저장합니다. PartiQL 을 사용하여 데이터를 
쿼리하여 보안 위험을 식별합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/137910-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q851 
한 대기업은 전 세계에 위치한 개발자에게 개발 목적으로 별도의 제한된 크기의 관리형 
PostgreSQL 데이터베이스를 제공하려고 합니다. 데이터베이스의 볼륨이 작아집니다. 
개발자는 적극적으로 작업할 때만 데이터베이스가 필요합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 개발자에게 별도의 Amazon Aurora 인스턴스를 시작할 수 있는 기능을 제공하십시오. 
근무일이 끝나면 Aurora 인스턴스를 종료하고 다음 근무일이 시작될 때 Aurora 인스턴스를 
시작하는 프로세스를 설정하십시오. 
B. Amazon Aurora 인스턴스 시작에 대한 크기 제한을 적용하는 AWS Service Catalog 
제품을 개발합니다. 개발자에게 개발 데이터베이스가 필요할 때 제품을 시작할 수 있는 
액세스 권한을 부여하십시오. 
C. Amazon Aurora 서버리스 클러스터를 생성합니다. 기본 용량 설정으로 클러스터에서 
데이터베이스를 시작하는 AWS Service Catalog 제품을 개발합니다. 개발자에게 제품에 대한 
액세스 권한을 부여합니다. 
D. AWS Trusted Advisor 가 유휴 Amazon RDS 데이터베이스를 확인하는지 모니터링합니다. 
식별된 유휴 RDS 데이터베이스를 종료하는 프로세스를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/139065-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q852 
한 회사에서 콘텐츠 관리 시스템을 제공하는 웹 애플리케이션을 구축하고 있습니다. 콘텐츠 
관리 시스템은 Amazon EC2 인스턴스에서 실행됩니다. 
애플리케이션 로드 밸런서(ALB). EC2 인스턴스는 여러 가용 영역에 걸쳐 Auto Scaling 
그룹에서 실행됩니다. 사용자는 콘텐츠 관리 시스템에 파일, 블로그 및 기타 웹사이트 
자산을 지속적으로 추가하고 업데이트하고 있습니다. 
솔루션 아키텍트는 모든 EC2 인스턴스가 지연 시간을 최소화하면서 최신 웹 사이트 
콘텐츠를 공유하는 솔루션을 구현해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 가장 최근에 시작된 EC2 인스턴스에서 웹 사이트 자산을 복사하려면 Auto Scaling 그룹 
수명 주기 정책에서 EC2 사용자 데이터를 업데이트하세요. 최신 EC2 인스턴스에서만 웹 
사이트 자산을 변경하도록 ALB 를 구성합니다. 
B. 웹 사이트 자산을 Amazon Elastic File System(Amazon EFS) 파일 시스템에 복사합니다. 
EFS 파일 시스템을 로컬로 탑재하도록 각 EC2 인스턴스를 구성합니다. EFS 파일 시스템에 
저장된 웹 사이트 자산을 참조하도록 웹 사이트 호스팅 애플리케이션을 구성합니다. 
C. 웹사이트 자산을 Amazon S3 버킷에 복사합니다. 각 EC2 인스턴스가 S3 버킷에서 
연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 웹 사이트 자산을 
다운로드하는지 확인하십시오. 파일을 최신 상태로 유지하려면 매 시간마다 S3 sync 명령을 
실행하세요. 
D. 웹 사이트 자산을 사용하여 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 
복원합니다. 새 EC2 인스턴스가 시작되면 EBS 스냅샷을 보조 EBS 볼륨으로 연결합니다. 
보조 EBS 볼륨에 저장된 웹 사이트 자산을 참조하도록 웹 사이트 호스팅 애플리케이션을 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139090-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
. 
Q853 
회사의 웹 애플리케이션은 VPC 의 Application Load Balancer 뒤에서 실행되는 여러 
Amazon EC2 인스턴스로 구성됩니다. MySQL DB 인스턴스용 Amazon RDS 에는 데이터가 
포함되어 있습니다. 회사에는 AWS 환경에서 의심스럽거나 예상치 못한 동작을 자동으로 
감지하고 대응할 수 있는 기능이 필요합니다. 이 회사는 이미 자사 아키텍처에 AWS WAF를 
추가했습니다. 
솔루션 설계자는 위협으로부터 보호하기 위해 다음으로 무엇을 해야 합니까? 
A. Amazon GuardDuty 를 사용하여 위협 탐지를 수행하십시오. GuardDuty 결과를 
필터링하고 AWS Lambda 함수를 호출하여 AWS WAF 규칙을 조정하도록 Amazon 
EventBridge(Amazon CloudWatch 이벤트)를 구성합니다. 
B. AWS Firewall Manager 를 사용하여 위협 탐지를 수행합니다. Firewall Manager 결과를 
필터링하고 AWS Lambda 함수를 호출하여 AWS WAF 웹 ACL 을 조정하도록 Amazon 
EventBridge(Amazon CloudWatch 이벤트)를 구성합니다. 
C. Amazon Inspector 를 사용하여 위협 탐지를 수행하고 AWS WAF 규칙을 업데이트합니다. 
웹 애플리케이션에 대한 액세스를 제한하려면 VPC 네트워크 ACL 을 만듭니다. 
D. Amazon Macie 를 사용하여 위협 탐지를 수행하고 AWS WAF 규칙을 업데이트합니다. 웹 
애플리케이션에 대한 액세스를 제한하려면 VPC 네트워크 ACL 을 만듭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/137862-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
. 
Q854 
한 회사가 Amazon Aurora 데이터베이스에 연결되는 Amazon EC2 인스턴스 그룹을 실행할 
계획입니다. 이 회사는 EC2 인스턴스와 Aurora DB 클러스터를 배포하기 위해 AWS 
CloudFormation 템플릿을 구축했습니다. 회사는 인스턴스가 안전한 방식으로 
데이터베이스에 인증되도록 허용하려고 합니다. 회사는 정적 데이터베이스 자격 증명을 
유지하고 싶지 않습니다. 
최소한의 운영 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 사용자 이름과 비밀번호를 사용하여 데이터베이스 사용자를 생성합니다. CloudFormation 
템플릿에 데이터베이스 사용자 이름 및 비밀번호에 대한 매개변수를 추가합니다. 
인스턴스가 시작될 때 매개변수를 EC2 인스턴스에 전달합니다. 
B. 사용자 이름과 비밀번호를 사용하여 데이터베이스 사용자를 생성합니다. AWS Systems 
Manager Parameter Store 에 사용자 이름과 암호를 저장합니다. Parameter Store 에서 
데이터베이스 자격 증명을 검색하도록 EC2 인스턴스를 구성합니다. 
C. IAM 데이터베이스 인증을 사용하도록 DB 클러스터를 구성합니다. IAM 인증에 사용할 
데이터베이스 사용자를 생성합니다. 인스턴스의 애플리케이션이 데이터베이스에 액세스할 
수 있도록 역할을 EC2 인스턴스와 연결합니다. 
D. IAM 사용자와 함께 IAM 데이터베이스 인증을 사용하도록 DB 클러스터를 구성합니다. 
IAM 사용자와 일치하는 이름을 가진 데이터베이스 사용자를 생성합니다. IAM 사용자를 EC2 
인스턴스와 연결하여 인스턴스의 애플리케이션이 데이터베이스에 액세스할 수 있도록 
합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/139091-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
. 
Q855 
회사에서는 SSL/TLS 인증서를 사용하도록 Amazon CloudFront 배포를 구성하려고 합니다. 
회사는 배포에 기본 도메인 이름을 사용하기를 원하지 않습니다. 대신 회사는 배포에 다른 
도메인 이름을 사용하기를 원합니다. 
추가 비용이 발생하지 않고 인증서를 배포할 수 있는 솔루션은 무엇인가요? 
A. useast-1 지역의 AWS Certificate Manager(ACM)에서 Amazon 에서 발급한 사설 
인증서를 요청합니다. 
B. uswest-1 리전의 AWS Certificate Manager(ACM)에서 Amazon 발급 사설 인증서를 
요청합니다. 
C. us-east-1 지역의 AWS Certificate Manager(ACU)에서 Amazon 발급 공인 인증서를 
요청합니다. 
D. us-west-1 지역의 AWS Certificate Manager(ACU)에서 Amazon 발급 공인 인증서를 
요청합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/137823-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 옵션은 AWS 서비스와 함께 사용할 공개 및 비공개 SSL/TLS 인증서를 쉽게 프로비저닝, 
관리 및 배포할 수 있는 서비스인 AWS Certificate Manager(ACM)에서 Amazon 에서 발급한 
공개 인증서를 요청하기 때문에 가장 효율적입니다. 내부 연결 자원. 또한 CloudFront 에서 
ACM 인증서를 사용하는 데 필요한 us-east-1 리전에서 인증서를 요청합니다. 또한 
ACM 은 지원되는 AWS 서비스와 함께 사용되는 인증서에 대해 비용을 청구하지 않으므로 
추가 비용 없이 인증서를 배포해야 한다는 요구 사항을 충족합니다. 이 솔루션은 SSL/TLS 
인증서를 사용하고 배포에 다른 도메인 이름을 사용하도록 CloudFront 배포를 구성해야 
하는 요구 사항을 충족합니다. 
옵션 A 는 조직 또는 Virtual Private Cloud(VPC) 내에서만 사용할 수 있는 인증서 유형인 
ACM 에서 Amazon 에서 발급한 사설 인증서를 요청하기 때문에 효율성이 떨어집니다. 
그러나 CloudFront 에는 공개 인증서가 필요하므로 이는 SSL/TLS 인증서를 사용하도록 
CloudFront 배포를 구성해야 하는 요구 사항을 충족하지 않습니다. 또한 올바른 us-east-1 
리전에서 인증서를 요청합니다. 
옵션 B 는 옵션 A 와 같은 이유로 올바르지 않은 ACM 에서 Amazon 에서 발급한 사설 
인증서를 요청하기 때문에 효율성이 떨어집니다. 또한 us-west-1 리전에서 인증서를 
요청합니다. us-east-1 지역. 
옵션 D 는 ACM 에서 Amazon 이 발행한 공용 인증서를 요청하기 때문에 효율성이 
떨어집니다. 이는 올바른 것입니다. 
하지만 us-west-1 리전에서 인증서를 요청합니다. 이는 CloudFront 가 us-east-1 리전의 
인증서를 요구하기 때문에 올바르지 않습니다. 
Q856 
회사는 운영 데이터를 생성하고 Amazon S3 버킷에 데이터를 저장합니다. 회사의 연간 
감사를 위해 외부 컨설턴트는 S3 버킷에 저장된 연간 보고서에 액세스해야 합니다. 외부 
컨설턴트는 7 일 동안 보고서에 액세스해야 합니다. 회사는 외부 컨설턴트가 보고서에만 
접근할 수 있도록 하는 솔루션을 구현해야 합니다. 
가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 공개 정적 웹 사이트를 호스팅하도록 구성된 새 S3 버킷을 생성하십시오. 작업 
데이터를 새 S3 버킷으로 마이그레이션합니다. S3 웹사이트 URL 을 외부 컨설턴트와 
공유하세요. 
B. 7 일 동안 S3 버킷에 대한 공개 액세스를 활성화합니다. 외부 컨설턴트가 감사를 
완료하면 S3 버킷에 대한 액세스 권한을 제거합니다. 
C. S3 버킷의 보고서에 액세스할 수 있는 새 IAM 사용자를 생성합니다. 외부 컨설턴트에게 
액세스 키를 제공합니다. 7 일 후에 액세스 키를 취소합니다. 
D. S3 버킷의 보고서 위치에 필요한 액세스 권한이 있는 미리 서명된 URL 을 생성합니다. 
미리 서명된 URL 을 외부 컨설턴트와 공유하세요. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/139092-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q857 
한 회사는 Amazon EC2 인스턴스에서 고성능 컴퓨팅(HPC) 워크로드를 실행할 계획입니다. 
워크로드에는 긴밀하게 결합된 노드 간 통신을 통해 대기 시간이 짧은 네트워크 성능과 
높은 네트워크 처리량이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 클러스터 배치 그룹의 일부가 되도록 EC2 인스턴스를 구성합니다. 
B. 전용 인스턴스 테넌시를 사용하여 EC2 인스턴스를 시작합니다. 
C. EC2 인스턴스를 스팟 인스턴스로 시작합니다. 
D. EC2 인스턴스가 시작될 때 온디맨드 용량 예약을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/137826-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 클러스터 배치 그룹: 이 유형의 배치 그룹은 단일 가용 영역 내에서 인스턴스를 
그룹화하여 지연 시간이 짧은 네트워크 성능과 높은 처리량을 제공하도록 설계되었습니다. 
긴밀하게 결합된 노드 간 통신이 필요한 애플리케이션에 이상적입니다. 
* 구성: 
* EC2 인스턴스를 시작할 때 클러스터 배치 그룹에서 시작하는 옵션을 지정합니다. 
* 이렇게 하면 인스턴스가 물리적으로 서로 가깝게 위치하여 대기 시간이 줄어들고 
네트워크 처리량이 늘어납니다. 
* 이익: 
* 짧은 지연 시간 통신: 클러스터 배치 그룹의 인스턴스는 향상된 네트워킹 기능을 
활용하여 지연 시간이 짧은 통신을 가능하게 합니다. 
* 높은 네트워크 처리량: 클러스터 배치 그룹 내의 네트워크 성능은 HPC 워크로드에 
필수적인 높은 처리량에 최적화되어 있습니다. 
Q858 
회사에는 500 마일(804.7km) 떨어져 있고 고속 광섬유 케이블로 상호 연결된 기본 및 보조 
데이터 센터가 있습니다. 이 회사는 미션 크리티컬 워크로드를 위해 데이터 센터와 AWS 
기반 VPC 간에 가용성이 높고 안전한 네트워크 연결이 필요합니다. 솔루션 아키텍트는 
최대의 복원력을 제공하는 연결 솔루션을 선택해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 두 개의 개별 장치에 있는 두 개의 Direct Connect 위치에서 종료되는 기본 데이터 
센터의 두 개의 AWS Direct Connect 연결 
B. 동일한 장치의 하나의 Direct Connect 위치에서 종료되는 각 기본 및 보조 데이터 
센터의 단일 AWS Direct Connect 연결 
C. 두 개의 개별 장치에 있는 두 개의 Direct Connect 위치에서 종료되는 각 기본 및 보조 
데이터 센터의 두 개의 AWS Direct Connect 연결 
D. 두 개의 개별 장치에 있는 하나의 Direct Connect 위치에서 종료되는 각 기본 및 보조 
데이터 센터의 단일 AWS Direct Connect 연결 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/140682-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
. 
Q859 
한 회사는 활용도가 높은 Oracle On-Demand DB 인스턴스용 Amazon RDS 를 여러 개 
실행하고 있습니다. RDS DB 인스턴스는 AWS Organizations 의 조직에 있는 멤버 계정에서 
실행됩니다. 
회사의 재무팀은 조직의 마스터 계정 및 회원 계정에 액세스할 수 있습니다. 재무팀은 AWS 
Trusted Advisor 를 사용하여 비용을 최적화하는 방법을 찾고 있습니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 마스터 계정에서 Trusted Advisor 권장 사항을 사용하십시오. 
B. RDS DB 인스턴스가 실행 중인 멤버 계정에서 Trusted Advisor 권장 사항을 사용합니다. 
C. Amazon RDS 예약 인스턴스 최적화에 대한 Trusted Advisor 점검을 검토합니다. 
D. Amazon RDS 유휴 DB 인스턴스에 대한 Trusted Advisor 점검을 검토합니다. 
E. 컴퓨팅 최적화에 대한 Trusted Advisor 검사를 검토합니다. AWS Compute Optimizer 를 
사용하여 결과를 교차 확인합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/137827-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q860 
솔루션 설계자가 애플리케이션을 생성 중입니다. 애플리케이션은 VPC 의 여러 가용 영역에 
걸쳐 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행됩니다. EC2 인스턴스는 기밀 
정보가 포함된 대용량 파일에 자주 액세스합니다. 이러한 파일은 처리를 위해 Amazon S3 
버킷에 저장됩니다. 솔루션 설계자는 데이터 전송 비용을 최소화하기 위해 네트워크 
아키텍처를 최적화해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. VPC 에서 Amazon S3 에 대한 게이트웨이 엔드포인트를 생성합니다. 프라이빗 서브넷의 
라우팅 테이블에서 게이트웨이 엔드포인트에 대한 항목을 추가합니다. 
B. 퍼블릭 서브넷에 단일 NAT 게이트웨이를 생성합니다. 프라이빗 서브넷의 라우팅 
테이블에서 NAT 게이트웨이를 가리키는 기본 경로를 추가합니다. 
C. VP 에서 Amazon S3 용 AWS PrivateLink 인터페이스 엔드포인트를 생성합니다. 프라이빗 
서브넷의 라우팅 테이블에서 인터페이스 엔드포인트에 대한 항목을 추가합니다. 
D. 퍼블릭 서브넷의 각 가용 영역에 대해 하나의 NAT 게이트웨이를 생성합니다. 프라이빗 
서브넷의 각 라우팅 테이블에서 동일한 가용 영역에 있는 NAT 게이트웨이를 가리키는 기본 
경로를 추가합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/137828-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q861 
한 회사에서 온프레미스 MySQL 데이터베이스를 AWS 로 이전하려고 합니다. 
데이터베이스는 클라이언트 측 애플리케이션에서 정기적으로 가져오기를 허용하므로 쓰기 
작업의 양이 많아집니다. 회사에서는 트래픽 양으로 인해 애플리케이션 내에서 성능 문제가 
발생할 수 있다는 점을 우려하고 있습니다. 
솔루션 아키텍트는 AWS 에서 아키텍처를 어떻게 설계해야 합니까? 
A. 프로비저닝된 IOPS SSD 스토리지를 사용하여 MySQL DB 인스턴스용 Amazon RDS 를 
프로비저닝합니다. Amazon CloudWatch 를 사용하여 쓰기 작업 지표를 모니터링합니다. 
필요한 경우 프로비저닝된 IOPS 를 조정합니다. 
B. 범용 SSD 스토리지를 갖춘 MySQL DB 인스턴스용 Amazon RDS 를 프로비저닝합니다. 
DB 인스턴스 앞에 Amazon ElastiCache 클러스터를 배치합니다. 대신 ElastiCache 를 
쿼리하도록 애플리케이션을 구성하십시오. 
C. 메모리 최적화 인스턴스 유형으로 Amazon DocumentDB(MongoDB 호환) 인스턴스를 
프로비저닝합니다. 성능 관련 문제가 있는지 Amazon CloudWatch 를 모니터링합니다. 
필요한 경우 인스턴스 클래스를 변경합니다. 
D. 범용 성능 모드에서 Amazon Elastic File System(Amazon EFS) 파일 시스템을 
프로비저닝합니다. IOPS 병목 현상이 있는지 Amazon CloudWatch 를 모니터링합니다. 
필요한 경우 프로비저닝된 처리량 성능 모드로 변경합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/138185-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q862 
회사는 중요한 보관 데이터 파일을 생성하는 애플리케이션을 AWS 클라우드에서 
실행합니다. 회사는 애플리케이션의 데이터 스토리지를 재설계하려고 합니다. 회사는 
데이터 파일을 암호화하고 데이터가 암호화되어 AWS 로 전송되기 전에 제 3 자가 데이터에 
액세스할 수 없도록 하고 싶어합니다. 회사는 이미 Amazon S3 버킷을 생성했습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 관리형 암호화 키로 클라이언트 측 암호화를 사용하도록 S3 버킷을 
구성합니다. S3 버킷을 사용하여 아카이브 파일을 저장하도록 애플리케이션을 구성합니다. 
B. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 
버킷을 사용하여 아카이브 파일을 저장하도록 애플리케이션을 구성합니다. 
C. AWS KMS 키(SSE-KMS)와 함께 이중 계층 서버 측 암호화를 사용하도록 S3 버킷을 
구성합니다. S3 버킷을 사용하여 아카이브 파일을 저장하도록 애플리케이션을 구성합니다. 
D. AWS KMS(AWS Key Management Service)에 저장된 키로 클라이언트 측 암호화를 
사용하도록 애플리케이션을 구성합니다. 구성 
S3 버킷에 아카이브 파일을 저장하는 애플리케이션입니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/138010-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q863 
회사는 데이터베이스 계층에 대한 기본 백업 설정과 함께 Amazon RDS 를 사용합니다. 
회사는 규제 요구 사항을 충족하기 위해 데이터베이스를 매일 백업해야 합니다. 회사는 
30 일 동안 백업을 보관해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 매일 RDS 스냅샷을 생성하는 AWS Lambda 함수를 작성합니다. 
B. 자동 백업을 위해 30 일의 보존 기간을 갖도록 RDS 데이터베이스를 수정합니다. 
C. AWS 시스템 관리자 유지 관리 기간을 사용하여 RDS 백업 보존 기간을 수정합니다. 
D. AWS CLI 를 사용하여 매일 수동 스냅샷을 생성합니다. RDS 백업 보존 기간을 
수정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139172-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q864 
AWS 에서 애플리케이션을 실행하는 회사는 Amazon Aurora DB 클러스터를 데이터베이스로 
사용합니다. 여러 사용자가 데이터에 액세스하고 읽는 피크 사용 시간 동안 모니터링 
시스템은 쓰기 쿼리에 대한 데이터베이스 성능 저하를 보여줍니다. 회사는 최대 사용량 
수요를 충족하기 위해 애플리케이션의 확장성을 높이고자 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 두 번째 Aurora DB 클러스터를 생성하십시오. 사용자의 데이터를 새 데이터베이스에 
복제하도록 복사 작업을 구성합니다. 두 번째 데이터베이스를 사용하여 데이터를 읽도록 
애플리케이션을 업데이트합니다. 
B. 기존 Aurora DB 클러스터 앞에 Amazon DynamoDB Accelerator(DAX) 클러스터를 
생성합니다. 읽기 전용 쿼리에 DAX 클러스터를 사용하도록 애플리케이션을 업데이트합니다. 
Aurora DB 클러스터에 직접 데이터를 씁니다. 
C. 기존 Aurora DB 클러스터에 Aurora 읽기 전용 복제본을 생성합니다. 읽기 전용 쿼리에 
복제본 엔드포인트를 사용하고 쓰기 쿼리에 클러스터 엔드포인트를 사용하도록 
애플리케이션을 업데이트합니다. 
D. Amazon Redshift 클러스터를 생성합니다. 사용자 데이터를 Redshift 클러스터에 
복사합니다. Redshift 클러스터에 연결하고 Redshift 클러스터에서 읽기 전용 쿼리를 
수행하도록 애플리케이션을 업데이트합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/141661-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q865 
회사의 실시간에 가까운 스트리밍 애플리케이션이 AWS 에서 실행되고 있습니다. 데이터가 
수집되면 데이터에 대한 작업이 실행되고 완료하는 데 30 분이 걸립니다. 워크로드는 
대량의 수신 데이터로 인해 높은 대기 시간을 경험하는 경우가 많습니다. 솔루션 설계자는 
성능을 향상시키기 위해 확장 가능한 서버리스 솔루션을 설계해야 합니다. 
솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (2 개 선택) 
A. Amazon Kinesis Data Firehose 를 사용하여 데이터를 수집하십시오. 
B. AWS Step Functions 와 함께 AWS Lambda 를 사용하여 데이터를 처리합니다. 
C. AWS Database Migration Service(AWS DMS)를 사용하여 데이터를 수집합니다. 
D. Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용하여 데이터를 처리합니다. 
E. Amazon Elastic Container Service(Amazon ECS)와 함께 AWS Fargate 를 사용하여 
데이터를 처리합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/137829-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q866 
회사는 VPC 의 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 
애플리케이션은 Amazon S3 버킷에 민감한 데이터를 써야 합니다. 공용 인터넷을 통해 
데이터를 전송할 수 없습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 용 게이트웨이 VPC 엔드포인트를 생성합니다. VPC 라우팅 테이블에 
엔드포인트에 대한 경로를 생성합니다. 
B. S3 버킷을 대상으로 하는 내부 Network Load Balancer 를 생성합니다. 
C. VPC 내부에 S3 버킷을 배포합니다. VPC 라우팅 테이블에서 버킷에 대한 경로를 
생성합니다. 
D. VPC 와 S3 지역 엔드포인트 사이에 AWS Direct Connect 연결을 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/137855-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q867 
회사는 Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용하여 Amazon EC2 
인스턴스에서 프로덕션 워크로드를 실행합니다. 솔루션 설계자는 현재 EBS 볼륨 비용을 
분석하고 최적화를 권장해야 합니다. 권장 사항에는 예상 월별 저축 기회가 포함되어야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Inspector 보고를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 생성하십시오. 
B. AWS 시스템 관리자 보고를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 결정합니다. 
C. Amazon CloudWatch 지표 보고를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 
결정합니다. 
D. AWS Compute Optimizer 를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/137854-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q868 
한 글로벌 기업이 AWS 에서 워크로드를 실행하고 있습니다. 이 회사의 애플리케이션은 
민감한 데이터 저장 및 분석을 위해 AWS 리전 전체에서 Amazon S3 버킷을 사용합니다. 
회사는 매일 수백만 개의 객체를 여러 S3 버킷에 저장합니다. 회사는 버전 관리가 
활성화되지 않은 모든 S3 버킷을 식별하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 이그잼토픽 문제 오류.  보기 A 없음 
B. Amazon S3 Storage Lens 를 사용하여 여러 지역에서 버전 관리가 활성화되지 않은 모든 
S3 버킷을 식별합니다. 
C. S3 용 IAM 액세스 분석기를 활성화하여 여러 지역에서 버전 관리가 활성화되지 않은 
모든 S3 버킷을 식별합니다. 
D. S3 다중 지역 액세스 포인트를 생성하여 지역 전체에 걸쳐 버전 관리가 활성화되지 않은 
모든 S3 버킷을 식별합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/137847-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
이그잼토픽 문제 오류.  보기 A 없음 
Q869 
한 회사에서 AWS 에 배포된 전자상거래 주문 처리 애플리케이션을 개선하려고 합니다. 
애플리케이션은 예측할 수 없는 트래픽 급증 중에 고객 경험에 영향을 주지 않고 각 주문을 
정확히 한 번만 처리해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Simple Queue Service (Amazon SQS) FIFO 대기열을 생성합니다. 모든 주문을 
SQS 대기열에 넣습니다. 주문을 처리할 대상으로 AWS Lambda 함수를 구성합니다. 
B. Amazon Simple Notification Service (Amazon SNS) 표준 주제를 생성합니다. 모든 주문을 
SNS 표준 주제에 게시합니다. 애플리케이션을 알림 대상으로 구성합니다. 
C. Amazon AppFlow 를 사용하여 흐름을 생성합니다. 주문을 흐름으로 보냅니다. 주문을 
처리할 대상으로 AWS Lambda 함수를 구성합니다. 
D. 주문 요청을 추적하도록 애플리케이션에서 AWS X-Ray 를 구성합니다. Amazon 
CloudWatch 에서 주문을 가져와 주문을 처리하도록 애플리케이션을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/138082-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q870 
회사에는 생산 및 개발이라는 두 개의 AWS 계정이 있습니다. 회사는 Development 계정의 
코드 변경 사항을 Production 계정으로 푸시해야 합니다. 알파 단계에서는 개발팀의 수석 
개발자 2 명만 프로덕션 계정에 액세스하면 됩니다. 베타 단계에서는 테스트를 수행하기 
위해 더 많은 개발자가 액세스해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 각 계정에서 AWS Management Console 을 사용하여 두 개의 정책 문서를 생성합니다. 
액세스가 필요한 개발자에게 정책을 할당합니다. 
B. 개발 계정에 IAM 역할을 생성합니다. IAM 역할에 프로덕션 계정에 대한 액세스 권한을 
부여합니다. 개발자가 역할을 맡도록 허용합니다. 
C. 프로덕션 계정에서 IAM 역할을 생성합니다. Development 계정을 지정하는 신뢰 정책을 
정의합니다. 개발자가 역할을 맡도록 허용합니다. 
D. 프로덕션 계정에 IAM 그룹을 생성합니다. Production 계정을 지정하는 신뢰 정책에 
그룹을 보안 주체로 추가합니다. 그룹에 개발자를 추가합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/137848-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q871 
회사에서는 웹 애플리케이션 콘텐츠에 대한 액세스를 제한하려고 합니다. 회사는 AWS 에서 
사용할 수 있는 인증 기술을 사용하여 콘텐츠를 보호해야 합니다. 또한 회사는 로그인 대기 
시간이 짧은 권한 부여 및 인증을 위한 서버리스 아키텍처를 구현하려고 합니다. 
솔루션은 웹 애플리케이션과 통합되어야 하며 웹 콘텐츠를 전역적으로 제공해야 합니다. 
현재 애플리케이션의 사용자 기반은 작지만 회사는 애플리케이션의 사용자 기반이 증가할 
것으로 예상하고 있습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 인증을 위해 Amazon Cognito 를 구성합니다. 인증을 위해 Lambda@Edge 를 구현합니다. 
웹 애플리케이션을 전 세계적으로 제공하도록 Amazon CloudFront 를 구성합니다. 
B. 인증을 위해 Microsoft Active Directory 용 AWS 디렉터리 서비스를 구성합니다. 인증을 
위해 AWS Lambda 를 구현합니다. Application Load Balancer 를 사용하여 웹 
애플리케이션을 전역적으로 제공합니다. 
C. 인증을 위해 Amazon Cognito 를 구성합니다. 인증을 위해 AWS Lambda 를 구현합니다. 
Amazon S3 Transfer Acceleration 을 사용하여 웹 애플리케이션을 전 세계적으로 
제공합니다. 
D. 인증을 위해 Microsoft Active Directory 용 AWS 디렉터리 서비스를 구성합니다. 인증을 
위해 Lambda@Edge 를 구현합니다. AWS Elastic Beanstalk 를 사용하여 웹 애플리케이션을 
전 세계적으로 제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/138553-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q872 
개발 팀은 개발, 스테이징 및 프로덕션 환경에 여러 AWS 계정을 사용합니다. 팀원들은 
활용도가 낮은 대규모 Amazon EC2 인스턴스를 출시해 왔습니다. 솔루션 아키텍트는 모든 
계정에서 대규모 인스턴스가 시작되지 않도록 해야 합니다. 
솔루션 설계자는 어떻게 최소한의 운영 오버헤드로 이 요구 사항을 충족할 수 있습니까? 
A. 대규모 EC2 인스턴스의 시작을 거부하도록 IAM 정책을 업데이트하십시오. 모든 
사용자에게 정책을 적용합니다. 
B. AWS Resource Access Manager 에서 대규모 EC2 인스턴스의 시작을 방지하는 리소스를 
정의합니다. 
C. 각 계정에 대규모 EC2 인스턴스의 시작을 거부하는 IAM 역할을 생성합니다. 
개발자에게 IAM 그룹에 역할에 대한 액세스 권한을 부여합니다. 
D. 기본 정책을 사용하여 마스터 계정의 AWS Organizations 에 조직을 생성합니다. 대규모 
EC2 인스턴스의 시작을 거부하는 서비스 제어 정책(SCP)을 생성하고 이를 AWS 계정에 
적용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/139180-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q873 
한 회사는 수백 대의 온프레미스 가상 머신(VM)을 Amazon EC2 인스턴스로 
마이그레이션했습니다. 인스턴스는 여러 Linux 배포판과 함께 다양한 Windows Server 
버전을 실행합니다. 회사는 운영 체제의 인벤토리 및 업데이트를 자동화하는 솔루션을 
원합니다. 또한 회사는 정기적인 월별 검토를 위해 각 인스턴스의 일반적인 취약점에 대한 
요약을 필요로 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 합니까? 
A. 모든 EC2 인스턴스를 관리하도록 AWS 시스템 관리자 패치 관리자를 설정합니다. 월별 
보고서를 생성하도록 AWS Security Hub 를 구성합니다. 
B. 모든 EC2 인스턴스를 관리하도록 AWS 시스템 관리자 패치 관리자를 설정합니다. 
Amazon Inspector 를 배포하고 월별 보고서를 구성합니다. 
C. AWS Shield Advanced 를 설정하고 월별 보고서를 구성합니다. AWS Config 를 배포하여 
EC2 인스턴스에 패치 설치를 자동화합니다. 
D. 모든 EC2 인스턴스를 모니터링하려면 계정에 Amazon GuardDuty 를 설정하십시오. AWS 
Config 를 배포하여 EC2 인스턴스에 패치 설치를 자동화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/137853-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q874 
회사는 AWS 클라우드에서 애플리케이션을 호스팅합니다. 애플리케이션은 Elastic Load 
Balancing(ELB) 로드 밸런서 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 
실행됩니다. 애플리케이션은 Amazon DynamoDB 테이블에 연결됩니다. 
재해 복구(DR) 목적을 위해 회사는 가동 중지 시간을 최소화하면서 다른 AWS 리전에서 
애플리케이션을 사용할 수 있는지 확인하려고 합니다. 
가동 중지 시간을 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. DR 지역에 Auto Scaling 그룹과 ELB 를 생성합니다. DynamoDB 테이블을 전역 테이블로 
구성합니다. 새 DR 지역의 ELB 를 가리키도록 DNS 장애 조치를 구성합니다. 
B. AWS CloudFormation 템플릿을 생성하여 필요할 때 시작할 EC2 인스턴스, ELB 및 
DynamoDB 테이블을 생성합니다. 새 DR 지역의 ELB 를 가리키도록 DNS 장애 조치를 
구성합니다. 
C. AWS CloudFormation 템플릿을 생성하여 EC2 인스턴스를 생성하고 필요할 때 시작할 
ELB 를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 새 DR 지역의 ELB 를 
가리키도록 DNS 장애 조치를 구성합니다. 
D. DR 지역에 Auto Scaling 그룹과 ELB 를 생성합니다. DynamoDB 테이블을 전역 테이블로 
구성합니다. DR 지역의 ELB 를 가리키도록 Amazon Route 53 을 업데이트하는 AWS Lambda 
함수를 호출하려면 평가 기간이 10 분인 Amazon CloudWatch 경보를 생성하십시오. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/137852-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q875 
회사는 프라이빗 서브넷의 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 
애플리케이션은 Amazon S3 버킷에 데이터를 저장하고 검색해야 합니다. 규제 요구 사항에 
따라 데이터는 공용 인터넷을 통해 이동해서는 안 됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하려면 솔루션 설계자가 무엇을 해야 
합니까? 
A. S3 버킷에 액세스하려면 NAT 게이트웨이를 배포하십시오. 
B. S3 버킷에 액세스하려면 AWS Storage Gateway 를 배포하십시오. 
C. S3 버킷에 액세스하기 위해 S3 인터페이스 엔드포인트를 배포합니다. 
D. S3 버킷에 액세스하려면 S3 게이트웨이 엔드포인트를 배포합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/138140-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q876 
회사는 단일 가용 영역에서 실행되는 Amazon EC2 인스턴스에 애플리케이션을 
호스팅합니다. OSI(Open Systems Interconnection) 모델의 전송 계층을 사용하여 
애플리케이션에 액세스할 수 있습니다. 회사는 고가용성을 확보하기 위해 애플리케이션 
아키텍처가 필요합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 다른 가용 영역에서 새 EC2 인스턴스를 구성합니다. Amazon Route 53 을 사용하여 
트래픽을 모든 인스턴스로 라우팅합니다. 
B. EC2 인스턴스 앞에 Network Load Balancer 를 구성합니다. 
C. 인스턴스에 대한 TCP 트래픽을 위해 Network Load Balancer 를 구성합니다. 인스턴스에 
대한 HTTP 및 HTTPS 트래픽에 대해 Application Load Balancer 를 구성합니다. 
D. EC2 인스턴스에 대한 Auto Scaling 그룹을 생성합니다. 여러 가용 영역을 사용하도록 
Auto Scaling 그룹을 구성합니다. 인스턴스에서 애플리케이션 상태 확인을 실행하도록 Auto 
Scaling 그룹을 구성합니다. 
E. Amazon CloudWatch 경보를 생성합니다. 중지된 상태로 전환되는 EC2 인스턴스를 다시 
시작하도록 경보를 구성합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/137849-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q877 
한 회사는 Amazon S3 를 사용하여 정적 웹 사이트를 호스팅합니다. 회사는 웹페이지에 
문의 양식을 추가하려고 합니다. 문의 양식에는 사용자가 이름, 이메일 주소, 전화번호 및 
사용자 메시지를 입력할 수 있는 동적 서버측 구성 요소가 있습니다. 
회사에서는 매월 사이트 방문 횟수가 100 회 미만일 것으로 예상합니다. 문의 양식은 
고객이 양식을 작성할 때 이메일로 회사에 알려야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Container Service(Amazon ECS)에서 동적 문의 양식을 호스팅합니다. 
타사 이메일 공급자에 연결하려면 Amazon Simple Email Service(Amazon SES)를 
설정하십시오. 
B. AWS Lambda 함수에서 문의 양식을 반환하는 Amazon API Gateway 엔드포인트를 
생성합니다. Amazon Simple 알림 서비스(Amazon SNS) 주제에 메시지를 게시하도록 API 
게이트웨이에서 또 다른 Lambda 함수를 구성합니다. 
C. 정적 콘텐츠와 동적 콘텐츠에 AWS Amplify 호스팅을 사용하여 웹 사이트를 
호스팅합니다. 서버측 스크립팅을 사용하여 문의 양식을 작성합니다. 메시지를 회사에 
전달하도록 Amazon Simple Queue Service(Amazon SQS)를 구성합니다. 
D. 웹 사이트를 Amazon S3 에서 Windows Server 를 실행하는 Amazon EC2 인스턴스로 
마이그레이션합니다. Windows Server 용 인터넷 정보 서비스(IIS)를 사용하여 웹 페이지를 
호스팅합니다. 클라이언트측 스크립팅을 사용하여 문의 양식을 작성합니다. 양식을 Amazon 
WorkMail 과 통합합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139252-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q878 
회사는 AWS Organizations 에 사업부를 위한 전용 AWS 계정을 생성합니다. 최근에는 
할당된 계정 소유자가 아닌 사업부 계정의 루트 사용자 이메일 주소로 중요한 알림이 
전송되었습니다. 회사는 청구, 운영 또는 보안의 알림 범주에 따라 향후 모든 알림을 다른 
직원에게 보낼 수 있기를 원합니다. 
이러한 요구 사항을 가장 안전하게 충족하는 솔루션은 무엇입니까? 
A. 회사에서 관리하는 단일 이메일 주소를 사용하도록 각 AWS 계정을 구성합니다. 모든 
계정 소유자가 이메일 계정에 액세스하여 알림을 받을 수 있는지 확인하십시오. 각 
사업부의 결제 팀, 보안 팀 및 운영 팀에 대한 해당 배포 목록을 사용하여 각 AWS 계정에 
대한 대체 연락처를 구성합니다. 
B. 회사가 관리하는 각 사업부에 대해 서로 다른 이메일 배포 목록을 사용하도록 각 AWS 
계정을 구성합니다. 경고에 응답할 수 있는 관리자 이메일 주소로 각 배포 목록을 
구성합니다. 각 사업부의 결제 팀, 보안 팀 및 운영 팀에 대한 해당 배포 목록을 사용하여 
각 AWS 계정에 대한 대체 연락처를 구성합니다. 
C. 각 AWS 계정 루트 사용자 이메일 주소를 각 사업부에서 한 사람의 개별 회사 관리 
이메일 주소로 구성합니다. 각 사업부의 결제 팀, 보안 팀 및 운영 팀에 대한 해당 배포 
목록을 사용하여 각 AWS 계정에 대한 대체 연락처를 구성합니다. 
D. 중앙 집중식 사서함으로 이동하는 이메일 별칭을 사용하도록 각 AWS 계정 루트 
사용자를 구성합니다. 청구 팀, 보안 팀 및 운영 팀에 대해 각각 단일 비즈니스 관리 
이메일 배포 목록을 사용하여 각 계정에 대한 대체 연락처를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/139746-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
A?? 
Q879 
한 회사가 AWS 에서 전자상거래 애플리케이션을 실행하고 있습니다. Amazon EC2 
인스턴스는 구매를 처리하고 구매 세부 정보를 Amazon Aurora PostgreSQL DB 클러스터에 
저장합니다. 
고객은 사용량이 가장 많은 시간에 애플리케이션 시간 초과를 경험하고 있습니다. 솔루션 
설계자는 애플리케이션이 최대 사용 요구 사항을 충족하도록 확장할 수 있도록 
애플리케이션을 다시 설계해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 작업 조합은 무엇입니까? (2 개 선택) 
A. 처리가 완료될 때까지 구매를 재시도하도록 새 EC2 인스턴스의 Auto Scaling 그룹을 
구성합니다. Amazon RDS Proxy 를 사용하여 DB 클러스터에 연결하도록 애플리케이션을 
업데이트합니다. 
B. Aurora PostgreSQL DB 클러스터 앞에 Amazon ElastiCache 클러스터를 사용하도록 
애플리케이션을 구성합니다. 
C. 구매 요청을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내도록 
애플리케이션을 업데이트합니다. SQS 대기열에서 읽는 새 EC2 인스턴스의 Auto Scaling 
그룹을 구성합니다. 
D. 처리가 완료될 때까지 티켓 구매를 재시도하도록 AWS Lambda 함수를 구성합니다. 
E. Amazon AP 를 구성하세요! 사용량 계획이 포함된 게이트웨이 REST API 입니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/139619-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q880 
AWS Organizations 를 사용하는 회사는 30 개의 서로 다른 AWS 계정에서 150 개의 
애플리케이션을 실행합니다. 회사는 AWS 비용 및 사용 보고서를 사용하여 마스터 계정에 
새 보고서를 생성했습니다. 보고서는 데이터 수집 계정의 버킷에 복제된 Amazon S3 
버킷으로 전달됩니다. 
회사의 고위 경영진은 이번 달 초부터 매일 NAT 게이트웨이 비용을 제공하는 사용자 정의 
대시보드를 보고 싶어합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 요청된 테이블 시각적 개체가 포함된 Amazon QuickSight 대시보드를 공유하십시오. 
AWS DataSync 를 사용하여 새 보고서를 쿼리하도록 QuickSight 를 구성합니다. 
B. 요청된 테이블 시각적 개체가 포함된 Amazon QuickSight 대시보드를 공유합니다. 
Amazon Athena 를 사용하여 새 보고서를 쿼리하도록 QuickSight 를 구성합니다. 
C. 요청된 테이블 시각적 개체가 포함된 Amazon CloudWatch 대시보드를 공유합니다. AWS 
DataSync 를 사용하여 새 보고서를 쿼리하도록 CloudWatch 를 구성합니다. 
D. 요청된 테이블 시각적 개체가 포함된 Amazon CloudWatch 대시보드를 공유합니다. 
Amazon Athena 를 사용하여 새 보고서를 쿼리하도록 CloudWatch 를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/137926-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q881 
한 회사는 기본 TTL 이 0 초인 Amazon CloudFront 배포를 사용하여 Amazon S3 에서 
트래픽이 많은 정적 웹 사이트를 호스팅하고 있습니다. 회사는 웹 사이트의 성능을 
향상시키기 위해 캐싱을 구현하려고 합니다. 그러나 회사에서는 배포 후 몇 분 이상 오래된 
콘텐츠가 제공되지 않도록 하고 싶어합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 캐싱 방법 조합을 구현해야 
합니까? (2 개 선택) 
A. CloudFront 기본 TTL 을 2 분으로 설정합니다. 
B. S3 버킷에 기본 TTL 을 2 분으로 설정합니다. 
C. Amazon S3 의 객체에 Cache-Control 개인 지시문을 추가합니다. 
D. AWS Lambda@Edge 함수를 생성하여 HTTP 응답에 Expires 헤더를 추가합니다. 시청자 
응답 시 실행되도록 기능을 구성합니다. 
E. Amazon S3 의 객체에 24 시간의 Cache-Control max-age 지시문을 추가합니다. 배포 시 
CloudFront 무효화를 생성하여 엣지 캐시에서 변경된 파일을 모두 지웁니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/137850-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
A, E?? 
Q882 
회사는 Amazon EC2 인스턴스와 AWS Lambda 함수를 사용하여 애플리케이션을 
실행합니다. EC2 인스턴스는 VPC 의 프라이빗 서브넷에서 실행됩니다. 애플리케이션이 
작동하려면 Lambda 함수가 EC2 인스턴스에 대한 직접 네트워크 액세스가 필요합니다. 
신청은 1 년 동안 진행됩니다. 애플리케이션이 사용하는 Lambda 함수의 수는 1 년 동안 
증가합니다. 회사는 모든 애플리케이션 리소스에 대한 비용을 최소화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. EC2 Instance Savings Plan 을 구매하세요. EC2 인스턴스가 포함된 프라이빗 서브넷에 
Lambda 함수를 연결합니다. 
B. EC2 인스턴스 Savings Plan 을 구매하세요. EC2 인스턴스가 실행되는 동일한 VPC 의 새 
퍼블릭 서브넷에 Lambda 함수를 연결합니다. 
C. Compute Savings Plan 을 구매하세요. EC2 인스턴스가 포함된 프라이빗 서브넷에 
Lambda 함수를 연결합니다. 
D. Compute Savings Plan 을 구매하세요. Lambda 서비스 VPC 에 Lambda 함수를 
유지합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/138489-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
. 
Q883 
한 회사가 AWS Control Tower 를 사용하여 AWS 에 다중 계정 전략을 배포했습니다. 회사는 
각 개발자에게 개별 AWS 계정을 제공했습니다. 회사는 개발자에게 발생하는 AWS 리소스 
비용을 제한하기 위한 제어 기능을 구현하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 각 개발자에게 CostCenter 키와 개발자 이름 값이 있는 태그를 사용하여 모든 리소스에 
태그를 지정하도록 지시합니다. 필수 태그 AWS Config 관리형 규칙을 사용하여 태그를 
확인하세요. 태그가 없는 리소스를 종료하는 AWS Lambda 함수를 생성합니다. 지출을 
모니터링하기 위해 각 개발자에게 일일 보고서를 보내도록 AWS Cost Explorer 를 
구성합니다. 
B. AWS 예산을 사용하여 각 개발자 계정에 대한 예산을 설정합니다. 실제 및 예측 값에 
대한 예산 알림을 설정하여 할당된 예산을 초과하거나 초과할 것으로 예상되는 경우 
개발자에게 알립니다. AWS Budgets 작업을 사용하여 개발자의 IAM 역할에 DenyAll 정책을 
적용하면 할당된 예산에 도달할 때 추가 리소스가 시작되는 것을 방지할 수 있습니다. 
C. AWS Cost Explorer 를 사용하여 각 개발자 계정의 비용을 모니터링하고 보고합니다. 
지출을 모니터링하기 위해 각 개발자에게 일일 보고서를 보내도록 Cost Explorer 를 
구성합니다. AWS 비용 이상 탐지를 사용하여 비정상적인 지출을 탐지하고 알림을 
제공합니다. 
D. AWS Service Catalog 를 사용하면 개발자가 제한된 비용 범위 내에서 리소스를 시작할 
수 있습니다. 각 AWS 계정에 AWS Lambda 함수를 생성하여 각 근무일이 끝나면 리소스 
실행을 중지합니다. 각 근무일이 시작될 때 리소스를 재개하도록 Lambda 함수를 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139799-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q884 
솔루션 설계자가 3 계층 웹 애플리케이션을 설계하고 있습니다. 아키텍처는 인터넷 연결 
ALB(Application Load Balancer)와 프라이빗 서브넷의 Amazon EC2 인스턴스에서 
호스팅되는 웹 계층으로 구성됩니다. 비즈니스 로직이 포함된 애플리케이션 계층은 
프라이빗 서브넷의 EC2 인스턴스에서 실행됩니다. 데이터베이스 계층은 프라이빗 서브넷의 
EC2 인스턴스에서 실행되는 Microsoft SQL Server 로 구성됩니다. 보안은 회사의 최우선 
과제입니다. 
솔루션 아키텍트는 어떤 보안 그룹 구성 조합을 사용해야 합니까? (3 개 선택) 
A. ALB 에 대한 보안 그룹의 인바운드 HTTPS 트래픽을 허용하도록 웹 계층에 대한 보안 
그룹을 구성합니다. 
B. 0.0.0.0/0 에 대한 아웃바운드 HTTPS 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 
구성합니다. 
C. 애플리케이션 계층에 대한 보안 그룹의 인바운드 Microsoft SQL Server 트래픽을 
허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다. 
D. 웹 계층의 보안 그룹에 대한 아웃바운드 HTTPS 트래픽과 Microsoft SQL Server 
트래픽을 허용하도록 데이터베이스 계층의 보안 그룹을 구성합니다. 
E. 웹 계층에 대한 보안 그룹의 인바운드 HTTPS 트래픽을 허용하도록 애플리케이션 
계층에 대한 보안 그룹을 구성합니다. 
F. 웹 계층의 보안 그룹에 대한 아웃바운드 HTTPS 트래픽과 Microsoft SQL Server 
트래픽을 허용하도록 애플리케이션 계층의 보안 그룹을 구성합니다. 
Answer: A, C, E 
https://www.examtopics.com/discussions/amazon/view/139800-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q885 
한 회사에서 프로덕션 애플리케이션의 새 버전을 출시했습니다. 회사의 워크로드는 
Amazon EC2, AWS Lambda, AWS Fargate 및 Amazon SageMaker 를 사용합니다. 
이제 회사는 사용량이 안정된 상태이므로 워크로드 비용을 최적화하려고 합니다. 회사는 
최소한의 저축 계획으로 가장 많은 서비스를 보장하기를 원합니다. 
이러한 요구 사항을 충족하는 저축 계획 조합은 무엇입니까? (2 개 선택) 
A. Amazon EC2 및 SageMaker 에 대한 EC2 인스턴스 Savings Plan 을 구매하십시오. 
B. Amazon EC2, Lambda 및 SageMaker 에 대한 Compute Savings Plan 을 구매하십시오. 
C. SageMaker 저축 플랜을 구매하세요. 
D. Lambda, Fargate 및 Amazon EC2 에 대한 Compute Savings Plan 을 구매하십시오. 
E. Amazon EC2 및 Fargate 에 대한 EC2 인스턴스 Savings Plan 을 구매하세요. 
Answer: C, D 
https://www.examtopics.com/discussions/amazon/view/139801-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q886 
회사에서는 Microsoft SQL Server 데이터베이스를 사용합니다. 회사의 애플리케이션은 
데이터베이스에 연결됩니다. 회사는 애플리케이션 코드를 최소한으로 변경하면서 Amazon 
Aurora PostgreSQL 데이터베이스로 마이그레이션하려고 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. AWS SCT(AWS Schema Conversion Tool)를 사용하여 애플리케이션에서 SQL 쿼리를 
다시 작성하십시오. 
B. Aurora PostgreSQL 에서 Babelfish 를 활성화하여 애플리케이션에서 SQL 쿼리를 
실행합니다. 
C. AWS Schema Conversion Tool(AWS SCT) 및 AWS Database Migration Service(AWS 
DMS)를 사용하여 데이터베이스 스키마와 데이터를 마이그레이션합니다. 
D. Amazon RDS Proxy 를 사용하여 애플리케이션을 Aurora PostgreSQL 에 연결합니다. 
E. AWS Database Migration Service(AWS DMS)를 사용하여 애플리케이션에서 SQL 쿼리를 
다시 작성합니다. 
Answer: B, C 
https://www.examtopics.com/discussions/amazon/view/139802-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 요구 사항 분석: 목표는 최소한의 애플리케이션 코드 변경으로 Microsoft SQL Server 에서 
Amazon Aurora PostgreSQL 로 마이그레이션하는 것입니다. 
* Aurora PostgreSQL 용 Babelfish: Babelfish 를 사용하면 Aurora PostgreSQL 이 SQL Server 
쿼리를 기본적으로 이해하여 애플리케이션 코드 변경 필요성을 줄일 수 있습니다. 
* AWS 스키마 변환 도구(SCT): 이 도구는 데이터베이스 스키마를 SQL Server 에서 
PostgreSQL 로 변환하는 데 도움이 됩니다. 
* AWS 데이터베이스 마이그레이션 서비스(DMS): DMS 를 사용하면 SQL Server 에서 Aurora 
PostgreSQL 로 데이터를 원활하게 마이그레이션할 수 있습니다. 
* 결합된 접근 방식: Babelfish 를 활성화하면 SQL 쿼리 호환성이 해결되고 SCT 와 DMS 는 
스키마와 데이터 마이그레이션을 처리합니다. 
참조 
* Aurora PostgreSQL 용 Babelfish: Babelfish 설명서 
* AWS SCT 및 DMS: AWS 데이터베이스 마이그레이션 서비스 
Q887 
한 회사는 Amazon Elastic Block Store(Amazon EBS)를 연결된 스토리지로 사용하는 
Amazon EC2 인스턴스에 애플리케이션을 다시 호스팅할 계획입니다. 솔루션 아키텍트는 
새로 생성된 모든 Amazon EBS 볼륨이 기본적으로 암호화되도록 솔루션을 설계해야 합니다. 
또한 솔루션은 암호화되지 않은 EBS 볼륨이 생성되는 것을 방지해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 항상 새 EBS 볼륨을 암호화하도록 EC2 계정 속성을 구성합니다. 
B. AWS Config 를 사용하세요. 암호화된 볼륨 식별자를 구성합니다. 기본 AWS Key 
Management Service(AWS KMS) 키를 적용합니다. 
C. EBS 볼륨의 암호화된 복사본을 생성하도록 AWS 시스템 관리자를 구성합니다. 암호화된 
볼륨을 사용하도록 EC2 인스턴스를 재구성합니다. 
D. AWS Key Management Service(AWS KMS)에서 고객 관리형 키를 생성합니다. 회사가 
워크로드를 마이그레이션할 때 키를 사용하도록 AWS Migration Hub 를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/140296-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q888 
전자상거래 회사는 실시간 분석을 위해 회사 웹사이트에서 사용자 클릭스트림 데이터를 
수집하려고 합니다. 웹사이트는 하루 종일 변동하는 트래픽 패턴을 경험합니다. 회사에는 
다양한 수준의 트래픽에 적응할 수 있는 확장 가능한 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 온디맨드 모드에서 Amazon Kinesis Data Streams 의 데이터 스트림을 사용하여 
클릭스트림 데이터를 캡처합니다. AWS Lambda 를 사용하여 실시간으로 데이터를 
처리합니다. 
B. Amazon Kinesis Data Firehose 를 사용하여 클릭스트림 데이터를 캡처합니다. AWS 
Glue 를 사용하여 실시간으로 데이터를 처리합니다. 
C. Amazon Kinesis Video Streams 를 사용하여 클릭스트림 데이터를 캡처합니다. AWS 
Glue 를 사용하여 실시간으로 데이터를 처리합니다. 
D. Apache Flink 용 Amazon Managed Service(이전의 Amazon Kinesis Data Analytics)를 
사용하여 클릭스트림 데이터를 캡처합니다. AWS Lambda 를 사용하여 실시간으로 데이터를 
처리합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/139803-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q889 
한 글로벌 기업이 AWS 에서 워크로드를 실행하고 있습니다. 이 회사의 애플리케이션은 
민감한 데이터 저장 및 분석을 위해 AWS 리전 전체에서 Amazon S3 버킷을 사용합니다. 
회사는 매일 수백만 개의 객체를 여러 S3 버킷에 저장합니다. 회사는 버전 관리가 
활성화되지 않은 모든 S3 버킷을 식별하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 여러 지역에서 버전 관리가 활성화되지 않은 모든 S3 버킷을 식별하는 규칙이 있는 
AWS CloudTrail 이벤트를 설정합니다. 
B. Amazon S3 Storage Lens 를 사용하여 여러 지역에서 버전 관리가 활성화되지 않은 모든 
S3 버킷을 식별합니다. 
C. S3 용 IAM 액세스 분석기를 활성화하여 여러 지역에서 버전 관리가 활성화되지 않은 
모든 S3 버킷을 식별합니다. 
D. S3 다중 지역 액세스 포인트를 생성하여 지역 전체에 걸쳐 버전 관리가 활성화되지 않은 
모든 S3 버킷을 식별합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139804-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
868 번 문제와 동일 
설명: 
* Amazon S3 Storage Lens: 
* S3 Storage Lens 는 개체 스토리지 사용 및 활동 추세에 대한 조직 전체의 가시성을 
제공합니다. 
* 버전 관리 상태를 포함하여 S3 버킷에 대한 지표와 통찰력을 생성할 수 있습니다. 
* 구성: 
* 조직 수준에서 S3 Storage Lens 를 활성화합니다. 
* 버전 관리 상태 지표를 포함하도록 대시보드를 구성합니다. 
* 버전이 지정되지 않은 버킷 식별: 
* S3 Storage Lens 대시보드를 사용하여 버전 관리가 활성화되지 않은 버킷을 필터링하고 
식별합니다. 
* Storage Lens 는 규정 준수를 강화하고 스토리지를 효과적으로 관리하는 데 사용할 수 
있는 자세한 통찰력과 보고서를 제공합니다. 
* 운영 효율성: S3 Storage Lens 를 사용하면 여러 리전 및 계정에 걸쳐 버킷 구성을 
모니터링하기 위한 사용하기 쉬운 중앙 집중식 인터페이스가 제공되므로 사용자 지정 
스크립트나 수동 확인의 필요성이 줄어듭니다. 
Q890 
회사는 재생성할 수 없는 많은 파일을 생성하는 애플리케이션에 대해 Amazon S3 스토리지 
비용을 최적화해야 합니다. 각 파일은 약 5MB 이며 Amazon S3 Standard 스토리지에 
저장됩니다. 
회사는 파일을 삭제하기 전에 해당 파일을 4 년 동안 보관해야 합니다. 파일에 즉시 
액세스할 수 있어야 합니다. 파일은 객체 생성 후 처음 30 일 동안 자주 액세스되지만 처음 
30 일 이후에는 거의 액세스되지 않습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 객체 생성 후 30 일이 지나면 파일을 S3 Glacier Instant Retrieval 로 이동하는 S3 수명 
주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 삭제합니다. 
B. 객체 생성 후 30 일이 지나면 파일을 S3 One Zone-Infrequent Access(S3 One 
Zone-IA)로 이동하는 S3 수명 주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 
파일을 삭제합니다. 
C. 객체 생성 후 30 일 후에 파일을 S3 Standard-Infrequent Access(S3 Standard-IA)로 
이동하는 S3 수명 주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 
삭제합니다. 
D. 객체 생성 후 30 일이 지나면 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 
이동하는 S3 수명 주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 S3 Glacier 
유연한 검색으로 이동합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/139805-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Amazon S3 Standard-IA: 이 스토리지 클래스는 자주 액세스하지 않지만 필요할 때 빠른 
액세스가 필요한 데이터를 위해 설계되었습니다. S3 Standard 에 비해 스토리지 비용이 
낮으면서도 높은 가용성과 내구성을 제공합니다. 
* 액세스 패턴: 파일은 처음 30 일 동안 자주 액세스되고 이후에는 거의 액세스되지 
않으므로 30 일 후에 S3 Standard-IA 로 전환하면 액세스 패턴에 맞춰 스토리지 비용이 
크게 절감됩니다. 
* 수명 주기 정책: 파일을 S3 Standard-IA 로 전환하는 수명 주기 정책을 구현하면 데이터 
수명 주기의 자동 관리가 보장되어 수동 개입 없이 파일을 저렴한 스토리지 클래스로 
이동할 수 있습니다. 4 년 후에 파일을 삭제하면 더 이상 필요하지 않은 데이터를 제거하여 
비용을 더욱 최적화합니다. 
Q891 
회사는 AWS 클라우드에서 중요한 스토리지 애플리케이션을 실행합니다. 애플리케이션은 두 
AWS 리전에서 Amazon S3 를 사용합니다. 회사는 애플리케이션이 공용 네트워크 정체 없이 
원격 사용자 데이터를 가장 가까운 S3 버킷으로 보내기를 원합니다. 또한 회사는 최소한의 
Amazon S3 관리로 애플리케이션 장애 조치를 원합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 두 지역 간에 활성-활성 설계를 구현합니다. 사용자에게 가장 가까운 지역 S3 
엔드포인트를 사용하도록 애플리케이션을 구성합니다. 
B. S3 다중 지역 액세스 포인트에 활성-수동 구성을 사용하십시오. 각 지역에 대한 글로벌 
엔드포인트를 생성합니다. 
C. 사용자에게 가장 가까운 지역 S3 엔드포인트로 사용자 데이터를 보냅니다. S3 버킷을 
동기화된 상태로 유지하도록 S3 교차 계정 복제 규칙을 구성합니다. 
D. 단일 글로벌 엔드포인트가 있는 활성-활성 구성에서 다중 지역 액세스 포인트를 
사용하도록 Amazon S3 를 설정합니다. S3 교차 리전 복제를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/139744-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q892 
한 회사가 온프레미스 위치에서 AWS 로 데이터 센터를 마이그레이션하고 있습니다. 
회사에는 개별 가상 서버에서 호스팅되는 여러 레거시 애플리케이션이 있습니다. 
애플리케이션 디자인은 변경할 수 없습니다. 
각 개별 가상 서버는 현재 자체 EC2 인스턴스로 실행됩니다. 솔루션 아키텍트는 AWS 로 
마이그레이션한 후 애플리케이션의 안정성과 내결함성을 보장해야 합니다. 애플리케이션은 
Amazon EC2 인스턴스에서 실행됩니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 최소 1 개, 최대 1 개의 Auto Scaling 그룹을 생성합니다. 각 애플리케이션 인스턴스의 
Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하여 Auto Scaling 그룹에 EC2 
인스턴스를 생성합니다. Auto Scaling 그룹 앞에 Application Load Balancer 를 구성합니다. 
B. AWS 백업을 사용하여 각 애플리케이션을 호스팅하는 EC2 인스턴스의 시간별 백업을 
생성합니다. Amazon S3 의 백업을 별도의 가용 영역에 저장합니다. 최신 백업에서 각 
애플리케이션의 EC2 인스턴스를 복원하도록 재해 복구 프로세스를 구성합니다. 
C. 각 애플리케이션 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI 에서 두 개의 
새로운 EC2 인스턴스를 시작합니다. 각 EC2 인스턴스를 별도의 가용 영역에 배치합니다. 
EC2 인스턴스를 대상으로 하는 Network Load Balancer 를 구성합니다. 
D. AWS Mitigation Hub Refactor Spaces 를 사용하여 각 애플리케이션을 EC2 인스턴스에서 
마이그레이션합니다. 각 애플리케이션의 기능을 개별 구성 요소로 분류합니다. AWS Fargate 
시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS)에서 각 
애플리케이션을 호스팅합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/139807-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
C?? 
Q893 
회사는 각 워크로드에 대해 AWS 계정을 생성하여 워크로드를 격리하려고 합니다. 회사에는 
워크로드에 대한 네트워킹 구성 요소를 중앙에서 관리하는 솔루션이 필요합니다. 또한 
솔루션은 자동 보안 제어(가드레일)가 포함된 계정을 생성해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Control Tower 를 사용하여 계정을 배포하십시오. 프라이빗 서브넷과 퍼블릭 
서브넷이 있는 VPC 가 있는 네트워킹 계정을 생성합니다. AWS Resource Access 
Manager(AWS RAM)를 사용하여 워크로드 계정과 서브넷을 공유합니다. 
B. AWS Organizations 를 사용하여 계정을 배포합니다. 프라이빗 서브넷과 퍼블릭 서브넷이 
있는 VPC 가 있는 네트워킹 계정을 생성합니다. AWS Resource Access Manager(AWS 
RAM)를 사용하여 워크로드 계정과 서브넷을 공유합니다. 
C. AWS Control Tower 를 사용하여 계정을 배포합니다. 각 워크로드 계정에 VPC 를 
배포합니다. 전송 게이트웨이 연결을 사용하여 검사 VPC 를 통해 라우팅하도록 각 VPC 를 
구성합니다. 
D. AWS Organizations 를 사용하여 계정을 배포합니다. 각 워크로드 계정에 VPC 를 
배포합니다. 전송 게이트웨이 연결을 사용하여 검사 VPC 를 통해 라우팅하도록 각 VPC 를 
구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/139745-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS Control Tower: AWS 모범 사례를 기반으로 안전한 다중 계정 AWS 환경을 설정하고 
관리하기 위한 관리형 서비스를 제공합니다. AWS Organizations 설정을 자동화하고 보안 
제어(가드레일)를 적용합니다. 
* 네트워킹 계정: 
* 프라이빗 및 퍼블릭 서브넷이 모두 있는 VPC 를 포함하는 중앙 집중식 네트워킹 계정을 
생성합니다. 
* 이 중앙 집중식 VPC 는 네트워킹 리소스를 관리하고 제어합니다. 
* AWS 리소스 액세스 관리자(AWS RAM): 
* AWS RAM 을 사용하여 네트워킹 계정의 서브넷을 다른 워크로드 계정과 공유합니다. 
* 이를 통해 서로 다른 워크로드 계정이 자체 VPC 를 관리할 필요 없이 공유 네트워킹 
리소스를 활용할 수 있습니다. 
* 운영 효율성: AWS Control Tower 를 사용하면 여러 AWS 계정의 설정 및 거버넌스가 
단순화되고, AWS RAM 은 네트워킹 리소스의 중앙 집중식 관리를 촉진하여 운영 오버헤드를 
줄이고 일관된 보안 및 규정 준수를 보장합니다. 
Q894 
회사는 ALB(Application Load Balancer) 뒤에 있는 Amazon EC2 인스턴스에서 웹 사이트를 
호스팅합니다. 웹사이트는 정적 콘텐츠를 제공합니다. 웹사이트 트래픽이 증가하고 
있습니다. 회사는 웹사이트 호스팅 비용을 최소화하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 웹 사이트를 Amazon S3 버킷으로 이동합니다. S3 버킷에 대한 Amazon CloudFront 
배포를 구성합니다. 
B. 웹 사이트를 Amazon S3 버킷으로 이동합니다. S3 버킷에 대한 Amazon ElastiCache 
클러스터를 구성합니다. 
C. 웹사이트를 AWS Amplify 로 이동합니다. Amplify 웹 사이트를 확인하도록 ALB 를 
구성합니다. 
D. 웹사이트를 AWS Amplify 로 이동합니다. 웹 사이트를 캐시하도록 EC2 인스턴스를 
구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/139860-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q895 
한 회사가 AWS 클라우드에서 호스팅되는 미디어 애플리케이션을 위한 공유 스토리지 
솔루션을 구현하고 있습니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 
있는 기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다. 
이러한 요구 사항을 충족하는 AWS 솔루션은 무엇입니까? 
A. AWS Storage Gateway 볼륨 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 
사용하는 파일 공유를 만듭니다. 애플리케이션 서버를 파일 공유에 연결합니다. 
B. AWS Storage Gateway 테이프 게이트웨이를 생성합니다. Amazon S3 를 사용하도록 
테이프를 구성합니다. 애플리케이션 서버를 테이프 게이트웨이에 연결합니다. 
C. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 
설치하고 구성합니다. 애플리케이션 서버를 파일 공유에 연결합니다. 
D. Windows 파일 서버용 Amazon FSx 파일 시스템을 생성합니다. 원본 서버에 파일 
시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/139861-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
249, 305 와 동일 문제 
Q896 
한 회사가 프로덕션 애플리케이션의 재해 복구(DR) 전략을 설계하고 있습니다. 
애플리케이션은 us-east-1 지역의 Amazon Aurora 클러스터에 있는 MySQL 
데이터베이스의 지원을 받습니다. 회사는 us-west-1 지역을 DR 지역으로 선택했습니다. 
회사의 목표 복구 지점 목표(RPO)는 5 분이고 목표 복구 시간 목표(RTO)는 20 분입니다. 
회사에서는 구성 변경을 최소화하려고 합니다. 
가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 프로덕션 애플리케이션의 Aurora MySQL 클러스터 라이터 인스턴스와 비슷한 크기로 
us-west-1 에 Aurora 읽기 전용 복제본을 생성합니다. 
B. Aurora 클러스터를 Aurora 글로벌 데이터베이스로 변환하십시오. 관리형 장애 조치를 
구성합니다. 
C. 교차 리전 복제 기능이 있는 us-west-1 에 새 Aurora 클러스터를 생성합니다. 
D. us-west-1 에 새 Aurora 클러스터를 생성합니다. AWS Database Migration Service(AWS 
DMS)를 사용하여 두 클러스터를 모두 동기화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139809-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q897 
회사는 일주일의 첫날이 되기 전에 매주 중요한 데이터 분석 작업을 실행합니다. 작업을 
완료하려면 분석을 완료하는 데 최소 1 시간이 필요합니다. 작업은 상태를 저장하며 중단을 
허용할 수 없습니다. 회사는 AWS 에서 작업을 실행하기 위한 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 작업에 대한 컨테이너를 생성합니다. Amazon EventBridge Scheduler 를 사용하여 
Amazon Elastic Container Service(Amazon ECS) 클러스터에서 AWS Fargate 작업으로 
실행되도록 작업을 예약합니다. 
B. AWS Lambda 함수에서 실행되도록 작업을 구성합니다. Amazon EventBridge 에서 예약 
규칙을 생성하여 Lambda 함수를 호출합니다. 
C. Amazon Linux 를 실행하는 Amazon EC2 스팟 인스턴스의 Auto Scaling 그룹을 
구성합니다. 분석을 실행하려면 인스턴스에 crontab 항목을 구성하십시오. 
D. 작업을 실행하도록 AWS DataSync 작업을 구성합니다. 일정에 따라 작업을 실행하도록 
cron 표현식을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/140209-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q898 
회사는 AWS 클라우드에서 워크로드를 실행합니다. 회사는 보안 데이터를 중앙에서 
수집하여 회사 전체의 보안을 평가하고 워크로드 보호를 개선하려고 합니다. 
최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Lake Formation 에서 데이터 레이크를 구성합니다. AWS Glue 크롤러를 사용하여 
보안 데이터를 데이터 레이크로 수집합니다. 
B. .csv 형식으로 보안 데이터를 수집하도록 AWS Lambda 함수를 구성합니다. Amazon S3 
버킷에 데이터를 업로드합니다. 
C. 보안 데이터를 수집하기 위해 Amazon Security Lake 에 데이터 레이크를 구성합니다. 
Amazon S3 버킷에 데이터를 업로드합니다. 
D. 보안 데이터를 Amazon RDS 클러스터에 로드하도록 AWS Database Migration 
Service(AWS DMS) 복제 인스턴스를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/139811-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q899 
한 회사가 5 개의 온프레미스 애플리케이션을 AWS 클라우드의 VPC 로 마이그레이션하고 
있습니다. 각 애플리케이션은 현재 온프레미스의 격리된 가상 네트워크에 배포되어 있으며 
AWS 클라우드에도 유사하게 배포되어야 합니다. 애플리케이션은 공유 서비스 VPC 에 
연결되어야 합니다. 모든 애플리케이션은 서로 통신할 수 있어야 합니다. 
마이그레이션이 성공하면 회사는 100 개 이상의 애플리케이션에 대해 마이그레이션 
프로세스를 반복합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 애플리케이션 VPC 와 공유 서비스 VPC 사이에 소프트웨어 VPN 터널을 배포합니다. 
해당 서브넷의 애플리케이션 VPC 사이의 경로를 공유 서비스 VPC 에 추가합니다. 
B. 애플리케이션 VPC 와 공유 서비스 VPC 간에 VPC 피어링 연결을 배포합니다. 피어링 
연결을 통해 해당 서브넷의 애플리케이션 VPC 간 경로를 공유 서비스 VPC 에 추가합니다. 
C. 애플리케이션 VPC와 공유 서비스 VPAdd가 해당 서브넷의 애플리케이션 VPC에서 공유 
서비스 VPC 와 애플리케이션 VPC 로 경로를 지정하는 AWS Direct Connect 연결을 
배포합니다. 공유 서비스 VPC 서브넷의 경로를 애플리케이션 VPC 에 추가합니다. 
D. 전송 게이트웨이와 애플리케이션 VPC, 공유 서비스 VPC 간의 연결을 사용하여 전송 
게이트웨이를 배포합니다. Transit Gateway 를 통해 해당 서브넷의 애플리케이션 VPC 와 
공유 서비스 VPC 에 대한 애플리케이션 VPC 사이의 경로를 추가합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/140211-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q900 
한 회사에서 Amazon Elastic Container Service(Amazon ECS)를 사용하여 하이브리드 
환경에서 온프레미스 애플리케이션을 실행하려고 합니다. 애플리케이션은 현재 온프레미스 
컨테이너에서 실행됩니다. 회사에는 온프레미스, 하이브리드 또는 클라우드 환경에서 
확장할 수 있는 단일 컨테이너 솔루션이 필요합니다. 회사는 AWS 클라우드에서 새로운 
애플리케이션 컨테이너를 실행해야 하며 HTTP 트래픽용 로드 밸런서를 사용해야 합니다. 
이러한 요구 사항을 충족하는 작업 조합은 무엇입니까? (2 개 선택) 
A. 클라우드 애플리케이션 컨테이너에 대해 AWS Fargate 시작 유형을 사용하는 ECS 
클러스터를 설정합니다. 온프레미스 애플리케이션 컨테이너에는 Amazon ECS Anywhere 
외부 시작 유형을 사용합니다. 
B. 클라우드 ECS 서비스를 위한 Application Load Balancer 를 설정합니다. 
C. 클라우드 ECS 서비스를 위한 Network Load Balancer 를 설정합니다. 
D. AWS Fargate 시작 유형을 사용하는 ECS 클러스터를 설정합니다. 클라우드 
애플리케이션 컨테이너와 온프레미스 애플리케이션 컨테이너에는 Fargate 를 사용하세요. 
E. 클라우드 애플리케이션 컨테이너에 Amazon EC2 시작 유형을 사용하는 ECS 클러스터를 
설정합니다. 온프레미스 애플리케이션 컨테이너에 대해 AWS Fargate 시작 유형과 함께 
Amazon ECS Anywhere 를 사용하십시오. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/140210-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q901 
한 회사가 워크로드를 AWS 로 마이그레이션하고 있습니다. 회사는 SQL Server 
인스턴스에서 실행되는 온프레미스 관계형 데이터베이스에 민감하고 중요한 데이터를 
보유하고 있습니다. 
회사는 AWS 클라우드를 사용하여 보안을 강화하고 데이터베이스의 운영 오버헤드를 
줄이고 싶어합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션합니다. 암호화를 위해 AWS Key 
Management Service(AWS KMS) AWS 관리형 키를 사용합니다. 
B. 데이터베이스를 SQL Server DB 인스턴스용 다중 AZ Amazon RDS 로 마이그레이션합니다. 
암호화를 위해 AWS Key Management Service(AWS KMS) AWS 관리형 키를 사용합니다. 
C. 데이터를 Amazon S3 버킷으로 마이그레이션합니다. Amazon Macie 를 사용하여 데이터 
보안을 보장하세요. 
D. 데이터베이스를 Amazon DynamoDB 테이블로 마이그레이션합니다. Amazon 
CloudWatch Logs 를 사용하여 데이터 보안을 보장하세요. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/139853-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q902 
회사에서 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 회사는 애플리케이션의 현재 
가용성을 높이고 싶어합니다. 회사는 애플리케이션 아키텍처에서 AWS WAF 를 사용하려고 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 두 개의 가용 영역에 걸쳐 애플리케이션을 호스팅하는 여러 Amazon EC2 인스턴스를 
포함하는 Auto Scaling 그룹을 생성합니다. 
Application Load Balancer(ALB)를 구성하고 Auto Scaling 그룹을 대상으로 설정합니다. 
WAF 를 ALB 에 연결합니다. 
B. 애플리케이션을 호스팅하는 여러 Amazon EC2 인스턴스를 포함하는 클러스터 배치 
그룹을 생성합니다. Application Load Balancer 를 구성하고 EC2 인스턴스를 대상으로 
설정합니다. WAF 를 배치 그룹에 연결합니다. 
C. 두 개의 가용 영역에 걸쳐 애플리케이션을 호스팅하는 두 개의 Amazon EC2 인스턴스를 
생성합니다. EC2 인스턴스를 ALB(Application Load Balancer)의 대상으로 구성합니다. 
WAF 를 ALB 에 연결합니다. 
D. 두 개의 가용 영역에 걸쳐 애플리케이션을 호스팅하는 여러 Amazon EC2 인스턴스를 
포함하는 Auto Scaling 그룹을 생성합니다. 
Application Load Balancer(ALB)를 구성하고 Auto Scaling 그룹을 대상으로 설정합니다. 
WAF 를 Auto Scaling 그룹에 연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/139856-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q903 
한 회사는 수많은 애플리케이션이 액세스하는 Amazon S3 버킷에서 데이터 레이크를 
관리합니다. S3 버킷에는 각 애플리케이션에 대한 고유한 접두사가 포함되어 있습니다. 
회사는 각 애플리케이션을 특정 접두사로 제한하고 각 접두사 아래의 개체를 세부적으로 
제어하기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 각 애플리케이션에 대한 전용 S3 액세스 포인트 및 액세스 포인트 정책을 생성합니다. 
B. S3 배치 작업 작업을 생성하여 S3 버킷의 각 객체에 대한 ACL 권한을 설정합니다. 
C. S3 버킷의 객체를 각 애플리케이션의 새 S3 버킷에 복제합니다. 접두사별로 복제 
규칙을 만듭니다. 
D. S3 버킷의 객체를 각 애플리케이션의 새 S3 버킷에 복제합니다. 각 애플리케이션에 
대한 전용 S3 액세스 포인트를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/139857-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q904 
회사에는 고객이 Amazon S3 버킷에 이미지를 업로드하는 데 사용하는 애플리케이션이 
있습니다. 매일 밤 회사는 그날 받은 모든 이미지를 처리하는 Amazon EC2 스팟 집합을 
시작합니다. 각 이미지를 처리하는 데는 2 분이 걸리며 512MB 의 메모리가 필요합니다. 
솔루션 설계자는 이미지가 업로드될 때 이미지를 처리하도록 애플리케이션을 변경해야 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 변경 사항은 무엇입니까? 
A. S3 이벤트 알림을 사용하여 Amazon Simple Queue Service(Amazon SQS) 대기열에 
이미지 세부 정보가 포함된 메시지를 씁니다. 대기열에서 메시지를 읽고 이미지를 
처리하도록 AWS Lambda 함수를 구성합니다. 
B. S3 이벤트 알림을 사용하여 Amazon Simple Queue Service(Amazon SQS) 대기열에 
이미지 세부 정보가 포함된 메시지를 씁니다. 대기열에서 메시지를 읽고 이미지를 
처리하도록 EC2 예약 인스턴스를 구성합니다. 
C. S3 이벤트 알림을 사용하여 이미지 세부 정보가 포함된 메시지를 Amazon SNS(Amazon 
SNS) 주제에 게시합니다. 주제를 구독하고 이미지를 처리하도록 Amazon Elastic Container 
Service(Amazon ECS)에서 컨테이너 인스턴스를 구성합니다. 
D. S3 이벤트 알림을 사용하여 이미지 세부 정보가 포함된 메시지를 Amazon SNS(Amazon 
SNS) 주제에 게시합니다. 주제를 구독하고 이미지를 처리하도록 AWS Elastic Beanstalk 
애플리케이션을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/139858-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q905 
한 회사에서 하이브리드 애플리케이션의 가용성과 성능을 개선하고자 합니다. 이 
애플리케이션은 다양한 AWS 리전의 Amazon EC2 인스턴스에 호스팅된 상태 저장 TCP 
기반 워크로드와 온프레미스에 호스팅된 상태 비저장 UDP 기반 워크로드로 구성되어 
있습니다. 
솔루션 아키텍트는 가용성과 성능을 개선하기 위해 어떤 작업 조합을 취해야 합니까? (두 
가지 선택) 
A. AWS Global Accelerator 를 사용하여 가속기를 만듭니다. 부하 분산 장치를 엔드포인트로 
추가합니다. 
B. Amazon Route 53 지연 기반 라우팅을 사용하여 요청을 부하 분산 장치로 라우팅하는 
오리진이 있는 Amazon CloudFront 배포를 만듭니다. 
C. 각 리전에 두 개의 애플리케이션 부하 분산 장치를 구성합니다. 첫 번째는 EC2 
엔드포인트로 라우팅하고 두 번째는 온프레미스 엔드포인트로 라우팅합니다. 
D. 각 리전에 EC2 엔드포인트를 처리하도록 네트워크 부하 분산 장치를 구성합니다. 
온프레미스 엔드포인트로 라우팅하는 각 리전에 네트워크 부하 분산 장치를 구성합니다. 
E. 각 리전에 EC2 엔드포인트를 처리하도록 네트워크 부하 분산 장치를 구성합니다. 각 
지역에서 온프레미스 엔드포인트로 라우팅하는 애플리케이션 로드 밸런서를 구성합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/144916-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q906 
한 회사가 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS)에서 자체 
관리형 Microsoft SQL Server 를 실행합니다. EBS 볼륨의 일일 스냅샷이 생성됩니다. 
최근 모든 만료된 EBS 스냅샷을 삭제하는 스냅샷 정리 스크립트를 실행하는 동안 회사의 
모든 EBS 스냅샷이 실수로 삭제되었습니다. 솔루션 아키텍트는 EBS 스냅샷을 무기한 
보관하지 않고도 데이터 손실을 방지하기 위해 아키텍처를 업데이트해야 합니다. 
어떤 솔루션이 최소한의 개발 노력으로 이러한 요구 사항을 충족할까요? 
A. 사용자의 IAM 정책을 변경하여 EBS 스냅샷 삭제를 거부합니다. 
B. 매일 스냅샷을 완료한 후 EBS 스냅샷을 다른 AWS 리전에 복사합니다. 
C. 휴지통에 7 일 EBS 스냅샷 보관 규칙을 만들고 모든 스냅샷에 규칙을 적용합니다. 
D. EBS 스냅샷을 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 복사합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/144969-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q907 
한 회사에서 테스트 환경에서 애플리케이션에 AWS CloudFormation 스택을 사용하려고 
합니다. 이 회사는 퍼블릭 액세스를 차단하는 Amazon S3 버킷에 CloudFormation 템플릿을 
저장합니다. 이 회사는 테스트 환경을 만들기 위한 특정 사용자 요청에 따라 S3 버킷의 
템플릿에 대한 CloudFormation 액세스 권한을 부여하려고 합니다. 솔루션은 보안 모범 
사례를 따라야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon S3 에 대한 게이트웨이 VPC 엔드포인트를 만듭니다. S3 객체 URL 을 사용하도록 
CloudFormation 스택을 구성합니다. 
B. S3 버킷을 대상으로 하는 Amazon API Gateway REST API 를 만듭니다. API Gateway 
URL 을 사용하도록 CloudFormation 스택을 구성합니다. 
C. 템플릿 객체에 대한 미리 서명된 URL 을 만듭니다. 미리 서명된 URL 을 사용하도록 
CloudFormation 스택을 구성합니다. 
D. S3 버킷의 템플릿 객체에 대한 퍼블릭 액세스를 허용합니다. 테스트 환경이 생성된 후 
퍼블릭 액세스를 차단합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145006-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q908 
회사에 AWS Organizations 의 조직에서 실행되는 애플리케이션이 있습니다. 이 회사는 
애플리케이션의 운영 지원을 아웃소싱합니다. 이 회사는 보안을 손상시키지 않고 외부 지원 
엔지니어에게 액세스를 제공해야 합니다. 
외부 지원 엔지니어는 AWS Management Console 에 액세스해야 합니다. 외부 지원 
엔지니어는 또한 프라이빗 서브넷에서 Amazon Linux 를 실행하는 회사의 Amazon EC2 
인스턴스에 대한 운영 체제 액세스가 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 안전하게 충족할까요? 
A. 모든 인스턴스에 AWS Systems Manager Agent(SSM Agent)가 설치되어 있는지 
확인합니다. Systems Manager 에 연결하는 데 필요한 정책이 있는 인스턴스 프로필을 
할당합니다. AWS IAM Identity Center 를 사용하여 외부 지원 엔지니어에게 콘솔 액세스를 
제공합니다. Systems Manager 
Session Manager 를 사용하여 필요한 권한을 할당합니다. 
B. 모든 인스턴스에 AWS Systems Manager Agent(SSM Agent)가 설치되어 있는지 
확인합니다. Systems Manager 에 연결하는 데 필요한 정책이 있는 인스턴스 프로필을 
할당합니다. Systems Manager Session Manager 를 사용하여 각 AWS 계정의 로컬 IAM 
사용자 자격 증명을 외부 지원 엔지니어에게 제공하여 콘솔에 액세스합니다. 
C. 모든 인스턴스에 외부 지원 엔지니어의 소스 IP 주소 범위에서만 SSH 액세스를 
허용하는 보안 그룹이 있는지 확인합니다. 콘솔 액세스를 위해 각 AWS 계정의 로컬 IAM 
사용자 자격 증명을 외부 지원 엔지니어에게 제공합니다. 각 외부 지원 엔지니어에게 
애플리케이션 인스턴스에 로그인할 수 있는 SSH 키 쌍을 제공합니다. 
D. 퍼블릭 서브넷에 베스천 호스트를 만듭니다. 외부 엔지니어의 IP 주소 범위에서만 
액세스를 허용하도록 베스천 호스트 보안 그룹을 설정합니다. 모든 인스턴스에 베스천 
호스트에서 SSH 액세스를 허용하는 보안 그룹이 있는지 확인합니다. 각 외부 지원 
엔지니어에게 애플리케이션 인스턴스에 로그인할 수 있는 SSH 키 쌍을 제공합니다. 콘솔 
액세스를 위해 엔지니어에게 로컬 계정 IAM 사용자 자격 증명을 제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145029-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q909 
한 회사에서 PostgreSQL 용 Amazon RDS 를 사용하여 us-east-1 지역에서 애플리케이션을 
실행합니다. 이 회사는 또한 기계 학습(ML) 모델을 사용하여 거의 실시간 보고서를 
기반으로 연간 수익을 예측합니다. 이 보고서는 동일한 PostgreSQL용 RDS 데이터베이스를 
사용하여 생성됩니다. 
업무 시간 동안 데이터베이스 성능이 저하됩니다. 이 회사는 데이터베이스 성능을 개선해야 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 지역 간 읽기 복제본을 만듭니다. 읽기 복제본에서 생성될 보고서를 구성합니다. 
B. PostgreSQL 용 RDS 에 대한 다중 AZ DB 인스턴스 배포를 활성화합니다. 스탠바이 
데이터베이스에서 생성될 보고서를 구성합니다. 
C. AWS Data Migration Service(AWS DMS)를 사용하여 데이터를 새 데이터베이스에 
논리적으로 복제합니다. 새 데이터베이스에서 생성될 보고서를 구성합니다. 
D. us-east-1 에서 읽기 복제본을 만듭니다. 읽기 복제본에서 생성될 보고서를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145030-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q910 
한 회사가 AWS 클라우드에서 다중 계층 퍼블릭 웹 애플리케이션을 호스팅합니다. 웹 
애플리케이션은 Amazon EC2 인스턴스에서 실행되고 데이터베이스는 Amazon RDS 에서 
실행됩니다. 이 회사는 다가오는 휴일 주말에 매출이 크게 증가할 것으로 예상합니다. 
솔루션 아키텍트는 2 분 이내의 세부성으로 웹 애플리케이션의 성능을 분석하는 솔루션을 
구축해야 합니다. 
솔루션 아키텍트는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon CloudWatch 로그를 Amazon Redshift 로 보냅니다. Amazon QuickSight 를 
사용하여 추가 분석을 수행합니다. 
B. 모든 EC2 인스턴스에서 자세한 모니터링을 활성화합니다. Amazon CloudWatch 
메트릭을 사용하여 추가 분석을 수행합니다. 
C. Amazon CloudWatch Logs 에서 EC2 로그를 가져오는 AWS Lambda 함수를 만듭니다. 
Amazon CloudWatch 메트릭을 사용하여 추가 분석을 수행합니다. 
D. EC2 로그를 Amazon S3 로 보냅니다. Amazon Redshift 를 사용하여 S3 버킷에서 로그를 
가져와 Amazon QuickSight 로 추가 분석을 위한 원시 데이터를 처리합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/144971-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q911 
한 회사에서 사진을 저장하고 공유하는 애플리케이션을 실행합니다. 사용자는 사진을 
Amazon S3 버킷에 업로드합니다. 사용자는 매일 약 150 장의 사진을 업로드합니다. 이 
회사는 각 새 사진의 썸네일을 만들고 두 번째 S3 버킷에 썸네일을 저장하는 솔루션을 
설계하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 장기 실행 Amazon EMR 클러스터에서 1 분마다 스크립트를 호출하도록 Amazon 
EventBridge 예약 규칙을 구성합니다. 썸네일이 없는 사진에 대한 썸네일을 생성하도록 
스크립트를 구성합니다. 썸네일을 두 번째 S3 버킷에 업로드하도록 스크립트를 구성합니다. 
B. 항상 켜져 있는 메모리 최적화된 Amazon EC2 인스턴스에서 1 분마다 스크립트를 
호출하도록 Amazon EventBridge 예약 규칙을 구성합니다. 썸네일이 없는 사진에 대한 
썸네일을 생성하도록 스크립트를 구성합니다. 썸네일을 두 번째 S3 버킷에 업로드하도록 
스크립트를 구성합니다. 
C. 사용자가 애플리케이션에 새 사진을 업로드할 때마다 AWS Lambda 함수를 호출하도록 
S3 이벤트 알림을 구성합니다. Lambda 함수를 구성하여 섬네일을 생성하고 섬네일을 두 
번째 S3 버킷에 업로드합니다. 
D. 사용자가 애플리케이션에 새 사진을 업로드할 때마다 AWS Lambda 함수를 호출하도록 
S3 Storage Lens 를 구성합니다. 
Lambda 함수를 구성하여 섬네일을 생성하고 섬네일을 두 번째 S3 버킷에 업로드합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/144972-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q912 
한 회사가 Amazon S3 Glacier Deep Archive 스토리지 클래스를 사용하여 Amazon S3 
버킷에 여러 접두사로 수백만 개의 객체를 저장했습니다. 이 회사는 보존해야 하는 데이터 
하위 집합을 제외한 3 년 이상 된 모든 데이터를 삭제해야 합니다. 이 회사는 보존해야 
하는 데이터를 식별했고 서버리스 솔루션을 구현하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. S3 인벤토리를 사용하여 모든 객체를 나열합니다. AWS CLI 를 사용하여 인벤토리 
목록에서 객체를 삭제하는 Amazon EC2 인스턴스에서 실행되는 스크립트를 만듭니다. 
B. AWS Batch 를 사용하여 보존해야 하는 데이터를 제외한 3 년 이상 된 객체를 
삭제합니다. 
C. AWS Glue 크롤러를 프로비저닝하여 3 년 이상 된 객체를 쿼리합니다. 오래된 객체의 
매니페스트 파일을 저장합니다. 매니페스트에서 객체를 삭제하는 스크립트를 만듭니다. 
D. S3 인벤토리를 활성화합니다. 객체를 필터링하고 삭제하는 AWS Lambda 함수를 
만듭니다. 인벤토리 보고서를 사용하여 객체를 삭제하려면 S3 배치 작업으로 Lambda 
함수를 호출합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145209-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
특정 데이터를 보존하면서 3 년 이상 된 객체를 삭제해야 하는 요구 사항을 충족하기 위해 
이 솔루션은 서버리스 기술을 활용하여 운영 오버헤드를 최소화합니다. 
S3 인벤토리: S3 인벤토리는 S3 버킷의 모든 객체와 마지막 수정 날짜와 같은 데이터를 
포함하도록 구성할 수 있는 메타데이터를 나열하는 플랫 파일을 제공합니다. 이 인벤토리는 
매일 또는 매주 생성할 수 있습니다. 
AWS Lambda 함수: Lambda 함수를 생성하여 S3 인벤토리 보고서를 처리하고 보존해야 할 
객체를 필터링하고 삭제해야 할 객체를 식별할 수 있습니다. 
S3 배치 작업: S3 배치 작업은 객체 삭제와 같은 작업을 대규모로 실행할 수 있습니다. S3 
배치 작업을 통해 Lambda 함수를 호출하면 식별된 객체를 삭제하는 프로세스를 
자동화하여 솔루션이 서버리스이고 최소한의 운영 관리가 필요하도록 할 수 있습니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(EC2 의 AWS CLI 스크립트): EC2 인스턴스에서 스크립트를 실행하면 불필요한 운영 
오버헤드가 추가되고 서버리스가 아닙니다. 
옵션 B(AWS Batch): AWS Batch 는 대규모 배치 컴퓨팅 워크로드를 실행하도록 
설계되었으며, 이 시나리오에서는 과도합니다. 
옵션 C(AWS Glue + 스크립트): AWS Glue 는 ETL 작업에 더 적합하며, 이 접근 방식은 
서버리스 Lambda 솔루션에 비해 불필요한 복잡성을 더합니다. 
Q913 
한 회사가 AWS 에서 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 여러 AWS 
Lambda 함수를 사용하여 단일 Amazon S3 버킷에서 민감한 데이터를 검색하여 처리합니다. 
이 회사는 권한이 있는 Lambda 함수만 데이터에 액세스할 수 있도록 해야 합니다. 이 
솔루션은 최소 권한 원칙을 준수해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 공유 IAM 역할을 통해 모든 Lambda 함수에 S3 버킷 전체 액세스 권한을 부여합니다. 
B. Lambda 함수가 VPC 내에서 실행되도록 구성합니다. Lambda 함수의 VPC 엔드포인트 
IP 주소에 따라 액세스 권한을 부여하는 버킷 정책을 구성합니다. 
C. 각 Lambda 함수에 대해 개별 IAM 역할을 만듭니다. IAM 역할에 S3 버킷 액세스 
권한을 부여합니다. 각 IAM 역할을 해당 Lambda 함수에 대한 Lambda 실행 역할로 
할당합니다. 
D. 함수 ARN 에 따라 Lambda 함수에 대한 액세스 권한을 부여하는 버킷 정책을 
구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145210-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q914 
한 회사에서 각 사업부를 위한 여러 마이크로서비스로 구성된 비생산 애플리케이션을 
개발했습니다. 단일 개발팀이 모든 마이크로서비스를 유지 관리합니다. 
현재 아키텍처는 정적 웹 프런트엔드와 애플리케이션 로직이 포함된 Java 기반 백엔드를 
사용합니다. 이 아키텍처는 또한 회사가 Amazon EC2 인스턴스에 호스팅하는 MySQL 
데이터베이스를 사용합니다. 
회사는 애플리케이션이 안전하고 전 세계적으로 사용 가능한지 확인해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Amazon CloudFront 와 AWS Amplify 를 사용하여 정적 웹 프런트엔드를 호스팅합니다. 
Amazon API Gateway 를 사용하여 마이크로서비스가 액세스하는 AWS Lambda 함수를 
사용하도록 마이크로서비스를 리팩터링합니다. MySQL 데이터베이스를 Amazon EC2 예약 
인스턴스로 마이그레이션합니다. 
B. Amazon CloudFront 와 Amazon S3 를 사용하여 정적 웹 프런트엔드를 호스팅합니다. 
Amazon API Gateway 를 사용하여 마이크로서비스가 액세스하는 AWS Lambda 함수를 
사용하도록 마이크로서비스를 리팩터링합니다. MySQL 데이터베이스를 Amazon RDS for 
MySQL 로 마이그레이션합니다. 
C. Amazon CloudFront 와 Amazon S3 를 사용하여 정적 웹 프런트엔드를 호스팅합니다. 
Network Load Balancer 뒤의 대상 그룹에 있는 AWS Lambda 함수를 사용하도록 
마이크로서비스를 리팩토링합니다. MySQL 데이터베이스를 Amazon RDS for MySQL 로 
마이그레이션합니다. 
D. Amazon S3 를 사용하여 정적 웹 프런트엔드를 호스팅합니다. Application Load Balancer 
뒤의 대상 그룹에 있는 AWS Lambda 함수를 사용하도록 마이크로서비스를 리팩토링합니다. 
MySQL 데이터베이스를 Amazon EC2 예약 인스턴스로 마이그레이션합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145211-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q915 
비디오 게임 회사가 글로벌 사용자에게 새로운 게임 애플리케이션을 배포하고 있습니다. 이 
회사는 플레이어에 대한 거의 실시간 리뷰와 순위를 제공하는 솔루션이 필요합니다. 
솔루션 아키텍트는 데이터에 빠르게 액세스할 수 있는 솔루션을 설계해야 합니다. 또한 이 
솔루션은 회사가 애플리케이션을 다시 시작할 경우 데이터가 디스크에 유지되도록 해야 
합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Amazon S3 버킷을 원본으로 하는 Amazon CloudFront 배포를 구성합니다. 플레이어 
데이터를 S3 버킷에 저장합니다. 
B. 여러 AWS 리전에 Amazon EC2 인스턴스를 만듭니다. 플레이어 데이터를 EC2 
인스턴스에 저장합니다. Amazon Route 53 을 지리적 위치 레코드로 구성하여 사용자를 가장 
가까운 EC2 인스턴스로 안내합니다. 
C. Redis Duster 용 Amazon ElastiCache 를 배포합니다. 플레이어 데이터를 ElastiCache 
클러스터에 저장합니다. 
D. Memcached Duster 용 Amazon ElastiCache 를 배포합니다. 플레이어 데이터를 
ElastiCache 클러스터에 저장합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145201-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 요구 사항 분석: 애플리케이션에는 데이터에 대한 거의 실시간 액세스, 지속성 및 
최소한의 운영 오버헤드가 필요합니다. 
* Redis 용 ElastiCache: 지속성을 갖춘 인 메모리 데이터 스토리지를 제공하여 빠른 
액세스와 내구성을 지원합니다. 
* 운영 오버헤드: 관리형 서비스는 설정, 유지 관리, 확장 부담을 줄여줍니다. 
* 구현: 
* Redis 클러스터용 ElastiCache 를 배포합니다. 
* AOF(Append-Only File) 또는 RDB(Redis Database Backup) 스냅샷을 사용하여 디스크에 
데이터를 유지하도록 Redis 를 구성합니다. 
* 결론: Redis 용 ElastiCache 는 빠른 액세스, 데이터 지속성 및 낮은 운영 오버헤드에 대한 
요구 사항을 충족합니다. 
Q916 
한 회사에서 민감한 데이터를 처리하는 AWS 애플리케이션을 설계하고 있습니다. 이 
애플리케이션은 여러 고객의 재무 데이터를 저장하고 처리합니다. 
규정 준수 요구 사항을 충족하려면 안전한 중앙 집중식 키 관리 솔루션을 사용하여 각 
고객의 데이터를 별도로 암호화해야 합니다. 이 회사는 AWS Key Management Service(AWS 
KMS)를 사용하여 암호화를 구현하려고 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. 각 고객에 대해 고유한 암호화 키를 생성합니다. Amazon S3 버킷에 키를 저장합니다. 
서버 측 암호화를 활성화합니다. 
B. 고객이 제공한 암호화 키를 안전하게 저장하는 AWS 환경에 하드웨어 보안 
어플라이언스를 배포합니다. 보안 어플라이언스를 AWS KMS 와 통합하여 애플리케이션의 
민감한 데이터를 암호화합니다. 
C. 단일 AWS KMS 키를 생성하여 애플리케이션 전체의 모든 민감한 데이터를 
암호화합니다. 
D. 세분화된 액세스 제어 및 로깅이 활성화된 각 고객의 데이터에 대해 별도의 AWS KMS 
키를 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145202-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 AWS Key Management Service(KMS)를 활용하여 최소한의 운영 오버헤드로 각 
고객의 데이터를 별도로 암호화해야 하는 요구 사항을 충족합니다. 
별도의 AWS KMS 키: 각 고객에 대해 별도의 KMS 키를 생성하면 각 고객의 데이터가 
고유한 키로 암호화되도록 할 수 있습니다. 이 접근 방식은 별도 암호화에 대한 규정 준수 
요구 사항을 충족하고 키에 대한 액세스를 세부적으로 제어할 수 있습니다. 
세분화된 액세스 제어: AWS KMS 를 사용하면 키 정책을 정의하고 IAM 정책을 사용하여 
키에 특정 권한을 부여할 수 있습니다. 이를 통해 권한이 있는 사용자 또는 서비스만 키에 
액세스할 수 있으므로 최소 권한 원칙이 유지됩니다. 
로깅 및 모니터링: AWS KMS 는 모든 키 사용 및 관리 활동을 로깅하는 AWS CloudTrail 과 
통합됩니다. 이는 규정 준수 요구 사항을 충족하는 데 필수적인 감사 추적을 제공합니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(S3 에 키 저장): S3 에 키를 저장하는 것은 KMS 와 동일한 수준의 보안, 액세스 제어 
또는 AWS 서비스와의 통합을 제공하지 않기 때문에 권장되지 않습니다. 
옵션 B(하드웨어 보안 어플라이언스): 하드웨어 보안 어플라이언스를 배포하면 상당한 운영 
오버헤드와 복잡성이 추가되지만 KMS 가 이미 안전하고 중앙 집중화된 키 관리 솔루션을 
제공한다는 점을 감안하면 불필요합니다. 
옵션 C(모든 데이터에 대한 단일 KMS 키): 단일 KMS 키를 사용하면 각 고객의 데이터를 
별도로 암호화해야 하는 요구 사항을 충족하지 못합니다. 
AWS 참조: 
AWS Key Management Service(KMS) - KMS, 기능 및 키 관리 모범 사례 개요. 
다중 테넌트 애플리케이션에 AWS KMS 사용 - 다중 테넌트에 KMS 를 사용하여 
애플리케이션을 설계하는 방법에 대한 지침. 
Q917 
회사는 고객 주문을 처리하기 위해 복원력 있는 웹 애플리케이션을 설계해야 합니다. 웹 
애플리케이션은 고객 경험에 영향을 미치거나 고객 주문을 잃지 않고 웹 트래픽과 
애플리케이션 사용량의 증가를 자동으로 처리해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. NAT 게이트웨이를 사용하여 웹 트래픽을 관리합니다. Amazon EC2 Auto Scaling 그룹을 
사용하여 처리된 고객 주문을 수신, 처리 및 저장합니다. AWS Lambda 함수를 사용하여 
처리되지 않은 주문을 캡처하고 저장합니다. 
B. 네트워크 로드 밸런서(NLB)를 사용하여 웹 트래픽을 관리합니다. 애플리케이션 로드 
밸런서를 사용하여 NL 에서 고객 주문을 수신합니다. 다중 AZ 배포와 함께 Amazon 
Redshift 를 사용하여 처리되지 않은 고객 주문과 처리된 고객 주문을 저장합니다. 
C. 게이트웨이 로드 밸런서(GWLB)를 사용하여 웹 트래픽을 관리합니다. Amazon Elastic 
Container Service(Amazon ECS)를 사용하여 고객 주문을 수신하고 처리합니다. GWLB 를 
사용하여 처리되지 않은 주문을 캡처하고 저장합니다. Amazon DynamoDB 를 사용하여 
처리된 고객 주문을 저장합니다. 
D. 애플리케이션 로드 밸런서를 사용하여 웹 트래픽을 관리합니다. Amazon EC2 Auto 
Scaling 그룹을 사용하여 고객 주문을 받고 처리합니다. Amazon Simple Queue 
Service(Amazon SQS)를 사용하여 처리되지 않은 주문을 저장합니다. 다중 AZ 배포가 있는 
Amazon RDS 를 사용하여 처리된 고객 주문을 저장합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145212-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q918 
한 회사에서 AWS DataSync 를 사용하여 온프레미스 시스템에서 AWS 로 수백만 개의 
파일을 마이그레이션하고 있습니다. 파일 크기는 평균 10KB 입니다. 
이 회사는 파일 스토리지에 Amazon S3 를 사용하려고 합니다. 마이그레이션 후 첫 1 년 
동안은 파일을 한두 번 액세스해야 하며 즉시 사용할 수 있어야 합니다. 1 년 후에는 파일을 
최소 7 년 동안 보관해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 보관 도구를 사용하여 파일을 큰 개체로 그룹화합니다. DataSync 를 사용하여 개체를 
마이그레이션합니다. 첫 1 년 동안 S3 Glacier Instant 
Retrieval 에 개체를 저장합니다. 수명 주기 구성을 사용하여 1 년 후 파일을 S3 Glacier 
Deep Archive 로 전환하고 보존 기간은 7 년입니다. 
B. 보관 도구를 사용하여 파일을 큰 개체로 그룹화합니다. DataSync 를 사용하여 개체를 S3 
Standard-Infrequent Access(S3 Standard-IA)에 복사합니다. 라이프사이클 구성을 사용하여 
1 년 후 7 년의 보존 기간으로 파일을 S3 Glacier Instant Retrieval 로 전환합니다. 
C. 파일의 대상 스토리지 클래스를 S3 Glacier Instant Retrieval 로 구성합니다. 라이프사이클 
정책을 사용하여 1 년 후 7 년의 보존 기간으로 파일을 S3 Glacier Flexible Retrieval 로 
전환합니다. 
D. DataSync 작업을 구성하여 파일을 S3 Standard-Infrequent Access(S3 Standard-IA)로 
전송합니다. 라이프사이클 구성을 사용하여 1 년 후 7 년의 보존 기간으로 파일을 S3 Deep 
Archive 로 전환합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145420-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q919 
한 회사에서 최근 온프레미스 Oracle 데이터베이스 워크로드를 리프트 앤 시프트 
마이그레이션하여 Amazon EC2 메모리 최적화 Linux 인스턴스에서 실행했습니다. EC2 
Linux 인스턴스는 64,000 IOPS 의 1TB 프로비저닝 IOPS SSD(io1) EBS 볼륨을 사용합니다. 
마이그레이션 후 데이터베이스 스토리지 성능은 온프레미스 데이터베이스 성능보다 
느립니다. 
어떤 솔루션이 스토리지 성능을 개선할까요? 
A. 프로비저닝 IOPS SSD(io1) EBS 볼륨을 더 추가합니다. OS 명령을 사용하여 LVM(논리적 
볼륨 관리) 스트라이프를 만듭니다. 
B. 프로비저닝 IOPS SSD(io1) EBS 볼륨을 64,000 IOPS 이상으로 늘립니다. 
C. 프로비저닝 IOPS SSD(io1) EBS 볼륨의 크기를 2TB 로 늘립니다. 
D. EC2 Linux 인스턴스를 스토리지 최적화 인스턴스 유형으로 변경합니다. 프로비저닝 
IOPS SSD(io1) EBS 볼륨을 변경하지 마세요. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145414-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q920 
한 회사가 Amazon EC2 에 호스팅된 웹 애플리케이션의 모놀리식 아키텍처에서 서버리스 
마이크로서비스 아키텍처로 마이그레이션하고 있습니다. 이 회사는 이벤트 중심의 느슨하게 
결합된 아키텍처를 지원하는 AWS 서비스를 사용하려고 합니다. 이 회사는 
게시/구독(pub/sub) 패턴을 사용하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon API Gateway REST API 를 구성하여 Amazon Simple Queue Service(Amazon SQS) 
대기열에 이벤트를 게시하는 AWS Lambda 함수를 호출합니다. 하나 이상의 구독자가 SQS 
대기열에서 이벤트를 읽도록 구성합니다. 
B. Amazon API Gateway REST API 를 구성하여 Amazon Simple Notification Service(Amazon 
SNS) 토픽에 이벤트를 게시하는 AWS Lambda 함수를 호출합니다. 하나 이상의 구독자가 
SNS 토픽에서 이벤트를 수신하도록 구성합니다. 
C. Amazon API Gateway WebSocket API 를 구성하여 향상된 팬아웃을 사용하여 Amazon 
Kinesis Data Streams 의 데이터 스트림에 씁니다. 
하나 이상의 구독자가 데이터 스트림에서 이벤트를 수신하도록 구성합니다. 
D. Amazon Simple Notification Service(Amazon SNS) 토픽에 이벤트를 게시하는 AWS 
Lambda 함수를 호출하도록 Amazon API Gateway HTTP API 를 구성합니다. 토픽에서 
이벤트를 수신하도록 하나 이상의 구독자를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145415-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
D?? 
Q921 
한 회사에서 최근 모놀리식 애플리케이션을 Amazon EC2 인스턴스와 Amazon RDS 로 
마이그레이션했습니다. 애플리케이션에는 밀접하게 결합된 모듈이 있습니다. 
애플리케이션의 기존 설계는 애플리케이션이 단일 EC2 인스턴스에서만 실행될 수 있는 
기능을 제공합니다. 
이 회사는 최대 사용 시간 동안 EC2 인스턴스에서 높은 CPU 사용률을 발견했습니다. 높은 
CPU 사용률은 Amazon RDS 에서 읽기 요청에 대한 성능이 저하됨을 의미합니다. 이 
회사는 높은 CPU 사용률을 줄이고 읽기 요청 성능을 개선하고자 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. EC2 인스턴스의 크기를 CPU 용량이 더 많은 EC2 인스턴스 유형으로 조정합니다. 최소 
및 최대 크기가 1 인 자동 확장 그룹을 구성합니다. 읽기 요청에 대한 RDS 읽기 복제본을 
구성합니다. 
B. EC2 인스턴스의 크기를 CPU 용량이 더 많은 EC2 인스턴스 유형으로 조정합니다. 최소 
및 최대 크기가 1 인 자동 확장 그룹을 구성합니다. RDS 읽기 복제본을 추가하고 모든 
읽기/쓰기 트래픽을 복제본으로 리디렉션합니다. 
C. 최소 크기 1, 최대 크기 2 로 자동 확장 그룹을 구성합니다. RDS DB 인스턴스를 CPU 
용량이 더 많은 인스턴스 유형으로 크기 조정합니다. 
D. EC2 인스턴스를 CPU 용량이 더 많은 EC2 인스턴스 유형으로 크기 조정합니다. 최소 
및 최대 크기 1 로 자동 확장 그룹을 구성합니다. RDS DB 인스턴스를 CPU 용량이 더 많은 
인스턴스 유형으로 크기 조정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145343-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
EC2 인스턴스의 높은 CPU 사용률과 읽기 요청에 대한 Amazon RDS 의 저하된 성능을 
해결하기 위해 솔루션에는 두 가지 주요 작업이 포함됩니다. EC2 인스턴스 크기 조정과 
Amazon RDS 읽기 복제본 활용. 
EC2 인스턴스 크기 조정: 첫 번째 단계는 EC2 인스턴스 크기를 최대 사용 시간 동안 더 
높은 계산 수요를 처리할 수 있도록 CPU 용량이 더 큰 유형으로 조정하는 것입니다. 
이렇게 하면 CPU 에 대한 즉각적인 부담을 완화하는 데 도움이 됩니다. 
크기가 1 인 자동 확장 그룹: 애플리케이션은 모놀리식 특성으로 인해 단일 EC2 
인스턴스에서만 실행할 수 있지만 최소 및 최대 크기가 1 인 자동 확장 그룹을 만들면 장애 
발생 시 인스턴스가 자동으로 다시 시작되거나 교체되어 고가용성을 유지할 수 있습니다. 
RDS 읽기 복제본: RDS 읽기 복제본을 구성하면 애플리케이션이 읽기 요청을 별도의 
인스턴스로 오프로드하여 기본 RDS 인스턴스의 부하를 줄일 수 있습니다. 이렇게 하면 
이전에 EC2 인스턴스의 높은 CPU 사용률로 인해 병목 현상이 발생했던 읽기 작업의 
성능이 향상됩니다. 
다른 옵션은 왜 안 됩니까?: 
옵션 B: 모든 트래픽을 RDS 읽기 복제본으로 리디렉션하는 것은 권장되지 않습니다. 
복제본은 쓰기 작업이 아닌 읽기 트래픽 전용이기 때문입니다. 이로 인해 데이터 일관성 
문제가 발생할 수 있습니다. 
옵션 C: RDS 인스턴스 유형 용량을 늘리면 도움이 되지만 EC2 인스턴스의 높은 CPU 
사용량을 해결하지 못하고 읽기 확장을 위한 솔루션도 제공하지 못합니다. 
옵션 D: EC2 와 RDS 인스턴스의 크기를 조정하면 용량이 늘어나지만 기본 RDS 
인스턴스에서 읽기 트래픽을 오프로드해야 하는 구체적인 요구 사항은 해결하지 못합니다. 
Q922 
회사에서 개발자 팀에 회사의 AWS 리소스에 대한 액세스 권한을 부여해야 합니다. 회사는 
리소스에 대해 높은 수준의 보안을 유지해야 합니다. 
회사에는 민감한 데이터에 대한 무단 액세스를 방지하는 액세스 제어 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 액세스 관리를 간소화하고 개발 작업을 간소화하기 위해 각 개발 팀원의 IAM 사용자 
자격 증명을 나머지 팀원과 공유합니다. 
B. 최소 권한 원칙에 따라 세분화된 권한이 있는 IAM 역할을 정의합니다. 각 개발자에게 
IAM 역할을 할당합니다. 
C. IAM 액세스 키를 생성하여 AWS 리소스에 대한 프로그래밍 방식 액세스를 부여합니다. 
액세스 키를 사용하여 개발자만 API 호출을 통해 AWS 리소스와 상호 작용하도록 
허용합니다. 
D. AWS Cognito 사용자 풀을 생성합니다. 사용자 풀을 사용하여 개발자에게 AWS 리소스에 
대한 액세스 권한을 부여합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145676-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q923 
한 회사가 Amazon EC2 인스턴스에서 모놀리식 웹 애플리케이션을 호스팅합니다. 
애플리케이션 사용자는 최근 특정 시간에 성능이 저하되었다고 보고했습니다. Amazon 
CloudWatch 메트릭 분석 결과 성능이 저하되는 기간 동안 CPU 사용률이 100%인 것으로 
나타났습니다. 
이 회사는 이 성능 문제를 해결하고 애플리케이션 가용성을 개선하고자 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (두 가지 
선택) 
A. AWS Compute Optimizer 를 사용하여 수직 확장을 위한 인스턴스 유형에 대한 권장 
사항을 얻습니다. 
B. 웹 서버에서 Amazon Machine Image(AMI)를 만듭니다. 새 시작 템플릿에서 AMI 를 
참조합니다. 
C. 수직 확장을 위한 Auto Scaling 그룹과 Application Load Balancer 를 만듭니다. 
D. AWS Compute Optimizer 를 사용하여 수평 확장을 위한 인스턴스 유형에 대한 권장 
사항을 얻습니다. 
E. 수평 확장을 위한 Auto Scaling 그룹과 Application Load Balancer 를 만듭니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/145038-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q924 
한 회사가 모든 비즈니스 애플리케이션을 AWS 클라우드에서 실행합니다. 이 회사는 AWS 
Organizations 를 사용하여 여러 AWS 계정을 관리합니다. 
솔루션 아키텍트는 IAM 사용자에게 부여된 모든 권한을 검토하여 필요한 것보다 더 많은 
권한이 있는 IAM 사용자를 파악해야 합니다. 
어떤 솔루션이 최소한의 관리 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Network Access Analyzer 를 사용하여 회사의 AWS 계정에 있는 모든 액세스 권한을 
검토합니다. 
B. IAM 사용자가 AWS 계정에서 리소스를 생성하거나 수정할 때 활성화되는 AWS 
CloudWatch 알람을 만듭니다. 
C. AWS Identity and Access Management(IAM) Access Analyzer 를 사용하여 회사의 모든 
리소스와 계정을 검토합니다. 
D. Amazon Inspector 를 사용하여 기존 IAM 정책의 취약성을 찾습니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/144976-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q925 
회사는 규정 준수를 위해 새로운 데이터 보존 정책을 구현해야 합니다. 이 정책의 일환으로 
Amazon S3 버킷에 저장된 중요한 문서는 일정 기간 동안 삭제 또는 수정되지 않도록 
보호해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 필요한 객체에서 S3 객체 잠금을 활성화하고 거버넌스 모드를 활성화합니다. 
B. 필요한 객체에서 S3 객체 잠금을 활성화하고 컴플라이언스 모드를 활성화합니다. 
C. S3 버킷에서 버전 관리를 활성화합니다. 지정된 기간 후에 객체를 삭제하도록 수명 주기 
정책을 설정합니다. 
D. 보존 기간 동안 객체를 S3 Glacier Flexible Retrieval 로 전환하도록 S3 수명 주기 정책을 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145213-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q926 
한 회사가 컨테이너에서 고객 대상 웹 애플리케이션을 실행합니다. 워크로드는 AWS 
Fargate 에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다. 웹 
애플리케이션은 리소스를 많이 사용합니다. 
웹 애플리케이션은 고객에게 주 7 일, 하루 24 시간 제공되어야 합니다. 회사는 
애플리케이션이 짧은 시간 동안 높은 트래픽을 경험할 것으로 예상합니다. 워크로드는 
고가용성이어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요? 
A. Fargate 로 ECS 용량 공급자를 구성합니다. 타사 도구를 사용하여 부하 테스트를 
수행합니다. Amazon CloudWatch 에서 Fargate 작업의 크기를 조정합니다. 
B. 정상 상태의 Fargate 와 버스트 추적의 Fargate Spot 으로 ECS 용량 공급자를 
구성합니다. 
C. 정상 상태의 Fargate Spot 과 버스트 추적의 Fargate 로 ECS 용량 공급자를 구성합니다. 
D. Fargate 로 ECS 용량 공급자를 구성합니다. AWS Compute Optimizer 를 사용하여 
Fargate 작업의 크기를 조정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/144978-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q927 
한 회사가 AWS 클라우드에서 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 
Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에 호스팅됩니다. 이 회사는 
DNS 에 Amazon Route 53 을 사용합니다. 
이 회사는 DDoS 공격을 탐지하기 위한 사전 대응적 참여가 가능한 관리형 솔루션이 
필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. AWS Config 를 활성화합니다. DDoS 공격을 탐지하는 AWS Config 관리형 규칙을 
구성합니다. 
B. AL 에서 AWS WAF 를 활성화합니다. DDoS 공격을 탐지하고 차단하는 규칙이 있는 AWS 
WAF 웹 ACL 을 만듭니다. 웹 ACL 을 ALB 와 연결합니다. 
C. ALB 액세스 로그를 Amazon S3 버킷에 저장합니다. DDoS 공격을 탐지하고 자동화된 
예방 조치를 취하도록 Amazon GuardDuty 를 구성합니다. 
D. AWS Shield Advanced 를 구독합니다. Route 53 에서 호스팅 영역을 구성합니다. ALB 
리소스를 보호된 리소스로 추가합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145214-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Shield Advanced 는 사전 대응 및 대응 기능을 통해 DDoS 공격에 대한 향상된 보호 
기능을 제공하도록 설계되어 이 시나리오에 가장 적합한 솔루션입니다. 
AWS Shield Advanced: 이 서비스는 DDoS 공격에 대한 고급 보호 기능을 제공합니다. 
여기에는 자세한 공격 진단, AWS DDoS 대응 팀(DRT)에 대한 24 시간 연중무휴 액세스, 
DDoS 관련 확장 요금에 대한 재정적 보호가 포함됩니다. Shield Advanced 는 또한 Route 
53 및 Application Load Balancer(ALB)와 통합되어 웹 애플리케이션에 대한 포괄적인 
보호를 보장합니다. 
Route 53 및 ALB 보호: Route 53 호스팅 영역 및 ALB 리소스를 AWS Shield Advanced 에 
추가하면 이러한 구성 요소가 향상된 보호 계획에 포함되도록 할 수 있습니다. Shield 
Advanced 는 트래픽을 적극적으로 모니터링하고 실시간 공격 완화를 제공하여 
애플리케이션에 대한 DDoS 공격의 영향을 최소화합니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(AWS Config): AWS Config 는 구성 관리 서비스이며 DDoS 보호 또는 감지 기능을 
제공하지 않습니다. 
옵션 B(AWS WAF): AWS WAF 는 일부 유형의 공격을 완화하는 데 도움이 될 수 있지만 
Shield Advanced 가 제공하는 포괄적인 DDoS 보호 및 사전 대응적 참여를 제공하지 
않습니다. 
옵션 C(GuardDuty): GuardDuty 는 AWS 환경 내에서 잠재적으로 악의적인 활동을 식별하는 
위협 탐지 서비스이지만 DDoS 보호를 제공하도록 특별히 설계된 것은 아닙니다. 
Q928 
한 회사가 VPC 에서 비디오 스트리밍 웹 애플리케이션을 호스팅합니다. 이 회사는 네트워크 
로드 밸런서(NLB)를 사용하여 실시간 데이터 처리를 위한 TCP 트래픽을 처리합니다. 
애플리케이션에 대한 무단 액세스 시도가 있었습니다. 
이 회사는 무단 액세스 시도를 방지하기 위해 최소한의 아키텍처 변경으로 애플리케이션 
보안을 개선하고자 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 무단 트래픽을 필터링하기 위해 NLB 에 직접 일련의 AWS WAF 규칙을 구현합니다. 
B. 신뢰할 수 있는 IP 주소만 허용하도록 보안 그룹으로 NLB 를 다시 만듭니다. 
C. 엄격한 IP 주소 허용 목록으로 구성된 기존 NLB 와 병렬로 두 번째 NLB 를 배포합니다. 
D. AWS Shield Advanced 를 사용하여 향상된 DDoS 보호를 제공하고 무단 액세스 시도를 
방지합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/144979-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q929 
한 의료 회사에서 암호화된 Amazon Simple Notification Service(Amazon SNS) 주제에 
알림을 게시하는 AWS Lambda 함수를 개발하고 있습니다. 알림에는 보호된 건강 
정보(PHI)가 포함되어 있습니다. 
SNS 주제는 암호화를 위해 AWS Key Management Service(AWS KMS) 고객 관리 키를 
사용합니다. 회사는 애플리케이션에 SNS 주제에 안전하게 메시지를 게시하는 데 필요한 
권한이 있는지 확인해야 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까?(세 가지 선택) 
A. Lambda 함수가 주제에 메시지를 게시할 수 있도록 허용하는 SNS 주제에 대한 리소스 
정책을 만듭니다. 
B. 고객 관리 키 대신 SNS 주제에 AWS KMS 키(SSE-KMS)를 사용하여 서버 측 암호화를 
사용합니다. 
C. 필요한 AWS KMS 권한이 있는 SNS 주제에서 사용하는 암호화 키에 대한 리소스 정책을 
만듭니다. 
D. SNS 주제의 리소스 정책에서 Lambda 함수의 Amazon 리소스 이름(ARN)을 지정합니다. 
E. API Gateway 리소스 정책을 사용하여 주제에 대한 액세스를 제어하기 위해 Amazon API 
Gateway HTTP API 를 SNS 주제와 연결합니다. 
F. AWS KMS 에서 고객 관리 키를 사용하는 데 필요한 IAM 권한이 있는 Lambda 실행 
역할을 구성합니다. 
Answer: A, C, F 
https://www.examtopics.com/discussions/amazon/view/144981-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q930 
한 회사에 직원 웹 포털이 있습니다. 직원은 포털에 로그인하여 급여 세부 정보를 
확인합니다. 이 회사는 직원이 스캔한 문서를 업로드하여 상환할 수 있는 새로운 시스템을 
개발하고 있습니다. 이 회사는 문서에서 텍스트 기반 데이터를 추출하고 추출한 정보를 각 
직원의 상환 ID 에 첨부하여 처리하는 프로그램을 실행합니다. 
직원 웹 포털은 100% 가동 시간이 필요합니다. 문서 추출 프로그램은 주문형 방식으로 
하루 종일 드물게 실행됩니다. 이 회사는 기존 웹 포털을 최소한으로 변경해야 하는 확장 
가능하고 비용 효율적인 새로운 시스템을 구축하려고 합니다. 이 회사는 코드를 변경하고 
싶어하지 않습니다. 
어떤 솔루션이 최소한의 구현 노력으로 이러한 요구 사항을 충족할까요? 
A. 웹 포털의 자동 확장 그룹에서 Amazon EC2 주문형 인스턴스를 실행합니다. AWS 
Lambda 함수를 사용하여 문서 
추출 프로그램을 실행합니다. 직원이 새 상환 문서를 업로드할 때 Lambda 함수를 
호출합니다. 
B. 웹 포털에 대한 자동 확장 그룹에서 Amazon EC2 스팟 인스턴스를 실행합니다. EC2 
스팟 인스턴스에서 문서 추출 프로그램을 실행합니다. 
직원이 새로운 상환 문서를 업로드할 때 문서 추출 프로그램 인스턴스를 시작합니다. 
C. 웹 포털과 문서 추출 프로그램을 실행하기 위해 저축 플랜을 구매합니다. 자동 확장 
그룹에서 웹 포털과 문서 추출 프로그램을 실행합니다. 
D. 웹 포털을 호스팅할 Amazon S3 버킷을 만듭니다. 기존 기능에 대해 Amazon API 
Gateway 와 AWS Lambda 함수를 사용합니다. Lambda 함수를 사용하여 문서 추출 
프로그램을 실행합니다. 새 문서 업로드와 연결된 API 가 호출될 때 Lambda 함수를 
호출합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145215-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
D?? 
Q931 
미디어 회사가 us-east-1 지역에 다중 계정 AWS 환경을 보유하고 있습니다. 이 회사는 
프로덕션 계정에 성능 지표를 게시하는 Amazon Simple Notification Service(Amazon SNS) 
토픽을 보유하고 있습니다. 이 회사는 로그 데이터를 처리하고 분석하기 위한 관리자 
계정에 AWS Lambda 함수를 보유하고 있습니다. 
관리자 계정에 있는 Lambda 함수는 중요한 지표가 보고될 때 프로덕션 계정에 있는 SNS 
토픽의 메시지에 의해 호출되어야 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (두 가지 선택) 
A. Amazon SNS 가 함수를 호출할 수 있도록 Lambda 함수에 대한 IAM 리소스 정책을 
만듭니다. 
B. 프로덕션 계정에 있는 SNS 토픽의 메시지를 버퍼링하기 위해 관리자 계정에 Amazon 
Simple Queue Service(Amazon SQS) 대기열을 구현합니다. Lambda 함수를 호출하도록 
SQS 대기열을 구성합니다. 
C. Lambda 함수가 토픽을 구독할 수 있도록 SNS 토픽에 대한 IAM 정책을 만듭니다. 
D. 프로덕션 계정에서 Amazon EventBridge 규칙을 사용하여 SNS 토픽 알림을 캡처합니다. 
관리자 계정에 있는 Lambda 함수로 알림을 전달하도록 EventBridge 규칙을 구성합니다. 
E. 프로덕션 계정의 Amazon S3 버킷에 성능 지표를 저장합니다. Amazon Athena 를 
사용하여 관리자 계정의 지표를 분석합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/145416-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
A, B?? 
Q932 
회사에서 온프레미스 위치에서 Amazon Elastic Kubernetes Service(Amazon EKS)로 
애플리케이션을 마이그레이션하고 있습니다. 회사는 
요구 사항을 준수하기 위해 회사 VPC 에 있는 포드에 대해 사용자 지정 서브넷을 사용해야 
합니다. 또한 회사는 포드가 포드의 VPC 내에서 안전하게 통신할 수 있도록 해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon EKS 의 포드에 대한 사용자 지정 서브넷 구성을 직접 관리하도록 AWS Transit 
Gateway 를 구성합니다. 
B. 회사의 온프레미스 IP 주소 범위에서 EKS 포드로 AWS Direct Connect 연결을 만듭니다. 
C. Kubernetes 용 Amazon VPC CNI 플러그인을 사용합니다. 포드가 사용할 VPC 클러스터에 
사용자 지정 서브넷을 정의합니다. 
D. 사용자 지정 서브넷 내의 특정 노드에 포드 배치를 제한하는 포드 안티-애니멀리티 
규칙이 있는 Kubernetes 네트워크 정책을 구현합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145298-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q933 
한 회사에서 모든 데이터를 AWS 에서 완벽하게 관리하는 단일 Amazon RDS for MySQL DB 
인스턴스에 저장하는 전자상거래 애플리케이션을 호스팅합니다. 
이 회사는 단일 장애 지점의 위험을 완화해야 합니다. 
어떤 솔루션이 최소한의 구현 노력으로 이러한 요구 사항을 충족할 수 있을까요? 
A. RDS DB 인스턴스를 수정하여 다중 AZ 배포를 사용합니다. 다음 유지 관리 기간 동안 
변경 사항을 적용합니다. 
B. 현재 데이터베이스를 새로운 Amazon DynamoDB Multi-AZ 배포로 마이그레이션합니다. 
이기종 마이그레이션 전략과 함께 AWS Database Migration Service(AWS DMS)를 사용하여 
현재 RDS DB 인스턴스를 DynamoDB 테이블로 마이그레이션합니다. 
C. 다중 AZ 배포에서 새 RDS DB 인스턴스를 만듭니다. 가장 최근 스냅샷에서 기존 RDS 
DB 인스턴스의 데이터를 수동으로 복원합니다. 
D. 최소 그룹 크기가 3 인 Amazon EC2 Auto Scaling 그룹에서 DB 인스턴스를 구성합니다. 
Amazon Route 53 단순 라우팅을 사용하여 모든 DB 인스턴스에 요청을 분산합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145008-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q934 
한 회사에 온프레미스 환경에서 파일을 공유하기 위한 여러 Microsoft Windows SMB 파일 
서버와 Linux NFS 파일 서버가 있습니다. 회사의 AWS 마이그레이션 계획의 일환으로 
회사는 AWS 클라우드에서 파일 서버를 통합하려고 합니다. 
회사에는 NFS 와 SMB 액세스를 모두 지원하는 관리형 AWS 스토리지 서비스가 필요합니다. 
솔루션은 프로토콜 간에 공유할 수 있어야 합니다. 솔루션은 가용성 영역 수준에서 
중복성이 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 스토리지에 Amazon FSx for NetApp ONTAP 을 사용합니다. 다중 프로토콜 액세스를 
구성합니다. 
B. 두 개의 Amazon EC2 인스턴스를 만듭니다. Windows SMB 파일 서버 액세스에 하나의 
EC2 인스턴스를 사용하고 Linux NFS 파일 서버 액세스에 하나의 EC2 인스턴스를 
사용합니다. 
C. SMB 액세스에 Amazon FSx for NetApp ONTAP 을 사용합니다. NFS 액세스에 Amazon 
FSx for Lustre 를 사용합니다. 
D. Amazon S3 스토리지를 사용합니다. Amazon S3 파일 게이트웨이를 통해 Amazon S3 에 
액세스합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145009-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q935 
소프트웨어 회사에서 중요한 웹 애플리케이션을 업그레이드해야 합니다. 이 애플리케이션은 
현재 회사가 퍼블릭 서브넷에 호스팅하는 단일 Amazon EC2 인스턴스에서 실행됩니다. EC2 
인스턴스는 MySQL 데이터베이스를 실행합니다. 애플리케이션의 DNS 레코드는 Amazon 
Route 53 영역에 게시됩니다. 
솔루션 아키텍트는 애플리케이션을 확장 가능하고 고가용성으로 재구성해야 합니다. 솔루션 
아키텍트는 또한 MySQL 읽기 지연 시간을 줄여야 합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (두 가지 선택) 
A. 두 번째 AWS 지역에서 두 번째 EC2 인스턴스를 시작합니다. Route 53 장애 조치 
라우팅 정책을 사용하여 트래픽을 두 번째 EC2 인스턴스로 리디렉션합니다. 
B. 여러 가용 영역에서 개인 EC2 인스턴스를 시작하기 위한 자동 확장 그룹을 만들고 
구성합니다. 새 애플리케이션 부하 분산 장치 뒤에 있는 대상 그룹에 인스턴스를 
추가합니다. 
C. 데이터베이스를 Amazon Aurora MySQL 클러스터로 마이그레이션합니다. 별도의 가용 
영역에서 기본 DB 인스턴스와 리더 DB 인스턴스를 만듭니다. 
D. 여러 AWS 지역에서 개인 EC2 인스턴스를 시작하기 위한 자동 확장 그룹을 만들고 
구성합니다. 인스턴스를 새 애플리케이션 로드 밸런서 뒤에 있는 대상 그룹에 추가합니다. 
E. 데이터베이스를 크로스 리전 읽기 복제본이 있는 Amazon Aurora MySQL 클러스터로 
마이그레이션합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/144933-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q936 
한 회사에서 수천 개의 AWS Lambda 함수를 실행합니다. 이 회사에는 모든 Lambda 
함수에서 사용하는 민감한 정보를 안전하게 저장할 솔루션이 필요합니다. 이 솔루션은 또한 
민감한 정보의 자동 로테이션을 관리해야 합니다. 
어떤 단계 조합이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할 수 있을까요? (두 
가지 선택) 
A. Lambda@Edge 를 사용하여 민감한 정보를 검색하고 생성하여 HTTP 보안 헤더를 
만듭니다. 
B. 민감한 정보를 검색하는 Lambda 계층을 만듭니다. 
C. AWS Secrets Manager 에 민감한 정보를 저장합니다. 
D. AWS Systems Manager Parameter Store 에 민감한 정보를 저장합니다. 
E. 민감한 정보를 검색하고 환경 변수를 생성하기 위한 전용 처리량이 있는 Lambda 
소비자를 만듭니다. 
Answer: C, D 
https://www.examtopics.com/discussions/amazon/view/145010-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q937 
한 회사에 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행되는 내부 애플리케이션이 
있습니다. EC2 인스턴스는 컴퓨팅 최적화되어 있으며 Amazon Elastic Block Store(Amazon 
EBS) 볼륨을 사용합니다. 
이 회사는 EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨에서 비용 최적화를 식별하려고 
합니다. 
어떤 솔루션이 가장 운영 효율성이 뛰어나 이러한 요구 사항을 충족할까요? 
A. 새 AWS 비용 및 사용 보고서를 만듭니다. 보고서에서 EC2 인스턴스, Auto Scaling 그룹 
및 EBS 볼륨에 대한 비용 권장 사항을 검색합니다. 
B. 새 Amazon CloudWatch 청구 알림을 만듭니다. 알림 상태에서 EC2 인스턴스, Auto 
Scaling 그룹 및 EBS 볼륨에 대한 비용 권장 사항을 확인합니다. 
C. EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨에 대한 비용 권장 사항에 대해 AWS 
Compute Optimizer 를 구성합니다. 
D. EC2 인스턴스에 대한 비용 권장 사항에 대해 AWS Compute Optimizer 를 구성합니다. 
새 AWS 비용 및 사용 보고서를 만듭니다. 보고서에서 Auto Scaling 그룹과 EBS 볼륨에 
대한 비용 권장 사항을 검색합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145011-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 요구 사항 분석: 회사는 운영 효율성이 높은 EC2 인스턴스, Auto Scaling 그룹 및 EBS 
볼륨에 대한 비용 최적화를 식별하려고 합니다. 
* AWS Compute Optimizer: 이 서비스는 EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨을 
포함하여 AWS 리소스를 최적화하는 데 도움이 되는 실행 가능한 권장 사항을 제공합니다. 
* 비용 권장 사항: Compute Optimizer 는 리소스 활용도를 분석하고 구성의 크기를 
조정하거나 최적화하기 위한 구체적인 권장 사항을 제공합니다. 
* 운영 효율성: Compute Optimizer 를 사용하면 비용 절감 기회를 식별하는 프로세스가 
자동화되어 수동 분석의 필요성이 줄어듭니다. 
* 구현: 
* AWS 계정에 대해 AWS Compute Optimizer 를 활성화합니다. 
* EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨에 대해 제공된 권장 사항을 검토하세요. 
* 결론: 이 솔루션은 최소한의 운영 노력으로 비용 최적화를 식별하는 포괄적이고 자동화된 
접근 방식을 제공합니다. 
Q938 
한 회사에서 단일 VPC의 여러 가용성 영역에 분산된 여러 Amazon EC2 인스턴스에 미디어 
스토어를 운영하고 있습니다. 이 회사는 모든 EC2 인스턴스 간에 데이터를 공유할 수 있는 
고성능 솔루션을 원하며, VPC 내에서만 데이터를 보관하는 것을 선호합니다. 
솔루션 아키텍트는 무엇을 권장해야 합니까? 
A. Amazon S3 버킷을 만들고 각 인스턴스의 애플리케이션에서 서비스 API 를 호출합니다. 
B. Amazon S3 버킷을 만들고 모든 인스턴스가 마운트된 볼륨으로 액세스하도록 
구성합니다. 
C. Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성하고 모든 인스턴스에 
마운트합니다. 
D. Amazon Elastic File System(Amazon EFS) 파일 시스템을 구성하고 모든 인스턴스에 
마운트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145679-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Elastic File System(EFS)은 여러 EC2 인스턴스에 마운트할 수 있는 관리형 파일 
스토리지 서비스입니다. VPC 내의 인스턴스 간에 데이터를 공유하기 위한 확장 가능하고 
성능이 뛰어난 솔루션을 제공합니다. 
고성능: EFS 는 높은 처리량과 IOPS 가 필요한 워크로드에 확장 가능한 성능을 제공합니다. 
특히 여러 인스턴스 간에 데이터를 공유해야 하는 애플리케이션에 적합합니다. 
사용 편의성: EFS는 여러 가용성 영역에 걸쳐 여러 인스턴스에 쉽게 마운트할 수 있어 VPC 
내의 모든 인스턴스에서 액세스할 수 있는 공유 파일 시스템을 제공합니다. 
보안: EFS 는 데이터가 VPC 내에 유지되도록 구성할 수 있으며, 저장 중 및 전송 중 
암호화를 지원합니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(API 가 있는 Amazon S3 버킷): S3 는 객체 스토리지에 적합하지만 파일 시스템이 
아니며 인스턴스 간에 공유되는 데이터에 필요한 저지연 액세스를 제공하지 않습니다. 
옵션 B(마운트된 볼륨으로서의 S3 버킷): S3 는 파일 시스템으로 마운트되도록 설계되지 
않았으며, 이 접근 방식은 불필요한 복잡성과 지연을 초래합니다. 
옵션 C(인스턴스 간에 공유되는 EBS 볼륨): EBS 볼륨은 여러 인스턴스에 동시에 연결할 수 
없습니다. EFS 와 같이 인스턴스 간에 공유되도록 설계되지 않았습니다. 
Q939 
한 회사에서 Amazon RDS for MySQL 인스턴스를 사용합니다. 연말 처리를 준비하기 위해 
회사는 회사의 보고 도구에서 추가 읽기 전용 쿼리를 수용하기 위해 읽기 복제본을 
추가했습니다. 읽기 복제본 CPU 사용량은 60%이고 기본 인스턴스 CPU 사용량은 
60%였습니다. 
연말 활동이 완료된 후 읽기 복제본의 CPU 사용량은 일정하게 25%입니다. 기본 
인스턴스의 CPU 사용량은 여전히 일정하게 60%입니다. 회사는 데이터베이스 크기를 
조정하고 향후 성장에 충분한 성능을 제공하고자 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 읽기 복제본 삭제 기본 인스턴스를 변경하지 마세요. 
B. 읽기 복제본을 더 작은 인스턴스 크기로 조정 기본 인스턴스를 변경하지 마세요. 
C. 읽기 복제본을 더 큰 인스턴스 크기로 조정 기본 인스턴스를 더 작은 인스턴스 크기로 
조정합니다. 
D. 읽기 복제본 삭제 기본 인스턴스의 크기를 더 큰 인스턴스로 조정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145680-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q940 
한 회사에서 데이터베이스를 Amazon RDS for PostgreSQL 로 마이그레이션하고 있습니다. 
이 회사는 애플리케이션을 Amazon EC2 인스턴스로 마이그레이션하고 있습니다. 이 회사는 
장기 실행 워크로드에 대한 비용을 최적화하고자 합니다. 
이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon RDS for PostgreSQL 워크로드에 온디맨드 인스턴스를 사용합니다. EC2 
인스턴스에 대한 선불 없음 옵션이 있는 1 년 컴퓨팅 절감 플랜을 구매합니다. 
B. Amazon RDS for PostgreSQL 워크로드에 대한 선불 없음 옵션이 있는 1 년 기간의 예약 
인스턴스를 구매합니다. EC2 인스턴스에 대한 선불 없음 옵션이 있는 1 년 기간의 EC2 
인스턴스 절감 플랜을 구매합니다. 
C. Amazon RDS for PostgreSQL 워크로드에 대한 부분 선불 옵션이 있는 1 년 기간의 예약 
인스턴스를 구매합니다. EC2 인스턴스에 대한 부분 선불 옵션이 있는 1 년 기간의 EC2 
인스턴스 절감 플랜을 구매합니다. 
D. Amazon RDS for PostgreSQL 워크로드에 대한 All Upfront 옵션으로 3 년 기간의 
Reserved Instances 를 구매합니다. EC2 인스턴스에 대한 All Upfront 옵션으로 3 년 EC2 
Instance Savings Plan 을 구매합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/144895-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q941 
한 회사에서 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터를 사용하고 
있습니다. 이 회사는 서비스 계정에 대한 IAM 역할(IRSA)을 사용하여 EKS 클러스터의 
Kubernetes 서비스 계정이 특정 AWS 리소스에 안전하고 세부적으로 액세스할 수 있도록 
해야 합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (두 가지 선택) 
A. 필요한 권한을 정의하는 IAM 정책을 만듭니다. 정책을 EKS 노드의 IAM 역할에 직접 
연결합니다. 
B. Kubernetes 서비스 계정이 특정 AWS 서비스에 액세스하지 못하도록 EKS 클러스터 
내에서 네트워크 정책을 구현합니다. 
C. 각 Kubernetes 서비스 계정에 대한 권한을 포함하도록 EKS 클러스터의 IAM 역할을 
수정합니다. IAM 역할과 Kubernetes 역할 간에 일대일 매핑을 보장합니다. 
D. 필요한 권한을 포함하는 IAM 역할을 정의합니다. Kubernetes 서비스 계정에 IAM 역할의 
Amazon ResourceName(ARN)을 주석으로 지정합니다. 
E. 서비스 계정에 대한 IAM 역할과 OpenID Connect(OIDC) ID 공급자 간에 신뢰 관계를 
설정합니다. 
Answer: D, E 
https://www.examtopics.com/discussions/amazon/view/145808-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
C, E?? 
Q942 
한 회사가 분석을 위해 Amazon S3 버킷에 기밀 데이터를 정기적으로 업로드합니다. 
회사의 보안 정책에 따라 객체는 휴면 상태에서 암호화되어야 합니다. 회사는 매년 암호화 
키를 자동으로 순환해야 합니다. 회사는 AWS CloudTrail 을 사용하여 키 순환을 추적할 수 
있어야 합니다. 또한 회사는 암호화 키 비용을 최소화해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 고객 제공 키로 서버 측 암호화 사용(SSE-C) 
B. Amazon S3 관리 키로 서버 측 암호화 사용(SSE-S3) 
C. AWS KMS 키로 서버 측 암호화 사용(SSE-KMS) 
D. 고객 관리 AWS KMS 키로 서버 측 암호화 사용 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145418-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
D?? 
Q943 
한 회사에서 지난 3 개월 동안 여러 애플리케이션을 AWS 로 마이그레이션했습니다. 이 
회사는 각 애플리케이션의 비용 내역을 알고 싶어합니다. 이 회사는 이 정보가 포함된 정기 
보고서를 받고 싶어합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요? 
A. AWS Budgets 를 사용하여 지난 3 개월 동안의 데이터를 .csv 파일로 다운로드합니다. 
원하는 정보를 찾습니다. 
B. AWS 비용 및 사용 보고서를 Amazon RDS DB 인스턴스에 로드합니다. SQL 쿼리를 
실행하여 원하는 정보를 가져옵니다. 
C. 모든 AWS 리소스에 비용 키와 애플리케이션 이름 값을 태그합니다. 비용 할당 태그를 
활성화합니다. Cost Explorer 를 사용하여 원하는 정보를 가져옵니다. 
D. 모든 AWS 리소스에 비용 키와 애플리케이션 이름 값을 태그합니다. AWS Billing and 
Cost Management 콘솔을 사용하여 지난 3 개월 동안의 청구서를 다운로드합니다. 원하는 
정보를 찾습니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145918-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q944 
전자상거래 회사가 고객에게 지속적인 서비스를 제공하기 위해 AWS 에 웹 애플리케이션을 
배포할 준비를 하고 있습니다. 아키텍처에는 회사가 Amazon EC2 인스턴스에 호스팅하는 
웹 애플리케이션, Amazon RDS 의 관계형 데이터베이스, 회사가 Amazon S3 에 저장하는 
정적 자산이 포함됩니다. 
회사는 애플리케이션에 대한 견고하고 회복성 있는 아키텍처를 설계하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 단일 가용 영역에 Amazon EC2 인스턴스를 배포합니다. 동일한 가용 영역에 RDS DB 
인스턴스를 배포합니다. 정적 자산을 저장하기 위해 버전 관리가 활성화된 Amazon S3 를 
사용합니다. 
B. 여러 가용 영역에 걸쳐 Auto Scaling 그룹에 Amazon EC2 인스턴스를 배포합니다. 다중 
AZ RDS DB 인스턴스를 배포합니다. Amazon CloudFront 를 사용하여 정적 자산을 
분산합니다. 
C. 단일 가용 영역에 Amazon EC2 인스턴스를 배포합니다. 교차 AZ 중복성을 위해 두 
번째 가용 영역에 RDS DB 인스턴스를 배포합니다. EC2 인스턴스에서 직접 정적 자산을 
제공합니다. 
D. AWS Lambda 함수를 사용하여 웹 애플리케이션을 제공합니다. 데이터베이스에 Amazon 
Aurora Serverless v2 를 사용합니다. 정적 자산을 Amazon Elastic File System(Amazon EFS) 
One Zone-Infrequent Access(One Zone-IA)에 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145527-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q945 
전자상거래 회사가 여러 AWS 계정에서 여러 내부 애플리케이션을 실행합니다. 이 회사는 
AWS Organizations 를 사용하여 AWS 계정을 관리합니다. 
회사의 네트워킹 계정에 있는 보안 어플라이언스는 AWS 계정에서 애플리케이션 간의 상호 
작용을 검사해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 네트워킹 계정에 네트워크 로드 밸런서(NLB)를 배포하여 보안 어플라이언스로 트래픽을 
전송합니다. 애플리케이션 계정에서 인터페이스 VPC 엔드포인트를 사용하여 NLB 로 
트래픽을 전송하도록 애플리케이션 계정을 구성합니다. 
B. 애플리케이션 계정에 애플리케이션 로드 밸런서(ALB)를 배포하여 보안 어플라이언스로 
직접 트래픽을 전송합니다. 
C. 네트워킹 계정에 게이트웨이 로드 밸런서(GWLB)를 배포하여 보안 어플라이언스로 
트래픽을 전송합니다. 애플리케이션 계정에서 인터페이스 GWLB 엔드포인트를 사용하여 
GWLB 로 트래픽을 전송하도록 애플리케이션 계정을 구성합니다. 
D. 애플리케이션 계정에 인터페이스 VPC 엔드포인트를 배포하여 보안 어플라이언스로 직접 
트래픽을 전송합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145014-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Gateway Load Balancer(GWLB)는 허브 앤 스포크 모델에서 보안 어플라이언스를 통해 
트래픽을 라우팅하도록 특별히 설계되어 여러 AWS 계정 간의 트래픽을 검사하는 데 
이상적인 솔루션입니다. 
GWLB 를 사용하면 타사 가상 어플라이언스를 투명하게 간소화, 확장 및 배포할 수 있으며 
인터페이스 엔드포인트(Gateway Load Balancer Endpoints)를 사용하여 여러 VPC 또는 
계정에서 작동할 수 있습니다. 
주요 AWS 기능: 
* 트래픽 검사: GWLB 를 사용하면 중앙 집중형 보안 어플라이언스가 여러 VPC 간의 
트래픽을 검사할 수 있으므로 계정 간 상호 작용을 검사하는 데 적합합니다. 
* 인터페이스 VPC 엔드포인트: 애플리케이션 계정에서 인터페이스 엔드포인트를 사용하면 
트래픽을 네트워킹 계정의 보안 어플라이언스로 안전하고 효율적으로 라우팅할 수 
있습니다. 
* AWS 설명서: GWLB 를 사용하면 중앙 집중형 네트워크 보안을 위한 AWS 모범 사례와 
일치하여 아키텍처를 간소화하고 운영 복잡성을 줄일 수 있습니다. 
Q946 
한 회사가 6 개의 Aurora 복제본이 포함된 Amazon Aurora MySQL DB 클러스터에서 
프로덕션 워크로드를 실행합니다. 이 회사는 부서 중 하나의 실시간 보고 쿼리를 Aurora 
복제본 3 개에 자동으로 분산하려고 합니다. 이 3 개의 복제본은 나머지 DB 클러스터와 
다른 컴퓨팅 및 메모리 사양을 가지고 있습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 워크로드에 대한 사용자 지정 엔드포인트를 만들고 사용합니다. 
B. 3 노드 클러스터 복제본을 만들고 리더 엔드포인트를 사용합니다. 
C. 선택한 3 개 노드에 대해 인스턴스 엔드포인트를 사용합니다. 
D. 리더 엔드포인트를 사용하여 읽기 전용 워크로드를 자동으로 분산합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145919-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Aurora 에서 사용자 지정 엔드포인트는 Aurora DB 클러스터의 특정 인스턴스 
집합으로 트래픽을 전달하는 부하 분산 엔드포인트를 만들 수 있는 기능입니다. 이는 특히 
구성이 다른 인스턴스 하위 집합으로 트래픽을 라우팅하거나 특정 워크로드(예: 보고 
쿼리)를 특정 인스턴스로 격리하려는 경우에 유용합니다. 
사용자 지정 엔드포인트: 올바른 솔루션은 부서에서 거의 실시간 보고에 사용하려는 세 
개의 Aurora 복제본을 포함하는 사용자 지정 엔드포인트를 만드는 것입니다. 이 사용자 
지정 엔드포인트는 지정된 컴퓨팅 및 메모리 구성을 가진 세 개의 선택된 복제본에만 보고 
쿼리를 분산하여 이러한 쿼리가 나머지 DB 클러스터에 영향을 미치지 않도록 합니다. 
기타 옵션: 
옵션 B(3 노드 클러스터 복제본 만들기): 이는 자체 리소스가 있는 별도의 클러스터를 
만들지만 필요하지 않으며 추가 비용이 발생할 수 있습니다. 또한 기존 복제본을 활용하지 
않습니다. 
옵션 C(인스턴스 엔드포인트 사용): 이는 확장 가능하거나 자동이 아닌 개별 인스턴스에 
대한 연결을 수동으로 관리하는 것을 포함합니다. 
옵션 D(리더 엔드포인트 사용): 리더 엔드포인트는 선택된 세 개만이 아니라 클러스터의 
모든 복제본에 읽기 쿼리를 분산합니다. 이는 보고 쿼리를 세 개의 특정 복제본으로만 
제한해야 한다는 요구 사항을 충족하지 못합니다. 
Q947 
한 회사가 온프레미스 데이터 센터의 서버에서 Node.js 함수를 실행합니다. 데이터 센터는 
PostgreSQL 데이터베이스에 데이터를 저장합니다. 회사는 서버의 환경 변수에 있는 연결 
문자열에 자격 증명을 저장합니다. 회사는 애플리케이션을 AWS 로 마이그레이션하고 
Node.js 애플리케이션 서버를 AWS Lambda 로 교체하려고 합니다. 회사는 또한 Amazon 
RDS for PostgreSQL 로 마이그레이션하고 데이터베이스 자격 증명이 안전하게 관리되도록 
하려고 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. AWS Systems Manager Parameter Store 에 데이터베이스 자격 증명을 매개변수로 
저장합니다. 30 일마다 비밀을 자동으로 순환하도록 Parameter Store 를 구성합니다. Lambda 
함수를 업데이트하여 매개변수에서 자격 증명을 검색합니다. 
B. AWS Secrets Manager 에 데이터베이스 자격 증명을 비밀로 저장합니다. Secrets 
Manager 를 구성하여 30 일마다 자격 증명을 자동으로 순환합니다. Lambda 함수를 
업데이트하여 비밀에서 자격 증명을 검색합니다. 
C. 데이터베이스 자격 증명을 암호화된 Lambda 환경 변수로 저장합니다. 자격 증명을 
순환하는 사용자 지정 Lambda 함수를 작성합니다. 
Lambda 함수를 30 일마다 실행되도록 예약합니다. 
D. 데이터베이스 자격 증명을 AWS Key Management Service(AWS KMS)에 키로 저장합니다. 
키에 대한 자동 로테이션을 구성합니다. Lambda 함수를 업데이트하여 KMS 키에서 자격 
증명을 가져옵니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145920-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Secrets Manager 는 데이터베이스 자격 증명과 같은 민감한 정보를 안전하게 저장하고 
관리하도록 특별히 설계되었습니다. Lambda 및 RDS 와 같은 AWS 서비스와 완벽하게 
통합되며 최소한의 운영 오버헤드로 자동 자격 증명 로테이션을 제공합니다. 
AWS Secrets Manager: Secrets Manager 에 데이터베이스 자격 증명을 저장하면 자격 
증명이 안전하게 저장, 암호화 및 관리됩니다. Secrets Manager 는 정기적 간격(예: 
30 일마다)으로 자격 증명을 자동으로 로테이션하는 기본 제공 메커니즘을 제공하여 
추가적인 수동 개입 없이도 보안 모범 사례를 유지하는 데 도움이 됩니다. 
Lambda 통합: Lambda 함수는 AWS SDK 를 사용하여 Secrets Manager 에서 자격 증명을 
검색하도록 쉽게 구성하여 런타임에 자격 증명에 안전하게 액세스할 수 있습니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(로테이션이 있는 매개변수 저장소): 매개변수 저장소는 매개변수를 안전하게 저장할 
수 있지만 Secrets Manager 는 비밀 관리 및 자동 로테이션에 더 적합하여 더 많은 기능과 
더 적은 운영 오버헤드를 제공합니다. 
옵션 C(암호화된 Lambda 환경 변수): 암호화된 경우에도 Lambda 환경 변수에 자격 
증명을 직접 저장하려면 회전을 관리하는 사용자 지정 코드가 필요하므로 운영 복잡성이 
증가합니다. 
옵션 D(자동 회전이 있는 KMS): KMS 는 암호화 키를 관리하기 위한 것이지 데이터베이스 
자격 증명과 같은 비밀을 저장하고 회전하기 위한 것이 아닙니다. 이 옵션은 자격 증명을 
안전하게 관리하기 위해 더 많은 사용자 지정 구현이 필요합니다. 
Q948 
한 회사에서 온프레미스 Oracle 데이터베이스에서 기존 및 진행 중인 데이터 변경 사항을 
Amazon RDS for Oracle 로 복제하려고 합니다. 복제할 데이터 양은 매일 다릅니다. 이 
회사는 데이터 복제에 AWS Database Migration Service(AWS DMS)를 사용하려고 합니다. 
솔루션은 복제 인스턴스에 필요한 용량만 할당해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 다중 AZ 배포로 AWS DMS 복제 인스턴스를 구성하여 여러 가용 영역에 인스턴스를 
프로비저닝합니다. 
B. 필요한 용량을 프로비저닝하는 동안 데이터를 분석하고 복제하기 위해 AWS DMS 
Serverless 복제 작업을 만듭니다. 
C. Amazon EC2 Auto Scaling 을 사용하여 복제할 데이터 양에 따라 AWS DMS 복제 
인스턴스의 크기를 늘리거나 줄입니다. 
D. AWS Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS)를 사용하여 
필요한 용량을 프로비저닝하는 동안 데이터를 분석하고 복제하여 AWS DMS 복제 용량을 
프로비저닝합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/144936-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q949 
한 회사에 다중 계층 웹 애플리케이션이 있습니다. 애플리케이션의 내부 서비스 구성 
요소는 Amazon EC2 인스턴스에 배포됩니다. 내부 서비스 구성 요소는 AWS 에서 
호스팅되는 타사 소프트웨어 서비스(SaaS) API 에 액세스해야 합니다. 
회사는 애플리케이션의 내부 서비스에서 타사 SaaS 애플리케이션으로 안전하고 비공개적인 
연결을 제공해야 합니다. 회사는 최소한의 공개 인터넷 노출이 있는지 확인해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. AWS 사이트 간 VPN 을 구현하여 타사 SaaS 공급자와 보안 연결을 설정합니다. 
B. AWS Transit Gateway 를 배포하여 애플리케이션의 VPC 와 타사 SaaS 공급자 간의 
트래픽을 관리하고 라우팅합니다. 
C. 타사 SaaS 공급자가 설정하도록 허용하지 않고 VPC 에서 아웃바운드 트래픽만 
허용하도록 AWS PrivateLink 를 구성합니다. 
D. AWS PrivateLink 를 사용하여 애플리케이션의 VPC 와 타사 SaaS 공급자 간의 비공개 
연결을 만듭니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/144937-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q950 
솔루션 아키텍트는 회사의 기업 네트워크를 VPC 에 연결하여 온프레미스에서 AWS 
리소스에 액세스할 수 있도록 해야 합니다. 솔루션은 네트워크 계층과 세션 계층에서 기업 
네트워크와 VPC 간의 모든 트래픽을 암호화해야 합니다. 또한 솔루션은 AWS 와 
온프레미스 시스템 간의 무제한 액세스를 방지하기 위한 보안 제어를 제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Direct Connect 를 구성하여 VPC 에 연결합니다. 필요에 따라 AWS 와 온프레미스 
간의 트래픽을 허용 및 거부하도록 VPC 경로 테이블을 구성합니다. 
B. 정의된 기업 IP 주소 집합에서만 AWS Management Console 에 액세스할 수 있도록 IAM 
정책을 만듭니다. IAM 정책과 역할을 사용하여 직무 책임에 따라 사용자 액세스를 
제한합니다. 
C. AWS Site-to-Site VPN 을 구성하여 VPC 에 연결합니다. 온프레미스에서 VPC 로 트래픽을 
전달하도록 경로 테이블 항목을 구성합니다. 온프레미스에서 필요한 트래픽만 허용하도록 
인스턴스 보안 그룹 및 네트워크 ACL 을 구성합니다. 
D. AWS Transit Gateway 를 구성하여 VPC 에 연결합니다. 온프레미스에서 VPC 로 트래픽을 
전달하도록 경로 테이블 항목을 구성합니다. 온프레미스에서 필요한 트래픽만 허용하도록 
인스턴스 보안 그룹과 네트워크 ACL 을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/144938-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 네트워크 및 세션 계층에서 암호화를 제공하는 요구 사항을 충족하는 동시에 
온프레미스 시스템과 AWS 리소스 간에 제어된 액세스를 허용합니다. 
AWS 사이트 간 VPN: 이 서비스를 사용하면 인터넷이나 AWS Direct Connect 를 통해 
온프레미스 네트워크와 AWS VPC 간에 안전하고 암호화된 연결을 설정할 수 있습니다. 
VPN 은 회사 네트워크와 AWS 간에 이동하는 네트워크 계층(IPsec)에서 데이터를 
암호화합니다. 
라우팅 및 보안 제어: 라우팅 테이블 항목을 구성하면 AWS 리소스를 대상으로 하는 
트래픽만 VPC 로 전송되도록 할 수 있습니다. 또한 보안 그룹과 네트워크 ACL 을 설정하여 
VPC 내의 인스턴스와 통신할 수 있는 트래픽을 추가로 제한하고 제어할 수 있습니다. 이 
접근 방식은 회사의 보안 정책에 맞춰 무제한 액세스를 방지하는 데 필요한 보안을 
제공합니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(AWS Direct Connect): Direct Connect 는 개인 연결을 제공하지만 본질적으로 
암호화를 제공하지 않습니다. 트래픽을 암호화하려면 추가 단계가 필요하며 세션 계층 
암호화를 처리하지 않습니다. 
옵션 B(콘솔 액세스를 위한 IAM 정책): 이 옵션은 기업 네트워크와 VPC 간의 네트워크 
수준 암호화 및 보안에 대한 요구 사항을 충족하지 않습니다. 
옵션 D(AWS Transit Gateway): Transit Gateway 는 여러 연결을 관리하는 데 도움이 될 수 
있지만 네트워크 계층에서 직접 암호화를 제공하지는 않습니다. 여전히 VPN 을 구성하거나 
암호화를 위한 다른 방법을 사용해야 합니다. 
Q951 
한 회사에 Amazon RDS for MySQL DB 클러스터의 데이터베이스에서 정보를 검색하는 
임베디드 자격 증명이 있는 사용자 지정 애플리케이션이 있습니다. 이 회사는 최소한의 
프로그래밍 작업으로 애플리케이션의 보안을 강화해야 합니다. 이 회사는 애플리케이션 
사용자를 위해 RDS for MySQL 데이터베이스에 자격 증명을 만들었습니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. AWS Key Management Service(AWS KMS)에 자격 증명을 저장합니다. AWS KMS 에 키를 
만듭니다. AWS KMS 에서 데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. 
자동 키 순환을 활성화합니다. 
B. 암호화된 로컬 스토리지에 자격 증명을 저장합니다. 로컬 스토리지에서 데이터베이스 
자격 증명을 로드하도록 애플리케이션을 구성합니다. Cron 작업을 만들어 자격 증명 순환 
일정을 설정합니다. 
C. AWS Secrets Manager 에 자격 증명을 저장합니다. Secrets Manager 에서 데이터베이스 
자격 증명을 로드하도록 애플리케이션을 구성합니다. Secrets Manager 에 대한 AWS 
Lambda 함수를 만들어 자격 증명 순환 일정을 설정합니다. 
D. AWS Systems Manager Parameter Store 에 자격 증명을 저장합니다. Parameter Store 에서 
데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. Parameter Store 를 
사용하여 RDS for MySQL 데이터베이스에 자격 증명 순환 일정을 설정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145017-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q952 
한 회사가 애플리케이션을 서버리스 솔루션으로 옮기고자 합니다. 서버리스 솔루션은 
SQL 을 사용하여 기존 데이터와 새 데이터를 분석해야 합니다. 이 회사는 Amazon S3 
버킷에 데이터를 저장합니다. 데이터는 저장 시 암호화되어야 하며 다른 AWS 리전에 
복제되어야 합니다. 
어떤 솔루션이 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족할 수 있을까요? 
A. AWS KMS 다중 리전 키(SSE-KMS)를 사용하여 서버 측 암호화를 사용하는 새 S3 
버킷을 만듭니다. 리전 간 복제(CRR)를 구성합니다. 새 S3 버킷에 데이터를 로드합니다. 
Amazon Athena 를 사용하여 데이터를 쿼리합니다. 
B. Amazon S3 관리 키(SSE-S3)를 사용하여 서버 측 암호화를 사용하는 새 S3 버킷을 
만듭니다. 리전 간 복제(CRR)를 구성합니다. 새 S3 버킷에 데이터를 로드합니다. Amazon 
RDS 를 사용하여 데이터를 쿼리합니다. 
C. 기존 S3 버킷에서 리전 간 복제(CRR)를 구성합니다. Amazon S3 관리 키(SSE-S3)를 
사용하여 서버 측 암호화를 사용합니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다. 
D. 기존 S3 버킷에서 S3 Cross-Region Replication(CRR)을 구성합니다. AWS KMS 다중 
지역 키(SSEKMS)로 서버 측 암호화를 사용합니다. Amazon RDS 를 사용하여 데이터를 
쿼리합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/144939-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
Q953 
한 회사에 수천 명의 사용자가 있는 웹 애플리케이션이 있습니다. 이 애플리케이션은 
사용자가 업로드한 8~10 개의 이미지를 사용하여 AI 이미지를 생성합니다. 사용자는 
6 시간마다 생성된 AI 이미지를 다운로드할 수 있습니다. 이 회사에는 또한 사용자가 생성된 
AI 이미지를 언제든지 다운로드할 수 있는 프리미엄 사용자 옵션이 있습니다. 
이 회사는 사용자가 업로드한 이미지를 사용하여 연 2 회 AI 모델 교육을 실행합니다. 이 
회사에는 이미지를 저장할 스토리지 솔루션이 필요합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까? 
A. 업로드된 이미지를 Amazon S3 Glacier Deep Archive 로 이동합니다. 프리미엄 사용자가 
생성한 AI 이미지를 S3 Standard 로 이동합니다. 프리미엄이 아닌 사용자가 생성한 AI 
이미지를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다. 
B. 업로드된 이미지를 Amazon S3 Glacier Deep Archive 로 이동합니다. 생성된 모든 AI 
이미지를 S3 Glacier Flexible Retrieval 로 이동합니다. 
C. 업로드된 이미지를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 
이동합니다. 프리미엄 사용자 생성 AI 이미지를 S3 Standard 로 이동합니다. 프리미엄이 
아닌 사용자 생성 AI 이미지를 S3 Standard-Infrequent Access(S3 Standard-IA)로 
이동합니다. 
D. 업로드된 이미지를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 
이동합니다. 생성된 모든 AI 이미지를 S3 Glacier Flexible Retrieval 로 이동합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145540-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
?? 
설명: 
* S3 One Zone-IA: 
* 여러 가용 영역 복원력이 필요하지 않고 자주 액세스하지 않는 데이터에 적합합니다. 
* 1 년에 2 번 AI 모델 훈련에만 사용되는 사용자 업로드 이미지를 저장하는 데 비용 
효율적입니다. 
* S3 Standard: 
* 높은 내구성과 가용성으로 자주 액세스하는 데이터에 이상적입니다. 
* 프리미엄 사용자 생성 AI 이미지를 여기에 저장하면 언제든지 쉽게 다운로드할 수 
있습니다. 
* S3 Standard-IA: 
* 자주 액세스하지 않지만 빠른 검색이 필요한 데이터를 위한 비용 효율적인 
스토리지입니다. 
* 프리미엄이 아닌 사용자 생성 AI 이미지는 여기에 저장합니다. 이러한 이미지는 
6 시간마다 한 번만 다운로드되므로 비용과 접근성 간의 균형이 잘 맞습니다. 
* 비용 효율성: 이 솔루션은 액세스 패턴 및 내구성 요구 사항에 따라 데이터를 분류하여 
각 유형의 데이터가 가장 비용 효율적인 방식으로 저장되도록 보장함으로써 스토리지 
비용을 최적화합니다. 
Q954 
한 회사가 AWS 에서 머신 러닝(ML) 모델을 개발하고 있습니다. 이 회사는 ML 모델을 
독립적인 마이크로서비스로 개발하고 있습니다. 마이크로서비스는 시작 시 Amazon S3 에서 
약 1GB 의 모델 데이터를 가져와 메모리에 로드합니다. 사용자는 비동기 API 를 통해 ML 
모델에 액세스합니다. 사용자는 요청이나 일괄 요청을 보낼 수 있습니다. 
이 회사는 수백 명의 사용자에게 ML 모델을 제공합니다. 모델의 사용 패턴은 불규칙합니다. 
일부 모델은 며칠 또는 몇 주 동안 사용되지 않습니다. 다른 모델은 한 번에 수천 개의 
요청을 일괄 수신합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. API 에서 네트워크 로드 밸런서(NLB)로 요청을 전달합니다. NLB 가 호출할 AWS Lambda 
함수로 ML 모델을 배포합니다. 자동 크기 조정을 사용하여 NLB 가 수신하는 트래픽에 따라 
Lambda 함수를 확장합니다. 
B. API 에서 애플리케이션 로드 밸런서(ALB)로 요청을 전달합니다. ALB 가 호출할 Amazon 
Elastic Container Service(Amazon ECS) 서비스로 ML 모델을 배포합니다. 자동 스케일링을 
사용하여 ALB 가 수신하는 추적에 따라 ECS 클러스터 인스턴스를 확장합니다. 
C. API 에서 Amazon Simple Queue Service(Amazon SQS) 대기열로 요청을 보냅니다. ML 
모델을 SQS 이벤트가 호출하는 AWS Lambda 함수로 배포합니다. 자동 스케일링을 
사용하여 SQS 대기열의 크기에 따라 Lambda 함수의 vCPU 수를 늘립니다. 
D. API 에서 Amazon Simple Queue Service(Amazon SQS) 대기열로 요청을 보냅니다. ML 
모델을 대기열에서 읽는 Amazon Elastic Container Service(Amazon ECS) 서비스로 
배포합니다. Amazon ECS 에 자동 스케일링을 사용하여 SQS 대기열의 크기에 따라 
클러스터 용량과 서비스 수를 모두 확장합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145943-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q955 
한 회사에서 ALB(Application Load Balancer) 뒤의 Auto Scaling 그룹에 있는 Amazon EC2 
인스턴스에서 웹 애플리케이션을 실행합니다. 이 애플리케이션은 Amazon Aurora MySQL 
DB 클러스터에 데이터를 저장합니다. 
이 회사는 재해 복구(DR) 솔루션을 만들어야 합니다. DR 솔루션의 허용 복구 시간은 최대 
30 분입니다. DR 솔루션은 기본 인프라가 정상일 때 고객 사용을 지원할 필요가 없습니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. ALB 와 Auto Scaling 그룹이 있는 두 번째 AWS 지역에 DR 인프라를 배포합니다. Auto 
Scaling 그룹의 원하는 용량과 최대 용량을 최소값으로 설정합니다. Aurora MySQL DB 
클러스터를 Aurora 글로벌 데이터베이스로 변환합니다. ALB 엔드포인트가 있는 
액티브-패시브 장애 조치를 위해 Amazon Route 53 을 구성합니다. 
B. AL 이 있는 두 번째 AWS 지역에 DR 인프라를 배포합니다. 두 번째 지역의 EC2 
인스턴스를 포함하도록 Auto Scaling 그룹을 업데이트합니다. Amazon Route 53 을 사용하여 
액티브-액티브 장애 조치를 구성합니다. Aurora MySQL DB 클러스터를 Aurora 글로벌 
데이터베이스로 변환합니다. 
C. AWS Backup 을 사용하여 Aurora MySQL DB 클러스터 데이터를 백업합니다. ALB 가 있는 
두 번째 AWS 지역에 DR 인프라를 배포합니다. 두 번째 지역의 EC2 인스턴스를 
포함하도록 Auto Scaling 그룹을 업데이트합니다. Amazon Route 53 을 사용하여 
액티브-액티브 장애 조치를 구성합니다. 
두 번째 지역에 Aurora MySQL DB 클러스터를 만듭니다. 백업에서 데이터를 복원합니다. 
D. AWS Backup 을 사용하여 인프라 구성을 백업합니다. 백업을 사용하여 두 번째 AWS 
지역에 필요한 인프라를 만듭니다. Auto Scaling 그룹의 원하는 용량을 0 으로 설정합니다. 
Amazon Route 53 을 사용하여 액티브-패시브 장애 조치를 구성합니다. Aurora MySQL DB 
클러스터를 Aurora 글로벌 데이터베이스로 변환합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/146208-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q956 
한 회사에서 데이터 처리 애플리케이션을 AWS 클라우드로 마이그레이션하고 있습니다. 이 
애플리케이션은 중단될 수 없는 여러 개의 단기 일괄 작업을 처리합니다. 각 일괄 작업이 
완료된 후 데이터가 생성됩니다. 이 데이터는 30 일 동안 액세스되고 2 년 동안 보관됩니다. 
이 회사는 AWS 클라우드에서 애플리케이션을 실행하는 데 드는 비용을 최대한 낮추고자 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 데이터 처리 애플리케이션을 Amazon EC2 스팟 인스턴스로 마이그레이션합니다. 
Amazon S3 Standard 에 데이터를 저장합니다. Amazon S3 Glacier Instant 로 데이터를 
이동합니다. 30 일 후 검색합니다. 2 년 후 데이터를 삭제하도록 만료일을 설정합니다. 
B. 데이터 처리 애플리케이션을 Amazon EC2 온디맨드 인스턴스로 마이그레이션합니다. 
Amazon S3 Glacier Instant Retrieval 에 데이터를 저장합니다. 30 일 후 데이터를 S3 Glacier 
Deep Archive 로 이동합니다. 2 년 후 데이터를 삭제하도록 만료일을 설정합니다. 
C. Amazon EC2 스팟 인스턴스를 배포하여 일괄 작업을 실행합니다. Amazon S3 
Standard 에 데이터를 저장합니다. 30 일 후에 Amazon S3 Glacier Flexible Retrieval 로 
데이터를 이동합니다. 2 년 후에 데이터를 삭제하도록 만료일을 설정합니다. 
D. 일괄 작업을 실행하기 위해 Amazon EC2 On-Demand 인스턴스를 배포합니다. Amazon 
S3 Standard 에 데이터를 저장합니다. 30 일 후에 Amazon S3 Glacier Deep Archive 로 
데이터를 이동합니다. 2 년 후에 데이터를 삭제하도록 만료일을 설정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145012-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
?? 
Q957 
회사에서 하이브리드 네트워크 아키텍처를 설계해야 합니다. 회사의 워크로드는 현재 AWS 
클라우드와 온프레미스 데이터 센터에 저장되어 있습니다. 워크로드는 통신하는 데 단일 
자릿수 대기 시간이 필요합니다. 회사는 AWS Transit Gateway 전송 게이트웨이를 사용하여 
여러 VPC 를 연결합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (두 가지 
선택) 
A. 각 VPC 에 AWS 사이트 간 VPN 연결을 설정합니다. 
B. VPC 에 연결된 전송 게이트웨이와 AWS Direct Connect 게이트웨이를 연결합니다. 
C. AWS Direct Connect 게이트웨이에 AWS 사이트 간 VPN 연결을 설정합니다. 
D. AWS Direct Connect 연결을 설정합니다. Direct Connect 게이트웨이에 전송 가상 
인터페이스(VIF)를 만듭니다. 
E. VPC 에 연결된 전송 게이트웨이와 AWS 사이트 간 VPN 연결을 연결합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/145777-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* AWS Direct Connect: 온프레미스 데이터 센터에서 AWS 로 전용 네트워크 연결을 
제공하여 짧은 지연 시간과 일관된 네트워크 성능을 보장합니다. 
* 직접 연결 게이트웨이 연결: 
* Direct Connect 게이트웨이: 다양한 AWS 지역에 걸쳐 VPC 를 연결하는 글로벌 네트워크 
전송 허브 역할을 합니다. 
* Transit Gateway 와의 연결: 온프레미스 데이터 센터와 Transit Gateway 에 연결된 여러 
VPC 간의 통신을 활성화합니다. 
* VIF(전송 가상 인터페이스): 
* 전송 VIF 생성: Direct Connect 를 전송 게이트웨이와 연결합니다. 
* 설정 단계: 
* Direct Connect 연결을 설정합니다. 
* Direct Connect 게이트웨이에 대한 전송 VIF 를 생성합니다. 
* Direct Connect 게이트웨이를 VPC 에 연결된 전송 게이트웨이와 연결합니다. 
* 비용 효율성: 이 조합은 VPN 연결의 반복되는 비용과 잠재적인 성능 가변성을 방지하여 
강력하고 대기 시간이 짧은 하이브리드 네트워크 솔루션을 제공합니다. 
Q958 
글로벌 전자상거래 회사가 AWS 에서 중요한 워크로드를 실행합니다. 워크로드는 다중 AZ 
배포를 위해 구성된 Amazon RDS for PostgreSQL DB 인스턴스를 사용합니다. 
고객들은 회사에서 데이터베이스 장애 조치를 겪을 때 애플리케이션 시간 초과가 
발생한다고 보고했습니다. 이 회사는 장애 조치 시간을 줄이기 위한 복원력 있는 솔루션이 
필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon RDS 프록시를 만듭니다. 프록시를 DB 인스턴스에 할당합니다. 
B. DB 인스턴스에 대한 읽기 복제본을 만듭니다. 읽기 추적을 읽기 복제본으로 이동합니다. 
C. 성능 통찰력을 활성화합니다. CPU 부하를 모니터링하여 시간 초과를 식별합니다. 
D. 정기적으로 자동 스냅샷을 만듭니다. 자동 스냅샷을 여러 AWS 리전에 복사합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145957-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* Amazon RDS 프록시: RDS 프록시는 연결을 풀링하고 공유하여 데이터베이스 오류에 대한 
애플리케이션의 복원력을 높이고 데이터베이스 장애 조치를 자동으로 처리할 수 있는 완전 
관리형 고가용성 데이터베이스 프록시입니다. 
* 장애 조치 시간 단축: RDS Proxy 를 사용하면 애플리케이션과 데이터베이스 간의 연결 
관리가 향상되어 장애 조치 시간이 크게 단축됩니다. RDS Proxy 는 연결 풀에서 연결을 
유지하고 장애 조치 중에 연결을 다시 설정하는 데 필요한 시간을 줄여줍니다. 
* 구성: 
* RDS Proxy 인스턴스를 생성합니다. 
* RDS for PostgreSQL DB 인스턴스에 연결하도록 프록시를 구성합니다. 
* 직접 데이터베이스 엔드포인트 대신 RDS Proxy 엔드포인트를 사용하도록 애플리케이션 
구성을 수정합니다. 
* 운영상의 이점: 이 솔루션은 고가용성을 제공하고 애플리케이션 코드를 최소한으로 
변경하여 장애 조치 중에 애플리케이션 시간 초과를 줄입니다. 
Q959 
한 회사에 개발 AWS 계정에서 실행되는 여러 Amazon RDS DB 인스턴스가 있습니다. 모든 
인스턴스에는 개발 리소스로 식별하는 태그가 있습니다. 이 회사는 개발 DB 인스턴스를 
업무 시간에만 일정에 따라 실행해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족할 수 있을까요? 
A. 중지해야 할 RDS 인스턴스를 식별하기 위해 Amazon CloudWatch 알람을 만듭니다. 
RDS 인스턴스를 시작하고 중지하기 위한 AWS Lambda 함수를 만듭니다. 
B. 시작 및 중지할 RDS 인스턴스를 식별하기 위한 AWS Trusted Advisor 보고서를 
만듭니다. RDS 인스턴스를 시작하고 중지하기 위한 AWS Lambda 함수를 만듭니다. 
C. RDS 인스턴스를 시작하고 중지하기 위한 AWS Systems Manager State Manager 연결을 
만듭니다. 
D. RDS 인스턴스를 시작하고 중지하기 위해 AWS Lambda 함수를 호출하는 Amazon 
EventBridge 규칙을 만듭니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145438-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
C?? 
Q960 
소비자 설문 조사 회사가 특정 지역에서 수년간 데이터를 수집했습니다. 이 회사는 이 
데이터를 AWS 지역의 Amazon S3 버킷에 저장합니다. 
이 회사는 새로운 지역의 마케팅 회사와 이 데이터를 공유하기 시작했습니다. 이 회사는 
회사의 AWS 계정에 S3 버킷에 대한 액세스 권한을 부여했습니다. 이 회사는 마케팅 
회사가 S3 버킷에서 데이터를 요청할 때 데이터 전송 비용을 최소화하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 회사의 S3 버킷에서 요청자 지불 기능을 구성합니다. 
B. 회사의 S3 버킷에서 마케팅 회사의 S3 버킷 중 하나로 S3 교차 지역 복제(CRR)를 
구성합니다. 
C. AWS Resource Access Manager 를 구성하여 S3 버킷을 마케팅 회사의 AWS 계정과 
공유합니다. 
D. 회사의 S3 버킷을 구성하여 S3 Intelligent-Tiering 을 사용합니다. S3 버킷을 마케팅 
회사의 S3 버킷 중 하나에 동기화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145552-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q961 
한 회사에서 AWS 를 사용하여 퍼블릭 전자상거래 웹사이트를 호스팅합니다. 이 웹사이트는 
인터넷에서 트래픽을 위해 AWS Global Accelerator 가속기를 사용합니다. 
Global Accelerator 가속기는 트래픽을 자동 확장 그룹의 진입점인 Application Load 
Balancer(ALB)로 전달합니다. 
이 회사는 최근 웹사이트에서 DDoS 공격을 확인했습니다. 이 회사는 향후 공격을 완화할 
솔루션이 필요합니다. 
어떤 솔루션이 최소한의 구현 노력으로 이러한 요구 사항을 충족할 수 있을까요? 
A. Global Accelerator 가속기에 대한 AWS WAF 웹 ACL 을 구성하여 속도 기반 규칙을 
사용하여 트래픽을 차단합니다. 
B. AWS Lambda 함수를 구성하여 VPC 네트워크 ACL 을 업데이트하여 ALB 메트릭을 읽고 
공격을 차단합니다. 
C. ALB 에서 AWS WAF 웹 ACL 을 구성하여 속도 기반 규칙을 사용하여 트래픽을 
차단합니다. 
D. Global Accelerator 가속기 앞에 Amazon CloudFront 배포를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/145442-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
A?? 
Q962 
한 회사에서는 Amazon DynamoDB 테이블을 사용하여 회사에서 기기에서 수신하는 
데이터를 저장합니다. DynamoDB 테이블은 고객용 웹사이트를 지원하여 고객 기기에서 
최근 활동을 표시합니다. 이 회사는 쓰기 및 읽기에 대한 프로비저닝된 처리량으로 
테이블을 구성했습니다. 이 회사는 매일 고객 기기 데이터에 대한 성능 지표를 계산하려고 
합니다. 이 솔루션은 테이블의 프로비저닝된 읽기 및 쓰기 용량에 최소한의 영향을 미쳐야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon Athena SQL 쿼리를 Amazon Athena DynamoDB 커넥터와 함께 사용하여 반복 
일정에 따라 성능 지표를 계산합니다. 
B. AWS Glue 작업을 AWS Glue DynamoDB 내보내기 커넥터와 함께 사용하여 반복 일정에 
따라 성능 지표를 계산합니다. 
C. Amazon Redshift COPY 명령을 사용하여 반복 일정에 따라 성능 지표를 계산합니다. 
D. Amazon EMR 작업을 Apache Hive 외부 테이블과 함께 사용하여 반복 일정에 따라 성능 
지표를 계산합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/146188-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Athena 는 DynamoDB 의 성능에 영향을 주지 않고 데이터를 쿼리하는 비용 
효율적인 서버리스 방식을 제공합니다. Athena DynamoDB 커넥터를 사용하면 회사에서 
DynamoDB 테이블에서 읽기 용량을 소모하지 않고 필요한 SQL 쿼리를 수행할 수 있으며, 
이는 프로비저닝된 처리량에 미치는 영향을 최소화하는 데 필수적입니다. 
주요 이점: 
* 프로비저닝된 용량에 미치는 영향 최소화: Athena 쿼리는 DynamoDB 의 읽기 용량에 
직접적인 영향을 미치지 않으므로 고객 대면 워크로드에 영향을 주지 않고 분석을 실행하는 
데 이상적입니다. 
* 비용 효율성: Athena 는 서버리스 솔루션이므로 실행하는 쿼리에 대해서만 비용을 
지불하므로 Amazon EMR 또는 Redshift 와 같은 전용 클러스터를 실행하는 것보다 비용 
효율성이 매우 높습니다. 
* AWS 설명서: Athena 를 사용하여 커넥터를 통해 DynamoDB 를 쿼리하는 것은 성능 
효율성 및 비용 최적화를 위한 AWS 모범 사례와 일치합니다. 
Q963 
솔루션 아키텍트가 AWS 에 배포될 새로운 상태 비저장 애플리케이션의 클라우드 
아키텍처를 설계하고 있습니다. 솔루션 아키텍트는 애플리케이션에 대한 Amazon Machine 
Image(AMI)와 시작 템플릿을 만들었습니다. 
처리해야 할 작업 수에 따라 필요에 따라 애플리케이션 Amazon EC2 인스턴스를 추가하고 
제거하는 동안 처리를 병렬로 실행해야 합니다. 애플리케이션은 느슨하게 결합되어야 
합니다. 작업 항목은 내구성 있게 저장되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 처리해야 할 작업을 보내기 위해 Amazon Simple Notification Service(Amazon SNS) 
토픽을 만듭니다. CPU 사용량에 따라 EC2 인스턴스를 추가하고 제거하도록 확장 정책을 
설정한 시작 템플릿을 사용하여 자동 확장 
그룹을 만듭니다. 
B. 처리해야 할 작업을 보관하기 위해 Amazon Simple Queue Service(Amazon SQS) 
대기열을 만듭니다. 네트워크 사용량에 따라 EC2 인스턴스를 추가하고 제거하도록 확장 
정책을 설정한 시작 템플릿을 사용하여 자동 확장 그룹을 만듭니다. 
C. 처리해야 할 작업을 보관할 Amazon Simple Queue Service(Amazon SQS) 대기열을 
만듭니다. SQS 대기열의 항목 수에 따라 EC2 인스턴스를 추가 및 제거하도록 스케일링 
정책이 설정된 시작 템플릿을 사용하여 자동 스케일링 그룹을 만듭니다. 
D. 처리해야 할 작업을 보낼 Amazon Simple Notification Service(Amazon SNS) 토픽을 
만듭니다. SNS 토픽에 게시된 메시지 수에 따라 EC2 인스턴스를 추가 및 제거하도록 
스케일링 정책이 설정된 시작 템플릿을 사용하여 자동 스케일링 그룹을 만듭니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/146180-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
"처리해야 할 작업을 보관할 Amazon SQS 대기열을 만듭니다. 컴퓨팅 애플리케이션에 대한 
Amazon EC2 자동 확장 그룹을 만듭니다. SQS 대기열의 항목 수에 따라 노드를 추가 및 
제거하도록 자동 확장 그룹에 대한 확장 정책을 설정합니다." 
이 경우 작업을 저장하기 위한 내구성 있고 느슨하게 결합된 솔루션을 찾아야 합니다. 
Amazon SQS 는 이 사용 사례에 이상적이며 대기열에서 기다리는 작업 수에 따라 동적 
확장을 사용하도록 구성할 수 있습니다. 이 확장을 구성하려면 인스턴스당 백로그 메트릭을 
사용할 수 있으며 대상 값은 유지 관리해야 하는 인스턴스당 허용 백로그입니다. 
Q964 
글로벌 전자상거래 회사가 모놀리식 아키텍처를 사용합니다. 이 회사는 증가하는 제품 
데이터 볼륨을 관리할 솔루션이 필요합니다. 솔루션은 확장 가능해야 하며 모듈식 서비스 
아키텍처가 있어야 합니다. 이 회사는 구조화된 데이터베이스 스키마를 유지 관리해야 
합니다. 또한 이 회사는 제품 데이터와 제품 이미지를 저장할 스토리지 솔루션이 
필요합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 컨테이너화된 애플리케이션을 
배포합니다. Application Load Balancer 를 사용하여 웹 트래픽을 분산합니다. Amazon RDS 
DB 인스턴스를 사용하여 제품 데이터와 제품 이미지를 저장합니다. 
B. AWS Lambda 함수를 사용하여 기존 모놀리식 애플리케이션을 관리합니다. Amazon 
DynamoDB 를 사용하여 제품 데이터와 제품 이미지를 저장합니다. Lambda 함수 간의 
이벤트 기반 통신을 위해 Amazon Simple Notifification Service(Amazon SNS)를 사용합니다. 
C. Amazon EC2 배포와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 
컨테이너화된 애플리케이션을 배포합니다. Amazon Aurora 클러스터를 사용하여 제품 
데이터를 저장합니다. AWS Step Functions 를 사용하여 작업 목록을 관리합니다. 제품 
이미지를 Amazon S3 Glacier Deep Archive 에 저장합니다. 
D. AWS Fargate 와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용하여 
컨테이너화된 애플리케이션을 배포합니다. 다중 AZ 배포와 함께 Amazon RDS 를 사용하여 
제품 데이터를 저장합니다. 제품 이미지를 Amazon S3 버킷에 저장합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/146026-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q965 
한 회사에서 온프레미스 환경에서 AWS 로 애플리케이션을 마이그레이션하고 있습니다. 
애플리케이션은 Amazon S3에 민감한 데이터를 저장합니다. 회사는 Amazon S3에 데이터를 
저장하기 전에 데이터를 암호화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 고객 관리 키로 클라이언트 측 암호화를 사용하여 데이터를 암호화합니다. 
B. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하여 데이터를 암호화합니다. 
C. 고객 제공 키(SSE-C)로 서버 측 암호화를 사용하여 데이터를 암호화합니다. 
D. Amazon S3 관리 키로 클라이언트 측 암호화를 사용하여 데이터를 암호화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/144898-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q966 
한 회사에서 여러 팀이 사용할 Amazon EMR 클러스터를 만들고자 합니다. 이 회사는 각 
팀의 빅데이터 워크로드가 각 팀이 상호 작용해야 하는 AWS 서비스에만 액세스할 수 
있도록 하려고 합니다. 이 회사는 워크로드가 클러스터의 기본 EC2 인스턴스에서 Instance 
Metadata Service Version 2(IMDSv2)에 액세스할 수 있기를 원하지 않습니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 팀에 필요한 각 AWS 서비스에 대한 인터페이스 VPC 엔드포인트를 구성합니다. 필요한 
인터페이스 VPC 엔드포인트를 사용하여 빅데이터 워크로드를 제출합니다. 
B. EMR 런타임 역할을 만듭니다. 클러스터가 런타임 역할을 사용하도록 구성합니다. 
런타임 역할을 사용하여 빅데이터 워크로드를 제출합니다. 
C. 각 팀에 필요한 권한이 있는 EC2 IAM 인스턴스 프로필을 만듭니다. 인스턴스 프로필을 
사용하여 빅데이터 워크로드를 제출합니다. 
D. EnableApplicationScopedIAMRole 옵션이 false 로 설정된 EMR 보안 구성을 만듭니다. 
보안 구성을 사용하여 빅데이터 워크로드를 제출합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/146028-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q967 
솔루션 아키텍트가 사용자가 등록 양식을 작성하고 제출하는 데 도움이 되는 
애플리케이션을 설계하고 있습니다. 솔루션 아키텍트는 웹 애플리케이션 서버 계층과 
작업자 계층을 포함하는 2 계층 아키텍처를 사용할 계획입니다. 
애플리케이션은 제출된 양식을 빠르게 처리해야 합니다. 애플리케이션은 각 양식을 정확히 
한 번만 처리해야 합니다. 솔루션은 데이터가 손실되지 않도록 해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 웹 애플리케이션 서버 계층과 작업자 계층 사이에 Amazon Simple Queue 
Service(Amazon SQS) FIFO 대기열을 사용하여 양식 데이터를 저장하고 전달합니다. 
B. 웹 애플리케이션 서버 계층과 작업자 계층 사이에 Amazon API Gateway HTTP API 를 
사용하여 양식 데이터를 저장하고 전달합니다. 
C. 웹 애플리케이션 서버 계층과 작업자 계층 사이에 Amazon Simple Queue 
Service(Amazon SQS) 표준 대기열을 사용하여 양식 데이터를 저장하고 전달합니다. 
D. AWS Step Functions Workjow 를 사용합니다. 웹 애플리케이션 서버 계층과 작업자 계층 
사이에 양식 데이터를 저장하고 전달하는 동기 Workjow 를 만듭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/144928-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q968 
한 금융 회사에서 온프레미스 검색 애플리케이션을 사용하여 다양한 생산자로부터 스트리밍 
데이터를 수집합니다. 이 애플리케이션은 검색 및 시각화 기능에 대한 실시간 업데이트를 
제공합니다. 
이 회사는 AWS 로 마이그레이션할 계획이며 AWS 네이티브 솔루션을 사용하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon EC2 인스턴스를 사용하여 데이터 스트림을 수집하여 Amazon S3 버킷에 
저장하기 위해 처리합니다. Amazon Athena 를 사용하여 데이터를 검색합니다. Amazon 
Managed Grafana 를 사용하여 시각화를 만듭니다. 
B. Amazon EMR 을 사용하여 데이터 스트림을 수집하여 Amazon Redshift 에 저장하기 위해 
처리합니다. Amazon Redshift Spectrum 을 사용하여 데이터를 검색합니다. Amazon 
QuickSight 를 사용하여 시각화를 만듭니다. 
C. Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 데이터 스트림을 수집하여 
Amazon DynamoDB 에 저장하기 위해 처리합니다. Amazon CloudWatch 를 사용하여 그래픽 
대시보드를 만들어 데이터를 검색하고 시각화합니다. 
D. Amazon Kinesis Data Streams 를 사용하여 데이터 스트림을 수집하여 Amazon 
OpenSearch Service 에 처리합니다. OpenSearch Service 를 사용하여 데이터를 검색합니다. 
Amazon QuickSight 를 사용하여 시각화를 만드세요. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/144929-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q969 
한 회사에서 현재 Linux 머신에서 ASP.NET 을 사용하는 온프레미스 애플리케이션을 
실행하고 있습니다. 이 애플리케이션은 리소스를 많이 사용하며 고객에게 직접 서비스를 
제공합니다. 
이 회사는 애플리케이션을 .NET 으로 현대화하려고 합니다. 이 회사는 컨테이너에서 
애플리케이션을 실행하고 Amazon CloudWatch 메트릭에 따라 확장하려고 합니다. 또한 이 
회사는 운영 유지 관리 활동에 소요되는 시간을 줄이려고 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. AWS App2Container 를 사용하여 애플리케이션을 컨테이너화합니다. AWS 
CloudFormation 템플릿을 사용하여 AWS Fargate 의 Amazon Elastic Container 
Service(Amazon ECS)에 애플리케이션을 배포합니다. 
B. AWS App2Container 를 사용하여 애플리케이션을 컨테이너화합니다. AWS 
CloudFormation 템플릿을 사용하여 Amazon EC2 인스턴스의 Amazon Elastic Container 
Service(Amazon ECS)에 애플리케이션을 배포합니다. 
C. AWS App Runner 를 사용하여 애플리케이션을 컨테이너화합니다. App Runner 를 사용하여 
AWS Fargate 의 Amazon Elastic Container Service(Amazon ECS)에 애플리케이션을 
배포합니다. 
D. AWS App Runner 를 사용하여 애플리케이션을 컨테이너화합니다. App Runner 를 사용하여 
Amazon EC2 인스턴스의 Amazon Elastic Kubernetes Service(Amazon EKS)에 
애플리케이션을 배포합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/146029-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q970 
한 회사에서 AWS 클라우드에서 새로운 내부 웹 애플리케이션을 설계하고 있습니다. 새로운 
애플리케이션은 AWS 관리 서비스에서 여러 직원의 사용자 이름과 비밀번호를 안전하게 
검색하여 저장해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. 직원 자격 증명을 AWS Systems Manager Parameter Store 에 저장합니다. AWS 
CloudFormation 과 BatchGetSecretValue API 를 사용하여 Parameter Store 에서 사용자 
이름과 비밀번호를 검색합니다. 
B. 직원 자격 증명을 AWS Secrets Manager 에 저장합니다. AWS CloudFormation 과 AWS 
Batch 를 BatchGetSecretValue API 와 함께 사용하여 Secrets Manager 에서 사용자 이름과 
비밀번호를 검색합니다. 
C. 직원 자격 증명을 AWS Systems Manager Parameter Store 에 저장합니다. AWS 
CloudFormation 과 AWS Batch 를 BatchGetSecretValue API 와 함께 사용하여 Parameter 
Store 에서 사용자 이름과 비밀번호를 검색합니다. 
D. 직원 자격 증명을 AWS Secrets Manager 에 저장합니다. AWS CloudFormation 과 
BatchGetSecretValue API 를 사용하여 Secrets Manager 에서 사용자 이름과 비밀번호를 
검색합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/147459-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q971 
ap-northeast-1 지역에 있는 한 회사는 수천 개의 AWS Outposts 서버를 보유하고 
있습니다. 이 회사는 전 세계의 원격 위치에 서버를 배포했습니다. 모든 서버는 100 개의 
파일로 구성된 새 소프트웨어 버전을 정기적으로 다운로드합니다. 모든 서버가 새 
소프트웨어 버전을 실행하기 전에 상당한 지연이 발생합니다. 
이 회사는 새 소프트웨어 버전의 배포 지연 시간을 줄여야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이 요구 사항을 충족할까요? 
A. ap-northeast-1 에 Amazon S3 버킷을 만듭니다. CachingDisabled 캐시 정책이 포함된 
ap-northeast-1 에 Amazon CloudFront 배포를 설정합니다. S3 버킷을 원본으로 구성합니다. 
서명된 URL 을 사용하여 소프트웨어를 다운로드합니다. 
B. ap-northeast-1 에 Amazon S3 버킷을 만듭니다. us-east-1 지역에 두 번째 S3 버킷을 
만듭니다. 버킷 간 복제를 구성합니다. ap-northeast-1 을 기본 오리진으로, us-east-1 을 
보조 오리진으로 사용하는 Amazon CloudFront 배포를 설정합니다. 서명된 URL 을 
사용하여 소프트웨어를 다운로드합니다. 
C. ap-northeast-1 에서 Amazon S3 버킷을 만듭니다. Amazon S3 Transfer Acceleration 을 
구성합니다. S3 Transfer Acceleration 엔드포인트를 사용하여 소프트웨어를 다운로드합니다. 
D. ap-northeast-1 에서 Amazon S3 버킷을 만듭니다. Amazon CloudFront 배포를 
설정합니다. S3 버킷을 오리진으로 구성합니다. 서명된 URL 을 사용하여 소프트웨어를 
다운로드합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145371-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q972 
한 회사에서 현재 Microsoft Windows Server 를 사용하여 온프레미스 주식 거래 
애플리케이션을 실행하고 있습니다. 이 회사는 애플리케이션을 AWS 클라우드로 
마이그레이션하려고 합니다. 
이 회사는 여러 가용 영역에서 블록 스토리지에 대한 저지연 액세스를 제공하는 고가용성 
솔루션을 설계해야 합니다. 
어떤 솔루션이 최소한의 구현 노력으로 이러한 요구 사항을 충족할 수 있을까요? 
A. Amazon EC2 인스턴스에서 두 가용 영역에 걸쳐 있는 Windows Server 클러스터를 
구성합니다. 두 클러스터 노드에 애플리케이션을 설치합니다. 두 클러스터 노드 간의 공유 
스토리지로 Amazon FSx for Windows File Server 를 사용합니다. 
B. Amazon EC2 인스턴스에서 두 가용 영역에 걸쳐 있는 Windows Server 클러스터를 
구성합니다. 두 클러스터 노드에 애플리케이션을 설치합니다. EC2 인스턴스에 연결된 
스토리지로 Amazon Elastic Block Store(Amazon EBS) 범용 SSD(gp3) 볼륨을 사용합니다. 
한 가용 영역의 한 EBS 볼륨에서 두 번째 가용 영역의 다른 EBS 볼륨으로 데이터를 
동기화하도록 애플리케이션 수준 복제를 설정합니다. 
C. 두 가용 영역의 Amazon EC2 인스턴스에 애플리케이션을 배포합니다. 한 EC2 
인스턴스를 활성 모드로 구성하고 두 번째 EC2 인스턴스를 대기 모드로 구성합니다. 
Amazon FSx for NetApp ONTAP Multi-AZ 파일 시스템을 사용하여 iSCSI(Internet Small 
Computer Systems Interface) 프로토콜을 사용하여 데이터에 액세스합니다. 
D. 두 개의 가용 영역에 있는 Amazon EC2 인스턴스에 애플리케이션을 배포합니다. 한 
EC2 인스턴스를 활성 모드로 구성하고 두 번째 EC2 인스턴스를 대기 모드로 구성합니다. 
EC2 인스턴스에 연결된 스토리지로 Amazon Elastic Block Store(Amazon EBS) Provisioned 
IOPS SSD(io2) 볼륨을 사용합니다. 한 가용 영역의 한 io2 볼륨에서 두 번째 가용 영역의 
다른 io2 볼륨으로 데이터를 동기화하도록 Amazon EBS 수준 복제를 설정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/146061-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
A?? 
Q973 
한 회사에서 인터넷 연결 애플리케이션 로드 밸런서(ALB)로 웹 애플리케이션을 설계하고 
있습니다. 
이 회사는 ALB 가 공개 인터넷에서 HTTPS 웹 트래픽을 수신해야 합니다. ALB 는 HTTPS 
트래픽만 포트 443 에서 Amazon EC2 인스턴스에 호스팅된 웹 애플리케이션 서버로 보내야 
합니다. ALB 는 포트 8443 에서 HTTPS 를 통해 웹 애플리케이션 서버의 상태 검사를 
수행해야 합니다. 
ALB 와 연관된 보안 그룹의 어떤 구성 조합이 이러한 요구 사항을 충족할까요? (세 가지 
선택) 
A. 포트 443 에 대해 0.0.0.0/0 에서 HTTPS 인바운드 트래픽을 허용합니다. 
B. 포트 443 에 대해 0.0.0.0/0 에서 모든 아웃바운드 트래픽을 허용합니다. 
C. 포트 443 에 대해 웹 애플리케이션 인스턴스로 HTTPS 아웃바운드 트래픽을 허용합니다. 
D. 포트 443 에 대해 웹 애플리케이션 인스턴스에서 HTTPS 인바운드 트래픽을 허용합니다. 
E. 포트 8443 에서 상태 확인을 위해 웹 애플리케이션 인스턴스로 HTTPS 아웃바운드 
트래픽을 허용합니다. 
F. 포트 8443 에서 상태 확인을 위해 웹 애플리케이션 인스턴스에서 HTTPS 인바운드 
트래픽을 허용합니다. 
Answer: A, C, E 
https://www.examtopics.com/discussions/amazon/view/146030-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q974 
한 회사가 AWS 에서 애플리케이션을 호스팅합니다. 이 애플리케이션은 사용자에게 사진을 
업로드하고 Amazon S3 버킷에 사진을 저장할 수 있는 기능을 제공합니다. 
이 회사는 Amazon CloudFront 와 사용자 지정 도메인 이름을 사용하여 eu-west-1 지역의 
S3 버킷에 사진 파일을 업로드하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? (두 가지 선택) 
A. AWS Certificate Manager(ACM)를 사용하여 us-east-1 지역에서 공개 인증서를 만듭니다. 
CloudFront 에서 인증서를 사용합니다. 
B. AWS Certificate Manager(ACM)를 사용하여 eu-west-1 에서 공개 인증서를 만듭니다. 
CloudFront 에서 인증서를 사용합니다. 
C. CloudFront 에서 업로드를 허용하도록 Amazon S3 를 구성합니다. S3 Transfer 
Acceleration 을 구성합니다. 
D. CloudFront 원본 액세스 제어(OAC)에서 업로드를 허용하도록 Amazon S3를 구성합니다. 
E. CloudFront 에서 업로드를 허용하도록 Amazon S3 를 구성합니다. Amazon S3 웹사이트 
엔드포인트를 구성합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/144941-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
Q975 
날씨 예보 회사에서 다양한 센서에서 지속적으로 온도 판독값을 수집합니다. 기존 데이터 
수집 프로세스에서 판독값을 수집하여 더 큰 Apache Parquet 파일에 집계합니다. 그런 
다음 프로세스에서 KMS 관리 키(CSE-KMS)를 사용하여 클라이언트 측 암호화를 사용하여 
파일을 암호화합니다. 마지막으로 프로세스에서 각 달력 날짜에 대한 별도의 접두사를 
사용하여 파일을 Amazon S3 버킷에 씁니다. 
회사에서는 특정 달력 날짜에 대한 샘플 이동 평균을 구하기 위해 데이터에 대해 가끔씩 
SQL 쿼리를 실행하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 암호화된 파일을 읽도록 Amazon Athena 를 구성합니다. Amazon S3 에서 직접 데이터에 
대한 SQL 쿼리를 실행합니다. 
B. Amazon S3 Select 를 사용하여 Amazon S3 에서 직접 데이터에 대한 SQL 쿼리를 
실행합니다. 
C. 암호화된 파일을 읽도록 Amazon Redshift 를 구성합니다. Redshift Spectrum 및 Redshift 
쿼리 편집기 v2 를 사용하여 Amazon S3 에서 직접 데이터에 대한 SQL 쿼리를 실행합니다. 
D. 암호화된 파일을 읽도록 Amazon EMR Serverless 를 구성합니다. Apache SparkSQL 을 
사용하여 Amazon S3 에서 직접 데이터에 대한 SQL 쿼리를 실행합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/145367-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Athena 는 데이터 웨어하우스가 필요 없이 Amazon S3 에 저장된 데이터에 대해 
SQL 쿼리를 직접 실행할 수 있는 서버리스 쿼리 서비스입니다. 실행하는 쿼리에 대해서만 
비용을 지불하고 Apache Parquet 파일을 효율적으로 처리할 수 있기 때문에 비용 
효율적입니다. 또한 Athena 는 KMS 와 통합되어 암호화된 데이터를 쿼리하는 데 
적합합니다. 
주요 AWS 기능: 
* 비용 효율적: Athena 는 쿼리에서 스캔한 데이터에 대해서만 요금을 청구하므로 가끔씩 
쿼리하는 경우 Redshift 나 EMR 에 비해 비용 효율적인 솔루션입니다. 
* 직접 S3 쿼리: Athena 는 데이터를 이동할 필요 없이 Parquet 파일을 포함하여 S3 에서 
직접 데이터를 쿼리하는 것을 지원합니다. 
* AWS 설명서: Athena 는 S3 의 암호화된 Parquet 파일과 호환되므로 이 시나리오에 
이상적인 선택이며 비용과 복잡성을 모두 줄입니다. 
Q976 
한 회사에서 AWS 에 새 애플리케이션을 구현하고 있습니다. 이 회사는 여러 AWS 지역 
내의 여러 가용성 영역에 걸쳐 여러 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 
이 애플리케이션은 인터넷을 통해 제공됩니다. 사용자는 전 세계에서 애플리케이션에 
액세스합니다. 
이 회사는 애플리케이션에 액세스하는 각 사용자가 사용자 위치에 가장 가까운 EC2 
인스턴스로 전송되도록 하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon Route 53 지리적 위치 라우팅 정책을 구현합니다. 인터넷 연결 애플리케이션 
부하 분산 장치를 사용하여 동일한 지역 내의 모든 가용성 영역에 트래픽을 분산합니다. 
B. Amazon Route 53 지리적 근접성 라우팅 정책을 구현합니다. 인터넷 연결 네트워크 부하 
분산 장치를 사용하여 동일한 지역 내의 모든 가용성 영역에 트래픽을 분산합니다. 
C. Amazon Route 53 다중값 응답 라우팅 정책을 구현합니다. 인터넷 연결 애플리케이션 
부하 분산 장치를 사용하여 동일한 지역 내의 모든 가용성 영역에 트래픽을 분산합니다. 
D. Amazon Route 53 가중치 라우팅 정책을 구현합니다. 인터넷 연결 네트워크 로드 
밸런서를 사용하여 동일한 지역 내의 모든 가용성 영역에 트래픽을 분산합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145571-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q977 
한 금융 서비스 회사가 민감한 금융 거래를 처리하기 위해 AWS 에서 새로운 
애플리케이션을 출시할 계획입니다. 이 회사는 Amazon EC2 인스턴스에 애플리케이션을 
배포합니다. 이 회사는 Amazon RDS for MySQL 을 데이터베이스로 사용합니다. 이 회사의 
보안 정책에 따라 데이터는 저장 시와 전송 시 암호화되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족할까요? 
A. AWS KMS 관리 키를 사용하여 Amazon RDS for MySQL 에 대한 저장 시 암호화를 
구성합니다. 전송 시 암호화를 위해 AWS Certificate Manager(ACM) SSL/TLS 인증서를 
구성합니다. 
B. AWS KMS 관리 키를 사용하여 Amazon RDS for MySQL 에 대한 저장 시 암호화를 
구성합니다. 전송 시 암호화를 위해 IPsec 터널을 구성합니다. 
C. Amazon RDS for MySQL 에 데이터를 저장하기 전에 타사 애플리케이션 수준 데이터 
암호화를 구현합니다. 전송 시 암호화를 위해 AWS Certificate Manager(ACM) SSL/TLS 
인증서를 구성합니다. 
D. AWS KMS 관리 키를 사용하여 Amazon RDS for MySQL 에 대한 저장 시 암호화를 
구성합니다. 전송 시 데이터를 암호화하기 위한 개인 연결을 활성화하기 위해 VPN 연결을 
구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/146035-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 회사의 보안 정책을 준수하는 동시에 최소한의 운영 오버헤드로 저장 및 전송 
중 암호화를 제공합니다. 
저장 중 암호화: Amazon RDS for MySQL 은 AWS Key Management Service(KMS) 관리 키를 
사용하여 저장 중 데이터를 암호화하도록 구성할 수 있습니다. 이 암호화는 백업, 읽기 
복제본, 스냅샷을 포함하여 디스크에 저장된 모든 데이터에 자동으로 적용됩니다. 이 
솔루션은 AWS 가 암호화 및 키 관리 프로세스를 관리하기 때문에 최소한의 운영 
오버헤드만 필요합니다. 
전송 중 암호화: AWS Certificate Manager(ACM)를 사용하면 SSL/TLS 인증서를 원활하게 
프로비저닝, 관리 및 배포할 수 있습니다. 이러한 인증서는 MySQL 인스턴스가 연결에 
SSL/TLS 를 사용하도록 구성하여 전송 중 데이터를 암호화하는 데 사용할 수 있습니다. 이 
설정은 애플리케이션과 데이터베이스 간에 데이터가 암호화되어 전송 중에 가로채지 않도록 
보호합니다. 
다른 옵션은 왜 안 되나요?: 
옵션 B(IPsec 터널): IPsec 터널은 전송 중 데이터를 암호화하지만 관리하기가 더 복잡하고 
추가 구성 및 유지 관리가 필요하여 운영 오버헤드가 더 높아집니다. 
옵션 C(타사 애플리케이션 수준 암호화): 애플리케이션 수준 암호화를 구현하면 복잡성이 
증가하고, 코드 변경이 필요하며, 운영 오버헤드가 증가합니다. 
옵션 D(암호화를 위한 VPN): 전송 중인 데이터를 암호화하기 위한 VPN 솔루션은 
불필요하며, 구현 및 관리가 더 간단한 SSL/TLS 에 비해 어떠한 이점도 제공하지 않으면서 
복잡성을 더합니다. 
Q978 
한 회사에서 온프레미스 Oracle 데이터베이스를 Amazon RDS for Oracle 데이터베이스로 
마이그레이션하고 있습니다. 이 회사는 규제 요구 사항을 충족하기 위해 90 일 동안 
데이터를 보관해야 합니다. 또한 이 회사는 최대 14 일 동안 특정 시점으로 데이터베이스를 
복원할 수 있어야 합니다. 
어떤 솔루션이 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족할 수 있을까요? 
A. Amazon RDS 자동 백업을 만듭니다. 보관 기간을 90 일로 설정합니다. 
B. 매일 Amazon RDS 수동 스냅샷을 만듭니다. 90 일이 지난 수동 스냅샷을 삭제합니다. 
C. Oracle 용 Amazon Aurora Clone 기능을 사용하여 시점 복원을 만듭니다. 90 일이 지난 
복제본을 삭제합니다. 
D. Amazon RDS 용 AWS Backup 을 사용하여 보관 기간이 90 일인 백업 계획을 만듭니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/145565-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS Backup 은 최소한의 운영 오버헤드로 백업을 관리하고, 90 일 동안 데이터를 보관하고 
최대 14 일 동안 특정 시점 복원을 활성화하는 규정 요구 사항을 충족하는 데 가장 적합한 
솔루션입니다. 
AWS Backup: AWS Backup 은 Amazon RDS 를 포함한 AWS 서비스 전반에서 자동화된 백업 
일정, 보관 관리 및 규정 준수 보고를 지원하는 중앙 집중식 백업 관리 솔루션을 
제공합니다. 백업 계획을 생성하면 보관 기간(이 경우 90 일)을 정의하고 백업 프로세스를 
자동화할 수 있습니다. 
PITR(Point-in-Time Restore): Amazon RDS 는 자동화된 백업으로 최대 35 일 동안 특정 
시점 복원을 지원합니다. RDS 와 함께 AWS Backup 을 사용하면 백업 전략이 지난 14 일 
이내의 특정 시점으로 데이터를 복원하는 요구 사항을 충족하는지 확인할 수 있습니다. 
다른 옵션은 왜 안 될까요?: 
옵션 A(RDS 자동 백업): RDS 자동 백업은 PITR 을 지원하지만 수동 개입 없이 35 일을 
초과하는 보관은 직접 지원하지 않습니다. 
옵션 B(수동 스냅샷): 스냅샷을 수동으로 생성하고 관리하는 것은 운영상 집약적이며 AWS 
Backup 에 비해 자동화가 덜 되어 있습니다. 
옵션 C(Aurora Clone): Aurora Clone 은 Amazon Aurora 에만 있는 기능이며 Amazon RDS for 
Oracle 에는 적용되지 않습니다. 
Q979 
한 회사에서 관계형 데이터베이스를 사용하여 사용자 데이터와 애플리케이션 구성을 
저장하는 새로운 애플리케이션을 개발하고 있습니다. 이 회사는 애플리케이션의 사용자 
수가 꾸준히 증가할 것으로 예상합니다. 이 회사는 데이터베이스 사용량이 가변적이고 
읽기가 많으며 가끔 쓰기가 있을 것으로 예상합니다. 
이 회사는 데이터베이스 솔루션의 비용을 최적화하려고 합니다. 이 회사는 필요한 성능을 
제공하는 AWS 관리형 데이터베이스 솔루션을 사용하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요? 
A. Amazon RDS 에 데이터베이스를 배포합니다. 읽기 및 쓰기 작업에 대한 일관된 성능을 
보장하기 위해 Provisioned IOPS SSD 스토리지를 사용합니다. 
B. Amazon Aurora Serverless 에 데이터베이스를 배포하여 실제 사용량에 따라 데이터베이스 
용량을 자동으로 확장하여 워크로드를 수용합니다. 
C. Amazon DynamoDB 에 데이터베이스를 배포합니다. 주문형 용량 모드를 사용하여 
워크로드를 수용하기 위해 처리량을 자동으로 확장합니다. 
D. Amazon RDS 에 데이터베이스를 배포합니다. 자기 스토리지를 사용하고 읽기 복제본을 
사용하여 워크로드를 수용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/146062-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Aurora Serverless 는 Amazon Aurora 를 위한 비용 효율적인 주문형 자동 확장 
구성입니다. 현재 수요에 따라 데이터베이스 용량을 자동으로 조정하므로 가변적이고 
예측할 수 없는 사용 패턴의 워크로드에 이상적입니다. 애플리케이션은 가끔씩 쓰고 꾸준히 
성장하는 읽기 중심적일 것으로 예상되므로 Aurora Serverless 는 데이터베이스 인스턴스 
관리 없이도 필요한 성능을 제공할 수 있습니다. 
비용 최적화: Aurora Serverless 는 사용하는 데이터베이스 용량에 대해서만 요금을 
청구하므로 특히 수요가 변동하는 워크로드의 경우 항상 실행되는 프로비저닝된 
데이터베이스 인스턴스에 비해 비용 효율적인 솔루션입니다. 
확장성: 실제 사용량에 따라 데이터베이스 용량을 자동으로 늘리거나 줄여 항상 적절한 
양의 리소스를 사용할 수 있도록 합니다. 
성능: Aurora Serverless는 Amazon Aurora와 동일한 기본 스토리지에 구축되어 높은 성능과 
가용성을 제공합니다. 
다른 옵션은 왜 안 되나요?: 
옵션 A(프로비저닝된 IOPS SSD 가 있는 RDS): 프로비저닝된 IOPS SSD 는 일관된 성능을 
보장하지만 일반적으로 Aurora Serverless 의 자동 확장 특성에 비해 비용이 많이 들고 
유연성이 떨어집니다. 
옵션 C(주문형 용량이 있는 DynamoDB): DynamoDB 는 NoSQL 데이터베이스이며 관계형 
데이터베이스 기능이 필요한 애플리케이션에 가장 적합하지 않을 수 있습니다. 
옵션 D(자기 스토리지 및 읽기 복제본이 있는 RDS): 자기 스토리지는 오래되었고 
일반적으로 느립니다. 읽기 복제본은 읽기 중심 워크로드에 도움이 되지만 전반적인 성능은 
최적이 아닐 수 있으며 자기 스토리지는 필요한 성능을 제공하지 않습니다. 
Q980 
한 회사가 VPC 내부의 여러 Amazon EC2 인스턴스에 애플리케이션을 호스팅합니다. 이 
회사는 각 고객을 위해 전용 Amazon S3 버킷을 만들어 Amazon S3 에 관련 정보를 
저장합니다. 
이 회사는 EC2 인스턴스에서 실행되는 애플리케이션이 회사의 AWS 계정에 속한 S3 
버킷에만 안전하게 액세스할 수 있도록 하려고 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. VPC에 연결된 Amazon S3용 게이트웨이 엔드포인트를 만듭니다. 애플리케이션에 필요한 
특정 버킷에만 액세스할 수 있도록 IAM 인스턴스 프로필 정책을 업데이트합니다. 
B. Amazon S3 에만 액세스할 수 있는 보안 그룹이 있는 퍼블릭 서브넷에 NAT 
게이트웨이를 만듭니다. NAT 게이트웨이를 사용하도록 경로 테이블을 업데이트합니다. 
C. VP 에 연결된 Amazon S3 용 게이트웨이 엔드포인트를 만듭니다. 거부 작업과 다음 조건 
키로 IAM 인스턴스 프로필 정책을 업데이트합니다. 
D. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. NAT 게이트웨이를 사용하도록 경로 
테이블을 업데이트합니다. 거부 작업과 다음 조건 키로 모든 버킷에 대한 버킷 정책을 
할당합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/147313-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
A?? 
Q981 
한 회사에서 민감한 고객 데이터를 처리하는 AWS 기반 클라우드 애플리케이션을 구축하고 
있습니다. 이 애플리케이션은 데이터베이스에 Amazon RDS, 개체 스토리지에 Amazon S3, 
서버리스 처리를 위해 AWS Lambda 를 호출하는 S3 이벤트 알림을 사용합니다. 
이 회사는 AWS IAM Identity Center 를 사용하여 사용자 자격 증명을 관리합니다. 개발, 
테스트 및 운영 팀은 민감한 고객 데이터의 기밀성을 보장하는 동시에 Amazon RDS 및 
Amazon S3 에 안전하게 액세스할 수 있어야 합니다. 이 솔루션은 최소 권한 원칙을 
준수해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족합니까? 
A. 최소 권한이 있는 IAM 역할을 사용하여 모든 팀에 액세스 권한을 부여합니다. 팀 
책임에 따라 Amazon RDS 및 S3 개체 액세스에 대한 특정 권한을 정의하는 사용자 지정 
IAM 정책으로 각 팀에 IAM 역할을 할당합니다. 
B. Identity Center 디렉터리로 IAM Identity Center 를 활성화합니다. Amazon RDS 및 
Amazon S3 에 대한 세부적인 액세스 권한이 있는 권한 집합을 만들고 구성합니다. 권한 
집합을 사용하여 특정 액세스 권한이 있는 그룹에 모든 팀을 할당합니다. 
C. 역할 기반 권한이 있는 모든 팀의 각 구성원에 대해 개별 IAM 사용자를 만듭니다. 
사용자 요구 사항에 따라 RDS 및 S3 액세스에 대한 사전 정의된 정책이 있는 IAM 역할을 
각 사용자에게 할당합니다. 주기적 자격 증명 평가를 위해 IAM Access Analyzer 를 
구현합니다. 
D. AWS Organizations 를 사용하여 각 팀에 대해 별도의 계정을 만듭니다. 최소 권한으로 
교차 계정 IAM 역할을 구현합니다. 팀 역할 및 책임에 따라 RDS 및 S3 액세스에 대한 
특정 권한을 부여합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/145821-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 솔루션은 최소한의 운영 오버헤드로 안전하고 최소 권한 액세스를 허용합니다. 
IAM Identity Center: AWS IAM Identity Center(이전 명칭 AWS SSO)를 사용하면 여러 AWS 
계정과 애플리케이션에 대한 액세스를 중앙에서 관리할 수 있습니다. IAM Identity Center 를 
사용하면 사용자 또는 그룹이 액세스할 수 있는 항목을 정의하는 권한 집합을 할당하여 
필요한 권한만 부여되도록 할 수 있습니다. 
권한 집합: IAM Identity Center 의 권한 집합을 사용하면 Amazon RDS 및 S3 와 같은 특정 
서비스에 대한 세부적인 액세스 제어를 정의할 수 있습니다. 최소 권한 원칙을 준수하여 
이러한 권한을 다양한 팀의 요구 사항에 맞게 조정할 수 있습니다. 
그룹 관리: 사용자를 그룹에 할당하고 해당 그룹을 특정 권한 집합과 연결하면 개별 IAM 
역할 및 정책을 관리하는 데 따른 복잡성과 오버헤드를 줄일 수 있습니다. 이 방법은 또한 
규정 준수 및 감사 프로세스를 간소화합니다. 
다른 옵션은 왜 안 될까요?: 
옵션 A(IAM 역할): IAM 역할은 최소 권한 액세스를 제공할 수 있지만, 여러 팀에서 여러 
역할과 정책을 관리하면 IAM Identity Center 를 사용하는 것에 비해 운영 오버헤드가 
증가합니다. 
옵션 C(개별 IAM 사용자): 개별 IAM 사용자와 역할을 관리하는 것은 번거로울 수 있으며 
IAM Identity Center 의 그룹 기반 관리에 비해 확장성이 떨어집니다. 
옵션 D(교차 계정 역할이 있는 AWS 조직): 별도의 계정과 교차 계정 역할을 만들면 이 
사용 사례에 불필요한 복잡성과 오버헤드가 추가되지만 IAM Identity Center 는 더 간단한 
솔루션을 제공합니다. 
AWS 참조: 
AWS IAM Identity Center - IAM Identity Center 를 사용하기 위한 개요 및 모범 사례. 
IAM Identity Center 를 사용하여 액세스 권한 관리 - 보안 액세스를 위한 권한 집합을 
만들고 관리하는 방법에 대한 가이드. 
Q982 
한 회사에 민감한 데이터 파일이 들어 있는 Amazon S3 버킷이 있습니다. 이 회사에는 
온프레미스 데이터 센터의 가상 머신에서 실행되는 애플리케이션이 있습니다. 이 회사는 
현재 AWS IAM Identity Center 를 사용하고 있습니다. 
이 애플리케이션은 S3 버킷의 파일에 대한 임시 액세스가 필요합니다. 이 회사는 
애플리케이션에 S3 버킷의 파일에 대한 보안 액세스 권한을 부여하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 회사의 온프레미스 데이터 센터의 공용 IP 주소 범위에서 버킷에 대한 액세스를 
허용하는 S3 버킷 정책을 만듭니다. 
B. IAM Roles Anywhere 를 사용하여 S3 버킷에 대한 액세스 권한을 부여하는 IAM Identity 
Center 에서 보안 자격 증명을 얻습니다. AWS CLI 를 사용하여 가상 머신이 역할을 맡도록 
구성합니다. 
C. 가상 머신에 AWS CLI 를 설치합니다. 버킷에 대한 액세스 권한이 있는 IAM 사용자의 
액세스 키로 AWS CLI 를 구성합니다. 
D. 버킷에 대한 액세스 권한을 부여하는 IAM 사용자와 정책을 만듭니다. AWS Secrets 
Manager 에 IAM 사용자의 액세스 키와 비밀 키를 저장합니다. 시작 시 액세스 키와 비밀 
키를 검색하도록 애플리케이션을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148505-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q983 
한 회사가 온프레미스 데이터 센터에서 디렉토리 서비스와 DNS 를 포함한 핵심 네트워크 
서비스를 호스팅합니다. 데이터 센터는 AWS Direct Connect(DX)를 사용하여 AWS 
클라우드에 연결됩니다. 이러한 네트워크 서비스에 대한 빠르고 비용 효율적이며 일관된 
액세스가 필요한 추가 AWS 계정이 계획되어 있습니다. 
솔루션 아키텍트는 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 무엇을 
구현해야 합니까? 
A. 각 새 계정에서 DX 연결을 만듭니다. 네트워크 트래픽을 온프레미스 서버로 
라우팅합니다. 
B. 모든 필수 서비스에 대해 DX VPC 에서 VPC 엔드포인트를 구성합니다. 네트워크 
트래픽을 온프레미스 서버로 라우팅합니다. 
C. 각 새 계정과 DX VPR 간에 VPN 연결을 만듭니다. 네트워크 트래픽을 온프레미스 
서버로 라우팅합니다. 
D. 계정 간에 AWS Transit Gateway 를 구성합니다. DX 를 전송 게이트웨이에 할당하고 
네트워크 트래픽을 온프레미스 서버로 라우팅합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/148506-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 요구 사항 분석: 여러 AWS 계정에서 온프레미스 네트워크 서비스에 빠르고 비용 
효율적이며 일관되게 액세스해야 합니다. 
* AWS Transit Gateway: VPC 와 온프레미스 네트워크를 연결하여 네트워크 관리를 중앙 
집중화하고 단순화합니다. 
* Direct Connect 통합: Transit Gateway 에 DX 를 할당하면 일관된 고성능 연결이 
보장됩니다. 
* 운영 오버헤드: Transit Gateway 가 라우팅 및 관리를 단순화하므로 최소화됩니다. 
* 구현: 
* AWS Transit Gateway 를 설정합니다. 
* 새 AWS 계정을 Transit Gateway 에 연결합니다. 
* Direct Connect 를 통해 Transit Gateway 를 통해 온프레미스 서버로 트래픽을 
라우팅합니다. 
* 결론: 이 솔루션은 연결 요구 사항을 충족하기 위해 확장 가능하고 비용 효율적이며 
오버헤드가 낮은 방법을 제공합니다. 
Q984 
한 회사가 여러 가용성 영역에 걸쳐 하나의 AWS 지역에서 주요 퍼블릭 웹 애플리케이션을 
호스팅합니다. 이 애플리케이션은 Amazon EC2 자동 확장 그룹과 애플리케이션 로드 
밸런서(ALB)를 사용합니다. 
웹 개발 팀은 수백만 명의 고객에게 동적 콘텐츠를 전 세계적으로 제공하는 회사의 역량을 
개선하기 위해 비용 최적화된 컴퓨팅 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon CloudFront 배포를 만듭니다. 기존 ALB 를 원본으로 구성합니다. 
B. Amazon Route 53 을 사용하여 각 고객의 지리적 위치에 따라 ALB 및 EC2 인스턴스에 
트래픽을 제공합니다. 
C. 퍼블릭 읽기 액세스가 활성화된 Amazon S3 버킷을 만듭니다. 웹 애플리케이션을 S3 
버킷으로 마이그레이션합니다. 웹사이트 호스팅을 위해 S3 버킷을 구성합니다. 
D. AWS Direct Connect 를 사용하여 웹 애플리케이션에서 각 고객의 위치로 직접 콘텐츠를 
제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/148507-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q985 
한 회사가 AWS 에 사용자 데이터를 저장합니다. 데이터는 업무 시간 동안 피크 사용량으로 
지속적으로 사용됩니다. 액세스 패턴은 다양하며, 일부 데이터는 한 번에 몇 달 동안 
사용되지 않습니다. 솔루션 아키텍트는 높은 가용성을 유지하면서도 최고 수준의 내구성을 
유지하는 비용 효율적인 솔루션을 선택해야 합니다. 
어떤 스토리지 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 Standard 
B. Amazon S3 Intelligent-Tiering 
C. Amazon S3 Glacier Deep Archive 
D. Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA) 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148508-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon S3 Intelligent-Tiering 은 이 시나리오에 가장 비용 효율적인 솔루션으로, 
고가용성과 내구성을 모두 제공하는 동시에 변경되는 액세스 패턴에 자동으로 조정합니다. 
데이터를 두 가지 액세스 계층으로 이동합니다. 하나는 빈번한 액세스에 최적화되었고 다른 
하나는 사용 패턴에 따라 빈번하지 않은 액세스에 최적화되었습니다. 
이 계층화를 통해 회사는 사용하지 않는 스토리지 비용을 지불하지 않고도 자주 액세스되는 
데이터를 더 쉽게 액세스할 수 있는 계층에 보관할 수 있습니다. 
주요 AWS 참조 및 S3 Intelligent-Tiering 의 이점: 
* 높은 내구성 및 가용성: Amazon S3 는 저장된 객체에 대해 99.999999999%의 내구성과 
99.9%의 가용성을 제공하여 데이터가 항상 보호되도록 합니다. 
* 자동 계층화: 데이터는 액세스 패턴에 따라 계층 간에 자동으로 이동되므로 예측할 수 
없거나 가변적인 액세스 패턴이 있는 워크로드에 이상적입니다. 
* 검색 수수료 없음: S3 One Zone-IA 또는 Glacier 와 달리 검색 수수료가 없으므로 액세스 
패턴이 시간이 지남에 따라 달라지는 시나리오에서 비용 효율성이 더 높습니다. 
* AWS 설명서: 비용 최적화 기둥에 따른 AWS Well-Architected Framework 에 따르면 S3 
Intelligent-Tiering 은 액세스 패턴이 시간이 지남에 따라 변경될 때 스토리지에 권장되며 
가용성을 유지하면서 비용을 최소화합니다. 
Q986 
한 회사에서 Amazon EC2 Linux 인스턴스에서 실행되는 애플리케이션을 테스트하고 
있습니다. 단일 500GB Amazon Elastic Block Store(Amazon EBS) General Purpose SSO(gp2) 
볼륨이 EC2 인스턴스에 연결되어 있습니다. 
이 회사는 Auto Scaling 그룹의 여러 EC2 인스턴스에 애플리케이션을 배포합니다. 모든 
인스턴스는 EBS 볼륨에 저장된 데이터에 액세스해야 합니다. 이 회사는 애플리케이션 
코드에 상당한 변경을 도입하지 않는 고가용성 및 복원력 있는 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. NFS 서버 소프트웨어를 사용하는 EC2 인스턴스를 프로비저닝합니다. 단일 500GB gp2 
EBS 볼륨을 인스턴스에 연결합니다. 
B. Amazon FSx for Windows File Server 파일 시스템을 프로비저닝합니다. 단일 가용성 영역 
내에서 파일 시스템을 SMB 파일 저장소로 구성합니다. 
C. 두 개의 250GB Provisioned IOPS SSD EBS 볼륨이 있는 EC2 인스턴스를 
프로비저닝합니다. 
D. Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝합니다. 파일 
시스템을 구성하여 일반 용도 성능 모드를 사용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/148509-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q987 
한 회사가 최근 고객을 위해 새로운 애플리케이션을 출시했습니다. 이 애플리케이션은 두 
개의 가용성 영역에 걸쳐 여러 Amazon EC2 인스턴스에서 실행됩니다. 최종 사용자는 
TCP 를 사용하여 애플리케이션과 통신합니다. 
애플리케이션은 고가용성이어야 하며 사용자 수가 증가함에 따라 자동으로 확장되어야 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (두 가지 
선택) 
A. EC2 인스턴스 앞에 네트워크 로드 밸런서를 추가합니다. 
B. EC2 인스턴스에 대한 자동 확장 그룹을 구성합니다. 
C. EC2 인스턴스 앞에 애플리케이션 로드 밸런서를 추가합니다. 
D. 애플리케이션에 대한 EC2 인스턴스를 수동으로 추가합니다. 
E. EC2 인스턴스 앞에 게이트웨이 로드 밸런서를 추가합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/148519-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q988 
한 회사에서 AWS 클라우드를 사용하는 새로운 모바일 앱의 아키텍처를 설계하고 있습니다. 
이 회사는 AWS Organizations 의 조직 단위(OU)를 사용하여 계정을 관리합니다. 이 회사는 
민감 및 비민감 값을 사용하여 Amazon EC2 인스턴스에 데이터 민감도 태그를 지정하려고 
합니다. IAM ID 는 태그 없이 태그를 삭제하거나 인스턴스를 만들 수 없어야 합니다. 
다음 요구 사항을 충족하는 단계 조합은 무엇입니까? (두 가지 선택) 
A. Organizations 에서 데이터 민감도 태그 키와 필요한 값을 지정하는 새 태그 정책을 
만듭니다. EC2 인스턴스에 대한 태그 값을 적용합니다. 태그 정책을 적절한 OU 에 
연결합니다. 
B. Organizations 에서 데이터 민감도 태그 키와 필요한 태그 값을 지정하는 새 서비스 제어 
정책(SCP)을 만듭니다. EC2 인스턴스에 대한 태그 값을 적용합니다. SCP 를 적절한 OU 에 
연결합니다. 
C. 태그 키가 지정되지 않은 경우 실행 중인 인스턴스를 거부하는 태그 정책을 만듭니다. 
ID 가 태그를 삭제하지 못하도록 하는 다른 태그 정책을 만듭니다. 태그 정책을 적절한 
OU 에 연결합니다. 
D. 태그 키가 지정되지 않은 경우 인스턴스 생성을 거부하는 서비스 제어 정책(SCP)을 
만듭니다. ID 가 태그를 삭제하지 못하도록 하는 다른 SCP 를 만듭니다. SCP 를 적절한 
OU 에 연결합니다. 
E. EC2 인스턴스가 데이터 민감도 태그와 지정된 값을 사용하는지 확인하는 AWS Config 
규칙을 만듭니다. 규정을 준수하지 않는 리소스가 발견되면 리소스를 삭제하도록 AWS 
Lambda 함수를 구성합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/148803-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
태그 지정 요구 사항을 충족하고 적절한 태그 없이 인스턴스 생성 또는 삭제를 방지하기 
위해 회사는 AWS Organizations 태그 정책과 서비스 제어 정책(SCP)을 조합하여 사용할 
수 있습니다. 
* 태그 정책: 리소스 전체에 특정 태그 값을 적용합니다. 필수 값(예: 민감, 민감하지 
않음)이 있는 태그 정책을 만들고 적절한 조직 단위(OU)에 연결하면 
태그 지정의 일관성이 보장됩니다. 
* SCP: SCP 는 태그 없이 인스턴스 생성을 방지하고 태그 삭제를 방지하여 규정 준수를 
강제하는 데 사용할 수 있습니다. 이러한 정책은 조직 전체에서 계정 수준의 작업을 
제어합니다. 
AWS 의 주요 기능: 
* 태그 정책은 계정 간 태그를 표준화하는 데 도움이 되고, SCP 는 정책을 위반하는 작업을 
제한하여 거버넌스를 시행합니다. 
* AWS 설명서: AWS 모범 사례는 AWS 조직 내 여러 계정에서 규정 준수를 시행하기 위해 
태그 정책과 SCP 를 사용하는 것을 권장합니다. 
Q989 
한 회사에서 AWS 에서 회사 고객 포털의 백엔드인 데이터베이스 워크로드를 실행합니다. 
이 회사는 PostgreSQL 용 Amazon RDS 에서 Multi-AZ 데이터베이스 클러스터를 
실행합니다. 
이 회사는 30 일 백업 보존 정책을 구현해야 합니다. 이 회사는 현재 자동 RDS 백업과 
수동 RDS 백업을 모두 보유하고 있습니다. 이 회사는 30 일 이내에 생성된 두 가지 기존 
RDS 백업을 모두 유지하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. AWS Backup 을 사용하여 자동 백업의 경우 RDS 백업 보존 정책을 30 일로 구성합니다. 
30 일 이상 된 수동 백업을 수동으로 삭제합니다. 
B. RDS 자동 백업을 비활성화합니다. 자동 백업과 30 일 이상 된 수동 백업을 삭제합니다. 
자동 백업의 경우 RDS 백업 보존 정책을 30 일로 구성합니다. 
C. 자동 백업의 경우 RDS 백업 보존 정책을 30 일로 구성합니다. 30 일 이상 된 수동 
백업을 수동으로 삭제합니다. 
D. RDS 자동 백업을 비활성화합니다. AWS CloudFormation 을 사용하여 30 일 이상 된 자동 
백업 및 수동 백업을 자동으로 삭제합니다. 자동 백업의 경우 RDS 백업 보존 정책을 
30 일로 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148459-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
D? 
Q990 
한 회사에서 레거시 애플리케이션을 AWS 로 마이그레이션할 계획입니다. 이 
애플리케이션은 현재 NFS 를 사용하여 온프레미스 스토리지 솔루션과 통신하여 
애플리케이션 데이터를 저장합니다. 이 목적을 위해 NFS 이외의 다른 통신 프로토콜을 
사용하도록 애플리케이션을 수정할 수 없습니다. 
솔루션 아키텍트는 마이그레이션 후 어떤 스토리지 솔루션을 사용하도록 권장해야 합니까? 
A. AWS DataSync 
B. Amazon Elastic Block Store(Amazon EBS) 
C. Amazon Elastic File System(Amazon EFS) 
D. Amazon EMR File System(Amazon EMRFS) 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148460-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
Amazon Elastic File System(EFS)은 NFS(Network File System) 통신이 필요한 레거시 
애플리케이션을 마이그레이션하는 데 이상적인 솔루션입니다. EFS 는 클라우드에서 
완벽하게 관리되고 확장 가능한 NFS 스토리지를 제공하며 표준 NFS 프로토콜을 지원하여 
AWS 로 마이그레이션한 후에도 레거시 애플리케이션이 수정 없이 NFS 를 계속 사용할 수 
있습니다. 
주요 AWS 기능: 
* NFS 지원: EFS 는 기본적으로 NFSv4 프로토콜을 지원하므로 NFS 통신에 의존하는 
워크로드에 가장 적합한 솔루션입니다. 
* 확장성 및 가용성: EFS 는 애플리케이션 수요가 증가함에 따라 자동으로 확장되므로 
가용성이 높고 안정적인 스토리지 솔루션입니다. 
* AWS 설명서: AWS 의 파일 스토리지 모범 사례에 따르면 EFS 는 클라우드 환경에서 NFS 
지원이 필요한 모든 워크로드에 권장됩니다. 
Q991 
한 회사에서 GPS 추적기를 사용하여 수천 마리의 바다 거북이의 이동 패턴을 기록합니다. 
추적기는 5 분마다 거북이가 100 야드(91.4m) 이상 이동했는지 확인합니다. 거북이가 
이동한 경우 추적기는 하나의 AWS 지역의 여러 가용성 영역에 있는 세 개의 Amazon EC2 
인스턴스에서 실행되는 웹 애플리케이션으로 새 좌표를 보냅니다. 
최근에 웹 애플리케이션은 예상치 못한 양의 추적기 데이터를 처리하는 동안 과부하가 
걸렸습니다. 이벤트를 재생할 방법이 없어서 데이터가 손실되었습니다. 솔루션 아키텍트는 
이 문제가 다시 발생하지 않도록 해야 하며 운영 오버헤드가 가장 적은 솔루션이 
필요합니다. 
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 데이터를 저장할 Amazon S3 버킷을 만듭니다. 버킷에서 처리할 새 데이터를 
스캔하도록 애플리케이션을 구성합니다. 
B. 전송된 위치 좌표를 처리할 Amazon API Gateway 엔드포인트를 만듭니다. AWS Lambda 
함수를 사용하여 각 항목을 동시에 처리합니다. 
C. 들어오는 데이터를 저장할 Amazon Simple Queue Service(Amazon SQS) 대기열을 
만듭니다. 처리를 위해 새 메시지를 폴링하도록 애플리케이션을 구성합니다. 
D. 전송된 위치 좌표를 저장할 Amazon DynamoDB 테이블을 만듭니다. 처리를 위해 새 
데이터를 테이블에서 쿼리하도록 애플리케이션을 구성합니다. TTL 을 사용하여 처리된 
데이터를 제거합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148885-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 요구 사항 분석: 예상치 못한 데이터 볼륨으로 인해 애플리케이션이 압도되어 데이터 
손실이 발생하고 재생 메커니즘이 필요했습니다. 
* Amazon SQS 개요: SQS 는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 
분리하고 확장하는 완전 관리형 메시지 대기열 서비스입니다. 
* 데이터 디커플링: 애플리케이션은 SQS 대기열을 사용하여 수신되는 트래커 데이터를 
안정적으로 저장하고 비동기식으로 처리하여 데이터 손실을 방지할 수 있습니다. 
* 구현: 
* SQS 대기열을 생성합니다. 
* 들어오는 데이터를 SQS 대기열로 보내도록 웹 애플리케이션을 수정합니다. 
* SQS 대기열을 폴링하고 메시지를 처리하도록 애플리케이션 인스턴스를 구성합니다. 
* 결론: 이 솔루션은 최소한의 운영 오버헤드로 요구 사항을 충족하므로 데이터가 손실되지 
않고 애플리케이션 자체 속도에 따라 처리될 수 있습니다. 
Q992 
회사의 소프트웨어 개발 팀에 Amazon RDS Multi-AZ 클러스터가 필요합니다. RDS 
클러스터는 온프레미스에 배포된 데스크톱 클라이언트의 백엔드 역할을 합니다. 데스크톱 
클라이언트는 RDS 클러스터에 직접 연결해야 합니다. 
회사는 팀이 사무실에 있을 때 클라이언트를 사용하여 클러스터에 연결할 수 있는 기능을 
개발 팀에 제공해야 합니다. 
어떤 솔루션이 필요한 연결을 가장 안전하게 제공합니까? 
A. VPC 와 두 개의 퍼블릭 서브넷을 만듭니다. 퍼블릭 서브넷에 RDS 클러스터를 만듭니다. 
회사 사무실의 고객 게이트웨이와 함께 AWS 사이트 간 VPN 을 사용합니다. 
B. VPC 와 두 개의 프라이빗 서브넷을 만듭니다. 프라이빗 서브넷에 RDS 클러스터를 
만듭니다. 회사 사무실의 고객 게이트웨이와 함께 AWS 사이트 간 VPN 을 사용합니다. 
C. VPC 와 두 개의 프라이빗 서브넷을 만듭니다. 프라이빗 서브넷에 RDS 클러스터를 
만듭니다. RDS 보안 그룹을 사용하여 회사 사무실 IP 범위에서 클러스터에 액세스할 수 
있도록 합니다. 
D. VPC 와 두 개의 퍼블릭 서브넷을 만듭니다. 퍼블릭 서브넷에 RDS 클러스터를 만듭니다. 
각 개발자에 대한 클러스터 사용자를 만듭니다. RDS 보안 그룹을 사용하여 사용자가 
클러스터에 액세스할 수 있도록 합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148461-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
C?? 
설명: 
* 요구 사항 분석: 사무실에서만 액세스할 수 있는 온프레미스 클라이언트에서 RDS 
클러스터로의 안전하고 직접적인 연결이 필요합니다. 
* 프라이빗 서브넷이 있는 VPC: RDS 클러스터에 공개적으로 액세스할 수 없도록 보장하여 
보안을 강화합니다. 
* 사이트 간 VPN: 온프레미스 사무실과 AWS VPC 간에 안전하고 암호화된 연결을 
제공합니다. 
* 구현: 
* 2 개의 프라이빗 서브넷이 있는 VPC 를 생성합니다. 
* 프라이빗 서브넷에서 RDS 클러스터를 시작합니다. 
* 사무실에 있는 고객 게이트웨이와 Site-to-Site VPN 연결을 설정합니다. 
* 결론: 이 설정은 최소한의 노출로 안전하고 직접적인 연결을 보장하여 사무실에서의 보안 
액세스 요구 사항을 충족합니다. 
Q993 
솔루션 아키텍트가 대량의 데이터를 일괄 처리하는 애플리케이션을 만들고 있습니다. 입력 
데이터는 Amazon S3 에 보관되고 출력 데이터는 다른 S3 버킷에 저장됩니다. 처리를 위해 
애플리케이션은 여러 Amazon EC2 인스턴스 간에 네트워크를 통해 데이터를 전송합니다. 
솔루션 아키텍트는 전체 데이터 전송 비용을 줄이기 위해 무엇을 해야 합니까? 
A. 모든 EC2 인스턴스를 자동 확장 그룹에 배치합니다. 
B. 모든 EC2 인스턴스를 동일한 AWS 리전에 배치합니다. 
C. 모든 EC2 인스턴스를 동일한 가용 영역에 배치합니다. 
D. 모든 EC2 인스턴스를 여러 가용 영역의 프라이빗 서브넷에 배치합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148462-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q994 
한 회사에서 Amazon Aurora MySQL DB 클러스터를 스토리지로 사용하는 다중 계층 웹 
애플리케이션을 호스팅합니다. 애플리케이션 계층은 Amazon EC2 인스턴스에 호스팅됩니다. 
회사의 IT 보안 지침에 따르면 데이터베이스 자격 증명은 암호화되고 14 일마다 순환해야 
합니다. 
솔루션 아키텍트는 최소한의 운영 노력으로 이 요구 사항을 충족하기 위해 무엇을 해야 
합니까? 
A. 새 AWS Key Management Service(AWS KMS) 암호화 키를 만듭니다. AWS Secrets 
Manager 를 사용하여 적절한 자격 증명과 함께 KMS 키를 사용하는 새 비밀을 만듭니다. 
비밀을 Aurora DB 클러스터와 연결합니다. 14 일의 사용자 지정 순환 기간을 구성합니다. 
B. AWS Systems Manager Parameter Store 에 두 개의 매개변수를 만듭니다. 하나는 문자열 
매개변수로 사용자 이름을 위한 것이고 다른 하나는 암호에 SecureString 유형을 사용하는 
것입니다. 암호 매개변수에 대해 AWS Key Management Service(AWS KMS) 암호화를 
선택하고 이러한 매개변수를 애플리케이션 계층에 로드합니다. 14 일마다 암호를 순환하는 
AWS Lambda 함수를 구현합니다. 
C. 자격 증명이 포함된 파일을 AWS Key Management Service(AWS KMS) 암호화 Amazon 
Elastic File System(Amazon EFS) 파일 시스템에 저장합니다. 애플리케이션 계층의 모든 
EC2 인스턴스에 EFS 파일 시스템을 마운트합니다. 파일 시스템에서 파일에 대한 액세스를 
제한하여 애플리케이션이 파일을 읽을 수 있고 슈퍼 사용자만 파일을 수정할 수 있도록 
합니다. 14 일마다 Aurora 에서 키를 순환하고 새 자격 증명을 파일에 쓰는 AWS Lambda 
함수를 구현합니다. 
D. 자격 증명이 포함된 파일을 애플리케이션이 자격 증명을 로드하는 데 사용하는 AWS 
Key Management Service(AWS KMS) 암호화 Amazon S3 버킷에 저장합니다. 올바른 자격 
증명이 사용되도록 정기적으로 파일을 애플리케이션에 다운로드합니다. 14 일마다 Aurora 
자격 증명을 순환하고 이러한 자격 증명을 S3 버킷의 파일에 업로드하는 AWS Lambda 
함수를 구현합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/148463-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q995 
스트리밍 미디어 회사가 사용자가 매일 소비하는 비디오 콘텐츠에 대한 수요 증가에 
대응하기 위해 인프라를 재구축하고 있습니다. 
이 회사는 비디오의 일부 콘텐츠를 차단하기 위해 테라바이트 크기의 비디오를 처리해야 
합니다. 비디오 처리에는 최대 20 분이 걸릴 수 있습니다. 
이 회사는 수요에 따라 확장되고 비용 효율적인 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. AWS Lambda 함수를 사용하여 비디오를 처리합니다. Amazon DynamoDB 에 비디오 
메타데이터를 저장합니다. Amazon S3 Intelligent-Tiering 에 비디오 콘텐츠를 저장합니다. 
B. Amazon Elastic Container Service(Amazon ECS)와 AWS Fargate 를 사용하여 비디오를 
처리하는 마이크로서비스를 구현합니다. Amazon Aurora 에 비디오 메타데이터를 저장합니다. 
Amazon S3 Intelligent-Tiering 에 비디오 콘텐츠를 저장합니다. 
C. ALB(Application Load Balancer) 뒤에 있는 자동 확장 그룹의 Amazon EC2 인스턴스를 
사용하여 비디오를 처리합니다. Amazon S3 Standard 에 비디오 콘텐츠를 저장합니다. 
Amazon Simple Queue Service(Amazon SQS)를 사용하여 대기열에 넣고 처리 작업을 
분리합니다. 
D. Amazon EC2 의 Amazon Elastic Kubernetes Service(Amazon EKS)에 컨테이너화된 
비디오 처리 애플리케이션을 배포합니다. 단일 가용성 영역의 Amazon RDS 에 비디오 
메타데이터를 저장합니다. Amazon S3 Glacier Deep Archive 에 비디오 콘텐츠를 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148465-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
C?? 
Q996 
한 회사가 Kubernetes 클러스터에서 온프레미스 애플리케이션을 실행합니다. 이 회사는 
최근 수백만 명의 신규 고객을 추가했습니다. 이 회사의 기존 온프레미스 인프라는 많은 
수의 신규 고객을 처리할 수 없습니다. 이 회사는 온프레미스 애플리케이션을 AWS 
클라우드로 마이그레이션해야 합니다. 
이 회사는 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터로 
마이그레이션합니다. 이 회사는 AWS 에서 새 아키텍처의 기본 컴퓨팅 인프라를 관리하고 
싶어하지 않습니다. 
어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. 자체 관리 노드를 사용하여 컴퓨팅 용량을 제공합니다. 새 EKS 클러스터에 
애플리케이션을 배포합니다. 
B. 관리 노드 그룹을 사용하여 컴퓨팅 용량을 제공합니다. 새 EKS 클러스터에 
애플리케이션을 배포합니다. 
C. AWS Fargate 를 사용하여 컴퓨팅 용량을 제공합니다. Fargate 프로필을 만듭니다. 
Fargate 프로필을 사용하여 애플리케이션을 배포합니다. 
D. Karpenter 와 함께 관리 노드 그룹을 사용하여 컴퓨팅 용량을 제공합니다. 새 EKS 
클러스터에 애플리케이션을 배포합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148468-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q997 
한 회사에서 사용자 프로필, 애플리케이션 설정, 거래 데이터를 저장하기 위한 구조화된 
데이터베이스가 필요한 새로운 애플리케이션을 출시합니다. 데이터베이스는 애플리케이션 
트래픽에 따라 확장 가능해야 하며 백업을 제공해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 오픈 소스 소프트웨어를 사용하여 Amazon EC2 인스턴스에 자체 관리형 데이터베이스를 
배포합니다. 비용 최적화를 위해 스팟 인스턴스를 사용합니다. Amazon S3 에 대한 자동 
백업을 구성합니다. 
B. Amazon RDS 를 사용합니다. 범용 SSD 스토리지가 있는 데이터베이스에 대해 주문형 
용량 모드를 사용합니다. 보존 기간이 7 일인 자동 백업을 구성합니다. 
C. 데이터베이스에 Amazon Aurora Serverless 를 사용합니다. 서버리스 용량 확장을 
사용합니다. Amazon S3 에 대한 자동 백업을 구성합니다. 
D. Amazon EC2 인스턴스에 자체 관리형 NoSQL 데이터베이스를 배포합니다. 비용 
최적화를 위해 예약 인스턴스를 사용합니다. Amazon S3 Glacier Flexible Retrieval 에 직접 
자동 백업을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148469-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q998 
한 회사가 AWS 에서 레거시 웹 애플리케이션을 실행합니다. 웹 애플리케이션 서버는 
VPC 의 퍼블릭 서브넷에 있는 Amazon EC2 인스턴스에서 실행됩니다. 웹 애플리케이션 
서버는 고객으로부터 이미지를 수집하여 로컬로 연결된 Amazon Elastic Block 
Store(Amazon EBS) 볼륨에 이미지 파일을 저장합니다. 이미지 파일은 백업을 위해 매일 밤 
Amazon S3 버킷에 업로드됩니다. 
솔루션 아키텍트는 이미지 파일이 퍼블릭 엔드포인트를 통해 Amazon S3 에 업로드되고 
있음을 발견합니다. 솔루션 아키텍트는 Amazon S3 로의 트래픽이 퍼블릭 엔드포인트를 
사용하지 않도록 해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. VPC 에 필요한 권한이 있는 S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 만듭니다. 
게이트웨이 VPC 엔드포인트를 사용하도록 서브넷 경로 테이블을 구성합니다. 
B. VPC 내부로 S3 버킷을 이동합니다. 프라이빗 IP 주소를 통해 S3 버킷에 액세스하도록 
서브넷 경로 테이블을 구성합니다. 
C. VPC 내부에서 Amazon EC2 인스턴스에 대한 Amazon S3 액세스 포인트를 만듭니다. 
Amazon S3 액세스 포인트를 사용하여 업로드할 웹 애플리케이션을 구성합니다. 
D. Amazon EC2 인스턴스가 있는 VPC 와 Amazon S3 사이에 AWS Direct Connect 연결을 
구성하여 전용 네트워크 경로를 제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/148806-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q999 
한 회사가 AWS 에서 전자상거래 웹사이트의 프로토타입을 만들고 있습니다. 이 웹사이트는 
애플리케이션 로드 밸런서, 웹 서버용 Amazon EC2 인스턴스의 자동 확장 그룹, Single-AZ 
구성으로 실행되는 MySQL DB 인스턴스용 Amazon RDS 로 구성되어 있습니다. 
제품 카탈로그를 검색하는 동안 웹사이트의 응답이 느립니다. 제품 카탈로그는 회사에서 
자주 업데이트하지 않는 MySQL 데이터베이스의 테이블 그룹입니다. 솔루션 아키텍트는 
제품 카탈로그 검색이 발생할 때 DB 인스턴스의 CPU 사용률이 높다는 것을 확인했습니다. 
솔루션 아키텍트는 제품 카탈로그를 검색하는 동안 웹사이트의 성능을 개선하기 위해 
무엇을 권장해야 합니까? 
A. 제품 카탈로그를 Amazon Redshift 데이터베이스로 마이그레이션합니다. COPY 명령을 
사용하여 제품 카탈로그 테이블을 로드합니다. 
B. Amazon ElastiCache for Redis 클러스터를 구현하여 제품 카탈로그를 캐시합니다. 지연 
로딩을 사용하여 캐시를 채웁니다. 
C. 데이터베이스 응답이 느릴 때 추가 EC2 인스턴스를 시작하기 위해 자동 확장 그룹에 
추가 확장 정책을 추가합니다. 
D. DB 인스턴스에 대한 다중 AZ 구성을 켭니다. EC2 인스턴스를 구성하여 데이터베이스로 
전송되는 제품 카탈로그 쿼리를 제한합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148470-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
* 요구 사항 분석: 제품 카탈로그 검색으로 인해 MySQL DB 인스턴스의 CPU 사용률이 
높아져 웹 사이트 속도가 느려지고 있습니다. 
* ElastiCache 개요: Redis 용 Amazon ElastiCache 를 사용하면 자주 액세스하는 데이터를 
캐시하여 데이터베이스의 로드를 줄일 수 있습니다. 
* 지연 로딩: 이 캐싱 전략은 데이터가 요청될 때만 캐시에 로드되어 반복 쿼리에 대한 
응답 시간을 향상시킵니다. 
* 구현: 
* Redis 클러스터용 ElastiCache 를 설정합니다. 
* 데이터베이스를 쿼리하기 전에 캐시를 확인하도록 애플리케이션을 수정합니다. 
* 캐시 누락 시 캐시를 채우려면 지연 로딩을 사용하세요. 
* 결론: 이 접근 방식은 제품 카탈로그 검색 중 데이터베이스 부하를 줄이고 웹 사이트 
성능을 향상시킵니다. 
================================================================ 
VCE 프로그램이 Q1000 번 문제 이상 인식을 하지 못하는 버그로 문제 번호를 Q100 번으로 
변경해서 표기합니다. 
================================================================ 
Q100 
한 회사가 현재 온프레미스 블록 스토리지 시스템에 5TB 의 데이터를 저장하고 있습니다. 
이 회사의 현재 스토리지 솔루션은 추가 데이터를 위한 제한된 공간을 제공합니다. 이 
회사는 낮은 지연 시간으로 자주 액세스하는 데이터를 검색할 수 있어야 하는 온프레미스 
애플리케이션을 실행합니다. 이 회사에는 클라우드 기반 스토리지 솔루션이 필요합니다. 
어떤 솔루션이 가장 높은 운영 효율성으로 이러한 요구 사항을 충족할까요? 
A. Amazon S3 파일 게이트웨이를 사용합니다. S3 파일 게이트웨이를 온프레미스 
애플리케이션과 통합하여 SMB 파일 시스템을 사용하여 파일을 저장하고 직접 검색합니다. 
B. 캐시된 볼륨을 iSCSI 대상으로 사용하는 AWS Storage Gateway 볼륨 게이트웨이를 
사용합니다. 
C. 저장된 볼륨을 iSCSI 대상으로 사용하는 AWS Storage Gateway 볼륨 게이트웨이를 
사용합니다. 
D. AWS Storage Gateway 테이프 게이트웨이를 사용합니다. 테이프 게이트웨이를 
온프레미스 애플리케이션과 통합하여 Amazon S3 에 가상 테이프를 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148471-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
이 회사는 일부 데이터 스토리지를 위해 현재 온프레미스 인프라를 유지하면서 낮은 대기 
시간으로 자주 액세스하는 데이터를 위한 클라우드 기반 스토리지 솔루션이 필요합니다. 
AWS Storage Gateway 의 캐시 볼륨이 있는 볼륨 게이트웨이는 이 시나리오에 가장 적합한 
솔루션입니다. 
자세한 설명: 
* AWS Storage Gateway - 볼륨 게이트웨이(캐시 볼륨): 
* 캐시 볼륨이 있는 볼륨 게이트웨이를 사용하면 자주 액세스하는 데이터를 AWS 
클라우드에 저장하고 가장 최근에 액세스한 데이터는 온프레미스에 로컬로 캐시할 수 
있습니다. 이를 통해 활성 데이터에 대한 액세스 대기 시간이 짧아지고 클라우드의 나머지 
데이터에 대한 확장성이 제공됩니다. 
* 캐시 볼륨 옵션은 기본 데이터를 Amazon S3 에 저장하지만 자주 액세스하는 데이터는 
로컬로 캐시하여 빠른 액세스를 보장합니다. 이 구성은 자주 사용하는 데이터에 대한 빠른 
액세스가 필요하지만 나머지는 클라우드 기반 스토리지를 허용할 수 있는 애플리케이션에 
적합합니다. 
* 회사가 온프레미스 스토리지가 제한되어 있기 때문에 캐시 볼륨은 추가 온프레미스 
스토리지 인프라에 대한 필요성을 줄여주기 때문에 이상적인 솔루션을 제공합니다. 
* 다른 옵션은 왜 안 되나요?: 
* 옵션 A(S3 파일 게이트웨이): S3 파일 게이트웨이는 S3 에 직접 데이터를 저장하기 위한 
파일 기반 인터페이스(SMB/NFS)를 제공합니다. 파일 스토리지에는 좋지만, iSCSI 타겟이 
있는 블록 레벨 스토리지에 대한 회사의 요구 사항으로 인해 Volume Gateway 가 더 
적합합니다. 
* 옵션 C(볼륨 게이트웨이 - 저장된 볼륨): 저장된 볼륨은 모든 데이터를 온프레미스에 
보관하고 AWS 에 비동기적으로 백업합니다. 여전히 상당한 온프레미스 스토리지가 
필요하기 때문에 회사의 스토리지 제한을 해결하지 못합니다. 
* 옵션 D(테이프 게이트웨이): 테이프 게이트웨이는 자주 액세스하는 저지연 데이터가 아닌 
보관 및 백업을 위해 설계되었습니다. 
Q101 
한 회사에서 음식 배달 서비스를 운영합니다. 최근 성장으로 인해 회사의 주문 처리 
시스템은 최대 트래픽 시간 동안 확장 문제를 겪고 있습니다. 현재 아키텍처에는 
애플리케이션에서 주문을 수집하는 Auto Scaling 그룹의 Amazon EC2 인스턴스가 
포함됩니다. Auto Scaling 그룹의 두 번째 EC2 인스턴스 그룹은 주문을 이행합니다. 
주문 수집 프로세스는 빠르게 진행되지만 주문 이행 프로세스는 더 오래 걸릴 수 있습니다. 
확장 이벤트로 인해 데이터가 손실되어서는 안 됩니다. 
솔루션 아키텍트는 주문 수집 프로세스와 주문 이행 프로세스가 모두 최대 트래픽 시간 
동안 적절하게 확장될 수 있도록 해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon CloudWatch 를 사용하여 두 Auto Scaling 그룹의 각 인스턴스에 대한 
CPUUtilization 메트릭을 모니터링합니다. 각 Auto Scaling 그룹의 최소 용량을 구성하여 
최대 워크로드 값을 충족합니다. 
B. Amazon CloudWatch 를 사용하여 두 Auto Scaling 그룹의 각 인스턴스에 대한 
CPUUtilization 메트릭을 모니터링합니다. CloudWatch 알람을 구성하여 Amazon Simple 
Notification Service(Amazon SNS) 주제를 호출하여 필요에 따라 추가 Auto Scaling 그룹을 
만듭니다. 
C. 두 개의 Amazon Simple Queue Service(Amazon SQS) 대기열을 프로비저닝합니다. 주문 
수집에 하나의 SQS 대기열을 사용합니다. 주문 이행에 두 번째 SQS 대기열을 사용합니다. 
EC2 인스턴스가 해당 대기열을 폴링하도록 구성합니다. 대기열에서 보내는 알림에 따라 
Auto Scaling 그룹을 확장합니다. 
D. 두 개의 Amazon Simple Queue Service(Amazon SQS) 대기열을 프로비저닝합니다. 주문 
수집에 하나의 SQS 대기열을 사용합니다. 주문 이행에 두 번째 SQS 대기열을 사용합니다. 
EC2 인스턴스가 해당 대기열을 폴링하도록 구성합니다. 각 대기열의 메시지 수에 따라 
Auto Scaling 그룹을 확장합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/148807-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q102 
한 온라인 게임 회사가 회사의 증가하는 사용자 기반을 지원하기 위해 사용자 데이터 
저장소를 Amazon DynamoDB 로 전환하고 있습니다. 현재 아키텍처에는 사용자 프로필, 
업적, 게임 내 거래가 포함된 DynamoDB 테이블이 포함됩니다. 
이 회사는 사용자에게 원활한 게임 환경을 유지하기 위해 견고하고 지속적으로 사용 
가능하며 회복성이 뛰어난 DynamoDB 아키텍처를 설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요? 
A. 단일 AWS 리전에 DynamoDB 테이블을 만듭니다. 주문형 용량 모드를 사용합니다. 
글로벌 테이블을 사용하여 여러 리전에 걸쳐 데이터를 복제합니다. 
B. DynamoDB Accelerator(DAX)를 사용하여 자주 액세스하는 데이터를 캐시합니다. 단일 
AWS 리전에 테이블을 배포하고 자동 확장을 활성화합니다. 추가 리전에 대한 크로스 리전 
복제를 수동으로 구성합니다. 
C. 여러 AWS 리전에 DynamoDB 테이블을 만듭니다. 주문형 용량 모드를 사용합니다. 
리전 간 크로스 리전 복제를 위해 DynamoDB Streams 를 사용합니다. 
D. DynamoDB 글로벌 테이블을 사용하여 자동 다중 리전 복제를 수행합니다. 여러 AWS 
지역에 테이블을 배포합니다. 프로비저닝된 용량 모드를 사용합니다. 자동 스케일링을 
활성화합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/148808-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q103 
한 회사에서 온프레미스에서 미디어 렌더링 애플리케이션을 실행합니다. 이 회사는 
스토리지 비용을 절감하고자 하며 모든 데이터를 Amazon S3 로 옮겼습니다. 온프레미스 
렌더링 애플리케이션은 스토리지에 대한 저지연 액세스가 필요합니다. 
이 회사는 애플리케이션에 대한 스토리지 솔루션을 설계해야 합니다. 스토리지 솔루션은 
원하는 애플리케이션 성능을 유지해야 합니다. 
어떤 스토리지 솔루션이 이러한 요구 사항을 가장 비용 효율적인 방식으로 충족할까요? 
A. Mountpoint for Amazon S3 를 사용하여 온프레미스 애플리케이션의 Amazon S3 에 있는 
데이터에 액세스합니다. 
B. Amazon S3 파일 게이트웨이를 구성하여 온프레미스 애플리케이션에 스토리지를 
제공합니다. 
C. Amazon S3 에서 Amazon FSx for Windows File Server 로 데이터를 복사합니다. Amazon 
FSx 파일 게이트웨이를 구성하여 온프레미스 애플리케이션에 스토리지를 제공합니다. 
D. 온프레미스 파일 서버를 구성합니다. Amazon S3 API 를 사용하여 S3 스토리지에 
연결합니다. 온프레미스 파일 서버에서 스토리지에 액세스하도록 애플리케이션을 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148809-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q104 
한 회사가 us-east-1 지역에 ERP(Enterprise Resource Planning) 시스템을 호스팅합니다. 
이 시스템은 Amazon EC2 인스턴스에서 실행됩니다. 고객은 EC2 인스턴스에 호스팅된 
퍼블릭 API 를 사용하여 ERP 시스템과 정보를 교환합니다. 국제 고객은 데이터 센터에서 
API 응답 시간이 느리다고 보고합니다. 
어떤 솔루션이 국제 고객의 응답 시간을 가장 비용 효율적으로 개선할까요? 
A. 각 고객의 데이터 센터에서 us-east-1 로 연결을 제공하는 퍼블릭 가상 
인터페이스(VIF)가 있는 AWS Direct Connect 연결을 만듭니다. Direct Connect 
게이트웨이를 사용하여 ERP 시스템 API 로 고객 API 요청을 라우팅합니다. 
B. API 앞에 Amazon CloudFront 배포를 설정합니다. 향상된 캐시 효율성을 제공하도록 
CachingOptimized 관리형 캐시 정책을 구성합니다. 
C. AWS Global Accelerator 를 설정합니다. 필요한 포트에 대한 리스너를 구성합니다. 
트래픽을 분산하기 위해 적절한 지역에 대한 엔드포인트 그룹을 구성합니다. API 에 대한 
그룹에 엔드포인트를 만듭니다. 
D. AWS Site-to-Site VPN 을 사용하여 지역과 고객 네트워크 간에 전용 VPN 터널을 
설정합니다. VPN 연결을 통해 API 로 트래픽을 라우팅합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148810-exam-aws-certified
-solutions-architect-associate-saa-c03/ 
B?? 
Q105 
회사는 회사가 웹사이트에 호스팅하는 설문 조사를 사용하여 고객 만족도를 추적합니다. 
설문 조사는 때때로 매시간 수천 명의 고객에게 도달합니다. 설문 조사 결과는 현재 회사 
직원이 결과를 수동으로 검토하고 고객 감정을 평가할 수 있도록 이메일 메시지로 회사에 
전송됩니다. 
회사는 고객 설문 조사 프로세스를 자동화하려고 합니다. 설문 조사 결과는 지난 12 개월 
동안 사용할 수 있어야 합니다. 
가장 확장 가능한 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 설문 조사 결과 데이터를 Amazon Simple Queue Service(Amazon SQS) 대기열에 연결된 
Amazon API Gateway 엔드포인트로 보냅니다. SQS 대기열을 폴링하고 감정 분석을 위해 
Amazon Comprehend 를 호출하고 결과를 Amazon DynamoDB 테이블에 저장하는 AWS 
Lambda 함수를 만듭니다. 모든 레코드의 TTL 을 미래 365 일로 설정합니다. 
B. 설문 조사 결과 데이터를 Amazon EC2 인스턴스에서 실행되는 API 로 보냅니다. API 를 
구성하여 설문 조사 결과를 Amazon DynamoDB 테이블에 새 레코드로 저장하고, 감정 
분석을 위해 Amazon Comprehend 를 호출하고, 두 번째 DynamoDB 테이블에 결과를 
저장합니다. 모든 레코드의 TTL 을 365 일 후로 설정합니다. 
C. 설문 조사 결과 데이터를 Amazon S3 버킷에 씁니다. S3 이벤트 알림을 사용하여 AWS 
Lambda 함수를 호출하여 데이터를 읽고 감정 분석을 위해 Amazon Rekognition 을 
호출합니다. 감정 분석 결과를 두 번째 S3 버킷에 저장합니다. 각 버킷에서 S3 수명 주기 
정책을 사용하여 365 일 후에 객체를 만료합니다. 
D. 설문 조사 결과 데이터를 Amazon Simple Queue Service(Amazon SQS) 대기열에 연결된 
Amazon API Gateway 엔드포인트로 보냅니다. SQS 대기열을 구성하여 감정 분석을 위해 
Amazon Lex 를 호출하고 결과를 Amazon DynamoDB 테이블에 저장하는 AWS Lambda 
함수를 호출합니다. 모든 레코드의 TTL 을 365 일 후로 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/148811-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q106 
한 회사에서 Amazon EC2 인스턴스의 일상적인 관리 및 패치에 AWS Systems Manager 를 
사용합니다. EC2 인스턴스는 ALB(Application Load Balancer) 뒤의 IP 주소 유형 대상 
그룹에 있습니다. 
새로운 보안 프로토콜은 패치 중에 회사에서 EC2 인스턴스를 서비스에서 제거해야 합니다. 
회사가 다음 패치 중에 보안 프로토콜을 따르려고 하면 패치 기간 중에 오류가 발생합니다. 
어떤 솔루션 조합으로 오류를 해결할 수 있습니까? (두 가지 선택) 
A. 대상 그룹의 대상 유형을 IP 주소 유형에서 인스턴스 유형으로 변경합니다. 
B. ALB 뒤의 IP 주소 유형 대상 그룹에 있는 인스턴스를 처리하도록 이미 최적화되어 
있으므로 기존 Systems Manager 문서를 변경하지 않고 계속 사용합니다. 
C. AWSEC2-PatchLoadBalanacerInstance Systems Manager Automation 문서를 구현하여 
패치 프로세스를 관리합니다. 
D. Systems Manager Maintenance Windows 를 사용하여 인스턴스를 서비스에서 자동으로 
제거하여 인스턴스를 패치합니다. 
E. Systems Manager State Manager 를 구성하여 인스턴스를 서비스에서 제거하고 패치 
일정을 관리합니다. ALB 상태 확인을 사용하여 트래픽을 다시 라우팅합니다. 
Answer: C, D 
https://www.examtopics.com/discussions/amazon/view/148812-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q107 
한 의료 회사가 여러 고객으로부터 얻은 방대한 양의 임상 시험 데이터에 대한 변환을 
수행하려고 합니다. 이 회사는 고객 데이터가 포함된 관계형 데이터베이스에서 데이터를 
추출해야 합니다. 그런 다음 회사는 일련의 복잡한 규칙을 사용하여 데이터를 변환합니다. 
이 회사는 변환이 완료되면 Amazon S3 에 데이터를 로드합니다. 
모든 데이터는 회사가 Amazon S3 에 데이터를 저장하기 전에 처리되는 위치에서 
암호화되어야 합니다. 모든 데이터는 고객별 키를 사용하여 암호화되어야 합니다. 
어떤 솔루션이 최소한의 운영 노력으로 이러한 요구 사항을 충족할 수 있을까요? 
A. 각 고객에 대해 하나의 AWS Glue 작업을 만듭니다. Amazon S3 관리 키(SSE-S3)를 
사용하여 서버 측 암호화를 사용하는 각 작업에 보안 구성을 연결하여 데이터를 
암호화합니다. 
B. 각 고객에 대해 하나의 Amazon EMR 클러스터를 만듭니다. 사용자 지정 클라이언트 측 
루트 키(CSE-Custom)를 사용하여 클라이언트 측 암호화를 사용하는 각 클러스터에 보안 
구성을 연결하여 데이터를 암호화합니다. 
C. 각 고객에 대해 하나의 AWS Glue 작업을 만듭니다. 각 작업에 AWS KMS 관리 
키(CSE-KMS)를 사용하여 클라이언트 측 암호화를 사용하는 보안 구성을 연결하여 
데이터를 암호화합니다. 
D. 각 고객에 대해 하나의 Amazon EMR 클러스터를 만듭니다. 각 클러스터에 AWS KMS 
키(SSE-KMS)를 사용하여 서버 측 암호화를 사용하는 보안 구성을 연결하여 데이터를 
암호화합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148544-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q108 
한 회사에서 단일 Amazon EC2 On-Demand 인스턴스에 웹사이트 분석 애플리케이션을 
호스팅합니다. 분석 애플리케이션은 매우 회복성이 뛰어나고 상태 비저장 모드에서 
실행되도록 설계되었습니다. 
이 회사는 애플리케이션이 바쁜 시간에 성능 저하 징후를 보이고 5xx 오류가 발생하는 
것을 알아챘습니다. 이 회사는 애플리케이션을 원활하게 확장해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 웹 애플리케이션의 Amazon Machine Image(AMI)를 만듭니다. AMI 를 사용하여 두 번째 
EC2 On-Demand 인스턴스를 시작합니다. Application Load Balancer 를 사용하여 두 EC2 
인스턴스에 부하를 분산합니다. 
B. 웹 애플리케이션의 Amazon Machine Image(AMI)를 만듭니다. AMI 를 사용하여 두 번째 
EC2 On-Demand 인스턴스를 시작합니다. Amazon Route 53 가중 라우팅을 사용하여 두 
EC2 인스턴스에 부하를 분산합니다. 
C. AWS Lambda 함수를 만들어 EC2 인스턴스를 중지하고 인스턴스 유형을 변경합니다. 
CPU 사용률이 75%를 넘을 때 Lambda 함수를 호출하는 Amazon CloudWatch 알람을 
만듭니다. 
D. 웹 애플리케이션의 Amazon Machine Image(AMI)를 만듭니다. AMI 를 실행 템플릿에 
적용합니다. 실행 템플릿을 포함하는 자동 확장 그룹을 만듭니다. 실행 템플릿을 구성하여 
Spot Fleet 을 사용합니다. 자동 확장 그룹에 애플리케이션 로드 밸런서를 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/148813-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q109 
한 회사에서 Amazon S3 버킷에 데이터가 저장된 환경을 운영합니다. 객체는 하루 종일 
자주 액세스됩니다. 이 회사는 S3 버킷에 저장된 데이터에 대해 엄격한 데이터 암호화 
요구 사항을 가지고 있습니다. 이 회사는 현재 암호화를 위해 AWS Key Management 
Service(AWS KMS)를 사용합니다. 
이 회사는 AWS KMS 에 대한 추가 호출 없이 S3 객체를 암호화하는 데 드는 비용을 
최적화하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon S3 관리 키(SSE-S3)로 서버 측 암호화를 사용합니다. 
B. 새 객체에서 AWS KMS 키(SSE-KMS)로 서버 측 암호화를 위해 S3 버킷 키를 
사용합니다. 
C. AWS KMS 고객 관리 키로 클라이언트 측 암호화를 사용합니다. 
D. AWS KMS 에 저장된 고객 제공 키(SSE-C)로 서버 측 암호화를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148814-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
S3 버킷 키는 KMS 에 대한 요청 수를 줄여 서버 측 암호화에 AWS KMS 를 사용하는 
비용을 줄입니다. S3 버킷 키를 활성화하면 회사는 KMS API 요청 수를 줄여 비용을 
최적화하는 동시에 KMS 키로 암호화 요구 사항을 충족할 수 있습니다. 
주요 AWS 기능: 
* 비용 최적화: S3 버킷 키는 KMS 호출 빈도를 줄여 암호화와 관련된 비용을 최적화하는 
동시에 키 관리에 AWS KMS 를 사용합니다. 
* KMS 암호화 준수: 이 솔루션은 KMS 관리 키를 사용하여 회사의 엄격한 암호화 요구 
사항을 계속 충족합니다. 
* AWS 설명서: 보안을 손상시키지 않고 암호화 비용을 최적화하려는 조직에 S3 버킷 키를 
사용하는 것이 좋습니다. 
Q110 
한 회사가 온프레미스 데이터 센터의 가상 머신(VM)에서 여러 워크로드를 실행합니다. 
회사는 빠르게 확장하고 있습니다. 온프레미스 데이터 센터는 비즈니스 요구 사항을 충족할 
만큼 빠르게 확장할 수 없습니다. 회사는 워크로드를 AWS 로 마이그레이션하려고 합니다. 
마이그레이션은 시간에 민감합니다. 회사는 비중요 워크로드에 대해 리프트 앤 시프트 
전략을 사용하려고 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (세 가지 선택) 
A. AWS Schema Conversion Tool(AWS SCT)을 사용하여 VM 에 대한 데이터를 수집합니다. 
B. AWS Application Migration Service 를 사용합니다. VM 에 AWS Replication Agent 를 
설치합니다. 
C. VM 의 초기 복제를 완료합니다. 테스트 인스턴스를 시작하여 VM 에서 수락 테스트를 
수행합니다. 
D. VM 에서 모든 작업을 중지합니다. 컷오버 인스턴스를 시작합니다. 
E. AWS App2Container(A2C)를 사용하여 VM 에 대한 데이터를 수집합니다. 
F. AWS Database Migration Service(AWS DMS)를 사용하여 VM 을 마이그레이션합니다. 
Answer: B, C, D 
https://www.examtopics.com/discussions/amazon/view/148815-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
설명: 
AWS 애플리케이션 마이그레이션 서비스(AWS MGN)는 리프트 앤 시프트 전략, 특히 시간에 
민감한 마이그레이션에 권장되는 툴입니다. 온프레미스 VM 을 AWS 로 복제하는 작업을 
자동화하여 마이그레이션 및 테스트에 필요한 노력을 최소화합니다. 
주요 단계 
* AWS MGN 을 통한 복제: AWS 복제 에이전트가 VM 에 설치되어 데이터를 AWS 로 
지속적으로 복제하므로 마이그레이션을 쉽게 관리할 수 있습니다. 
* 테스트 및 컷오버: 초기 복제를 통해 최종 컷오버를 수행하기 전에 AWS 에서 테스트할 
수 있으므로 마이그레이션 프로세스가 원활하고 데이터 무결성을 유지할 수 있습니다. 
* AWS 설명서: 다운타임과 중단을 최소화하면서 가상 머신을 클라우드로 
마이그레이션하려면 AWS MGN 을 사용하는 것이 좋습니다. 
Q111 
한 회사가 프라이빗 서브넷에 애플리케이션을 호스팅합니다. 이 회사는 이미 
애플리케이션을 Amazon Cognito 와 통합했습니다. 이 회사는 Amazon Cognito 사용자 풀을 
사용하여 사용자를 인증합니다. 
이 회사는 애플리케이션을 수정하여 애플리케이션이 Amazon S3 버킷에 사용자 문서를 
안전하게 저장할 수 있도록 해야 합니다. 
어떤 단계 조합을 통해 Amazon S3 를 애플리케이션과 안전하게 통합할 수 있을까요? (두 
가지 선택) 
A. Amazon Cognito ID 풀을 만들어 사용자가 성공적으로 로그인할 때 보안 Amazon S3 
액세스 토큰을 생성합니다. 
B. 기존 Amazon Cognito 사용자 풀을 사용하여 사용자가 성공적으로 로그인할 때 Amazon 
S3 액세스 토큰을 생성합니다. 
C. 이 회사가 애플리케이션을 호스팅하는 동일한 VPC 에 Amazon S3 VPC 엔드포인트를 
만듭니다. 
D. 이 회사가 애플리케이션을 호스팅하는 VPC 에 NAT 게이트웨이를 만듭니다. Amazon 
Cognito 에서 시작되지 않은 모든 요청을 거부하도록 S3 버킷에 정책을 할당합니다. 
E. 사용자의 IP 주소에서만 액세스를 허용하는 정책을 S3 버킷에 연결합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/148817-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
A, B?? 
설명: 
Amazon S3 를 사용자 인증에 Amazon Cognito 를 사용하는 애플리케이션과 안전하게 
통합하려면 다음 두 단계가 필수적입니다. 
자세한 설명: 
* 1 단계: Amazon Cognito ID 풀 만들기(옵션 A) 
* Amazon Cognito ID 풀을 사용하면 사용자가 Cognito 사용자 풀에서 성공적으로 인증한 
후 Amazon S3 와 같은 AWS 리소스에 액세스할 수 있는 임시 AWS 자격 증명을 얻을 수 
있습니다. 
ID 풀은 AWS Identity and Access Management(IAM)를 사용하여 임시 자격 증명을 
생성하여 사용자 인증과 AWS 서비스 액세스 간의 격차를 메웁니다. 
* 사용자가 Cognito 사용자 풀을 사용하여 로그인하면 ID 풀은 애플리케이션이 S3 에 
안전하게 액세스하는 데 사용할 수 있는 특정 권한이 있는 IAM 역할을 제공합니다. 이를 
통해 각 사용자는 S3 버킷에 액세스하는 동안 적절한 액세스 제어를 할 수 있습니다. 
* 이는 사용자가 문서에 대한 S3 버킷에 대한 임시 및 최소 권한 액세스만 할 수 있도록 
하는 안전한 방법입니다. 
* 2 단계: Amazon S3 VPC 엔드포인트 만들기(옵션 C) 
* Amazon S3 VPC 엔드포인트를 만들면 회사는 인터넷을 통과할 필요 없이 
애플리케이션(개인 서브넷에 호스팅됨)과 S3 버킷 간의 통신이 AWS 개인 네트워크를 통해 
이루어지도록 합니다. 이를 통해 보안이 강화되고 데이터가 공용 네트워크에 노출되는 것을 
방지할 수 있습니다. 
* VPC 엔드포인트를 사용하면 애플리케이션이 VPC 내에서 비공개로 안전하게 S3 버킷에 
액세스할 수 있습니다. 또한 트래픽이 AWS 네트워크 내에 머물도록 하여 공격 표면을 
줄이고 전반적인 보안을 개선합니다. 
다른 옵션이 틀린 이유: 
* 옵션 B: Amazon Cognito 사용자 풀은 S3 액세스 토큰을 생성하는 것이 아니라 사용자 
인증에 사용되기 때문에 이는 틀렸습니다. S3 액세스를 제공하려면 AWS 자격 증명을 
제공하는 Amazon Cognito Identity Pools 를 사용해야 합니다. 
* 옵션 D: 이 시나리오에서는 NAT 게이트웨이가 필요하지 않습니다. S3 액세스를 위해 
VPC 엔드포인트를 사용하면 트래픽을 AWS 내에 유지하여 보다 안전하고 비용 효율적인 
솔루션을 제공합니다. 
* 옵션 E: IP 주소에 따라 액세스를 제한하는 정책을 첨부하는 것은 확장성도 효율적이지 
않습니다. 사용자의 동적 IP 주소를 관리해야 하며, 이는 이 사용 사례에 효과적인 보안 
조치가 아닙니다. 
Q112 
한 회사에 고객의 주문을 처리하는 3 계층 웹 애플리케이션이 있습니다. 웹 계층은 
애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스로 구성됩니다. 처리 계층은 
EC2 인스턴스로 구성됩니다. 이 회사는 Amazon Simple Queue Service(Amazon SQS)를 
사용하여 웹 계층과 처리 계층을 분리했습니다. 스토리지 계층은 Amazon DynamoDB 를 
사용합니다. 
피크 타임에 일부 사용자는 주문 처리 지연과 홀을 보고합니다. 이 회사는 이러한 지연 
중에 EC2 인스턴스가 100% CPU 사용률로 실행되고 SQS 대기열이 가득 찬다는 것을 
알아챘습니다. 피크 타임은 가변적이고 예측할 수 없습니다. 
이 회사는 애플리케이션의 성능을 개선해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon EC2 자동 확장에 예약된 확장을 사용하여 피크 사용 시간 동안 처리 계층 
인스턴스를 확장합니다. CPU 사용률 메트릭을 사용하여 확장 시기를 결정합니다. 
B. DynamoDB 백엔드 계층 앞에 Amazon ElastiCache for Redis 를 사용합니다. 대상 
활용도를 메트릭으로 사용하여 확장 시기를 결정합니다. 
C. Amazon CloudFront 배포를 추가하여 웹 계층에 대한 응답을 캐시합니다. HTTP 대기 
시간을 메트릭으로 사용하여 확장 시기를 결정합니다. 
D. Amazon EC2 Auto Scaling 대상 추적 정책을 사용하여 처리 계층 인스턴스를 확장합니다. 
ApproximateNumberOfMessages 속성을 사용하여 확장 시기를 결정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/148818-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q113 
회사의 프로덕션 환경은 월요일부터 토요일까지 지속적으로 실행되는 Amazon EC2 
온디맨드 인스턴스로 구성되어 있습니다. 인스턴스는 일요일에 12 시간만 실행되어야 하며 
중단을 허용할 수 없습니다. 회사는 프로덕션 환경의 비용을 최적화하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 일요일에 12시간만 실행되는 EC2 인스턴스에 대해 예약된 예약 인스턴스를 구매합니다. 
월요일부터 토요일까지 지속적으로 실행되는 EC2 인스턴스에 대해 표준 예약 인스턴스를 
구매합니다. 
B. 일요일에 12 시간만 실행되는 EC2 인스턴스에 대해 변환 가능한 예약 인스턴스를 
구매합니다. 월요일부터 토요일까지 지속적으로 실행되는 EC2 인스턴스에 대해 표준 예약 
인스턴스를 구매합니다. 
C. 일요일에 12 시간만 실행되는 EC2 인스턴스에 대해 스팟 인스턴스를 사용합니다. 
월요일부터 토요일까지 지속적으로 실행되는 EC2 인스턴스에 대해 표준 예약 인스턴스를 
구매합니다. 
D. 일요일에 12 시간만 실행되는 EC2 인스턴스에 대해 스팟 인스턴스를 사용합니다. 
월요일부터 토요일까지 지속적으로 실행되는 EC2 인스턴스에 대해 Convertible Reserved 
Instances 를 구매하세요. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/148819-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q114 
디지털 이미지 처리 회사가 온프레미스 모놀리식 애플리케이션을 AWS 클라우드로 
마이그레이션하려고 합니다. 이 회사는 수천 개의 이미지를 처리하고 처리 워크플로의 
일부로 대용량 파일을 생성합니다. 
이 회사는 증가하는 이미지 처리 작업을 관리할 솔루션이 필요합니다. 이 솔루션은 또한 
이미지 처리 워크플로의 수동 작업을 줄여야 합니다. 이 회사는 솔루션의 기본 인프라를 
관리하고 싶어하지 않습니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Amazon EC2 Spot Instances 와 함께 Amazon Elastic Container Service(Amazon ECS)를 
사용하여 이미지를 처리합니다. Amazon Simple Queue Service(Amazon SQS)를 구성하여 
워크플로를 조정합니다. 처리된 파일을 Amazon Elastic File System(Amazon EFS)에 
저장합니다. 
B. AWS Batch 작업을 사용하여 이미지를 처리합니다. AWS Step Functions 를 사용하여 
워크플로를 조정합니다. 처리된 파일을 Amazon S3 버킷에 저장합니다. 
C. AWS Lambda 함수와 Amazon EC2 Spot Instances 를 사용하여 이미지를 처리합니다. 
처리된 파일을 Amazon FSx 에 저장합니다. 
D. 이미지를 처리하기 위해 Amazon EC2 인스턴스 그룹을 배포합니다. AWS Step 
Functions 를 사용하여 워크플로를 조정합니다. 처리된 파일을 Amazon Elastic Block 
Store(Amazon EBS) 볼륨에 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148820-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q115 
한 회사의 이미지 호스팅 웹사이트는 전 세계 사용자에게 모바일 기기에서 이미지를 업로드, 
보기, 다운로드할 수 있는 기능을 제공합니다. 이 회사는 현재 Amazon S3 버킷에서 정적 
웹사이트를 호스팅하고 있습니다. 
웹사이트의 인기가 높아짐에 따라 웹사이트 성능이 저하되었습니다. 사용자는 이미지를 
업로드하고 다운로드할 때 지연 문제가 발생한다고 보고했습니다. 
이 회사는 웹사이트의 성능을 개선해야 합니다. 
어떤 솔루션이 최소한의 구현 노력으로 이러한 요구 사항을 충족할 수 있을까요? 
A. S3 버킷에 Amazon CloudFront 배포를 구성하여 다운로드 성능을 개선합니다. S3 
Transfer Acceleration 을 활성화하여 업로드 성능을 개선합니다. 
B. 여러 AWS 리전에서 적절한 크기의 Amazon EC2 인스턴스를 구성합니다. 
애플리케이션을 EC2 인스턴스로 마이그레이션합니다. Application Load Balancer 를 
사용하여 웹사이트 트래픽을 EC2 인스턴스 간에 균등하게 분산합니다. AWS Global 
Accelerator 를 구성하여 지연 시간이 짧은 글로벌 수요를 처리합니다. 
C. S3 버킷을 원본으로 사용하는 Amazon CloudFront 배포를 구성하여 다운로드 성능을 
개선합니다. 업로드 성능을 개선하기 위해 CloudFront 를 사용하여 이미지를 업로드하도록 
애플리케이션을 구성합니다. 여러 AWS 리전에 S3 버킷을 만듭니다. 사용자 위치에 따라 
사용자 데이터를 복제하도록 버킷에 대한 복제 규칙을 구성합니다. 각 사용자 위치에 가장 
가까운 S3 버킷으로 다운로드를 리디렉션합니다. 
D. 네트워크 성능을 개선하기 위해 S3 버킷에 대한 AWS Global Accelerator 를 구성합니다. 
애플리케이션이 S3 버킷 대신 Global Accelerator 를 사용하도록 엔드포인트를 만듭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/148821-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q116 
한 회사가 VPC 의 애플리케이션 로드 밸런서(ALB) 뒤에 있는 프라이빗 서브넷에서 
애플리케이션을 실행합니다. VPC 에는 NAT 게이트웨이와 인터넷 게이트웨이가 있습니다. 
애플리케이션은 Amazon S3 API 를 호출하여 객체를 저장합니다. 
회사의 보안 정책에 따라 애플리케이션의 트래픽은 인터넷을 통과해서는 안 됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. S3 인터페이스 엔드포인트를 구성합니다. Amazon S3 로의 아웃바운드 트래픽을 허용하는 
보안 그룹을 만듭니다. 
B. S3 게이트웨이 엔드포인트를 구성합니다. 엔드포인트를 사용하도록 VPC 경로 테이블을 
업데이트합니다. 
C. NAT 게이트웨이에 할당된 Elastic IP 주소에서 트래픽을 허용하도록 S3 버킷 정책을 
구성합니다. 
D. 레거시 애플리케이션이 배포된 동일한 서브넷에 두 번째 NAT 게이트웨이를 만듭니다. 
두 번째 NAT 게이트웨이를 사용하도록 VPC 경로 테이블을 업데이트합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148824-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q117 
한 회사에 Amazon EC2 인스턴스의 Amazon Elastic Kubernetes Service(Amazon EKS) 
클러스터에서 실행되는 애플리케이션이 있습니다. 이 애플리케이션에는 Amazon 
DynamoDB 를 사용하는 UI 와 애플리케이션 배포의 일부로 Amazon S3 를 사용하는 데이터 
서비스가 있습니다. 
이 회사는 UI 용 EKS Pod 가 Amazon DynamoDB 에만 액세스할 수 있고 데이터 서비스용 
EKS Pod 가 Amazon S3 에만 액세스할 수 있도록 해야 합니다. 이 회사는 AWS Identity and 
Access Management(IAM)를 사용합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 필요한 권한으로 Amazon S3 및 DynamoDB 액세스에 대한 별도의 IAM 정책을 
만듭니다. 두 IAM 정책을 EC2 인스턴스 프로필에 연결합니다. 역할 기반 액세스 
제어(RBAC)를 사용하여 해당 EKS Pod 에 대한 Amazon S3 또는 DynamoDB 액세스를 
제어합니다. 
B. 필요한 권한으로 Amazon S3 및 DynamoDB 액세스에 대한 별도의 IAM 정책을 
만듭니다. Amazon S3 IAM 정책을 데이터 서비스용 EKS Pod 에 직접 연결하고 DynamoDB 
정책을 UI 용 EKS Pod 에 연결합니다. 
C. UI 및 데이터 서비스에 대해 별도의 Kubernetes 서비스 계정을 만들어 IAM 역할을 
맡습니다. 데이터 서비스 계정에 AmazonS3FullAccess 정책을 연결하고 UI 서비스 계정에 
AmazonDynamoDBFullAccess 정책을 연결합니다. 
D. UI 및 데이터 서비스에 대해 별도의 Kubernetes 서비스 계정을 만들어 IAM 역할을 
맡습니다. 서비스 계정에 대한 IAM 역할(IRSA)을 사용하여 UI 의 EKS Pod 에 대한 액세스를 
Amazon S3 에 제공하고 데이터 서비스의 EKS Pod 에 대한 액세스를 DynamoDB 에 
제공합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/148825-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
C?? 
Q118 
회사는 보안 정책을 준수하는 방식으로 전 세계에 분산된 개발 팀에 회사의 AWS 리소스에 
대한 보안 액세스를 제공해야 합니다. 
회사는 현재 내부 인증을 위해 온프레미스 Active Directory 를 사용합니다. 회사는 AWS 
Organizations 를 사용하여 여러 프로젝트를 지원하는 여러 AWS 계정을 관리합니다. 
회사는 기존 인프라와 통합하여 중앙 집중식 ID 관리 및 액세스 제어를 제공하는 솔루션이 
필요합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할 수 있을까요? 
A. AWS Directory Service 를 설정하여 AWS 에서 AWS 관리 Microsoft Active Directory 를 
만듭니다. 온프레미스 Active Directory 와 신뢰 관계를 설정합니다. Active Directory 그룹에 
할당된 IAM 로트를 사용하여 회사의 AWS 계정 내에서 AWS 리소스에 액세스합니다. 
B. 각 개발자에 대한 IAM 사용자를 만듭니다. 각 프로젝트에 대한 각 사용자의 참여에 
따라 각 IAM 사용자의 권한을 수동으로 관리합니다. 추가 보안 계층으로 다중 요소 
인증(MFA)을 적용합니다. 
C. AWS Directory Service 에서 AD Connector 를 사용하여 온프레미스 Active Directory 에 
연결합니다. AD Connector 를 AWS IAM Identity Center 와 통합합니다. 각 AD 그룹에 특정 
AWS 계정 및 리소스에 대한 액세스 권한을 부여하기 위해 권한 집합을 구성합니다. 
D. Amazon Cognito 를 사용하여 ID 페더레이션 솔루션을 배포합니다. ID 페더레이션 
솔루션을 온프레미스 Active Directory 와 통합합니다. Amazon Cognito 를 사용하여 개발자가 
AWS 계정 및 리소스에 액세스할 수 있도록 액세스 토큰을 제공합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/148826-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Q119 
한 회사가 AWS 클라우드에서 애플리케이션을 개발하고 있습니다. 애플리케이션의 HTTP 
API 에는 Amazon API Gateway 에 게시된 중요한 정보가 포함되어 있습니다. 중요한 정보는 
회사 내부 네트워크에 속하는 신뢰할 수 있는 제한된 IP 주소에서만 액세스할 수 있어야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 미리 정의된 IP 주소 집합에 대한 액세스를 제한하기 위해 API Gateway 비공개 통합을 
설정합니다. 
B. 특별히 허용되지 않은 모든 IP 주소에 대한 액세스를 거부하는 API 에 대한 리소스 
정책을 만듭니다. 
C. 비공개 서브넷에 API 를 직접 배포합니다. 네트워크 ACL 을 만듭니다. 특정 IP 주소에서 
트래픽을 허용하는 규칙을 설정합니다. 
D. 신뢰할 수 있는 IP 주소에서만 인바운드 트래픽을 허용하도록 API Gateway 에 연결된 
보안 그룹을 수정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/148827-exam-aws-certified-sol
utions-architect-associate-saa-c03/ 
Examtopics 끝 
==================================================================== 
Q1 
회사에서 최근 마케팅 캠페인의 효과를 측정하려고 합니다. 회사는 판매 데이터의 csv 
파일에 대해 일괄 처리를 수행하고 그 결과를 1 시간에 한 번씩 Amazon S3 버킷에 
저장합니다. S3 는 페타바이트 단위의 개체입니다. 이 회사는 Amazon Athena 에서 일회성 
쿼리를 실행하여 특정 지역의 특정 날짜에 가장 인기 있는 제품을 확인합니다. 쿼리가 
실패하거나 완료되는 데 예상보다 오래 걸리는 경우가 있습니다. 
쿼리 성능과 안정성을 개선하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까? (2 개 
선택) 
A. S3 객체 크기를 128MB 미만으로 줄입니다. 
B. Amazon S3 의 날짜 및 지역별로 데이터를 분할합니다. 
C. 파일을 Amazon S3 에 큰 단일 객체로 저장합니다. 
D. Amazon Kinesis Data Analytics 를 사용하여 일괄 처리 작업의 팬으로 쿼리를 실행합니다. 
E. AWS Glue 추출, 변환 및 로드(ETL) 프로세스를 사용하여 csv 파일을 Apache Parquet 
형식으로 변환합니다. 
Answer: B, E 
설명: 
이 솔루션은 판매 데이터의 csv 파일에 대해 일괄 처리를 수행하고 그 결과를 1 시간에 한 
번씩 Amazon S3 버킷에 저장함으로써 마케팅 캠페인의 효과를 측정하는 요구 사항을 
충족합니다. AWS 듀오 ETL 프로세스는 AWS Glue 또는 AWS Data Pipeline 과 같은 
서비스를 사용하여 S3 에서 데이터를 추출하고 이를 Apache Parquet 와 같은 보다 효율적인 
형식으로 변환한 다음 S3 에 다시 로드할 수 있습니다. Apache Parquet 는 스캔되는 데이터 
양을 줄이고, 압축 비율을 개선하고, 조건자 푸시다운을 활성화하여 Athena 의 쿼리 성능과 
안정성을 향상할 수 있는 열 기반 스토리지 형식입니다. 
참고: 
https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-
athena/ 
Q2 
회사는 여러 벤더를 사용하여 Amazon S3 버킷에 저장된 디지털 자산을 배포합니다. 이 
회사는 공급업체 AWS 계정에 이러한 S3 버킷의 객체를 다운로드하는 데 필요한 최소한의 
액세스 권한이 있는지 확인하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 익명의 읽기 권한과 모든 버킷을 나열할 수 있는 권한이 있는 버킷 정책을 설계합니다. 
B. 사용자에게 읽기 전용 액세스 권한을 부여하는 버킷 정책을 설계합니다. IAM 엔터티를 
보안 주체로 지정합니다. 
C. IAM 역할에 대해 지정된 읽기 전용 액세스 정책이 있는 교차 계정 IAM 역할을 
생성합니다. 
D. 공급업체 사용자에게 읽기 전용 액세스 권한을 부여하는 사용자 정책 및 공급업체 
사용자 그룹을 만듭니다. 
Answer: C 
설명: 
교차 계정 IAM 역할은 한 AWS 계정의 사용자에게 다른 AWS 계정의 리소스에 대한 
액세스 권한을 부여하는 방법입니다. 교차 계정 IAM 역할에는 읽기 전용 액세스 정책이 
연결되어 있어 사용자가 객체를 수정하거나 삭제하지 않고도 S3 버킷에서 객체를 
다운로드할 수 있습니다. 교차 계정 IAM 역할은 또한 각 계정에서 여러 IAM 사용자 및 
정책을 관리하는 운영 오버헤드를 줄입니다. 교차 계정 IAM 역할은 질문의 모든 요구 
사항을 충족하지만 다른 옵션은 그렇지 않습니다. 
참조: 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-walkthroughs-mana
ging-accessexample2.html 
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.h
tml 
Q3 
솔루션 설계자는 회사의 고객 대면 애플리케이션을 설계하고 있습니다. 애플리케이션의 
데이터베이스는 일년 내내 명확하게 정의된 액세스 패턴을 가지며 연중 시간에 따라 다양한 
읽기 및 쓰기 횟수를 갖게 됩니다. 회사는 데이터베이스에 대한 감사 기록을 7 일 동안 
보관해야 합니다. RPO(복구 지점 목표)는 5 시간 미만이어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Auto Scaling 과 함께 Amazon DynamoDB 를 사용하십시오. 온디맨드 백업 및 Amazon 
DynamoDB Streams 를 사용합니다. 
B. Amazon Redshift 를 사용합니다. 동시성 확장을 구성합니다. 감사 로깅을 활성화합니다. 
4 시간마다 데이터베이스 스냅샷을 수행합니다. 
C. 프로비저닝된 IOPS 와 함께 Amazon RDS 를 사용합니다. 데이터베이스 감사 매개변수 
활성화 5 시간마다 데이터베이스 스냅샷을 수행합니다. 
D. Auto Scaling 과 함께 Amazon Aurora MySQL 을 사용합니다. 데이터베이스 감사 
매개변수를 활성화하십시오. 
Answer: D 
설명: 
A(X) : DynamoDB Streams 는 수정/변경 사항을 최대 24 시간까지밖에 로그에 저장할 수 
없음. 이를 변경할 수도 없음. 
DynamoDB Streams 의 모든 데이터는 24 시간 동안 유지됩니다. 특정 테이블에 대한 지난 
24 시간 동안의 활동을 조회하고 분석할 수 있습니다. 그러나 24 시간이 지난 데이터는 
언제든 트리밍(제거)될 수 있습니다....기존 스트림을 수동으로 삭제하기 위한 메커니즘은 
없습니다. 보유 제한이 만료(24 시간)될 때까지 기다려야 하며, 모든 스트림 레코드가 
삭제됩니다. 
https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/Streams.ht
ml 
B(X) : Redshift 는 데이터베이스 서비스가 아니라 데이터 웨어하우스 서비스. 
C(X) : 프로비저닝되었으므로 확장성이 떨어짐. 
D(O) : Amazon Aurora MySQL 은 기본적으로 Auto Scaling 기능이 켜져있음. 복구 시간도 
매우 짧음. 데이터베이스 감사 로그 또한 다운로드 가능 
Aurora 는 단일 AWS 리전에서 다중 가용 영역에 걸쳐 DB 클러스터에 데이터 복사본을 
저장합니다. DB 클러스터에 Aurora 복제본이 하나 이상인 경우에는 장애가 발생하더라도 
Aurora 복제본이 기본 인스턴스로 승격됩니다. 이 실패 이벤트로 인해 예외적으로 실패하는 
읽기 및 쓰기 작업 동안 짧은 중단이 발생합니다. 하지만, 일반적인 서비스 복구 시간은 
120 초 미만이지만 대부분 60 초 미만에 복원됩니다. 
https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/Concepts.Auror
aHighAvailability.html#Concepts.AuroraHighAvailability.Data 
Amazon Aurora MySQL 의 고성능 고급 감사 기능을 사용하여 데이터베이스 활동을 감사할 
수 있습니다. 이를 위해 여러 DB 클러스터 파라미터를 설정하여 감사 로그 수집을 
활성화합니다. 콘솔을 사용하여 감사 로그를 확인하고 다운로드할 수 있습니다. 
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Auditin
g.html 
Q4 
회사에서 고성능 컴퓨팅 및 인공 지능을 사용하여 사기 방지 및 감지 기술을 개선하려고 
합니다. 회사는 가능한 한 빨리 단일 워크로드를 완료하기 위해 분산 처리가 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Kubernetes Service(Amazon EKS) 및 여러 컨테이너를 사용합니다. 
B. AWS ParallelCluster 및 MPI(Message Passing Interface) 라이브러리를 사용합니다. 
C. Application Load Balancer 및 Amazon EC2 인스턴스를 사용합니다. 
D. AWS Lambda 함수를 사용합니다. 
Answer: B 
설명 
AWS ParallelCluster 는 AWS 에서 고성능 컴퓨팅(HPC) 클러스터를 생성하고 관리할 수 있는 
서비스입니다. 여러 EC2 인스턴스에서 분산 워크로드를 실행할 수 있는 AWS Batch 를 
비롯한 여러 스케줄러를 지원합니다. 
MPI 는 병렬 컴퓨팅에서 프로세스 간 메시지 전달을 위한 표준입니다. 데이터 송수신, 
프로세스 동기화, 통신 그룹 관리 등의 기능을 제공합니다. 
AWS ParallelCluster 및 MPI 라이브러리를 사용하면 다음과 같은 이점을 얻을 수 있습니다. 
* 인스턴스 유형, 노드 수, 네트워크 구성 및 스토리지 옵션과 같은 특정 요구 사항을 
충족하는 HPC 클러스터를 쉽게 생성하고 구성할 수 있습니다. 
* AWS 의 확장성과 탄력성을 활용하여 서버 프로비저닝이나 관리에 대한 걱정 없이 대규모 
병렬 워크로드를 실행할 수 있습니다. 
* MPI 라이브러리를 사용하여 프로세스 간 통신 및 데이터 교환을 활성화하여 병렬 
애플리케이션의 성능과 효율성을 최적화할 수 있습니다. 
* Open MPI, Intel MPI 및 MPICH 와 같이 AWS ParallelCluster 와 호환되는 다양한 MPI 구현 
중에서 선택할 수 있습니다. 
Q5 
회사에는 다양한 AWS 리전의 다양한 AWS 계정에 분산된 프로덕션 워크로드가 있습니다. 
회사는 AWS Cost Explorer 를 사용하여 비용과 사용량을 지속적으로 모니터링합니다. 
회사는 워크로드의 비용 및 사용량 지출이 비정상적인 경우 알림을 받기를 원합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 프로덕션 워크로드가 실행 중인 AWS 계정에서 AWS Cost Management 콘솔의 Cost 
Explorer 를 사용하여 연결 계정 예산을 생성합니다. 
B. 프로덕션 워크로드가 실행 중인 AWS 계정에서 AWS 비용 관리 콘솔의 AWS 비용 이상 
탐지를 사용하여 연결된 계정 모니터를 생성합니다. 
C. 프로덕션 워크로드가 실행 중인 AWS 계정에서 AWS Cost Management 콘솔의 비용 
이상 탐지를 사용하여 비용 및 사용 보고서를 생성합니다. 
D. 매주 보고서를 작성하고 이메일 메시지를 보내 회사에 알립니다. 
E. 필수 임계값으로 구독을 생성하고 주간 요약을 사용하여 회사에 알립니다. 
Answer: B, E 
설명: 
AWS 비용 이상 탐지를 사용하면 AWS 리소스의 비용과 사용량을 추적하고 비정상적인 
지출 패턴이 있을 때 경고를 보내는 모니터를 생성할 수 있습니다. AWS 서비스, 계정, 태그 
또는 비용 범주와 같은 다양한 차원을 기반으로 모니터를 생성할 수 있습니다. 또한 이상이 
감지되면 이메일이나 Amazon SNS 로 알려주는 알림 구독을 생성할 수도 있습니다. 경고의 
임계값과 빈도를 지정하고 이상 현상에 대한 주간 요약을 수신하도록 선택할 수 있습니다. 
Q6 
회사에 다양한 런타임으로 AWS Lambda 함수를 분당 최대 800 번 호출하는 이벤트 기반 
애플리케이션이 있습니다. Lambda 함수는 Amazon Aurora MySQL DB 클러스터에 저장된 
데이터에 액세스합니다. 회사는 사용자 활동이 증가함에 따라 연결 시간 초과를 인지하고 
있습니다. 데이터베이스에 과부하가 걸린 흔적이 없습니다. CPU, 메모리 및 디스크 액세스 
메트릭이 모두 낮습니다. 
어떤 솔루션이 운영 오버헤드를 최소화하면서 이 문제를 해결할 것입니까? 
A. 더 많은 연결을 처리하려면 Aurora MySQL 노드의 크기를 조정하십시오. 데이터베이스 
연결 시도에 대해 Lambda 함수에서 재시도 논리를 구성합니다. 
B. 데이터베이스에서 일반적으로 읽는 항목을 캐시하도록 읽기용 Amazon ElastiCache 를 
설정합니다. 읽기를 위해 ElastiCache 에 연결하도록 Lambda 함수를 구성합니다. 
C. Aurora 복제본을 리더 노드로 추가합니다. 작성기 엔드포인트가 아닌 DB 클러스터의 
판독기 엔드포인트에 연결하도록 Lambda 함수를 구성합니다. 
D. Amazon RDS 프록시를 사용하여 프록시를 생성합니다. DB 클러스터를 대상 
데이터베이스로 설정 DB 클러스터가 아닌 프록시에 연결하도록 Lambda 함수를 
구성합니다. 
Answer: D 
설명 1: 
A(X) : 노드 크기 조절은 아무 상관 없음. 
B(X) : 데이터베이스 자체에 부하가 걸리는 것이 아니므로 읽기 부하를 분산하는 
ElastiCache 는 솔루션으로 적합하지 않음. 
C(X) : 데이터베이스 자체에 부하가 걸리는 것이 아니므로 읽기 부하를 분산하는 복제본은 
솔루션으로 적합하지 않음. 
D(O) : RDS 프록시를 사용하여 예기치 않은 데이터베이스 트래픽 급증을 처리할 수 
있습니다. 급증을 처리하지 않으면 연결 초과 구독 또는 빠른 속도의 새 연결 생성으로 
인한 문제가 발생할 수 있습니다. RDS 프록시는 데이터베이스 연결 풀을 설정하고 이 
풀에서 연결을 재사용합니다.  
https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/rds-proxy.html 
설명 2: 
1. 데이터베이스가 과부하의 징후를 보이지 않습니다. CPU, 메모리 및 디스크 액세스 
메트릭은 모두 낮음==>A 및 C 출력입니다. 노드 인스턴스를 추가하거나 읽기 전용 
복제본을 추가할 수는 없습니다. 
2. "최소 운영 오버헤드"==>B 출력, b 는 람다를 구성해야 하기 때문입니다. 
3. ROS 프록시: 자주 사용되지 않는 연결을 공유합니다. 장애 조치를 통한 고가용성. 
효율성 향상==>프록시는 장애 조치를 활용하여 시간 초과 rds 인스턴스에서 정상 rds 
인스턴스로 트래픽을 리디렉션할 수 있습니다. 그래서 D 가 맞습니다. 
Q7 
솔루션 설계자가 다중 서브넷 VPC 아키텍처를 개발 중입니다. 솔루션은 2 개의 가용 영역에 
있는 6 개의 서브넷으로 구성됩니다. 서브넷은 공용, 사설 및 데이터베이스 전용으로 
정의됩니다. 프라이빗 서브넷에서 실행되는 Amazon EC2 인스턴스만 데이터베이스에 
액세스할 수 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 now route table 을 생성합니다. 
라우팅 테이블을 데이터베이스 서브넷에 연결합니다. 
B. 퍼블릭 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 거부하는 보안 
그룹을 생성합니다. 보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다. 
C. 프라이빗 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 허용하는 보안 
그룹을 생성합니다. 보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다. 
D. 퍼블릭 서브넷과 프라이빗 서브넷 사이에 새로운 피어링 연결을 생성합니다. 프라이빗 
서브넷과 데이터베이스 서브넷 간에 다른 피어링 연결을 만듭니다. 
Answer: C 
설명 1: 
전체적인 프로세스는 퍼블릭 서브넷 -> 프라이빗 서브넷(EC2 인스턴스가 있는 곳) -> 
데이터베이스 전용 서브넷. 
데이터베이스를 구동하는 인스턴스의 보안은 Security Group 이 담당. Security Group 은 
허용 설정만 가능하고 차단 설정은 불가능하며, 기본적으로 모든 인바운드 트래픽을 차단. 
따라서 허용할 곳만 등록시켜두면 나머지는 자동으로 다 차단하는 셈. 
보안 그룹은 연결된 리소스에 도달하고 나갈 수 있는 트래픽을 제어합니다. 예를 들어 보안 
그룹을 EC2 인스턴스와 연결하면 인스턴스에 대한 인바운드 및 아웃바운드 트래픽을 
제어합니다. 허용 규칙을 지정할 수 있지만 거부 규칙은 지정할 수 없습니다. 보안 그룹을 
처음 만들 때 인바운드 규칙이 없습니다. 따라서 보안 그룹에 인바운드 규칙을 추가하기 
전에는 어떤 인바운드 트래픽도 허용되지 않습니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/VPC_SecurityGroups.html 
설명 2: 
보안 그룹은 상태 저장입니다. 모든 인바운드 트래픽은 기본적으로 차단됩니다. 트래픽 
인바운드를 허용하는 인바운드 규칙을 생성하면 해당 트래픽이 자동으로 다시 백아웃됩니다. 
보안 그룹을 사용하여 특정 IP 주소를 차단할 수 없습니다(대신 네트워크 액세스 제어 목록 
사용). 
허용 규칙은 지정할 수 있지만 거부 규칙은 지정할 수 없습니다. 보안 그룹을 처음 
생성하면 인바운드 규칙이 없습니다. 따라서 인바운드 규칙을 보안 그룹에 추가할 때까지 
다른 호스트에서 시작하여 인스턴스로 들어오는 인바운드 트래픽은 허용되지 않습니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-security-groups.html#VPC
SecurityGroups 
Q8 
한 회사는 사용자 디바이스에서 센서 데이터를 수집하는 AWS 에 3 계층 환경을 갖추고 
있습니다. 트래픽은 NIB(Network Load Balancer)를 거쳐 웹 계층의 Amazon EC2 
인스턴스로, 마지막으로 데이터베이스 호출을 수행하는 애플리케이션 계층의 EC2 
인스턴스로 이동합니다. 웹 계층으로 전송되는 데이터의 보안을 향상하려면 솔루션 
설계자가 무엇을 해야 합니까? 
A. TLS 수신기를 구성하고 NLB 에 서버 인증서를 추가합니다. 
B. AWS Shield Advanced 를 구성하고 NLB 에서 AWS WAF 를 활성화합니다. 
C. 로드 밸런서를 Application Load Balancer 로 변경하고 여기에 AWS WAF 를 연결합니다. 
D. AWS KMS(AWS Key Management Service)를 사용하여 EC2 인스턴스에서 Amazon 
Elastic Block Store(Amazon EBS) 볼륨을 암호화합니다. 
Answer: A 
설명: 
A: 전송 중인 데이터를 어떻게 보호합니까? 
모범 사례: 
보안 키 및 인증서 관리 구현: AWS Certificate Manager(ACM)와 같은 인증서 관리 서비스를 
사용하는 등 엄격한 액세스 제어를 적용하면서 암호화 키와 인증서를 안전하게 저장하고 
적절한 시간 간격으로 교체합니다. 
전송 중 암호화 적용: 조직, 법률 및 규정 준수 요구 사항을 충족하는 데 도움이 되는 
적절한 표준 및 권장 사항을 기반으로 정의된 암호화 요구 사항을 적용합니다. 
의도하지 않은 데이터 액세스 자동 감지: GuardDuty 와 같은 도구를 사용하여 데이터 분류 
수준에 따라 정의된 경계 외부로 데이터를 이동하려는 시도를 자동으로 감지합니다. 예를 
들어 DNS 프로토콜을 사용하여 알 수 없거나 신뢰할 수 없는 네트워크에 데이터를 
복사하는 트로이 목마를 감지합니다. . 
네트워크 통신 인증: TLS(전송 계층 보안) 또는 IPsec 과 같은 인증을 지원하는 프로토콜을 
사용하여 통신 ID 를 확인합니다. 
https://wa.aws.amazon.com/wat.question.SEC_9.en.html 
Q9 
IoT 회사가 사용자의 수면에 대한 데이터를 수집하는 센서가 있는 매트리스를 출시합니다. 
센서는 Amazon S3 버킷으로 데이터를 전송합니다. 센서는 매일 밤 각 매트리스에 대해 약 
2MB 의 데이터를 수집합니다. 회사는 각 매트리스에 대한 데이터를 처리하고 요약해야 
합니다. 결과는 가능한 한 빨리 제공되어야 하며 데이터 처리에는 1GB 의 메모리가 
필요하며 30 초 이내에 완료됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Scalajob 과 함께 AWS Glue 를 사용합니다. 
B. Apache Spark 스크립트와 함께 Amazon EMR 을 사용합니다. 
C. Python 스크립트와 함께 AWS Lambda 를 사용합니다. 
D. PySpark 작업과 함께 AWS Glue 를 사용합니다. 
Answer: C 
설명 
AWS Lambda 는 호출 수와 함수 실행 시간에 따라 요금을 부과합니다. 데이터 처리 작업이 
상대적으로 작기 때문에(데이터 2MB) Lambda 가 비용 효율적인 선택입니다. 인프라를 
프로비저닝하고 유지 관리할 필요 없이 실제 사용량에 대해서만 비용을 지불하면 됩니다. 
Q10 
한 회사가 여러 대륙에 걸쳐 도시의 온도, 습도, 기압 데이터를 수집합니다. 사이트당 매일 
수집되는 평균 데이터 양은 500GB 입니다. 각 사이트에는 고속 인터넷 연결이 제공됩니다. 
회사의 일기 예보 애플리케이션은 단일 지역을 기반으로 하며 매일 데이터를 분석합니다. 
이러한 모든 글로벌 사이트에서 데이터를 집계하는 가장 빠른 방법은 무엇입니까? 
A. 대상 버킷에서 Amazon S3 Transfer Acceleration 을 활성화합니다. 멀티파트 업로드를 
사용하여 사이트 데이터를 대상 버킷에 직접 업로드합니다. 
B. 가장 가까운 AWS 지역의 Amazon S3 버킷에 사이트 데이터를 업로드합니다. S3 교차 
리전 복제를 사용하여 객체를 대상 버킷에 복사합니다. 
C. 가장 가까운 AWS 리전으로 데이터를 전송하도록 매일 AWS Snowball 작업을 
예약합니다. S3 교차 리전 복제를 사용하여 객체를 대상 버킷에 복사합니다. 
D. 가장 가까운 지역의 Amazon EC2 인스턴스에 데이터를 업로드합니다. Amazon Elastic 
Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 하루에 한 번씩 EBS 스냅샷을 
찍어 중앙 리전에 복사합니다. 중앙 지역에 EBS 볼륨을 복원하고 매일 데이터 분석을 
실행합니다. 
Answer: A 
설명: 
다음을 포함하여 다양한 이유로 버킷에서 Transfer Acceleration 을 사용하려고 할 수 
있습니다. 
전 세계에서 중앙 집중식 버킷에 업로드하는 고객이 있습니다. 대륙 전체에 걸쳐 
정기적으로 기가바이트에서 테라바이트에 이르는 데이터를 전송합니다. AmazonS3 에 
업로드할 때 인터넷을 통해 사용 가능한 대역폭을 모두 활용할 수 없습니다. 
Amazon S3 Transfer Acceleration 은 대규모 객체의 장거리 전송 시 Amazon S3 와의 콘텐츠 
전송 속도를 50~500%까지 높일 수 있습니다. 광범위한 사용자가 있는 웹 또는 모바일 
애플리케이션을 보유하고 있거나 애플리케이션이 멀리 떨어진 곳에서 호스팅되는 고객 S3 
버킷은 인터넷을 통해 길고 가변적인 업로드 및 다운로드 속도를 경험할 수 있습니다. 
참고: 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/transfer-acceleration.ht
ml 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/mpuoverview.html 
Q11 
회사의 주문 시스템은 클라이언트의 요청을 Amazon EC2 인스턴스로 보냅니다. EC2 
인스턴스는 주문을 처리하고 남성은 Amazon RDS 의 데이터베이스에 주문을 저장합니다. 
사용자들은 시스템에 오류가 발생하면 주문을 다시 처리해야 한다고 보고합니다. 회사는 
시스템 중단이 발생할 경우 자동으로 주문을 처리할 수 있는 탄력적인 솔루션을 원합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. EC2 인스턴스를 Auto Scaling 그룹으로 이동 Amazon Elastic Container Service(Amazon 
ECS) 작업을 대상으로 하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 
생성합니다. 
B. EC2 인스턴스를 ALB(Application Load Balancer) 뒤의 Auto Scaling 그룹으로 
이동합니다. ALB 엔드포인트에 메시지를 보내도록 주문 시스템을 업데이트합니다. 
C. EC2 인스턴스를 Auto Scaling 그룹으로 이동합니다. Amazon Simple Queue 
Service(Amazon SQS) 대기열로 메시지를 보내도록 주문 시스템을 구성합니다. 대기열의 
메시지를 사용하도록 EC2 인스턴스를 구성합니다. 
D. Amazon Simple 알림 서비스(Amazon SNS) 주제를 생성합니다. AWS Lambda 함수를 
생성하고 함수를 SNS 주제에 구독합니다. SNS 주제에 메시지를 보내도록 주문 시스템을 
구성합니다. AWS Systems Manager Run Command 를 사용하여 메시지를 처리하도록 EC2 
인스턴스에 명령을 보냅니다. 
Answer: C 
설명: 
시스템 중단 시 자동으로 주문을 처리할 수 있는 탄력적인 솔루션을 보유해야 한다는 
회사의 요구 사항을 충족하려면 솔루션 설계자는 내결함성 아키텍처를 구현해야 합니다. 
주어진 시나리오에 따라 잠재적인 해결책은 EC2 인스턴스를 Auto Scaling 그룹으로 
이동하고 Amazon Simple Queue Service(Amazon SQS) 대기열로 메시지를 보내도록 주문 
시스템을 구성하는 것입니다. 그러면 EC2 인스턴스가 대기열의 메시지를 사용할 수 
있습니다. 
Q12 
회사에서 1PB 온프레미스 이미지 리포지토리를 AWS 로 마이그레이션하려고 합니다. 
이미지는 서버리스 웹 애플리케이션에서 사용됩니다. 리포지토리에 저장된 이미지는 거의 
액세스되지 않지만 즉시 사용할 수 있어야 합니다. 또한 미사용 이미지를 암호화하고 
우발적인 삭제로부터 보호해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 클라이언트 측 암호화를 구현하고 이미지를 Amazon S3 Glacier 볼트에 저장합니다. 
우발적인 삭제를 방지하기 위해 볼트 잠금을 설정합니다. 
B. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스의 Amazon S3 버킷에 
이미지를 저장합니다. S3 버킷에서 버전 관리, 기본 암호화 및 MFA 삭제를 활성화합니다. 
C. Amazon FSx for Windows File Server 파일 공유에 이미지를 저장합니다. AWS Key 
Management Service(AWS KMS) 고객 마스터 키(CMK)를 사용하여 파일 공유의 이미지를 
암호화하도록 Amazon FSx 파일 공유를 구성합니다. 우발적인 삭제를 방지하려면 이미지에 
NTFS 권한 집합을 사용하십시오. 
D. Infrequent Access 스토리지 클래스의 Amazon Elastic File System(Amazon EFS) 파일 
공유에 이미지를 저장합니다. AWS Key Management Service(AWS KMS) 고객 마스터 
키(CMK)를 사용하여 파일 공유의 이미지를 암호화하도록 EFS 파일 공유를 구성합니다. 
우발적인 삭제를 방지하려면 이미지에 NFS 권한 집합을 사용하십시오. 
Answer: B 
설명: 
서버리스 웹 애플리케이션과 호환되는 온프레미스 파일 공유에 대한 탄력적이고 내구성 
있는 대체를 제공하기 때문에 이 대답은 정확합니다. Amazon S3 는 모든 양의 데이터를 
저장하고 인터넷을 통해 제공할 수 있는 완전관리형 객체 스토리지 서비스입니다. 다음 
기능을 지원합니다. 
복원력: Amazon S3 는 리전 내의 여러 가용 영역에 데이터를 저장하고 99.999999999%(11 
9)의 내구성을 제공합니다. 또한 서로 다른 AWS 리전에 있는 버킷 간에 객체를 자동 및 
비동기식으로 복사할 수 있는 교차 리전 복제를 지원합니다. 
내구성: Amazon S3 는 Amazon S3 관리형 키(SSE-S3), AWS KMS 키(SSE-KMS) 또는 고객 
제공 키(SSE-C)로 서버 측 암호화를 사용하여 유휴 데이터를 암호화합니다. 또한 
SSL/TLS 를 사용하여 전송 중 암호화를 지원합니다. 또한 Amazon S3 는 동일한 버킷에 
객체의 여러 버전을 유지하는 버전 관리 및 객체 버전을 삭제하거나 버킷의 버전 관리 
상태를 변경하기 위해 추가 인증이 필요한 MFA 삭제와 같은 데이터 보호 기능을 
제공합니다. 
성능: Amazon S3 는 정적 및 동적 웹 콘텐츠를 제공하기 위한 고성능 및 확장성을 
제공합니다. 또한 요청을 AWS 엣지 로케이션으로 라우팅하여 데이터 전송 속도를 높이는 
S3 Transfer Acceleration 및 간단한 SQL 표현식을 사용하여 객체에서 데이터의 하위 
집합만 검색할 수 있는 S3 Select 와 같은 기능을 지원합니다. 
S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스는 거의 액세스하지 
않지만 필요할 때 즉시 사용할 수 있어야 하는 이미지를 저장하는 데 적합합니다. S3 
Standard 와 동일한 높은 내구성, 처리량 및 짧은 대기 시간을 제공하지만 GB 당 스토리지 
비용은 더 낮고 요청당 비용은 더 높습니다. 
Q13 
회사는 AWS 에서 고성능 컴퓨팅(HPC) 워크로드를 실행합니다. 워크로드에는 긴밀하게 
연결된 노드 간 통신을 통해 대기 시간이 짧은 네트워크 성능과 높은 네트워크 처리량이 
필요했습니다. Amazon EC2 인스턴스는 컴퓨팅 및 스토리지 용량에 적합한 크기이며 기본 
옵션을 사용하여 시작됩니다. 
솔루션 설계자는 워크로드의 성능을 개선하기 위해 무엇을 제안해야 합니까? 
A. Amazon EC2 인스턴스를 시작하는 동안 클러스터 배치 그룹을 선택하십시오. 
B. Amazon EC2 인스턴스를 시작하는 동안 전용 인스턴스 테넌시를 선택합니다. 
C. Amazon EC2 인스턴스를 시작하는 동안 Elastic Inference 액셀러레이터를 선택합니다. 
D. Amazon EC2 인스턴스를 시작하는 동안 필요한 용량 예약을 선택합니다. 
Answer: A 
설명 
https://docs.aws.amazon.com/ko_kr/AWSCloudFormation/latest/UserGuide/aws-resource
-ec2-placementgroup.html 
"클러스터 배치 그룹은 네트워크 대기 시간이 짧고 네트워크 처리량이 높은 단일 가용 영역 
내 인스턴스의 논리적 그룹입니다." 
-> 긴밀하게 결합된 노드 = Cluster Deployment Group. 
Q14 
회사는 Amazon RDS 를 백엔드 데이터베이스로 사용하는 서버리스 애플리케이션을 AWS 에 
보유하고 있습니다. 애플리케이션에서 트래픽이 예기치 않게 갑자기 증가하는 경우가 
있습니다. 트래픽이 증가하는 동안 애플리케이션은 데이터베이스에 대한 연결을 자주 열고 
닫으므로 애플리케이션이 데이터베이스에서 오류를 수신하거나 연결이 끊어집니다. 회사는 
애플리케이션이 항상 확장 가능하고 가용성이 높은지 확인해야 합니다. 
애플리케이션에 대한 코드 변경 없이 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 서버리스 애플리케이션의 RDS 데이터베이스 옵션 그룹에서 최대 연결 수를 늘리십시오. 
B. 최대 로드 트래픽을 충족하도록 RDS DB 인스턴스의 인스턴스 크기를 늘립니다. 
C. 서버리스 애플리케이션과 Amazon RDS 간에 Amazon RDS 프록시를 배포합니다. 
D. Amazon RDS 용 예약 인스턴스를 구입하여 피크 로드 트래픽 동안 데이터베이스의 
가용성을 높입니다. 
Answer: C 
설명: 
Amazon RDS Proxy 는 애플리케이션의 확장성, 데이터베이스 장애에 대한 복원력, 보안을 
강화하는 완전 관리형 데이터베이스 프록시입니다. RDS Proxy 는 애플리케이션과 관계형 
데이터베이스 사이에 위치하여 설정된 데이터베이스 연결을 풀링하고 공유하여 
데이터베이스 효율성과 애플리케이션 확장성을 개선합니다. 또한 RDS Proxy 는 일시적인 
오류에 대한 연결 관리 및 쿼리 재시도를 처리하여 데이터베이스의 부하를 줄입니다. 
서버리스 애플리케이션과 Amazon RDS 사이에 RDS Proxy 를 배포하면 오류가 발생하거나 
연결이 끊어질 수 있는 데이터베이스 연결을 자주 열고 닫는 것을 방지할 수 있습니다. 이 
솔루션은 또한 운영 비용을 절감하고 애플리케이션의 가용성을 향상시킵니다. 
참조: 
https://aws.amazon.com/rds/proxy/ 
Q15 
회사에서는 온프레미스 데이터 세트의 보조 복사본으로 Amazon S3 를 사용하려고 합니다. 
회사는 이 사본에 액세스할 필요가 거의 없습니다. 스토리지 솔루션의 비용은 최소화되어야 
합니다. 
이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까? 
A. S3 Standard 
B. S3 Intelligent-Tiering 
C. S3 Standard -Infrequent Access(S3 Standard -IA) 
D. S3 One Zone-Infrequent Access(S3 One Zone-IA) 
Answer: D 
설명: 
S3 One Zone-IA 는 자주 액세스하지 않지만 필요할 때 빠른 액세스가 필요한 데이터용으로 
설계된 스토리지 클래스입니다. 최소 3 개의 가용 영역(AZ)에 데이터를 저장하는 다른 S3 
스토리지 클래스와 달리 S3 One Zone-IA 는 단일 AZ 에 데이터를 저장하며 S3 
Standard-IA 보다 비용이 20% 저렴합니다. 이 스토리지 클래스는 거의 액세스할 필요가 
없는 온프레미스 데이터 세트의 보조 복사본에 대한 저렴한 솔루션을 제공하므로 회사의 
요구 사항을 충족합니다. 다른 스토리지 클래스는 가격이 더 높거나 자주 액세스하지 않는 
데이터에 적합하지 않습니다. 
참고: 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-class-intro.html 
Q16 
회사가 AWS Business Support 플랜에 가입되어 있습니다. 규정 준수 규칙에 따라 회사는 
배포를 진행하기 전에 AWS 인프라 상태를 확인해야 합니다. 회사에는 새로운 배포를 
시작할 때 인프라 상태를 확인하기 위한 프로그래밍 방식의 자동화된 방법이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 각 배포를 시작할 때 AWS Trusted Advisor API 를 사용하십시오. API 가 문제를 반환하는 
경우 모든 새 배포를 일시 중지합니다. 
B. 각 배포를 시작할 때 AWS 상태 API 를 사용하십시오. API 가 문제를 반환하는 경우 모든 
새 배포를 일시 중지합니다. 
C. 각 배포 시작 시 AWS Support API 를 쿼리합니다. API 가 미해결 문제를 반환하는 경우 
모든 새 배포를 일시 중지합니다. 
D. 배포에 앞서 각 워크로드에 API 호출을 보냅니다. API 호출이 실패하면 배포를 일시 
중지합니다. 
Answer: B 
설명: 
AWS 상태 API 는 AWS Personal Health Dashboard 에 표시되는 AWS 상태 정보에 대한 
프로그래밍 방식의 액세스를 제공합니다. API 작업을 사용하여 AWS 서비스 및 리소스에 
영향을 미치는 AWS 상태 이벤트에 대한 정보를 얻을 수 있습니다. API 를 사용하여 조직의 
상태 기반 통찰력을 활성화하거나 비활성화할 수도 있습니다. 각 배포 시작 시 AWS 상태 
API 를 사용하여 AWS 인프라 상태를 확인하고 API 가 문제를 반환하는 경우 모든 새 
배포를 일시 중지할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/health/latest/APIReference/Welcome.html 
Q17 
회사는 애플리케이션과 함께 Amazon Aurora PostgreSQL 프로비저닝 클러스터를 
사용합니다. 애플리케이션의 최대 트래픽은 30 분에서 몇 시간 동안 하루에 여러 번 
발생합니다. 
애플리케이션의 최대 트래픽을 처리하기 위해 데이터베이스 용량이 프로비저닝되었지만 
피크가 아닌 시간 동안 데이터베이스에서 용량이 낭비되었습니다. 회사는 데이터베이스 
비용을 절감하려고 합니다. 
최소한의 운영 노력으로 이러한 요구 사항을 충족할 수 있는 솔루션은 무엇입니까? 
A. 데이터베이스 활용도를 모니터링하려면 Amazon CloudWatch 경보를 설정하십시오. 
트래픽 양에 따라 데이터베이스 용량을 확장하거나 축소합니다. 
B. 데이터베이스를 Auto Scaling 그룹의 Amazon EC2 인스턴스로 마이그레이션합니다. 
트래픽 양에 따라 인스턴스 수를 늘리거나 줄입니다. 
C. 데이터베이스를 Amazon Aurora Serverless DB 클러스터로 마이그레이션하여 트래픽 
양에 따라 용량을 확장하거나 축소합니다. 
D. 매일 시작 시 필요한 데이터베이스 용량을 프로비저닝하도록 AWS Lambda 함수를 
예약합니다. 하루가 끝날 때마다 용량을 줄이도록 다른 Lambda 기능을 예약하십시오. 
Answer: C 
설명: 
* 요구 사항 분석: 데이터베이스는 하루에 여러 번 피크 트래픽을 경험하지만 피크가 아닌 
시간에는 용량이 낭비됩니다. 목표는 최소한의 운영 노력으로 비용을 줄이는 것입니다. 
* Aurora Serverless 개요: Aurora Serverless 는 현재 수요에 따라 데이터베이스 용량을 
자동으로 조정하여 피크 시간대에는 확장하고 피크가 아닌 시간에는 축소합니다. 
* 비용 효율성: Aurora Serverless 는 사용한 용량에 대해서만 비용을 청구하므로 피크 
트래픽에 대한 프로비저닝보다 비용 효율적입니다. 
* 운영 효율성: Aurora Serverless 는 용량 관리를 위해 Lambda 기능을 수동으로 
조정하거나 예약할 필요가 없습니다. 
* 구현: 프로비저닝된 Aurora PostgreSQL 클러스터의 데이터베이스를 Aurora Serverless 
클러스터로 마이그레이션합니다. 
Q18 
한 회사에서 테스트 환경에서 애플리케이션에 AWS CloudFormatlon 스택을 사용하려고 
합니다. 이 회사는 퍼블릭 액세스를 차단하는 Amazon S3 버킷에 CloudFormation 템플릿을 
저장합니다. 이 회사는 테스트 환경을 만들기 위한 특정 사용자 요청에 따라 S3 버킷의 
템플릿에 대한 CloudFormation 액세스 권한을 부여하려고 합니다. 솔루션은 보안 모범 
사례를 따라야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon S3 용 게이트웨이 VPC 엔드포인트를 생성합니다. S3 객체 URL 을 사용하도록 
CloudFormation 스택을 구성합니다. 
B. S3 버킷을 대상으로 하는 Amazon API Gateway REST API 를 생성합니다. API 게이트웨이 
URL 을 사용하도록 CloudFormat10n 스택을 구성합니다. 
C. 템플릿 객체에 대해 미리 서명된 URL 을 생성합니다. 미리 서명된 URL 을 사용하도록 
CloudFormation 스택을 구성합니다. 
D. S3 버킷의 템플릿 객체에 대한 공개 액세스를 허용합니다. 테스트 환경이 생성된 후 
공개 접근을 차단합니다. 
Answer: C 
설명: 
이를 통해 CloudFormation 은 공개 액세스 권한을 부여하거나 추가 리소스를 생성하지 
않고도 S3 버킷의 템플릿에 액세스할 수 있습니다. 미리 서명된 URL 은 객체에 액세스할 
권한이 있는 IAM 사용자 또는 역할의 액세스 키로 서명된 URL 입니다. 미리 서명된 URL 은 
이를 수신하는 누구나 사용할 수 있지만 지정된 시간이 지나면 만료됩니다. 템플릿 객체에 
대해 미리 서명된 URL 을 생성하고 이를 사용하도록 CloudFormation 스택을 구성함으로써 
회사는 특정 사용자 요청에 따라 템플릿에 대한 CloudFormation 액세스 권한을 부여하고 
보안 모범 사례를 따를 수 있습니다. 
Q19 
한 회사가 여러 AWS 계정에서 중앙 계정의 Amazon S3 버킷으로 AWS CloudTrail 로그를 
보냅니다. 회사는 CloudTrail 로그를 보관해야 합니다. 또한 회사는 언제든지 CloudTrail 
로그를 쿼리할 수 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 중앙 집중식 계정의 CloudTraiI 이벤트 기록을 사용하여 Amazon Athena 테이블을 
생성합니다. Athena 에서 CloudTrail 로그를 쿼리합니다. 
B. CloudTrail 로그를 관리하도록 Amazon Neptune 인스턴스를 구성합니다. Neptune 에서 
CloudTraiI 로그를 쿼리합니다. 
C. 로그를 Amazon DynamoDB 테이블로 보내도록 CloudTrail 을 구성합니다. Amazon 
QulCkSight 에서 대시보드를 생성하여 테이블의 로그를 쿼리합니다. 
D. Amazon Athena 를 사용하여 Athena 노트북을 생성합니다. 로그를 노트북으로 보내도록 
CloudTrail 을 구성합니다. Athena 에서 쿼리를 실행합니다. 
Answer: A 
설명: 
이를 통해 회사는 CloudTrail 로그를 유지하고 언제든지 쿼리할 수 있습니다. 회사는 중앙 
집중식 계정의 CloudTrail 이벤트 기록을 사용하여 여러 AWS 계정의 최근 API 활동을 보고, 
필터링하고, 다운로드할 수 있습니다. CloudTrail 이벤트 기록에서 Amazon Athena 테이블을 
생성함으로써 회사는 표준 SQL 을 사용하여 S3 의 데이터를 쉽게 분석할 수 있는 서버리스 
대화형 쿼리 서비스를 사용할 수 있습니다. Athena 에서 CloudTrail 로그를 쿼리함으로써 
회사는 사용자 활동 및 리소스 변경 사항에 대한 통찰력을 얻을 수 있습니다. 
Q20 
한 기업에서 CompanyConfidential Amazon S3 버킷에 대한 액세스 권한이 없어야 하는 새 
클라우드 엔지니어를 모집했습니다. 클라우드 엔지니어는 AdminTools 라는 S3 버킷에 대한 
읽기 및 쓰기 권한이 있어야 합니다. 
어떤 IAM 정책이 이러한 기준을 충족합니까? 
A. 
B.  
C.  
D.  
Answer: A 
설명: 
A(O) : arn:aws:s3:::AdminTools 는 버킷 자체를 의미. arn:aws:s3:::AdminTools/* 는 버킷 
내 모든 객체를 의미 
다음은 특정 Amazon S3 버킷 내에 포함된 모든 항목을 나타낸 예제입니다. 이하의 내용 
참고. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_elements_r
esource.html 
B(X) : CompanyConfidention 버킷에 권한이 없어야 하는데 s3:ListBucket 권한이 있으므로 
오답. 
C(X) : AdminTools 버킷에 s3:ListBucket 권한이 있어야 하는데 없으므로 오답. 
s3:ListBucket 권한이 없이 읽고 쓰는 권한만 가지는 것은 무의미. 아래 링크 참고. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_examples_s
3_rw-bucket.html 
D(X) : Allow, Deny 에 모두 AdminTools/*가 등록되어있으므로 오답. Deny 문은 Allow 문보다 
우선시 되기 때문. 
정책이 Allow 설명문과 Deny 설명문을 포함한 요청에 적용된다면 Deny 설명문은 Allow 
설명문에 우선합니다. 이 요청은 명시적으로 거부됩니다. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_evaluation-
logic.html 
Q21 
회사는 AWS 에서 호스팅되는 서비스 솔루션으로 고성능 컴퓨팅(HPC) 워크로드를 구축할 
계획입니다. 16 개의 Amazon EC2 Linux 인스턴스 그룹에는 노드 간 통신에 가장 낮은 지연 
시간이 필요합니다. 인스턴스에는 고성능 스토리지를 위한 공유 블록 장치 볼륨도 
필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 클러스터 배치 그룹을 사용합니다. Amazon EBS 다중 연결을 사용하여 단일 
프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨을 모든 인스턴스에 
연결합니다. 
B. 클러스터 배치 그룹을 사용합니다. Amazon Elastic File System(Amazon EFS)을 사용하여 
인스턴스 간에 공유 파일 시스템을 생성합니다. 
C. 파티션 배치 그룹을 사용합니다. Amazon Elastic File System(Amazon EFS)을 사용하여 
인스턴스 간에 공유 파일 시스템을 생성합니다. 
D. 스프레드 배치 그룹을 사용합니다. Amazon EBS 다중 연결을 사용하여 단일 
프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨을 모든 인스턴스에 
연결합니다. 
Answer: A 
설명  
노드 간 통신에 가장 낮은 지연 시간 = 클러스터 배치 그룹. A,B 둘 중 하나가 정답. 
A(O) : Amazon EBS 다중 연결을 사용하면 단일 프로비저닝된 IOPS SSD(io1 또는 io2) 
볼륨을 동일한 가용 영역에 있는 여러 인스턴스에 연결할 수 있습니다. 여러 다중 연결 
지원 볼륨을 인스턴스 또는 인스턴스 집합에 연결할 수 있습니다....다중 연결을 사용하면 
동시 쓰기 작업을 관리하는 클러스터링된 Linux 애플리케이션에서 더 쉽게 더 높은 
애플리케이션 가용성을 얻을 수 있습니다.....다중 연결 지원 볼륨은 동일한 가용 영역에 
있는 최대 16 개의 Nitro 시스템 기반 Linux 인스턴스에 연결할 수 있습니다.....다중 연결은 
프로비저닝된 IOPS SSD(io1 및 io2) 볼륨에만 지원됩니다 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volumes-multi.html 
Provisioned IOPS SSD 볼륨의 크기는 4GiB 에서 16TiB 사이가 될 수 있고 볼륨당 100 
IOPS 에서 최대 64,000 IOPS 가 프로비저닝될 수 있습니다. Nitro 시스템에 구축된 
인스턴스에서만 최대 64,000 IOPS 를 달성할 수 있습니다. 다른 인스턴스 패밀리에서는 
최대 32,000 IOPS 성능을 얻을 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/provisioned-iops.html#E
BSVolumeTypes_piops 
B(X) : 공유 블록 장치 볼륨이라고 했으므로 오답. 블록 스토리지는 EBS. 그래도 IOPS 
자체는 EBS 보다 더 높은 편. 
Amazon EFS 범용 및 최대 I/O 라는 두 가지 성능 모드를 제공합니다. 
◎범용 모드 : 최대 35,000 IOPS 를 지원하며 작업당 지연 시간이 가장 낮습니다. EFS One 
Zone 스토리지 클래스가 있는 파일 시스템은 항상 범용 성능 모드를 사용합니다. EFS 
Standard 스토리지 클래스가 있는 파일 시스템의 경우 기본 범용 성능 모드 또는 최대 I/O 
성능 모드를 사용할 수 있습니다. 
◎최대 I/O 모드 : 500,000+ IOPS 를 지원하며 범용 모드에 비해 작업당 지연 시간이 더 
깁니다. https://docs.aws.amazon.com/ko_kr/efs/latest/ug/performance.html 
Q22 
한 회사는 Amazon EC2 인스턴스 및 Amazon Elastic Block Store(Amazon EBS)에서 자체 
관리형 Microsoft SQL Server 를 실행합니다. EBS 볼륨의 일일 스냅샷이 생성됩니다. 
최근 만료된 모든 EBS 스냅샷을 삭제하는 스냅샷 정리 스크립트를 실행하는 동안 회사의 
모든 EBS 스냅샷이 실수로 삭제되었습니다. 솔루션 아키텍트는 EBS 스냅샷을 무기한 
보관하지 않고 데이터 손실을 방지하기 위해 아키텍처를 업데이트해야 합니다. 
최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EBS 스냅샷 삭제를 거부하도록 사용자의 IAM 정책을 변경합니다. 
B. 매일 스냅샷을 완료한 후 EBS 스냅샷을 다른 AWS 리전에 복사합니다. 
C. 휴지통에 7 일 EBS 스냅샷 보관 규칙을 생성하고 모든 스냅샷에 적용합니다. 
D. EBS 스냅샷을 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 복사합니다. 
Answer: C 
설명: 
* 요구 사항 분석: EBS 스냅샷이 실수로 삭제되는 것을 방지하고 무기한 보존을 방지하는 
것이 목표입니다. 
* EBS 스냅샷용 휴지통: AWS 휴지통에서는 스냅샷의 즉각적인 삭제를 방지하는 보관 
규칙을 허용하여 우발적인 삭제에 대비한 안전망을 제공합니다. 
* 보관 규칙: 7 일 보관 규칙은 스냅샷이 즉시 영구적으로 삭제되지 않도록 보장하여 실수로 
삭제한 경우 복구할 수 있는 시간을 제공합니다. 
* 구현: 
* AWS 계정에서 휴지통을 활성화합니다. 
* EBS 스냅샷의 기간을 7 일로 지정하는 보관 규칙을 만듭니다. 
* 이 규칙을 모든 EBS 스냅샷에 적용합니다. 
* 결론: 이 솔루션은 최소한의 개발 노력으로 실수로 삭제되어 데이터가 손실되는 것을 
방지하는 자동화된 방법을 제공합니다. 
Q23 
회사의 애플리케이션이 AWS 에서 실행됩니다. 애플리케이션은 S3 Standard-infrequent 
Access(S3 Standard-IA) 스토리지 클래스를 사용하는 Amazon S3 버킷에 대용량 문서를 
저장합니다. 회사는 데이터 저장 비용을 계속 지불하지만 총 S3 비용을 절감하고자 합니다. 
회사는 승인된 외부 사용자가 밀리초 단위로 문서에 액세스할 수 있기를 원합니다. 이러한 
요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 요청자 지불 버킷이 되도록 S3 버킷을 구성합니다. 
B. 모든 기존 객체와 향후 객체에 대해 스토리지 계층을 S3 Standard 로 변경합니다. 
C. S3 Docket 에서 S3 Transfer Acceleration 을 켭니다. 
D. Amazon CloudFront 를 사용하여 S3 버킷에 대한 모든 요청을 처리합니다. 
Answer: D 
설명: 
이 옵션은 .html, .css, .js 및 이미지 파일과 같은 정적 및 동적 웹 콘텐츠를 사용자에게 
빠르게 배포하는 웹 서비스인 Amazon CloudFront 를 사용하기 때문에 가장 효율적입니다. 
또한 CloudFront 를 사용하여 S3 버킷에 대한 모든 요청을 처리하므로 에지 위치에서 
콘텐츠를 캐싱하고 거기에서 콘텐츠를 제공하여 S3 비용을 줄입니다. 또한 CloudFront 가 
지연 시간이 짧고 데이터 전송 속도가 빠른 콘텐츠를 제공하므로 인증된 외부 사용자가 
밀리초 안에 문서에 액세스할 수 있습니다. 이 솔루션은 데이터 저장 비용을 계속 
지불하면서 총 S3 비용을 절감해야 한다는 요구 사항을 충족합니다. 
옵션 A 는 S3 버킷을 요청자 지불 버킷으로 구성하기 때문에 덜 효율적입니다. 이는 데이터 
전송 및 요청 비용을 버킷 소유자에서 요청자에게 이전하는 방법입니다. 그러나 이것은 
회사가 여전히 데이터 저장 및 자체 사용자의 요청에 대해 비용을 지불해야 하므로 총 S3 
비용을 줄이지 않습니다. 
옵션 B 는 높은 내구성과 가용성으로 자주 액세스하는 데이터를 저장하는 방법인 모든 기존 
및 향후 객체에 대해 스토리지 계층을 S3 Standard 로 변경하기 때문에 효율성이 
떨어집니다. 
그러나 S3 Standard 는 S3 Standard-IA 보다 스토리지 비용이 높기 때문에 총 S3 비용은 
줄어들지 않습니다. 
옵션 C 는 CloudFront 엣지 로케이션을 통해 요청을 라우팅하여 S3 버킷 안팎으로 전송 
속도를 높이는 방법인 S3 버킷에 대해 S3 Transfer Acceleration 을 활성화하기 때문에 
효율성이 떨어집니다. 그러나 S3 Transfer Acceleration 에는 데이터 전송 및 요청에 대한 
추가 요금이 있으므로 총 S3 비용은 줄어들지 않습니다. 
Q24 
한 회사가 두 개의 AWS 지역에서 3 계층 애플리케이션을 실행합니다. 웹 계층, 
애플리케이션 계층, 데이터베이스 계층은 Amazon EC2 인스턴스에서 실행됩니다. 이 
회사는 데이터베이스 계층에 Amazon RDS for Microsoft SQL Server Enterprise 를 
사용합니다. 주간 및 월간 보고서를 실행할 때 데이터베이스 계층에 높은 부하가 
발생합니다. 이 회사는 데이터베이스 계층의 부하를 줄이고자 합니다. 
어떤 솔루션이 최소한의 관리 노력으로 이러한 요구 사항을 충족할까요? 
A. 읽기 전용 복제본을 생성합니다. 새로운 읽기 복제본을 사용하도록 보고서를 
구성합니다. 
B. RDS 데이터베이스를 Amazon DynamoDB 로 변환_ DynamoDB 를 사용하도록 보고서를 
구성합니다. 
C. 더 큰 인스턴스 크기를 선택하여 기존 RDS DB 인스턴스를 수정합니다. 
D. 기존 ROS DB 인스턴스를 수정하고 인스턴스를 Auto Scaling 그룹에 넣습니다. 
Answer: A 
설명: 
이를 통해 회사는 RDS 데이터베이스의 읽기 전용 복제본을 생성하고 데이터베이스 계층의 
로드를 줄일 수 있습니다. 읽기 전용 복제본을 생성하면 회사는 기본 데이터베이스 
인스턴스의 읽기 트래픽을 하나 이상의 복제본으로 오프로드할 수 있습니다. 새로운 읽기 
전용 복제본을 사용하도록 보고서를 구성함으로써 회사는 데이터베이스 계층의 성능과 
가용성을 향상시킬 수 있습니다. 
Q25 
회사는 Amazon EC2 인스턴스 및 Amazon RDS 에서 2 계층 애플리케이션을 호스팅합니다. 
응용 프로그램의 요구 사항은 시간에 따라 다릅니다. 업무 시간 이후와 주말에는 부하가 
최소화됩니다. EC2 인스턴스는 최소 2 개의 인스턴스와 최대 5 개의 인스턴스로 구성된 EC2 
Auto Scaling 그룹에서 실행됩니다. 응용 프로그램은 항상 사용할 수 있어야 하지만 회사는 
전체 비용을 걱정합니다. 
가용성 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 모든 EC2 스팟 인스턴스를 사용합니다. 사용하지 않을 때는 RDS 데이터베이스를 
중지합니다. 
B. 5 개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plan 을 구매합니다. RDS 예약 
DB 인스턴스를 구매합니다. 
C. 두 개의 EC2 예약 인스턴스를 구매합니다. 필요에 따라 최대 3 개의 추가 EC2 스팟 
인스턴스를 사용합니다. 사용하지 않을 때는 RDS 데이터베이스를 중지합니다. 
D. 2 개의 EC2 인스턴스를 포함하는 EC2 Instance Savings Plan 을 구매합니다. 필요에 따라 
최대 3 개의 추가 EC2 온디맨드 인스턴스를 사용합니다. RDS 예약 DB 인스턴스를 
구매합니다. 
Answer: C 
설명: 
이 솔루션은 하루 중 시간에 따라 수요가 가변적이며 전체 비용을 최소화하면서 항상 
사용할 수 있어야 하는 2 계층 애플리케이션의 요구 사항을 충족합니다. EC2 예약 
인스턴스는 기본 사용 수준에 대해 온디맨드 인스턴스에 비해 상당한 비용 절감을 제공할 
수 있으며 필요할 때 용량 예약을 보장할 수 있습니다. EC2 스팟 인스턴스는 피크 시간 
동안 애플리케이션에 필요한 추가 용량에 대해 온디맨드 인스턴스에 비해 최대 90% 절감 
효과를 제공할 수 있습니다. 스팟 인스턴스는 중단을 허용하고 다른 인스턴스로 교체할 수 
있는 상태 비저장 애플리케이션에 적합합니다. RDS 데이터베이스를 사용하지 않을 때 
중지하면 데이터베이스 계층 실행 비용을 줄일 수 있습니다. 
여분의 용량이 충분하지 않거나 스팟 가격이 최대 가격을 초과하는 경우 모든 EC2 스팟 
인스턴스를 사용하면 애플리케이션의 가용성에 영향을 미칠 수 있으므로 옵션 A 는 
올바르지 않습니다. RDS 데이터베이스를 사용하지 않을 때 중지하면 데이터베이스 계층 
실행 비용을 줄일 수 있지만 애플리케이션의 가용성에도 영향을 미칠 수 있습니다. 
5 개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plans 를 구매하면 시간당 컴퓨팅 
사용량이 고정되어 애플리케이션의 실제 사용 패턴과 일치하지 않을 수 있으므로 옵션 B 는 
올바르지 않습니다. RDS 예약 DB 인스턴스를 구매하면 데이터베이스 계층을 절약할 수 
있지만 사용하지 않을 때 데이터베이스를 중지할 수는 없습니다. 
두 개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plans 를 구매하면 시간당 컴퓨팅 
사용량이 고정되어 애플리케이션의 실제 사용 패턴과 일치하지 않을 수 있으므로 옵션 D 는 
올바르지 않습니다. 필요에 따라 최대 3 개의 추가 EC2 온디맨드 인스턴스를 사용하면 스팟 
인스턴스를 사용하는 것보다 더 많은 비용이 발생할 수 있습니다. 
참조: 
https://aws.amazon.com/ec2/pricing/reserved-instances/ 
https://aws.amazon.com/ec2/spot/ 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_StopInstance.html 
Q26 
한 회사가 문서 관리 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 애플리케이션은 
Linux 서버에서 실행됩니다. 회사는 애플리케이션을 Auto Scaling 그룹의 Amazon EC2 
인스턴스로 마이그레이션합니다. 회사는 공유 스토리지 파일 시스템에 7TB 의 문서를 
저장합니다. 외부 관계형 데이터베이스가 문서를 추적합니다. 
문서는 한 번 저장되며 언제든지 참조를 위해 여러 번 검색할 수 있습니다. 회사는 
마이그레이션 도중 애플리케이션을 수정할 수 없습니다. 스토리지 솔루션은 가용성이 
높아야 하며 시간에 따른 확장을 지원해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 향상된 네트워킹을 갖춘 EC2 인스턴스를 공유 NFS 스토리지 시스템으로 배포합니다. 
NFS 공유를 내보냅니다. Auto Scaling 그룹의 EC2 인스턴스에 NFS 공유를 탑재합니다. 
B. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용하는 Amazon 
S3 버킷을 생성합니다. Auto Scaling 그룹의 EC2 인스턴스에 S3 버킷을 탑재합니다. 
C. SFTP 용 AWS 전송 및 Amazon S3 버킷을 사용하여 SFTP 서버 엔드포인트를 
배포합니다. SFTP 서버에 연결하도록 Auto Scaling 그룹의 EC2 인스턴스를 구성합니다. 
D. 여러 가용 영역에 마운트 지점이 있는 Amazon Elastic File System(Amazon EFS) 파일 
시스템을 생성합니다. EFS Stondard-intrcqucnt Access(Standard-IA) 스토리지 클래스를 
사용합니다. Auto Scaling 그룹의 EC2 인스턴스에 NFS 공유를 탑재합니다. 
Answer: D 
설명: 
* 요구 사항 분석: 회사에서는 마이그레이션 중에 애플리케이션을 수정하지 않고도 문서 
관리 애플리케이션을 위한 가용성과 확장성이 뛰어난 스토리지가 필요합니다. 
* EFS 개요: Amazon EFS 는 다양한 가용 영역에 걸쳐 여러 EC2 인스턴스에 동시에 탑재할 
수 있는 확장 가능한 파일 스토리지를 제공합니다. 
* EFS Standard-IA: Standard-IA 스토리지 클래스를 사용하면 고가용성과 확장성을 
유지하면서 자주 액세스하지 않는 데이터에 대한 비용을 줄이는 데 도움이 됩니다. 
* 구현: 
* EFS 파일 시스템을 생성합니다. 
* 고가용성을 보장하려면 여러 가용 영역에 탑재 대상을 구성하세요. 
* Auto Scaling 그룹의 EC2 인스턴스에 EFS 파일 시스템을 탑재합니다. 
* 결론: 이 솔루션은 애플리케이션 수정 없이도 고가용성, 확장성 및 비용 효율성 요구 
사항을 충족합니다. 
Q27 
한 회사가 AWS 클라우드에 웹 애플리케이션을 보유하고 있으며 거래 데이터를 실시간으로 
수집하려고 합니다. 회사에서는 데이터 중복을 방지하고 인프라 관리를 원하지 않습니다. 
회사는 데이터가 수집된 후 해당 데이터에 대해 추가 처리를 수행하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 구성합니다. 데이터를 
처리하기 위해 FIFO 대기열에 대한 이벤트 소스 매핑으로 AWS Lambda 함수를 
구성합니다. 
B. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열 구성 AWS Batch 작업을 
사용하여 대기열에서 중복 데이터 제거 데이터를 처리하도록 AWS Lambda 함수를 
구성합니다. 
C. Amazon Kinesis Data Streams 를 사용하여 수신 트랜잭션 데이터를 중복 데이터를 
제거하는 AWS Batch 작업으로 전송합니다. 데이터를 처리하기 위한 사용자 지정 
스크립트를 실행하는 Amazon EC2 인스턴스를 시작합니다. 
D. 중복 데이터를 제거하기 위해 들어오는 트랜잭션 데이터를 AWS Lambda 함수로 
보내도록 AWS Step Functions 상태 머신을 설정합니다. 데이터를 처리하기 위해 사용자 
지정 스크립트를 실행하는 Amazon EC2 인스턴스를 시작합니다. 
Answer: A 
설명: 
* 요구사항 이해 : 회사는 거래 데이터를 실시간으로 수집하고, 데이터 중복을 방지하며, 
인프라 관리 없이 추가 처리를 수행해야 합니다. 
* 옵션 분석: 
* Lambda 를 사용한 SQS FIFO 대기열: 데이터가 순서대로 처리되도록 보장하고 중복을 
방지합니다. Lambda 는 서버를 관리할 필요 없이 처리를 처리합니다. 
* AWS Batch 를 사용한 SQS FIFO 대기열: 중복이 보장되지 않지만 AWS Batch 에 추가적인 
복잡성과 관리 오버헤드가 발생합니다. 
* AWS Batch 및 EC2를 사용한 Kinesis Data Streams: 인프라 관리를 원하지 않는다는 요구 
사항에 어긋나는 더 많은 구성 요소 및 인프라 관리가 필요합니다. 
* Lambda 및 EC2 를 사용한 Step Functions: 여러 서비스 설정이 필요하며 여전히 EC2 
인스턴스 관리가 필요하므로 복잡성이 증가합니다. 
* 최고의 솔루션: 
* SQS FIFO 대기열(Lambda 포함): 이 조합은 실시간 데이터 처리를 보장하고, 중복을 
방지하며, 인프라 관리를 최소화하여 모든 요구 사항을 효율적으로 충족합니다. 
Q28 
한 회사가 Amazon S3 를 사용하여 rts sialic 웹사이트를 호스팅합니다. 이 회사는 
웹페이지에 연락처 양식을 추가하려고 합니다. 연락처 양식에는 사용자가 이름, 이메일 
주소, 전화번호 및 사용자 메시지를 입력할 수 있는 동적 server-sKle 구성 요소가 
있습니다. 이 회사는 매달 100 건 미만의 사이트 방문이 있을 것으로 예상합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요? 
A. Amazon Elastic Container Service(Amazon ECS)에서 동적 연락처 양식 페이지를 
호스팅합니다. Amazon Simple Email Service(Amazon SES)를 설정하여 모든 타사 이메일 
공급자에 연결합니다. 
B. Amazon Simple Email Service(Amazon SES)를 호출하는 AWS Lambda 백엔드가 있는 
Amazon API Gateway 엔드포인트를 만듭니다. 
C. Amazon Ughtsail 을 배포하여 정적 웹페이지를 동적으로 변환합니다. 클라이언트 측 
스크립트를 사용하여 연락처 양식을 빌드합니다. 양식을 Amazon WorkMail 과 통합합니다. 
D. t2.micro Amazon EC2 인스턴스를 만듭니다. LAMP(Linux, Apache, MySQL, 
PHP/Perl/Python) 스택을 배포하여 웹페이지를 호스팅합니다. 클라이언트 측 스크립팅을 
사용하여 연락처 양식을 빌드합니다. 양식을 Amazon WorkMail 과 통합합니다. 
Answer: B 
Q29 
Amazon EC2 인스턴스에 호스팅된 회사 웹사이트는 분류된 데이터를 처리하여 저장합니다. 
애플리케이션은 Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 씁니다. 회사는 
EBS 볼륨에 쓰여진 모든 데이터가 저장 시 암호화되도록 해야 합니다. 
어떤 솔루션이 이 요구 사항을 충족할까요? 
A. EBS 암호화를 지정하는 IAM 역할을 만듭니다. 역할을 EC2 인스턴스에 연결합니다. 
B. EBS 볼륨을 암호화된 볼륨으로 만듭니다. EBS 볼륨을 EC2 인스턴스에 연결합니다. 
C. 키가 Encrypt 이고 값이 True 인 EC2 인스턴스 태그를 만듭니다. EBS 수준에서 암호화가 
필요한 모든 인스턴스에 태그를 지정합니다. 
D. 계정에서 EBS 암호화를 적용하는 AWS Key Management Service(AWS KMS) 키 정책을 
만듭니다. 키 정책이 활성화되어 있는지 확인합니다. 
Answer: B 
설명: 
EBS 볼륨에 쓰여진 모든 데이터가 저장 시 암호화되도록 하는 가장 간단하고 효과적인 
방법은 EBS 볼륨을 암호화된 볼륨으로 만드는 것입니다. 새 EBS 볼륨을 생성할 때 암호화 
옵션을 선택하거나 기존의 암호화되지 않은 볼륨을 새 암호화된 볼륨으로 복사하여 이를 
수행할 수 있습니다. 암호화에 사용할 AWS KMS 키를 지정하거나 기본 AWS 관리 키를 
사용할 수도 있습니다. 암호화된 EBS 볼륨을 EC2 인스턴스에 연결하면 EC2 호스트에서 
데이터가 자동으로 암호화되고 복호화됩니다. 이 솔루션에는 추가 IAM 역할, 태그 또는 
정책이 필요하지 않습니다. 
Q30 
한 회사에서 AWS 에서 새로운 애플리케이션을 위한 마이크로서비스 기반 아키텍처를 
설계하고 있습니다. 각 마이크로서비스는 자체 Amazon EC2 인스턴스 세트에서 실행됩니다. 
각 마이크로서비스는 Amazon S3 및 Amazon Simple Queue Service(Amazon SQS)와 같은 
여러 AWS 서비스와 상호 작용해야 합니다. 
이 회사는 최소 권한 원칙에 따라 각 EC2 인스턴스의 권한을 관리하려고 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 각 마이크로서비스에 IAM 사용자를 할당합니다. 애플리케이션 코드에 저장된 액세스 
키를 사용하여 AWS 서비스 요청을 인증합니다. 
B. 모든 AWS 서비스에 액세스할 수 있는 권한이 있는 단일 IAM 역할을 만듭니다. 
마이크로서비스를 실행하는 모든 EC2 인스턴스에 IAM 역할을 연결합니다. 
C. AWS Organizations 를 사용하여 각 마이크로서비스에 대해 별도의 계정을 만듭니다. 
계정 수준에서 권한을 관리합니다. 
D. 각 마이크로서비스의 특정 요구 사항에 따라 개별 IAM 역할을 만듭니다. IAM 역할을 
적절한 EC2 인스턴스에 연결합니다. 
Answer: D 
설명: 
각 마이크로서비스가 다른 AWS 서비스와 상호 작용하는 마이크로서비스 아키텍처를 
설계할 때는 최소 권한의 원칙을 따르는 것이 필수적입니다. 즉, 각 마이크로서비스에 
작업을 수행하는 데 필요한 권한만 부여하여 무단 액세스 또는 우발적 작업의 위험을 
줄이는 것을 의미합니다. 
권장되는 접근 방식은 각 마이크로서비스에 필요한 특정 권한을 부여하는 정책이 있는 개별 
IAM 역할을 만드는 것입니다. 그런 다음 이러한 역할을 해당 마이크로서비스를 실행하는 
EC2 인스턴스와 연결해야 합니다. 이렇게 하면 각 EC2 인스턴스가 특정 IAM 역할을 맡고 
AWS 에서 권한을 자동으로 관리합니다. 
IAM 역할은 인스턴스 메타데이터 서비스를 통해 임시 자격 증명을 제공하므로 
애플리케이션 코드에 자격 증명을 하드 코딩할 필요가 없으므로 보안이 강화됩니다. 
AWS 참조: 
* Amazon EC2 의 IAM 역할은 EC2 인스턴스가 장기 자격 증명을 관리하지 않고도 IAM 
역할을 사용하여 AWS 서비스에 안전하게 액세스하는 방법을 설명합니다. 
* IAM 모범 사례에는 최소 권한 원칙을 구현하고 IAM 역할을 효과적으로 사용하기 위한 
권장 사항이 포함되어 있습니다. 
다른 옵션이 틀린 이유: 
* A. 각 마이크로서비스에 IAM 사용자를 할당합니다. 이렇게 하려면 장기 자격 증명(액세스 
키)을 관리해야 하며, 이는 피해야 합니다. 애플리케이션 코드에 키를 저장하는 것은 
안전하지 않으며 유지 관리 부담이 발생합니다. 
* B. 단일 IAM 역할 생성: 모든 서비스에 걸쳐 광범위한 권한이 있는 단일 역할은 보안성이 
낮기 때문에 최소 권한 원칙을 위반합니다. 
* C. AWS 조직 사용: 이 접근 방식은 불필요한 복잡성을 추가합니다. 각 마이크로서비스에 
대한 계정 수준에서 권한을 관리하는 것은 이 사용 사례에 과도하며 최소 권한 원칙을 
준수하지 않습니다. 
Q31 
한 회사에서 API 를 호스팅하기 위해 Amazon EC2 Auto Scaling 그룹을 사용합니다. EC2 
인스턴스는 Application Load Balancer(ALB)와 연결된 대상 그룹에 있습니다. 이 회사는 
Amazon Aurora PostgreSQL 데이터베이스에 데이터를 저장합니다. 
API 에는 주간 유지 관리 기간이 있습니다. 이 회사는 API 가 주간 유지 관리 기간 동안 
정적 유지 관리 응답을 반환하도록 해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이 요구 사항을 충족할까요? 
A. Aurora PostgreSQL 에서 키와 값을 포함하는 필드가 있는 테이블을 만듭니다. 유지 관리 
플래그에 대한 키를 만듭니다. 유지 관리 기간이 시작되면 플래그를 설정합니다. API 가 
유지 관리 플래그에 대한 테이블을 쿼리하고 플래그가 설정된 경우 유지 관리 응답을 
반환하도록 구성합니다. 유지 관리 기간이 끝나면 플래그를 재설정합니다. 
B. Amazon Simple Queue Service(Amazon SQS) 대기열을 만듭니다. EC2 인스턴스를 
대기열에 구독합니다. 유지 관리 기간이 시작되면 대기열에 메시지를 게시합니다. 
인스턴스가 대기열에서 유지 관리 시작 메시지를 수신하면 유지 관리 메시지를 반환하도록 
API 를 구성합니다. 
유지 관리 기간이 끝나면 대기열에 다른 메시지를 게시하여 정상 작동을 복원합니다. 
C. 요청의 경로가 와일드카드와 일치할 때 유지 관리 응답을 반환하는 ALB 에 리스너 
규칙을 만듭니다. 규칙 우선 순위를 1 로 설정합니다. 유지 관리를 수행합니다. 유지 관리 
기간이 끝나면 리스너 규칙을 삭제합니다. 
D. Amazon Simple Notification Service(Amazon SNS) 토픽 만들기 EC2 인스턴스를 토픽에 
구독합니다. 유지 관리 기간이 시작되면 토픽에 메시지를 게시합니다. 인스턴스가 토픽에서 
유지 관리 시작 메시지를 받으면 유지 관리 응답을 반환하도록 API 를 구성합니다. 유지 
관리 기간이 끝나면 토픽에 다른 메시지를 게시하여 정상 작동을 복원합니다. 
Answer: C 
설명: 
유지 관리 기간 동안 유지 관리 응답을 반환하는 Application Load Balancer(ALB)에 리스너 
규칙을 만드는 것은 운영 오버헤드가 가장 적은 가장 간단한 솔루션입니다. 규칙은 모든 
수신 요청과 일치하고 사용자 지정 응답을 반환하도록 구성할 수 있으며 유지 관리가 
완료되면 쉽게 제거할 수 있습니다. 
* 옵션 A(Aurora 테이블 플래그): 이렇게 하면 임시 유지 관리 응답에 불필요한 복잡성이 
추가됩니다. 
* 옵션 B 와 D(SQS 또는 SNS): 이 옵션은 간단한 유지 관리 메시지에 필요한 것보다 더 
많은 구성 요소를 도입합니다. 
Q32 
한 회사에서 전자상거래 웹 애플리케이션에 대한 평가 시스템을 개발하고 있습니다. 이 
회사에는 사용자가 제출한 평가를 Amazon DynamoDB 테이블에 저장하는 솔루션이 
필요합니다. 
이 회사는 개발자가 DynamoDB 테이블과 직접 상호 작용할 필요가 없도록 하려고 합니다. 
솔루션은 확장 가능하고 재사용 가능해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. 애플리케이션 로드 밸런서(ALB)를 만듭니다. AWS Lambda 함수를 만들고 ALB 에서 
함수를 대상 그룹으로 설정합니다. ALB 를 통해 put_item 메서드를 사용하여 Lambda 
함수를 호출합니다. 
B. AWS Lambda 함수를 만듭니다. Boto3 의 put-item 메서드를 사용하여 DynamoDB 
테이블과 상호 작용하도록 Lambda 함수를 구성합니다. 웹 애플리케이션에서 Lambda 
함수를 호출합니다. 
C. Amazon Simple Queue Service(Amazon SQS) 대기열과 SQS 트리거 유형이 있는 AWS 
Lambda 함수를 만듭니다. 개발자에게 고객 평가를 JSON 메시지로 SQS 대기열에 
추가하도록 지시합니다. Lambda 함수를 구성하여 큐에서 평점을 가져와 DynamoDB 에 
평점을 저장합니다. 
D. Amazon API Gateway REST API 만들기 리소스를 정의하고 새 POST 메서드 만들기 통합 
유형으로 AWS 를 선택하고 서비스로 DynamoDB 를 선택합니다. 작업을 PutItem 으로 
설정합니다. 
Answer: D 
설명: 
Amazon API Gateway 는 개발자가 직접 액세스하지 않고도 DynamoDB 와 상호 작용할 수 
있는 확장 가능하고 재사용 가능한 솔루션을 제공합니다. DynamoDB 의 PutItem 작업과 
통합되는 POST 메서드로 REST API 를 설정하면 개발자는 데이터베이스와 직접 상호 
작용하지 않고도 API Gateway 를 통해 DynamoDB 테이블에 데이터(예: 사용자 평점)를 
제출할 수 있습니다. 이 솔루션은 서버리스이며 운영 오버헤드를 최소화합니다. 
* 옵션 A: Lambda 와 함께 ALB 를 사용하면 복잡성이 증가하고 이 사용 사례에서는 
효율성이 떨어집니다. 
* 옵션 B: Lambda 를 사용하는 것은 가능하지만 API Gateway 는 더 확장 가능하고 재사용 
가능한 인터페이스를 제공합니다. 
* 옵션 C: Lambda 와 함께 SQS 를 사용하면 간단한 put 작업에 불필요한 구성 요소가 
도입됩니다. 
Q33 
미디어 회사가 AWS 에서 비디오 처리 워크로드를 호스팅합니다. 워크로드는 자동 확장 
그룹의 Amazon EC2 인스턴스를 사용하여 다양한 수준의 수요를 처리합니다. 워크로드는 
원본 비디오와 처리된 비디오를 Amazon S3 버킷에 저장합니다. 
이 회사는 비디오 처리 워크로드가 확장 가능한지 확인하려고 합니다. 이 회사는 리소스 
제약으로 인해 처리 시도가 실패하는 것을 방지하려고 합니다. 아키텍처는 처리 기능에 
영향을 미치지 않고 비디오 업로드가 갑자기 급증해도 처리할 수 있어야 합니다. 
어떤 솔루션이 최소한의 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Amazon EC2 인스턴스에서 AWS Lambda 함수로 워크로드를 마이그레이션합니다. 새 
비디오가 업로드될 때 Lambda 함수를 호출하도록 Amazon S3 이벤트 알림을 구성합니다. 
Lambda 함수가 비디오를 직접 처리하고 처리된 비디오를 S3 버킷에 다시 저장하도록 
구성합니다. 
B. Amazon EC2 인스턴스에서 AWS Lambda 함수로 워크로드를 마이그레이션합니다. 새 
비디오가 업로드될 때 Amazon S3 를 사용하여 Amazon Simple Notification Service(Amazon 
SNS) 주제를 호출합니다. 
Lambda 함수를 SNS 주제에 구독합니다. Lambda 함수를 구성하여 비디오를 비동기적으로 
처리하고 처리된 비디오를 S3 버킷에 다시 저장합니다. 
C. 새 비디오가 업로드될 때 Amazon Simple Queue Service(Amazon SQS) 대기열에 
메시지를 보내도록 Amazon S3 이벤트 알림을 구성합니다. 기존 Auto Scaling 그룹을 
구성하여 SQS 대기열을 폴링하고 비디오를 처리하고 처리된 비디오를 S3 버킷에 다시 
저장합니다. 
D. 새 비디오가 업로드될 때 AWS Step Functions 상태 머신을 호출하도록 Amazon S3 
업로드 트리거를 구성합니다. 작업 메시지를 Amazon SQS 대기열에 배치하여 비디오 처리 
워크플로를 조정하도록 상태 머신을 구성합니다. 작업 메시지를 구성하여 EC2 인스턴스를 
호출하여 비디오를 처리합니다. 처리된 비디오를 S3 버킷에 다시 저장합니다. 
Answer: C 
설명: 
이 솔루션은 리소스 제약으로 인해 실패한 처리 시도를 방지하는 동시에 워크로드의 확장성 
요구 사항을 해결합니다. 
* Amazon S3 이벤트 알림은 새 비디오가 업로드될 때마다 SQS 대기열에 메시지를 
트리거하는 데 사용할 수 있습니다. 
* EC2 인스턴스의 기존 자동 확장 그룹은 SQS 대기열을 폴링하여 대기열에 작업이 있는 
경우에만 EC2 인스턴스가 비디오를 처리하도록 할 수 있습니다. 
* SQS 는 비디오 업로드 및 처리 단계를 분리하여 시스템이 EC2 인스턴스에 과부하를 주지 
않고 비디오 업로드의 갑작스러운 급증을 처리할 수 있도록 합니다. 
자동 확장을 사용하면 EC2 인스턴스가 수요에 따라 확장 또는 축소할 수 있어 리소스 
부족으로 인한 처리 실패를 피하면서 비용 효율성을 유지할 수 있습니다. 
AWS 참조: 
* S3 이벤트 알림은 S3 이벤트에 대한 알림을 구성하는 방법을 자세히 설명합니다. 
* Amazon SQS 는 시스템 구성 요소를 분리하는 완전 관리형 메시지 대기열 서비스입니다. 
* 자동 확장 EC2 는 수요에 따라 EC2 인스턴스의 자동 확장을 관리하는 방법을 
설명합니다. 
다른 옵션이 틀린 이유: 
* A. AWS Lambda 함수: Lambda 는 일부 워크로드를 처리할 수 있지만 비디오 처리에는 
종종 리소스가 많이 필요하고 오래 실행되므로 EC2 가 더 적합한 솔루션입니다. 
* B. Lambda 와 함께 SNS 사용: A 와 유사하게 Lambda 는 시간 및 메모리 제한으로 인해 
대규모 비디오 처리에 적합하지 않습니다. 
* D. AWS Step Functions: 유효한 오케스트레이션 솔루션이지만, 이는 더 간단한 SQS 기반 
솔루션에 비해 복잡성과 오버헤드가 더 큽니다. 
Q34 
한 금융 회사가 거래 플랫폼을 AWS 로 마이그레이션하고 있습니다. 거래 플랫폼은 대량의 
시장 데이터를 처리하고 주식 거래를 처리합니다. 이 회사는 온프레미스 데이터 센터에서 
AWS 로 일관되고 지연 시간이 짧은 네트워크 연결을 설정해야 합니다. 
이 회사는 VPC 에서 리소스를 호스팅합니다. 솔루션은 공용 인터넷을 사용해서는 안 
됩니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. AWS 클라이언트 VPN 을 사용하여 온프레미스 데이터 센터를 AWS 에 연결합니다. 
B. AWS Direct Connect 를 사용하여 온프레미스 데이터 센터에서 AWS 로 연결을 
설정합니다. 
C. AWS PrivateLink 를 사용하여 온프레미스 데이터 센터에서 AWS 로 연결을 설정합니다. 
D. AWS 사이트 간 VPN 을 사용하여 온프레미스 데이터 센터를 AWS 에 연결합니다. 
Answer: B 
설명: 
AWS Direct Connect 는 공용 인터넷을 사용하지 않고도 온프레미스 데이터 센터에서 
AWS 로 일관되고 지연 시간이 짧은 연결을 설정하는 데 가장 적합한 솔루션입니다. Direct 
Connect 는 전용, 고처리량, 저지연 네트워크 연결을 제공하며, 이는 대량의 시장 데이터와 
주식 거래를 처리하는 거래 플랫폼과 같은 성능에 민감한 애플리케이션에 이상적입니다. 
Direct Connect 는 AWS VPC 에 대한 개인 연결을 제공하여 데이터가 공용 인터넷을 
통과하지 않도록 보장하여 보안과 성능 일관성을 모두 향상시킵니다. 
AWS 참조: 
* AWS Direct Connect 는 일관되고 저지연 성능으로 AWS 서비스에 대한 전용 네트워크 
연결을 제공합니다. 
* 거래 플랫폼과 같은 성능에 민감한 워크로드를 위한 AWS 에서 고성능을 위한 모범 사례. 
다른 옵션이 틀린 이유: 
* A. AWS 클라이언트 VPN: 이는 보안 연결을 제공하지만 공용 인터넷을 통해 이루어지며 
거래 플랫폼의 저지연, 고성능 요구 사항에 맞게 설계되지 않았습니다. 
* C. AWS PrivateLink: PrivateLink 는 AWS 내의 VPC 와 서비스를 연결하는 데 사용되지만 
온프레미스 데이터 센터를 AWS 에 연결하도록 설계되지 않았습니다. 
* D. AWS 사이트 간 VPN: 이 방식은 안전한 연결을 제공하지만 공용 인터넷을 사용하므로 
지연 시간이 발생할 수 있으며 사용 사례의 저지연성 요구 사항을 충족하지 못합니다. 
Q35 
한 회사에서 Amazon EC2 인스턴스에 새로운 게임 애플리케이션을 배포하고 있습니다. 
게임 애플리케이션은 공유 스토리지에 액세스할 수 있어야 합니다. 
이 회사에서는 애플리케이션이 기존 사용자 지정 프로토콜을 사용하여 공유 스토리지에 
액세스할 수 있는 기능을 제공하는 고성능 솔루션이 필요합니다. 이 솔루션은 낮은 지연 
시간을 보장하고 운영 효율성이 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon FSx 파일 게이트웨이를 만듭니다. 기존 사용자 지정 프로토콜을 사용하는 파일 
공유를 만듭니다. 
애플리케이션을 호스팅하는 EC2 인스턴스를 파일 공유에 연결합니다. 
B. Amazon EC2 Windows 인스턴스를 만듭니다. 인스턴스에 Windows 파일 공유 역할을 
설치하고 구성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스를 파일 공유에 
연결합니다. 
C. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다. Lustre 를 지원하도록 
파일 시스템을 구성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스를 파일 시스템에 
연결합니다. 
D. Amazon FSx for Lustre 파일 시스템을 만듭니다. 애플리케이션을 호스팅하는 EC2 
인스턴스를 파일 시스템에 연결합니다. 
Answer: D 
설명: 
Amazon FSx for Lustre 는 고성능의 완전 관리형 파일 시스템으로, 특히 게임과 같이 높은 
처리량과 낮은 지연 시간이 필수적인 사용 사례에서 공유 스토리지에 대한 낮은 지연 시간 
액세스가 필요한 애플리케이션에 이상적입니다. EC2 인스턴스와 쉽게 통합되어 빠르고 확장 
가능한 공유 스토리지를 제공하며 특정 애플리케이션 요구 사항에 맞는 사용자 지정 
프로토콜을 지원합니다. 
* 옵션 A(FSx 파일 게이트웨이): FSx 파일 게이트웨이는 하이브리드 클라우드 
스토리지용으로 설계되었으며 고성능 게임 워크로드에는 적합하지 않습니다. 
* 옵션 B(EC2 Windows 인스턴스): Windows 인스턴스에 파일 공유를 설정하면 추가적인 
관리 오버헤드가 발생하고 필요한 성능을 제공하지 못합니다. 
* 옵션 C(Lustre 가 포함된 EFS): Lustre 는 FSx 와 통합되어 있지만 EFS 는 기본적으로 
Lustre 를 지원하지 않습니다. 
Q36 
제조 회사가 VPC 에서 주문 처리 애플리케이션을 실행합니다. 이 회사는 애플리케이션에서 
Open Authorization(OAuth)을 사용하는 외부 Salesforce 시스템으로 메시지를 안전하게 
보내려고 합니다. 
솔루션 아키텍트는 회사의 주문 처리 애플리케이션을 외부 Salesforce 시스템과 통합해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. HTTPS 엔드포인트로 데이터를 푸시하는 팬아웃 구성에서 Amazon Simple Notification 
Service(Amazon SNS) 토픽을 만듭니다. 주문 처리 애플리케이션을 구성하여 SNS 토픽에 
메시지를 게시합니다. 
B. HTTP 대상이 있는 Amazon Data Firehose 전달 스트림으로 데이터를 푸시하는 팬아웃 
구성에서 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. 주문 처리 
애플리케이션을 구성하여 SNS 토픽에 메시지를 게시합니다. 
C. Amazon EventBridge 규칙을 만들고 Amazon EventBridge API 대상 파트너를 구성합니다. 
주문 처리 애플리케이션을 구성하여 Amazon EventBridge 에 메시지를 게시합니다. 
D. 아웃바운드 MSK Connect 커넥터가 있는 Amazon Managed Streaming for Apache 
Kafka(Amazon MSK) 토픽을 만듭니다. 주문 처리 애플리케이션을 구성하여 MSK 토픽에 
메시지를 게시합니다. 
Answer: C 
설명: 
Amazon EventBridge API 대상을 사용하면 OAuth 로 보안된 API 를 포함하여 HTTP API 를 
사용하여 AWS 에서 Salesforce 와 같은 외부 시스템으로 데이터를 보낼 수 있습니다. 이를 
통해 주문 처리 애플리케이션에서 Salesforce 로 메시지를 보내기 위한 안전하고 확장 
가능한 솔루션을 제공합니다. 
* 옵션 A 및 B(SNS): SNS 는 OAuth 로 보안된 외부 API 에 적합하지 않으며 필요한 OAuth 
통합이 없습니다. 
* 옵션 D(MSK): Amazon MSK 는 Kafka 기반 스트리밍 솔루션으로, Salesforce 로 간단한 
메시지를 전달하기에는 과도합니다. 
Q37 
한 회사에서 AWS 서비스와 비 AWS 서비스에서 실행되는 워크로드에 대한 AWS API 
호출을 감사하기 위한 중앙 집중형 솔루션을 설정해야 합니다. 이 회사는 7 년 동안 감사 
로그를 저장해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Amazon S3 에 데이터 레이크를 설정합니다. AWS CloudTrail 로그와 비 AWS 서비스의 
로그를 데이터 레이크에 통합합니다. CloudTrail 을 사용하여 7 년 동안 로그를 저장합니다. 
B. AWS CloudTrail Lake 에 대한 사용자 지정 통합을 구성하여 AWS 서비스와 비 AWS 
서비스에서 CloudTrail 이벤트를 수집하고 저장합니다. CloudTrail 을 사용하여 7 년 동안 
로그를 저장합니다. 
C. AWS 서비스에 대해 AWS CloudTrail 을 활성화합니다. 비 AWS 서비스를 CloudTrail 에 
수집하여 7 년 동안 로그를 저장합니다. 
D. 새 Amazon CloudWatch Logs 그룹을 만듭니다. 비 AWS 서비스의 감사 데이터를 
CloudWatch Logs 그룹으로 보냅니다. AWS 에서 실행되는 워크로드에 대해 AWS 
CloudTrail 을 활성화합니다. CloudTrail 을 사용하여 7 년 동안 로그를 저장합니다. 
Answer: B 
설명: 
AWS CloudTrail Lake 는 AWS 및 비 AWS 서비스 모두에 대한 CloudTrail 이벤트의 수집, 
저장 및 쿼리를 허용하는 완전 관리형 서비스입니다. CloudTrail Lake 는 다양한 소스에서 
로그를 수집하도록 사용자 정의하여 중앙 집중식 감사 솔루션을 보장할 수 있습니다. 또한 
장기 저장을 지원하므로 로그를 7 년 동안 보관하여 규정 준수 요구 사항을 충족할 수 
있습니다. 
* 옵션 A(데이터 레이크): S3 에 데이터 레이크를 설정하면 CloudTrail Lake 에 비해 
불필요한 운영 복잡성이 발생합니다. 
* 옵션 C(비 AWS 서비스를 CloudTrail 에 수집): CloudTrail Lake 는 운영 오버헤드가 적어 
이 작업에 더 적합합니다. 
* 옵션 D(CloudWatch 로그): CloudWatch 는 로그를 저장할 수 있지만 CloudTrail Lake 는 
API 감사 및 저장을 위해 특별히 설계되었습니다. 
Q38 
미디어 회사가 Amazon EC2 인스턴스에서 실행되는 비디오 변환 도구를 사용하고 있습니다. 
비디오 변환 도구는 Windows EC2 인스턴스와 Linux EC2 인스턴스의 조합에서 실행됩니다. 
각 비디오 파일의 크기는 수십 기가바이트입니다. 비디오 변환 도구는 가능한 한 짧은 시간 
내에 비디오 파일을 처리해야 합니다. 이 회사에는 비디오 변환 도구를 호스팅하는 모든 
EC2 인스턴스에 마운트할 수 있는 단일 중앙 집중식 파일 스토리지 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 하드 디스크 드라이브(HDD) 스토리지가 있는 Amazon FSx for Windows File Server 를 
배포합니다. 
B. 솔리드 스테이트 드라이브(SSD) 스토리지가 있는 Amazon FSx for Windows File 
Server 를 배포합니다. 
C. 최대 I/O 성능 모드로 Amazon Elastic File System(Amazon EFS)을 배포합니다. 
D. 범용 성능 모드로 Amazon Elastic File System(Amazon EFS)을 배포합니다. 
Answer: C 
설명: 
Max I/O 성능 모드가 있는 Amazon EFS 는 여러 EC2 인스턴스에서 비디오 처리와 같이 
높은 수준의 병렬 처리가 필요한 워크로드를 위해 설계되었습니다. EFS 는 Windows 및 
Linux EC2 인스턴스에 모두 마운트할 수 있는 공유 파일 스토리지를 제공하며, Max I/O 
모드는 여러 인스턴스에서 대용량 파일과 동시 액세스를 처리하는 데 최상의 성능을 
보장합니다. 
* 옵션 A 및 B(Windows 파일 서버용 FSx): Windows 파일 서버용 FSx 는 Windows 
워크로드에 최적화되어 있으며 Linux 인스턴스나 고처리량 병렬 워크로드에는 적합하지 
않습니다. 
* 옵션 D(EFS 일반 용도 모드): 일반 용도 모드는 대기 시간이 짧지만 대규모 동시 
워크로드에 필요한 높은 처리량은 지원하지 않습니다. 
Q39 
한 회사가 다중 테넌트 Amazon S3 버킷에 고객 데이터를 저장합니다. 각 고객의 데이터는 
고객에게 고유한 접두사에 저장됩니다. 이 회사는 특정 고객의 데이터를 소스 버킷과 
동일한 AWS 리전에 있는 새로운 전용 S3 버킷으로 마이그레이션해야 합니다. 이 회사는 
생성 날짜 및 버전 ID 와 같은 객체 메타데이터를 보존해야 합니다. 
마이그레이션이 완료되면 회사는 원래 다중 테넌트 S3 버킷에서 마이그레이션된 고객의 
소스 데이터를 삭제해야 합니다. 
어떤 솔루션 조합이 이러한 요구 사항을 가장 적은 오버헤드로 충족할 수 있을까요? (3 개 
선택) 
A. 대상 버킷으로 새 S3 버킷을 만듭니다. 새 버킷에서 버전 관리를 활성화합니다. 
B. S3 일괄 작업을 사용하여 지정된 접두사에서 대상 버킷으로 객체를 복사합니다. 
C. S3 CopyObject API 를 사용하여 스크립트를 만들어 데이터를 대상 S3 버킷으로 
복사합니다. 
D. S3 동일 리전 복제(SRR)를 구성하여 소스 버킷의 지정된 접두사에서 대상 버킷으로 
기존 데이터를 복제합니다. 
E. AWS DataSync 를 구성하여 소스 버킷의 지정된 접두사에서 대상 버킷으로 데이터를 
마이그레이션합니다. 
F. S3 수명 주기 정책을 사용하여 데이터가 대상 버킷으로 마이그레이션된 후 소스 
버킷에서 객체를 삭제합니다. 
Answer: A, B, F 
설명: 
이러한 솔루션을 결합하면 메타데이터를 보존하고 정리를 보장하면서 데이터를 
마이그레이션하는 효율적이고 자동화된 방법을 제공합니다. 
* 마이그레이션 중에 버전 ID 와 같은 객체 메타데이터를 보존하기 위해 버전 관리가 
활성화된 새 S3 버킷을 만듭니다(옵션 A). 
* S3 일괄 작업(옵션 B)을 사용하여 소스 버킷의 특정 접두사에서 대상 버킷으로 데이터를 
효율적으로 복사하여 최소한의 오버헤드를 보장합니다. 
* S3 수명 주기 정책(옵션 F)을 사용하여 마이그레이션된 후 소스 버킷에서 데이터를 
자동으로 삭제하여 수동 개입을 줄입니다. 
* 옵션 C(CopyObject API): 이 방법은 더 많은 수동 스크립팅과 노력이 필요합니다. 
* 옵션 D(동일 지역 복제): SRR 은 일회성 마이그레이션이 아닌 지속적인 복제를 위해 
설계되었습니다. 
* 옵션 E(DataSync): DataSync 는 이 작업에 필요한 것보다 더 많은 복잡성을 추가합니다. 
Q40 
한 회사에서 사내 직원을 위한 개인 웹사이트를 게시하려고 합니다. 웹사이트는 여러 HTML 
페이지와 이미지 파일로 구성되어 있습니다. 웹사이트는 HTTPS 를 통해서만 사용할 수 
있어야 하며 사내 직원만 사용할 수 있어야 합니다. 솔루션 아키텍트는 웹사이트 파일을 
Amazon S3 버킷에 저장할 계획입니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 소스 IP 주소가 사내 환경의 공용 IP 주소가 아닌 경우 액세스를 거부하는 S3 버킷 
정책을 만듭니다. S3 버킷을 가리키도록 Amazon Route 53 별칭 레코드를 설정합니다. 사내 
직원에게 별칭 레코드를 제공하여 직원이 웹사이트에 액세스할 수 있도록 합니다. 
B. 웹사이트에 액세스할 수 있도록 S3 액세스 지점을 만듭니다. 소스 IP 주소가 사내 
환경의 공용 IP 주소가 아닌 경우 액세스를 거부하는 액세스 지점 정책을 연결합니다. 사내 
직원에게 S3 액세스 지점 별칭을 제공하여 직원이 웹사이트에 액세스할 수 있도록 합니다. 
C. S3 버킷에 대해 구성된 OAC(원본 액세스 제어)가 포함된 Amazon CloudFront 배포를 
만듭니다. SSL 을 위해 AWS Certificate Manager 를 사용합니다. 온프레미스 IP 주소에 대한 
액세스를 허용하는 IP 설정 규칙이 있는 AWS WAF 를 사용합니다. CloudFront 배포를 
가리키도록 Amazon Route 53 별칭 레코드를 설정합니다. 
D. S3 버킷에 대해 구성된 원본 액세스 제어(OAC)가 포함된 Amazon CloudFront 배포를 
만듭니다. 버킷의 객체에 대한 CloudFront 서명 URL 을 만듭니다. CloudFront 배포를 
가리키도록 Amazon Route 53 별칭 레코드를 설정합니다. 서명된 URL 을 온프레미스 
직원에게 제공하여 직원에게 웹사이트에 대한 액세스 권한을 부여합니다. 
Answer: C 
설명: 
이 솔루션은 CloudFront 를 사용하여 SSL 인증서에 대한 AWS Certificate Manager(ACM)를 
사용하여 HTTPS 를 통해 웹사이트를 안전하게 제공합니다. 원본 액세스 제어(OAC)는 
CloudFront 만 S3 버킷에 직접 액세스할 수 있도록 합니다. IP 설정 규칙이 있는 AWS 
WAF 는 웹사이트에 대한 액세스를 제한하여 온프레미스 IP 주소만 허용합니다. Route 53 은 
CloudFront 배포를 가리키는 별칭 레코드를 만드는 데 사용됩니다. 이 설정은 낮은 관리 
오버헤드로 웹사이트에 대한 안전하고 개인적인 액세스를 보장합니다. 
* 옵션 A 및 B: S3 버킷 정책 및 액세스 포인트는 HTTPS 지원을 제공하지 않으며 WAF 가 
있는 CloudFront 와 동일한 수준의 보안을 제공하지 않습니다. 
* 옵션 D: 서명된 URL 은 온프레미스 직원을 위한 영구적인 솔루션보다는 일시적이고 
만료되는 액세스에 더 적합합니다. 
Q41 
온라인 교육 플랫폼은 수천 명의 학생이 동시에 비디오 레슨에 접속하는 피크 사용 시간 
동안 지연과 버퍼링을 경험합니다. 솔루션 아키텍트는 교육 플랫폼의 성능을 개선해야 
합니다. 
플랫폼은 응답성을 잃지 않으면서 예측할 수 없는 트래픽 급증을 처리해야 합니다. 
플랫폼은 항상 원활한 비디오 재생 성능을 제공해야 합니다. 플랫폼은 각 비디오 레슨의 
여러 사본을 만들고 다양한 비트레이트로 사본을 저장하여 인터넷 속도가 다른 사용자에게 
서비스를 제공해야 합니다. 가장 작은 비디오 크기는 7GB 입니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon ElastiCache 를 사용하여 모든 필수 비트레이트로 비디오를 캐시합니다. AWS 
Lambda 함수를 사용하여 비디오를 처리하고 비디오를 필수 비트레이트로 변환합니다. 
B. 피크 부하에 맞게 크기가 조정된 Amazon EC2 인스턴스를 포함하는 자동 크기 조정 
그룹을 만듭니다. 
자동 크기 조정 그룹을 사용하여 비디오를 제공합니다. 자동 크기 조정 그룹을 사용하여 
비디오를 필수 비트레이트로 변환합니다. 
C. 모든 비디오의 사본을 모든 필수 비트레이트로 Amazon S3 버킷에 저장합니다. 단일 
Amazon EC2 인스턴스를 사용하여 비디오를 제공합니다. 
D. Amazon Kinesis Video Streams 를 사용하여 비디오를 저장하고 제공합니다. AWS Lambda 
함수를 사용하여 비디오를 처리하고 비디오를 필수 비트레이트로 변환합니다. 
Answer: C 
설명: 
비트레이트가 다른 비디오 콘텐츠를 제공하는 가장 비용 효율적인 솔루션은 각 비디오의 
여러 버전을 Amazon S3 에 저장하는 것입니다. S3 는 대용량 미디어 파일에 대한 확장 
가능하고 비용 효율적인 스토리지를 제공합니다. 단일 Amazon EC2 인스턴스에서 비디오를 
제공하면 지연 시간이 짧고 S3 스토리지는 비용을 최소화하는 데 도움이 됩니다. 
* 옵션 A(ElastiCache): 대용량 비디오 파일을 메모리에 캐싱하는 것은 엄청나게 비용이 
많이 들고 불필요합니다. 
* 옵션 B(자동 확장 그룹): 자동 확장 그룹을 사용하여 비디오를 제공하는 것은 정적 
스토리지에 S3 를 활용하는 것에 비해 비용 효율이 낮습니다. 
* 옵션 D(Kinesis 비디오 스트림): Kinesis 비디오 스트림은 실시간 비디오 스트리밍을 위해 
설계되었으며, 사전 녹화된 비디오를 저장하고 제공하는 데 적합하지 않습니다. 
Q42 
한 회사가 AWS 클라우드에서 결제 처리 시스템을 운영합니다. 자금이 부족하거나 기술적 
문제로 인해 결제가 실패하면 사용자가 결제를 다시 제출하려고 시도하는 경우가 있습니다. 
때로는 결제 재제출로 인해 동일한 결제 ID 에 대한 여러 결제 메시지가 호출됩니다. 
솔루션 아키텍트는 결제 처리 시스템이 메시지가 생성된 시기에 따라 동일한 결제 ID 를 
가진 결제 메시지를 순차적으로 수신하도록 해야 합니다. 처리 시스템은 메시지를 수신한 
순서대로 메시지를 처리해야 합니다. 솔루션은 분석을 위해 모든 결제 메시지를 10 일 동안 
보관해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? (2 개 선택) 
A. 결제 ID 를 파티션 키로 사용하는 Amazon DynamoDB 테이블에 결제 메시지를 씁니다. 
B. 결제 ID 를 파티션 키로 사용하는 Amazon Kinesis 데이터 스트림에 결제 메시지를 
씁니다. 
C. 결제 ID 를 키로 사용하는 Amazon ElastiCache for Memcached 클러스터에 결제 
메시지를 씁니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열에 결제 메시지를 씁니다. 메시지 
속성을 설정하여 결제 ID 를 사용합니다. 
E. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 결제 메시지를 씁니다. 
메시지 그룹을 설정하여 결제 ID 를 사용합니다. 
Answer: B, E 
설명: 
Amazon Kinesis 와 SQS FIFO 대기열은 모두 메시지의 순차적 처리를 보장합니다. 
Kinesis 에서 결제 ID 를 파티션 키로 사용하거나 SQS FIFO 대기열에서 메시지 그룹으로 
사용하면 메시지가 순서대로 처리됩니다. 두 솔루션 모두 메시지를 장기간(최대 10 일) 
보관할 수 있으므로 이 결제 처리 사용 사례에 적합합니다. 
* 옵션 A(DynamoDB): DynamoDB 는 실시간 처리를 위한 메시지 순서를 보장하지 
않습니다. 
* 옵션 C(ElastiCache): ElastiCache 는 캐싱용이며 순차적 메시지 처리에는 적합하지 
않습니다. 
* 옵션 D(표준 SQS 대기열): 표준 SQS 대기열은 메시지 순서를 보장하지 않습니다. 
Q43 
한 회사에서 이메일 수집을 자동화하는 솔루션이 필요합니다. 이 회사는 이메일 메시지를 
자동으로 구문 분석하고, 이메일 첨부 파일을 찾고, 모든 첨부 파일을 거의 실시간으로 
Amazon S3 버킷에 저장해야 합니다. 
이메일 볼륨은 매일 크게 다릅니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon Simple Email Service(Amazon SES)에서 이메일 수신을 설정합니다. 규칙 세트와 
수신 규칙을 만듭니다. Amazon SES 에서 이메일 본문과 첨부 파일을 처리하기 위해 호출할 
수 있는 AWS Lambda 함수를 만듭니다. 
B. Amazon Simple Email Service(Amazon SES)에서 이메일 콘텐츠 필터링을 설정합니다. 
발신자, 수신자, 메시지 본문 및 첨부 파일을 기반으로 콘텐츠 필터링 규칙을 만듭니다. 
C. Amazon Simple Email Service(Amazon SES)에서 이메일 수신을 설정합니다. 이메일 
본문과 첨부 파일을 처리하도록 Amazon SES 및 S3 이벤트 알림을 구성합니다. 
D. 이메일 본문과 첨부 파일을 처리하는 AWS Lambda 함수를 만듭니다. Amazon 
EventBridge 를 사용하여 Lambda 함수를 호출합니다. 들어오는 이메일을 수신하도록 
EventBridge 규칙을 구성합니다. 
Answer: A 
설명: 
Amazon SES(Simple Email Service)를 사용하면 수신 이메일을 자동으로 수집할 수 
있습니다. SES 에서 이메일 수신을 설정하고 수신 규칙이 있는 규칙 세트를 만들면 SES 가 
이메일을 받을 때마다 AWS Lambda 함수를 호출하도록 구성할 수 있습니다. 그러면 
Lambda 함수가 이메일 본문과 첨부 파일을 처리하여 모든 첨부 파일을 Amazon S3 버킷에 
저장할 수 있습니다. 이 솔루션은 확장성이 뛰어나고 비용 효율적이며 최소한의 운영 
오버헤드로 거의 실시간으로 이메일을 처리합니다. 
* 옵션 B(콘텐츠 필터링): 이는 콘텐츠를 기준으로만 이메일을 필터링하며 S3 에 첨부 
파일을 저장하는 기능은 제공하지 않습니다. 
* 옵션 C(S3 이벤트 알림): SES 는 S3 에 이메일을 저장할 수 있지만 Lambda 가 있는 
SES 는 실시간으로 첨부 파일을 처리하는 데 더 많은 유연성을 제공합니다. 
* 옵션 D(EventBridge 규칙): EventBridge 는 수신 이메일을 직접 수신할 수 없으므로 이 
솔루션은 올바르지 않습니다. 
Q44 
한 회사에서 Amazon EC2 인스턴스 세트를 사용하여 웹사이트를 호스팅합니다. 이 
웹사이트는 Amazon S3 버킷을 사용하여 이미지와 미디어 파일을 저장합니다. 
이 회사는 웹사이트 인프라 생성을 자동화하여 여러 AWS 리전에 웹사이트를 배포하려고 
합니다. 또한 이 회사는 EC2 인스턴스에 S3 버킷에 대한 액세스 권한을 제공하여 
인스턴스가 AWS Identity and Access Management(IAM)를 사용하여 데이터를 저장하고 
액세스할 수 있도록 하려고 합니다. 
이러한 요구 사항을 가장 안전하게 충족하는 솔루션은 무엇입니까? 
A. 웹 서버 EC2 인스턴스에 대한 AWS CloudFormation 템플릿을 만듭니다. 
CloudFormation 템플릿의 AWS::EC2::Instance 엔터티의 UserData 섹션에 IAM 액세스 
키를 저장합니다. 
B. IAM 비밀 액세스 키와 액세스 키 ID 가 포함된 파일을 만듭니다. 새 S3 버킷에 파일을 
저장합니다. AWS CloudFormation 템플릿을 만듭니다. 템플릿에서 액세스 키와 액세스 키 
ID 가 포함된 S3 객체의 위치를 지정하는 매개변수를 만듭니다. 
C. 웹 서버 EC2 인스턴스가 S3 버킷에 액세스할 수 있도록 허용하는 IAM 역할과 IAM 
액세스 정책을 만듭니다. 웹 서버 EC2 인스턴스에 대한 AWS CloudFormation 템플릿을 
만듭니다. 여기에는 IAM 역할과 IAM 액세스 정책을 참조하는 IAM 인스턴스 프로필 
엔터티가 포함됩니다. 
D. IAM 에서 IAM 비밀 액세스 키와 액세스 키 ID 를 검색하여 웹 서버 EC2 인스턴스에 
저장하는 스크립트를 만듭니다. AWS CloudFormation 템플릿의 AWS::EC2::Instance 
엔터티의 UserData 섹션에 스크립트를 포함합니다. 
Answer: C 
설명: 
EC2 인스턴스가 S3 버킷에 액세스하도록 허용하는 가장 안전한 솔루션은 IAM 역할을 
사용하는 것입니다. 필요한 권한(예: S3 버킷 읽기 및 쓰기)을 부여하는 액세스 정책으로 
IAM 역할을 만들 수 있습니다. 그런 다음 IAM 역할은 IAM 인스턴스 프로필을 통해 EC2 
인스턴스와 연결됩니다. 
역할을 인스턴스와 연결하면 EC2 인스턴스가 역할을 안전하게 가정하고 인스턴스 
메타데이터 서비스를 통해 임시 자격 증명을 받을 수 있습니다. 이렇게 하면 인스턴스나 
애플리케이션 내에 자격 증명(예: 액세스 키)을 저장할 필요가 없으므로 보안이 강화되고 
자격 증명이 노출될 위험이 줄어듭니다. 
AWS CloudFormation 을 사용하면 EC2 인스턴스, IAM 역할 및 관련 정책을 포함한 전체 
인프라 생성을 자동화할 수 있습니다. 
AWS 참조: 
* EC2 인스턴스의 IAM 역할은 AWS 서비스에 대한 보안 액세스를 위해 IAM 역할을 
사용하는 방법을 설명합니다. 
* AWS CloudFormation 사용 설명서는 CloudFormation 템플릿을 사용하여 리소스를 
만들고 관리하는 방법을 자세히 설명합니다. 
다른 옵션이 틀린 이유: 
* A. IAM 액세스 키를 UserData 에 저장: 장기 자격 증명을 인스턴스 사용자 데이터에 
저장하여 노출될 수 있으므로 안전하지 않습니다. 
* B. 액세스 키를 S3 에 저장: 장기 자격 증명을 관리하고 배포해야 하므로 안전하지 
않습니다. 
* D. 스크립트를 통해 액세스 키 검색: 이 방법은 임시 자격 증명을 자동으로 제공하는 IAM 
역할을 사용하는 것보다 불필요하게 복잡하고 보안성이 떨어집니다. 
Q45 
한 회사에 여러 AWS 리전에 Amazon EC2 인스턴스가 있습니다. 모든 인스턴스는 동일한 
Amazon S3 버킷에서 기밀 데이터를 저장하고 검색합니다. 이 회사는 현재 아키텍처의 
보안을 개선하고자 합니다. 
이 회사는 VPC 내의 Amazon EC2 인스턴스만 S3 버킷에 액세스할 수 있도록 하려고 
합니다. 
이 회사는 버킷에 대한 다른 모든 액세스를 차단해야 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. IAM 정책을 사용하여 S3 버킷에 대한 액세스를 제한합니다. 
B. 서버 측 암호화(SSE)를 사용하여 S3 버킷의 데이터를 저장 중에 암호화합니다. EC2 
인스턴스에 암호화 키를 저장합니다. 
C. Amazon S3 에 대한 VPC 엔드포인트를 만듭니다. 엔드포인트에서만 연결을 허용하도록 
S3 버킷 정책을 구성합니다. 
D. 고객 관리 키와 함께 AWS Key Management Service(AWS KMS)를 사용하여 데이터를 
S3 버킷으로 보내기 전에 데이터를 암호화합니다. 
Answer: C 
설명: 
S3 에 대한 VPC 엔드포인트를 만들고 엔드포인트에서만 액세스할 수 있도록 버킷 정책을 
구성하면 VPC 내의 EC2 인스턴스만 S3 버킷에 액세스할 수 있습니다. 이 솔루션은 공개 
인터넷 액세스가 필요 없이 네트워크 수준에서 액세스를 제한하여 보안을 개선합니다. 
* 옵션 A(IAM 정책): IAM 정책만으로는 네트워크 위치에 따라 액세스를 제한할 수 
없습니다. 
* 옵션 B 및 D(암호화): 암호화는 저장 데이터를 보호하지만 버킷에 대한 네트워크 
액세스를 제한하지 않습니다. 
Q46 
물류 회사가 운송업체와 배송 상태 정보를 공유하기 위한 데이터 교환 플랫폼을 만들고 
있습니다. 
물류 회사는 모든 배송 정보와 메타데이터를 볼 수 있습니다. 이 회사는 운송업체에 배송 
데이터 업데이트를 배포합니다. 
각 운송업체는 회사와 관련된 배송 업데이트만 볼 수 있어야 합니다. 운송업체는 물류 
회사에서 볼 수 있는 전체 세부 정보를 볼 수 없습니다. 이 회사는 각 운송업체가 데이터를 
공유할 수 있도록 Amazon Simple Notification Service(Amazon SNS) 주제를 만듭니다. 일부 
운송업체는 모바일 앱을 사용하여 배송 상태 업데이트를 제출합니다. 
이 회사는 각 운송업체가 회사와 관련된 데이터에 대한 특정 액세스 권한을 제공하는 
데이터 교환 플랫폼을 만들어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족할까요? 
A. 모바일 앱에서 배송 업데이트를 Amazon Simple Queue Service(Amazon SQS)로 
수집합니다. 
SNS 주제에 업데이트를 게시합니다. 필터 정책을 적용하여 각 메시지의 본문을 다시 
작성합니다. 
B. 모바일 앱에서 배송 업데이트를 Amazon Simple Queue Service(Amazon SQS)로 
수집합니다. 
AWS Lambda 함수를 사용하여 Amazon SQS 에서 업데이트를 사용하고 각 메시지의 본문을 
다시 작성합니다. 업데이트를 SNS 주제에 게시합니다. 
C. 모바일 앱에서 두 번째 SNS 주제로 배송 업데이트를 수집합니다. 업데이트를 운송업체 
SNS 주제에 게시합니다. 필터 정책을 적용하여 각 메시지의 본문을 다시 작성합니다. 
D. 모바일 앱에서 Amazon Simple Queue Service(Amazon SQS)로 배송 업데이트를 
수집합니다. Amazon EventBridge Pipes 에서 메시지를 필터링하고 다시 작성합니다. 
업데이트를 SNS 주제에 게시합니다. 
Answer: B 
설명: 
가장 좋은 해결책은 Amazon SQS 를 사용하여 모바일 앱에서 업데이트를 수신하고 AWS 
Lambda 함수로 처리하는 것입니다. Lambda 함수는 각 운송업체에 대해 필요에 따라 
메시지 본문을 다시 작성한 다음 배포를 위해 적절한 SNS 주제에 업데이트를 게시할 수 
있습니다. 이 설정은 각 운송업체가 관련 데이터만 수신하고 관리형 서비스를 사용하여 
운영 오버헤드를 최소화하도록 합니다. 
* 옵션 A(SNS 필터 정책): SNS 에는 전달하기 전에 메시지 본문을 다시 쓸 수 있는 기능이 
없습니다. 
* 옵션 C(두 번째 SNS 토픽): 추가 SNS 토픽을 사용하면 메시지 재작성 요구 사항을 
해결하지 않고 불필요한 복잡성이 추가됩니다. 
* 옵션 D(EventBridge Pipes): EventBridge Pipes 는 이 사용 사례에 필요한 것보다 더 
복잡하고 Lambda 는 로직을 더 효율적으로 처리할 수 있습니다. 
Q47 
한 회사에서 최근 한 AWS 지역에서 고가용성을 제공하는 새로운 제품을 출시했습니다. 이 
제품은 Amazon Elastic Container Service(Amazon ECS)에서 실행되는 애플리케이션, 
퍼블릭 Application Load Balancer(ALB) 및 Amazon DynamoDB 테이블로 구성되어 
있습니다. 이 회사는 여러 지역에서 애플리케이션을 고가용성으로 만들어 주는 솔루션을 
원합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3 개 선택) 
A. 다른 지역에서 새 ALB 를 통해 액세스할 수 있는 새 ECS 클러스터에 애플리케이션을 
배포합니다. 
B. Amazon Route 53 장애 조치 레코드를 만듭니다. 
C. DynamoDB 테이블을 수정하여 DynamoDB 글로벌 테이블을 만듭니다. 
D. 같은 지역에서 새 ALB 를 통해 액세스할 수 있는 Amazon Elastic Kubernetes 
Service(Amazon EKS) 클러스터에 애플리케이션을 배포합니다. 
E. DynamoDB 테이블을 수정하여 글로벌 보조 인덱스(GSI)를 만듭니다. 
F. 애플리케이션에 대한 AWS PrivateLink 엔드포인트를 만듭니다. 
Answer: A, B, C 
설명: 
애플리케이션을 여러 지역에서 고가용성으로 만들려면: 
* 새로운 ECS 클러스터와 ALB 를 사용하여 다른 지역에 애플리케이션을 배포하여 지역 
중복성을 보장합니다. 
* Route 53 장애 조치 라우팅을 사용하여 장애 발생 시 트래픽을 자동으로 정상 지역으로 
전달합니다. 
* DynamoDB 글로벌 테이블을 사용하여 데이터베이스가 여러 지역에서 복제되고 사용 
가능하도록 보장하여 각 지역에서 읽기 및 쓰기 작업을 지원합니다. 
* 옵션 D(동일한 지역의 EKS 클러스터): 이는 지역 중복성을 제공하지 않습니다. 
* 옵션 E(글로벌 보조 인덱스): GSI 는 쿼리 성능을 개선하지만 다중 지역 가용성을 
제공하지 않습니다. 
* 옵션 F(PrivateLink): PrivateLink 는 보안 통신을 위한 것이지 지역 간 고가용성을 위한 
것이 아닙니다. 
Q48 
한 회사에서 온프레미스 데이터 센터에서 AWS 클라우드의 새 VPC 로 새 애플리케이션을 
마이그레이션하고 있습니다. 
이 회사에는 여러 서브넷과 애플리케이션을 공유하는 여러 AWS 계정과 VPC 가 있습니다. 
이 회사는 새 애플리케이션에 대한 세분화된 액세스 제어를 원합니다. 이 회사는 새 
애플리케이션에 대한 액세스 권한이 부여된 계정과 VPC 의 모든 네트워크 리소스가 
애플리케이션에 액세스할 수 있도록 하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 새 애플리케이션 VPC 에 액세스해야 하는 각 VPC 에 대한 VPC 피어링 연결을 
설정합니다. 각 VPC 에서 경로 테이블을 업데이트하여 연결을 활성화합니다. 
B. 새 애플리케이션을 호스팅하는 계정에 전송 게이트웨이를 배포합니다. 애플리케이션에 
연결해야 하는 각 계정과 전송 게이트웨이를 공유합니다. 새 애플리케이션을 호스팅하는 
VPC 와 전송 게이트웨이에서 경로 테이블을 업데이트하여 연결을 활성화합니다. 
C. AWS PrivateLink 엔드포인트 서비스를 사용하여 다른 VPC 에서 새 애플리케이션에 
액세스할 수 있도록 합니다. 
엔드포인트 정책을 사용하여 애플리케이션에 대한 액세스를 제어합니다. 
D. 애플리케이션 로드 밸런서(ALB)를 사용하여 새 애플리케이션을 인터넷에 노출합니다. 
인증 및 권한 부여 프로세스를 구성하여 지정된 VPC 만 애플리케이션에 액세스할 수 
있도록 합니다. 
Answer: B 
설명: 
* A. VPC 피어링: 여러 VPC 를 관리하기 복잡한 완전 메시 아키텍처를 만듭니다. 
* B. 트랜짓 게이트웨이: 중앙 허브를 통해 여러 VPC 와 온프레미스 네트워크를 연결하여 
네트워크 관리를 간소화합니다. 
* C. PrivateLink: 애플리케이션 엔드포인트와의 통신을 제한하지만 전체 VPC 연결을 
허용하지 않을 수 있습니다. 
* D. 인터넷 노출이 있는 ALB: 안전하지 않거나 개인 네트워크 통신에만 국한되지 
않습니다. 
Q49 
한 회사에서 수요 급증에 대응하고 주문된 프로세스를 처리하기 위해 확장해야 하는 소셜 
미디어 애플리케이션을 개발하고 있습니다. 
어떤 AWS 서비스가 이러한 요구 사항을 충족합니까? 
A. 분리를 위한 Fargate, RDS, SQS 가 있는 ECS. 
B. 분리를 위한 Fargate, RDS, SNS 가 있는 ECS. 
C. DynamoDB, Lambda, DynamoDB Streams, Step Functions. 
D. 분리를 위한 Elastic Beanstalk, RDS, SNS. 
Answer: A 
* 옵션 A 는 확장성을 위해 ECS 와 Fargate 를 결합하고, 관계형 데이터를 위해 RDS 를 
결합하고, 메시지 순서(FIFO 대기열)를 통해 분리를 위해 SQS 를 결합합니다. 
* 옵션 B 는 메시지 순서를 유지하지 않는 SNS 를 사용합니다. 
* 옵션 C 는 서버리스 워크플로에는 적합하지만 관계형 데이터는 적합하지 않습니다. 
* 옵션 D 는 확장에 대한 유연성이 낮은 Elastic Beanstalk 에 의존합니다. 
Q50 
한 회사에서 AWS Secrets Manager 에 저장된 RDS 자격 증명에 액세스해야 하는 EC2 
인스턴스에서 애플리케이션을 실행합니다. 
어떤 솔루션이 이 요구 사항을 충족합니까? 
A. IAM 역할을 만들고 각 EC2 인스턴스 프로필에 역할을 연결합니다. ID 기반 정책을 
사용하여 역할에 비밀에 대한 액세스 권한을 부여합니다. 
B. IAM 사용자를 만들고 각 EC2 인스턴스 프로필에 사용자를 연결합니다. 리소스 기반 
정책을 사용하여 사용자에게 비밀에 대한 액세스 권한을 부여합니다. 
C. 비밀에 대한 리소스 기반 정책을 만듭니다. EC2 Instance Connect 를 사용하여 비밀에 
액세스합니다. 
D. 비밀에 대한 ID 기반 정책을 만듭니다. EC2 인스턴스에 대한 직접 액세스 권한을 
부여합니다. 
Answer: A 
* 옵션 A 는 EC2 인스턴스 프로필에 연결된 IAM 역할을 사용하여 Secrets Manager 에 대한 
안전하고 자동화된 액세스를 가능하게 합니다. 이는 권장되는 접근 방식입니다. 
* 옵션 B 는 IAM 사용자를 사용하는데, 이는 보안성이 낮고 관리하기 어렵습니다. 
* 옵션 C 는 프로그래밍 방식으로 비밀에 액세스하는 데 실용적이지 않습니다. 
* 옵션 D 는 EC2 인스턴스에 대한 직접 액세스 권한을 부여하여 모범 사례를 위반합니다. 
Q51 
한 회사에 동적 트래픽 부하를 처리하는 웹사이트가 있습니다. 웹사이트 아키텍처는 예약된 
스케일링을 사용하도록 구성된 자동 스케일링 그룹의 Amazon EC2 인스턴스를 기반으로 
합니다. 
각 EC2 인스턴스는 Amazon Elastic File System(Amazon EFS) 볼륨에서 코드를 실행하고 
공유 데이터를 동일한 볼륨에 다시 저장합니다. 
이 회사는 웹사이트 비용을 최적화하려고 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 자동 스케일링 그룹을 재구성하여 원하는 인스턴스 수를 설정합니다. 예약된 스케일링을 
끕니다. 
B. 더 큰 EC2 인스턴스를 사용하는 자동 스케일링 그룹에 대한 새 시작 템플릿 버전을 
만듭니다. 
C. 대상 추적 스케일링 정책을 사용하도록 자동 스케일링 그룹을 재구성합니다. 
D. EFS 볼륨을 인스턴스 스토어 볼륨으로 바꿉니다. 
Answer: C 
설명: 
* A. 고정된 원하는 인스턴스: 트래픽 부하 변동에 적응하지 못해 비효율성이 발생합니다. 
* B. 더 큰 EC2 인스턴스: 불필요하게 비용이 증가합니다. 
* C. 대상 추적 확장 정책: 실제 수요에 따라 용량을 조정하여 비용을 최적화합니다. 
* D. 인스턴스 스토어 볼륨: 지속적이지 않으며 인스턴스 간 공유 데이터에 적합하지 
않습니다. 
Q52 
한 회사에서 고가용성 자연어 처리(NLP) 애플리케이션을 개발하고 있습니다. 이 
애플리케이션은 대량의 동시 요청을 처리합니다. 이 애플리케이션은 엔터티 인식, 감정 
분석, 텍스트 데이터에 대한 핵심 구문 추출과 같은 NLP 작업을 수행합니다. 이 회사는 
애플리케이션이 처리하는 데이터를 고가용성 및 확장 가능한 데이터베이스에 저장해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 들어오는 요청을 처리하기 위한 Amazon API Gateway REST API 엔드포인트를 만듭니다. 
각 요청에 대해 AWS Lambda 함수를 호출하도록 REST API 를 구성합니다. 텍스트 데이터에 
대한 NLP 작업을 수행하기 위해 Amazon Comprehend 를 호출하도록 Lambda 함수를 
구성합니다. 처리된 데이터를 Amazon DynamoDB 에 저장합니다. 
B. 들어오는 요청을 처리하기 위한 Amazon API Gateway HTTP API 엔드포인트를 만듭니다. 
각 요청에 대해 AWS Lambda 함수를 호출하도록 HTTP API 를 구성합니다. 텍스트 데이터에 
대한 NLP 작업을 수행하기 위해 Amazon Translate 를 호출하도록 Lambda 함수를 
구성합니다. 처리된 데이터를 Amazon ElastiCache 에 저장합니다. 
C. 들어오는 요청을 버퍼링하기 위한 Amazon SQS 대기열을 만듭니다. Amazon EC2 
인스턴스의 자동 확장 그룹에 NLP 애플리케이션을 배포합니다. Amazon Comprehend 를 
사용하여 NLP 작업을 수행합니다. 처리된 데이터를 Amazon RDS 데이터베이스에 
저장합니다. 
D. 들어오는 요청을 처리하기 위해 Amazon API Gateway WebSocket API 엔드포인트를 
만듭니다. 각 요청에 대해 AWS Lambda 함수를 호출하도록 WebSocket API 를 구성합니다. 
Lambda 함수를 구성하여 Amazon Textract 를 호출하여 텍스트 데이터에서 NLP 작업을 
수행합니다. 처리된 데이터를 Amazon ElastiCache 에 저장합니다. 
Answer: A 
설명: 
* A. API Gateway + DynamoDB: NLP 작업을 위해 높은 확장성, 낮은 대기 시간 및 Amazon 
Comprehend 와의 원활한 통합을 제공합니다. 
* B. HTTP API + Translate + ElastiCache: Translate 는 감정 분석이나 엔터티 인식과 같은 
NLP 작업과 관련이 없습니다. ElastiCache 는 영구 저장소에 적합하지 않습니다. 
* C. SQS + EC2 + RDS: 복잡성과 운영 오버헤드가 증가합니다. RDS 는 동시 부하가 많을 때 
효과적으로 확장되지 않을 수 있습니다. 
* D. WebSocket API + Textract: Textract 는 NLP 작업과 관련이 없습니다. WebSocket API 는 
이 사용 사례에 최적의 선택이 아닙니다. 
Q53 
한 회사에서 AWS 계정에 액세스할 수 있는 개인 데이터 센터에서 실행되는 타사 시스템을 
제공하려고 합니다. 이 회사는 타사 시스템에서 직접 AWS API 를 호출하려고 합니다. 
이 회사에는 디지털 인증서를 관리하기 위한 기존 프로세스가 있습니다. 이 회사는 SAML 
또는 OpenID Connect(OIDC) 기능을 사용하고 싶지 않으며 장기 AWS 자격 증명을 
저장하고 싶지 않습니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 통신 채널의 클라이언트 및 서버 측 인증을 허용하도록 상호 TLS 를 구성합니다. 
B. AWS Signature Version 4 를 구성하여 AWS API 에 대한 수신 HTTPS 요청을 인증합니다. 
C. Kerberos 를 구성하여 AWS API 에서 검증할 수 있는 어설션에 대한 티켓을 교환합니다. 
D. AWS Identity and Access Management(IAM) Roles Anywhere 를 구성하여 X.509 인증서를 
AWS 자격 증명으로 교환하여 AWS API 와 상호 작용합니다. 
Answer: D 
설명: 
* A. 상호 TLS: 보안 통신을 제공하지만 AWS 자격 증명 교환과 통합되지 않습니다. 
* B. AWS Signature v4: AWS 와 직접 통합해야 하며 외부 시스템에 대한 보안이 낮습니다. 
* C. Kerberos: AWS API 인증에 기본적으로 지원되지 않습니다. 
* D. IAM Roles Anywhere: 장기 자격 증명 없이 X.509 인증서를 사용하여 AWS API 
액세스를 활성화합니다. 
Q54 
한 회사에서 Amazon API Gateway REST API 와 AWS Lambda 함수를 사용하여 API 를 
개발했습니다. 이 API 는 전 세계 사용자에게 정적 및 동적 콘텐츠를 제공합니다. 이 회사는 
API 요청에 대한 콘텐츠 전송 대기 시간을 줄이려고 합니다. 전 세계 사용자의 대기 시간을 
어떻게 줄일 수 있습니까? 
A. REST API 를 엣지 최적화 API 엔드포인트로 배포합니다. 캐싱을 활성화합니다. 전송 중인 
데이터를 압축하기 위해 콘텐츠 인코딩을 활성화합니다. 
B. REST API 를 지역 API 엔드포인트로 배포합니다. 캐싱을 활성화합니다. 전송 중인 
데이터를 압축하기 위해 콘텐츠 인코딩을 활성화합니다. 
C. REST API 를 엣지 최적화 API 엔드포인트로 배포합니다. 캐싱을 활성화합니다. Lambda 
함수에 대한 예약된 동시성을 구성합니다. 
D. REST API 를 지역 API 엔드포인트로 배포합니다. 캐싱을 활성화합니다. Lambda 함수에 
대한 예약된 동시성을 구성합니다. 
Answer: A 
* 엣지 최적화 API 엔드포인트는 CloudFront 를 통해 요청을 라우팅하여 글로벌 사용자의 
대기 시간을 줄입니다. 
* 옵션 A 는 대기 시간을 최소화하기 위해 엣지 최적화, 캐싱 및 압축을 올바르게 
구현합니다. 
* 옵션 B 와 D 는 엣지 최적화를 사용하지 않아 글로벌 사용자의 대기 시간이 길어집니다. 
* 옵션 C 와 D 의 예약된 동시성은 백엔드 확장성을 개선하지만 글로벌 지연 시간을 직접 
해결하지는 못합니다. 
Q55 
DynamoDB 데이터를 최소한의 운영 오버헤드로 장기 분석에 사용할 수 있는 방법은 
무엇입니까? 
A. S3 에 대한 DynamoDB 증분 내보내기를 구성합니다. 
B. S3 에 레코드를 쓰도록 DynamoDB Streams 를 구성합니다. 
C. DynamoDB 데이터를 S3 에 복사하도록 EMR 을 구성합니다. 
D. DynamoDB 데이터를 HDFS 에 복사하도록 EMR 을 구성합니다. 
Answer: A 
* 옵션 A 는 분석을 위해 S3 에 데이터를 내보내기 위한 가장 자동화되고 비용 효율적인 
솔루션입니다. 
* 옵션 B 는 S3 에 대한 Streams 의 수동 설정을 포함합니다. 
* 옵션 C 와 D 는 EMR 에 복잡성을 도입합니다. 
Q56 
웹사이트에서 Auto Scaling 및 EFS 가 있는 EC2 인스턴스를 사용합니다. 이 회사는 어떻게 
비용을 최적화할 수 있습니까? 
A. Auto Scaling 그룹을 재구성하여 원하는 수의 인스턴스를 설정합니다. 예약된 스케일링을 
끕니다. 
B. 더 큰 EC2 인스턴스를 사용하는 새 시작 템플릿 버전을 만듭니다. 
C. Auto Scaling 그룹을 재구성하여 대상 추적 스케일링 정책을 사용합니다. 
D. EFS 볼륨을 인스턴스 스토어 볼륨으로 바꿉니다. 
Answer: C 
* 옵션 C 는 대상 추적 스케일링 정책을 사용하여 수요에 따라 동적 스케일링을 보장하여 
비용을 최적화합니다. 
* 옵션 A 는 과도한 프로비저닝으로 인해 비용이 증가합니다. 
* 옵션 B 는 더 큰 인스턴스를 사용하여 비용을 증가시킵니다. 
* 옵션 D 는 인스턴스 스토어 볼륨이 일시적이고 EFS 와 같은 공유 스토리지에 적합하지 
않기 때문에 실행 불가능합니다. 
Q57 
한 회사에서 개발팀에 대한 새로운 보안 규정 준수 요구 사항을 구현하여 승인된 Amazon 
Machine Images(AMI) 사용을 제한하려고 합니다. 
이 회사는 모든 Amazon EC2 인스턴스에 대해 승인된 운영 체제와 소프트웨어에만 액세스 
권한을 제공하려고 합니다. 이 회사는 솔루션이 EC2 인스턴스를 시작하기 위한 리드 
타임을 최소화하기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 승인된 AMI 로 시작된 EC2 인스턴스만 포함하는 AWS Service Catalog 를 사용하여 
포트폴리오를 만듭니다. 모든 필수 소프트웨어가 AMI 에 사전 설치되어 있는지 확인합니다. 
개발자가 포트폴리오를 사용할 수 있도록 필요한 권한을 만듭니다. 
B. EC2 Image Builder 를 사용하여 승인된 운영 체제와 소프트웨어가 포함된 AMI 를 
만듭니다. 
개발자에게 해당 AMI 에 대한 액세스 권한을 부여하여 EC2 인스턴스를 시작합니다. 
C. 승인된 운영 체제가 포함된 AMI 를 만듭니다. 개발자에게 승인된 AMI 를 사용하도록 
지시합니다. 새 EC2 인스턴스가 시작될 때 AWS Systems Manager 스크립트를 실행하는 
Amazon EventBridge 규칙을 만듭니다. 리포지토리에서 필요한 소프트웨어를 설치하도록 
스크립트를 구성합니다. 
D. 승인되지 않은 AMI 로 EC2 인스턴스가 시작되는 것을 감지하기 위한 AWS Config 
규칙을 만듭니다. 해당 인스턴스를 종료하고 승인된 AMI 로 인스턴스를 다시 시작하기 위한 
수정 규칙을 연결합니다. AWS Systems Manager 를 사용하여 EC2 인스턴스가 시작될 때 
승인된 소프트웨어를 자동으로 설치합니다. 
Answer: A 
설명: 
AWS Service Catalog 는 조직이 사용자가 배포할 수 있는 승인된 제품(AMI 포함) 
카탈로그를 관리할 수 있도록 설계되었습니다. 사전 승인된 AMI 로 시작된 EC2 인스턴스만 
포함된 포트폴리오를 만들면 회사는 모든 EC2 인스턴스에 대해 승인된 운영 체제 및 
소프트웨어의 준수를 강제할 수 있습니다. Service Catalog 는 또한 EC2 인스턴스 시작 
프로세스를 간소화하여 리드 타임을 줄이는 동시에 개발자가 승인된 구성만 사용하도록 
합니다. 
* 옵션 B(EC2 Image Builder): EC2 Image Builder 는 AMI 를 만들고 관리하는 데 도움이 
되지만 Service Catalog 가 제공하는 강제 메커니즘은 제공하지 않습니다. 
* 옵션 C(EventBridge 규칙 및 Systems Manager 스크립트): 이 솔루션은 반응형이며 
Service Catalog 에 비해 운영상 복잡성이 더 큽니다. 
* 옵션 D(AWS Config 규칙): 이 옵션은 반응형(비준수 인스턴스를 시작 후 종료)이며 
추가적인 운영 오버헤드를 발생시킵니다. 
Q58 
한 회사가 상당한 양의 민감한 고객 데이터를 저장하는 AWS 환경의 보안을 강화하고 
있습니다. 이 회사에는 여러 Amazon S3 버킷에 저장된 민감한 데이터를 자동으로 
식별하고 분류하는 솔루션이 필요합니다. 이 솔루션은 데이터 침해에 자동으로 대응하고 
규정을 준수하지 않는 데이터가 발견되면 즉시 이메일을 통해 회사 보안 팀에 경고해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon GuardDuty 를 사용합니다. AWS Lambda 함수를 구성하여 알림을 Amazon 
Simple Notification Service(Amazon SNS) 주제로 라우팅합니다. 보안 팀을 SNS 주제에 
구독합니다. 
B. Amazon GuardDuty 를 사용합니다. AWS Lambda 함수를 구성하여 알림을 Amazon 
Simple Queue Service(Amazon SQS) 대기열로 라우팅합니다. 두 번째 Lambda 함수를 
구성하여 SQS 대기열을 주기적으로 폴링하고 Amazon Simple Email Service(Amazon 
SES)를 사용하여 보안 팀에 이메일을 보냅니다. 
C. Amazon Macie 를 사용합니다. Amazon EventBridge 를 Macie 와 통합하고 EventBridge 를 
구성하여 Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 보냅니다. 보안 
팀을 SNS 토픽에 구독합니다. 
D. Amazon Macie 를 사용합니다. Amazon EventBridge 를 Macie 와 통합하고 EventBridge 를 
구성하여 알림을 Amazon Simple Queue Service(Amazon SQS) 대기열로 라우팅합니다. 
AWS Lambda 함수를 구성하여 SQS 대기열을 주기적으로 폴링하고 Amazon Simple Email 
Service(Amazon SES)를 사용하여 보안 팀에 알림을 보냅니다. 
Answer: C 
설명: 
* A & B. GuardDuty: 위협 탐지용으로 설계되었으며 S3 버킷에서 민감한 데이터를 
식별하거나 분류하기 위한 것이 아닙니다. 
* C. EventBridge + SNS 가 있는 Macie: 민감한 데이터를 자동으로 식별하고 알림을 
트리거하며 SNS 를 사용하여 이메일을 통해 즉시 알림을 보냅니다. 
* D. EventBridge + SQS 가 있는 Macie: 주기적 폴링으로 인해 지연이 발생하고 불필요한 
복잡성이 추가됩니다. 
Q59 
한 회사가 AWS 에서 주문 관리 애플리케이션을 실행합니다. 이 애플리케이션을 사용하면 
고객이 주문을 하고 신용 카드로 결제할 수 있습니다. 이 회사는 Amazon CloudFront 
배포를 사용하여 애플리케이션을 제공합니다. 
보안 팀은 모든 수신 요청에 대한 로깅을 설정했습니다. 보안 팀은 사용자가 로깅 구성을 
수정하는 경우 알림을 생성하는 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (2 개 선택) 
A. 사용자가 CloudFront 배포를 생성하거나 수정할 때 호출되는 Amazon EventBridge 
규칙을 구성합니다. AWS Lambda 함수를 EventBridge 규칙의 대상으로 추가합니다. 
B. Application Load Balancer(ALB)를 만듭니다. ALB 에 대한 AWS WAF 규칙을 
활성화합니다. 보안 위반을 감지하도록 AWS Config 규칙을 구성합니다. 
C. CloudFront 배포 로깅의 변경 사항을 감지하는 AWS Lambda 함수를 만듭니다. Lambda 
함수가 Amazon Simple Notification Service(Amazon SNS)를 사용하여 보안 팀에 알림을 
보내도록 구성합니다. 
D. Amazon GuardDuty 를 설정합니다. GuardDuty 를 구성하여 CloudFront 배포의 결과를 
모니터링합니다. AWS Lambda 함수를 만들어 결과를 처리합니다. 
E. Amazon API Gateway 에서 개인 API 를 만듭니다. AWS WAF 규칙을 사용하여 개인 API 를 
일반적인 보안 문제로부터 보호합니다. 
Answer: A, C 
설명: 
* A. EventBridge 규칙: CloudFront 배포의 수정 사항을 실시간으로 감지하고 Lambda 
함수를 트리거하여 추가 작업을 수행합니다. 
* B. ALB + Config: CloudFront 로깅 변경과는 관련이 없는 ALB 보안 위반에 초점을 
맞춥니다. 
* C. Lambda + SNS: 로깅 구성의 변경 사항에 대한 실시간 알림을 제공합니다. 
* D. GuardDuty: 로깅 구성 변경이 아닌 위협 감지에 초점을 맞춥니다. 
* E. API Gateway + WAF: CloudFront 로깅 변경과 관련이 없습니다. 
Q60 
한 회사에서 높은 IOPS 가 필요한 HPC 워크로드를 실행합니다. 
다음 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. Amazon EFS 를 고성능 파일 시스템으로 사용합니다. 
B. Amazon FSx for Lustre 를 고성능 파일 시스템으로 사용합니다. 
C. EC2 인스턴스의 자동 확장 그룹을 만듭니다. 예약 인스턴스를 사용합니다. 분산 배치 
그룹을 구성합니다. 분석에 AWS Batch 를 사용합니다. 
D. Amazon S3 의 Mountpoint 를 고성능 파일 시스템으로 사용합니다. 
E. EC2 인스턴스의 자동 확장 그룹을 만듭니다. 혼합 인스턴스 유형과 클러스터 배치 
그룹을 사용합니다. 분석에 Amazon EMR 을 사용합니다. 
Answer: B, E 
* 옵션 B: FSx for Lustre 는 높은 IOPS 가 있는 HPC 워크로드를 위해 설계되었습니다. 
* 옵션 E: 클러스터 배치 그룹은 HPC 분석 워크로드에 대한 저지연 네트워킹을 
보장합니다. 
* 옵션 A: Amazon EFS 는 HPC 에 최적화되지 않았습니다. 
* 옵션 D: S3 의 Mountpoint 는 높은 IOPS 요구 사항을 충족하지 못합니다. 
Q61 
로펌은 특정 미래 날짜까지 수정이나 삭제를 방지하면서 파일을 공개적으로 읽을 수 있게 
하려면 어떻게 해야 합니까? 
A. 정적 웹사이트 호스팅을 위해 구성된 Amazon S3 버킷에 파일을 업로드합니다. 모든 
AWS 주체에게 읽기 전용 IAM 권한을 부여합니다. 
B. S3 버킷을 만듭니다. S3 버전 관리를 활성화합니다. 보존 기간이 있는 S3 객체 잠금을 
사용합니다. CloudFront 배포를 만듭니다. 버킷 정책을 사용하여 액세스를 제한합니다. 
C. S3 버킷을 만듭니다. S3 버전 관리를 활성화합니다. AWS Lambda 로 이벤트 트리거를 
구성하여 개인 S3 버킷에서 수정된 객체를 복원합니다. 
D. 정적 웹사이트 호스팅을 위해 S3 버킷에 파일을 업로드합니다. 보존 기간이 있는 S3 
객체 잠금을 사용합니다. 읽기 전용 IAM 권한을 부여합니다. 
Answer: B 
* 옵션 B 는 불변성에 대한 규정 준수를 충족하기 위해 S3 객체 잠금 및 버전 관리를 
사용합니다. 
CloudFront 는 성능을 향상시키는 반면 버킷 정책은 안전한 액세스를 보장합니다. 
* 옵션 A 에는 불변성 보호 장치가 없습니다. 
* 옵션 C 는 불필요한 복잡성을 도입합니다. 
* 옵션 D 는 CloudFront 가 제공하는 추가적인 보안 이점을 활용할 수 없습니다. 
Q62 
DynamoDB 의 거래 데이터를 거의 실시간 분석을 위해 S3 데이터 레이크로 수집하려면 
어떻게 해야 합니까? 
A. DynamoDB Streams 를 사용하여 S3 에 쓰는 Lambda 함수를 호출합니다. 
B. DynamoDB Streams 를 사용하여 S3 에 쓰는 Data Firehose 에 쓰는 Lambda 함수를 
호출합니다. 
C. DynamoDB 에서 Kinesis Data Streams 를 활성화합니다. S3 에 쓰는 Lambda 함수를 
호출하도록 구성합니다. 
D. DynamoDB 에서 Kinesis Data Streams 를 활성화합니다. Data Firehose 를 사용하여 S3 에 
씁니다. 
Answer: A 
* 옵션 A 는 DynamoDB Streams 와 Lambda 를 사용하여 S3 에 실시간으로 수집하는 가장 
간단한 솔루션입니다. 
* 옵션 B, C, D 는 Data Firehose 또는 Kinesis 와 함께 불필요한 복잡성을 추가합니다. 
Q63 
국제적인 회사에서 Amazon S3 버킷의 데이터를 전 세계에 있는 직원과 공유해야 합니다. 
이 회사에는 직원에게 S3 버킷에 대한 액세스 권한을 제공하는 보안 솔루션이 필요합니다. 
직원은 이미 AWS IAM Identity Center 에 등록되어 있습니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. 각 직원에 대해 Amazon S3 사전 서명 URL 을 생성하는 헬프 데스크 애플리케이션을 
만듭니다. 사전 서명 URL 이 만료 기간이 짧도록 구성합니다. 직원에게 회사 헬프 데스크에 
연락하여 S3 버킷에 액세스할 수 있는 사전 서명 URL 을 받도록 지시합니다. 
B. IAM Identity Center 에서 Amazon S3 액세스를 위한 그룹을 만듭니다. S3 버킷에 
액세스해야 하는 직원을 그룹에 추가합니다. 그룹에서 Amazon S3 액세스를 허용하는 IAM 
정책을 만듭니다. 
직원에게 AWS 액세스 포털을 사용하여 AWS Management Console 에 액세스하고 S3 
버킷으로 이동하도록 지시합니다. 
C. Amazon S3 파일 게이트웨이를 만듭니다. 데이터 업로드를 위한 공유 하나와 데이터 
다운로드를 위한 공유 하나를 만듭니다. Amazon EC2 인스턴스에서 SFTP 서비스를 
설정합니다. EC2 인스턴스에 공유를 마운트합니다. 직원들에게 SFTP 서버를 사용하도록 
지시합니다. 
D. AWS Transfer Family SFTP 엔드포인트를 구성합니다. 사용자 지정 ID 공급자 옵션을 
선택합니다. AWS Secrets Manager 를 사용하여 사용자 자격 증명을 관리합니다. 직원들에게 
Transfer Family SFTP 를 사용하도록 지시합니다. 
Answer: B 
Q64 
전자상거래 회사가 온프레미스 Microsoft SQL Server 데이터베이스를 AWS 클라우드로 
마이그레이션할 계획입니다. 이 회사는 데이터베이스를 SQL Server Always On 가용성 
그룹으로 마이그레이션해야 합니다. 클라우드 기반 솔루션은 고가용성이어야 합니다. 
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 3 개의 가용성 영역에 SQL Server 가 있는 3 개의 Amazon EC2 인스턴스를 배포합니다. 
EC2 인스턴스에 Amazon Elastic Block Store(Amazon EBS) 볼륨 하나를 연결합니다. 
B. 데이터베이스를 SQL Server 용 Amazon RDS 로 마이그레이션합니다. 다중 AZ 배포를 
구성하고 복제본을 읽습니다. 
C. 3 개의 가용성 영역에 SQL Server 가 있는 3 개의 Amazon EC2 인스턴스를 배포합니다. 
Amazon FSx for Windows File Server 를 스토리지 계층으로 사용합니다. 
D. 3 개의 가용성 영역에 SQL Server 가 있는 3 개의 Amazon EC2 인스턴스를 배포합니다. 
Amazon S3 를 스토리지 계층으로 사용합니다. 
Answer: C 
설명: 
* A. EBS 가 있는 EC2: SQL Server Always On 가용성 그룹을 효과적으로 지원하지 
않습니다. 
* B. RDS Multi-AZ: 고가용성을 제공하지만 SQL Server Always On 가용성 그룹은 지원하지 
않습니다. 
* C. EC2 with FSx for Windows: FSx 가 SQL Server 클러스터링과 호환되는 공유 스토리지를 
제공하므로 SQL Server Always On 에 가장 적합한 솔루션입니다. 
* D. EC2 with S3: S3 는 SQL Server 스토리지에 적합하지 않습니다. 
Q65 
한 회사가 AWS 에서 다중 계층 재고 보고 애플리케이션을 호스팅합니다. 이 회사는 수요에 
따라 재고 보고서를 생성할 수 있는 비용 효율적인 솔루션이 필요합니다. 관리자는 새 
보고서를 생성할 수 있어야 합니다. 보고서를 완료하는 데 약 5~10 분이 걸립니다. 
애플리케이션은 각 보고서를 생성하는 관리자 사용자의 이메일 주소로 보고서를 보내야 
합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? 
A. Amazon Elastic Container Service(Amazon ECS)를 사용하여 보고서 생성 코드를 
호스팅합니다. Amazon API Gateway HTTP API 를 사용하여 코드를 호출합니다. Amazon 
Simple Email Service(Amazon SES)를 사용하여 보고서를 관리자 사용자에게 보냅니다. 
B. Amazon EventBridge 를 사용하여 예약된 AWS Lambda 함수를 호출하여 보고서를 
생성합니다. Amazon Simple Notification Service(Amazon SNS)를 사용하여 보고서를 관리자 
사용자에게 보냅니다. 
C. Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 보고서 생성 코드를 
호스팅합니다. Amazon API Gateway REST API 를 사용하여 코드를 호출합니다. Amazon 
Simple Notification Service(Amazon SNS)를 사용하여 보고서를 관리자 사용자에게 
보냅니다. 
D. AWS Lambda 함수를 만들어 보고서를 생성합니다. 함수 URL 을 사용하여 함수를 
호출합니다. Amazon Simple Email Service(Amazon SES)를 사용하여 관리자 사용자에게 
보고서를 보냅니다. 
Answer: D 
설명: 
* A. ECS + API Gateway: 주문형, 간헐적 작업 부하에 대해 지나치게 복잡하고 비용이 많이 
듭니다. 
* B. EventBridge + SNS: 주문형 생성에는 EventBridge 일정이 필요하지 않습니다. 
* C. EKS + API Gateway: 이 사용 사례에는 과도하며 운영 오버헤드가 높습니다. 
* D. Lambda + SES: 주문형 보고서를 생성하고 이메일로 보내는 데 가장 비용 효율적이고 
효율적인 솔루션입니다. 
Q66 
한 회사에서 MySQL 을 사용하는 온프레미스 온라인 트랜잭션 처리(OLTP) 데이터베이스를 
AWS 관리형 데이터베이스 관리 시스템으로 마이그레이션할 계획입니다. 여러 보고 및 분석 
애플리케이션이 주말과 매월 말에 온프레미스 데이터베이스를 많이 사용합니다. 클라우드 
기반 솔루션은 주말과 매월 말에 읽기 중심의 급증을 처리할 수 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 데이터베이스를 Amazon Aurora MySQL 클러스터로 마이그레이션합니다. 복제본을 
사용하여 급증을 처리하도록 Aurora Auto Scaling 을 구성합니다. 
B. 데이터베이스를 MySQL 을 실행하는 Amazon EC2 인스턴스로 마이그레이션합니다. 임시 
스토리지가 있는 EC2 인스턴스 유형을 사용합니다. Amazon EBS Provisioned IOPS SSD(io2) 
볼륨을 인스턴스에 연결합니다. 
C. 데이터베이스를 Amazon RDS for MySQL 데이터베이스로 마이그레이션합니다. RDS for 
MySQL 데이터베이스를 다중 AZ 배포에 맞게 구성하고 자동 확장을 설정합니다. 
D. 데이터베이스에서 Amazon Redshift 로 마이그레이션합니다. OLTP 및 분석 애플리케이션 
모두에 대한 데이터베이스로 Amazon Redshift 를 사용합니다. 
Answer: A 
설명: 
* A. Aurora MySQL: 기본 제공 복제 및 자동 확장 기능으로 OLTP 워크로드를 효율적으로 
처리합니다. 
* B. MySQL 이 포함된 EC2: 많은 수동 유지 관리가 필요하고 원활하게 확장되지 않습니다. 
* C. MySQL 용 RDS: Aurora 에 비해 자동 확장이 제한적입니다. 
* D. Redshift: 주로 OLAP 용이며 OLTP 워크로드에는 적합하지 않습니다. 
Q67 
회사는 S3 버킷에서 PII 를 감지하고 보안 팀에 알리려면 어떻게 해야 합니까? 
A. Amazon Macie 를 사용합니다. SensitiveData 결과에 대한 EventBridge 규칙을 만들고 
SNS 알림을 보냅니다. 
B. Amazon GuardDuty 를 사용합니다. CRITICAL 결과에 대한 EventBridge 규칙을 만들고 
SNS 알림을 보냅니다. 
C. Amazon Macie 를 사용합니다. SensitiveData:S3Object/Personal 결과에 대한 
EventBridge 규칙을 만들고 SQS 알림을 보냅니다. 
D. Amazon GuardDuty 를 사용합니다. CRITICAL 결과에 대한 EventBridge 규칙을 만들고 
SQS 알림을 보냅니다. 
Answer: A 
설명: 
* Amazon Macie 는 S3 에서 PII 를 감지하도록 특별히 제작되었습니다. 
* 옵션 A는 EventBridge 를 사용하여 SensitiveData 결과를 필터링하고 SNS를 통해 알림을 
보내 요구 사항을 충족합니다. 
* 옵션 B 와 D 는 PII 감지용으로 설계되지 않은 GuardDuty 를 포함합니다. 
* 옵션 C 는 즉각적인 알림에 덜 적합한 SQS 를 사용합니다. 
Q68 
한 회사에서 온프레미스에서 Microsoft Windows SMB 파일 공유를 실행하여 
애플리케이션을 지원합니다. 이 회사는 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 
이 회사는 여러 Amazon EC2 인스턴스에서 스토리지를 공유하려고 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? (2 개 선택) 
A. 탄력적 처리량을 갖춘 Amazon Elastic File System(Amazon EFS) 파일 시스템을 
만듭니다. 
B. Amazon FSx for NetApp ONTAP 파일 시스템을 만듭니다. 
C. Amazon Elastic Block Store(Amazon EBS)를 사용하여 인스턴스에서 자체 관리형 
Windows 파일 공유를 만듭니다. 
D. Amazon FSx for Windows File Server 파일 시스템을 만듭니다. 
E. Amazon FSx for OpenZFS 파일 시스템을 만듭니다. 
Answer: A, D 
설명: 
* A. Amazon EFS: 최소한의 운영 오버헤드로 확장 가능한 공유 파일 스토리지 솔루션을 
제공합니다. Linux 기반 워크로드에 이상적입니다. 
* B. Amazon FSx for NetApp ONTAP: NetApp 특정 기능이 필요한 워크로드에 더 
적합합니다. 
* C. Amazon EBS: 파일 공유의 수동 관리가 필요하여 운영 오버헤드가 증가합니다. 
* D. Amazon FSx for Windows File Server: 운영 오버헤드가 낮은 Windows SMB 워크로드에 
가장 적합합니다. 
* E. Amazon FSx for OpenZFS: Linux 및 Unix 기반 워크로드에 더 적합합니다. 
Q69 
한 회사가 최근 데이터웨어하우스를 AWS 로 마이그레이션했습니다. 이 회사는 AWS 에 대한 
AWS Direct Connect 연결을 보유하고 있습니다. 회사 사용자는 시각화 도구를 사용하여 
데이터웨어하우스를 쿼리합니다. 
데이터웨어하우스가 반환하는 쿼리의 평균 크기는 50MB 입니다. 시각화 도구가 생성하는 
평균 시각화 크기는 500KB 입니다. 데이터웨어하우스가 반환하는 결과 집합은 캐시되지 
않습니다. 
이 회사는 데이터웨어하우스와 회사 간의 데이터 전송 비용을 최적화하려고 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 시각화 도구를 온프레미스에 호스팅합니다. 인터넷을 통해 데이터웨어하우스에 직접 
연결합니다. 
B. 시각화 도구를 데이터웨어하우스와 동일한 AWS 리전에 호스팅합니다. 인터넷을 통해 
시각화 도구에 액세스합니다. 
C. 시각화 도구를 온프레미스에 호스팅합니다. Direct Connect 연결을 통해 
데이터웨어하우스에 연결합니다. 
D. 시각화 도구를 데이터웨어하우스와 동일한 AWS 리전에 호스팅합니다. Direct Connect 
연결을 통해 시각화 도구에 액세스합니다. 
Answer: D 
설명: 
* A. 인터넷을 통한 온프레미스 도구: 인터넷을 통한 대량 데이터 전송으로 인해 비용이 
많이 발생합니다. 
* B. 인터넷을 통한 AWS 지역 도구: Direct Connect 를 활용하지 않아 잠재적인 지연 및 더 
높은 비용이 발생합니다. 
* C. Direct Connect 를 통한 온프레미스 도구: 쿼리 및 시각화에 지연이 추가됩니다. 
* D. Direct Connect 를 통한 AWS 지역 도구: 지연을 줄이고 Direct Connect 를 활용하여 
데이터 전송 비용을 최적화합니다. 
Q70 
미디어 회사가 AWS 에서 비디오를 업로드하기 위한 웹 애플리케이션을 호스팅합니다. 
인증된 사용자만 인증 후 지정된 시간 내에 업로드해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. 인증된 사용자에 대한 IAM 임시 보안 자격 증명을 생성하도록 애플리케이션을 
구성합니다. 
B. 사용자가 인증될 때 사전 서명된 URL 을 생성하는 AWS Lambda 함수를 만듭니다. 
C. Amazon Cognito 와 통합되어 애플리케이션을 통한 직접 S3 버킷 액세스를 제어하고 
기록하는 사용자 지정 인증 서비스를 개발합니다. 
D. AWS 보안 토큰 서비스(AWS STS)를 사용하여 인증된 사용자에게 비디오를 S3 버킷에 
직접 업로드할 수 있는 임시 권한을 부여하는 사전 정의된 IAM 역할을 수행합니다. 
Answer: B 
* 옵션 B: 사전 서명된 URL 은 S3 에 대한 임시 인증된 액세스를 제공하여 업로드를 지정된 
시간 프레임으로 제한합니다. 이 솔루션은 가볍고 효율적이며 구현하기 쉽습니다. 
* 옵션 A 는 IAM 임시 자격 증명을 관리해야 하므로 복잡성이 증가합니다. 
* 옵션 C 는 불필요한 개발 노력이 필요합니다. 
* 옵션 D 는 미리 서명된 URL 보다 STS 와 역할에 더 많은 복잡성을 도입합니다. 
Q71 
한 회사에서 AWS 클라우드에 데이터 레이크를 구현하려고 합니다. 이 회사는 특정 팀만 
데이터 레이크의 민감한 데이터에 액세스할 수 있도록 해야 합니다. 이 회사는 데이터 
레이크에 대한 행 수준 액세스 제어를 보유해야 합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? 
A. Amazon RDS 를 사용하여 데이터를 저장합니다. 데이터 거버넌스 및 액세스 제어를 위해 
IAM 역할과 권한을 사용합니다. 
B. Amazon Redshift 를 사용하여 데이터를 저장합니다. 데이터 거버넌스 및 액세스 제어를 
위해 IAM 역할과 권한을 사용합니다. 
C. Amazon S3 를 사용하여 데이터를 저장합니다. 데이터 거버넌스 및 액세스 제어를 위해 
AWS Lake Formation 을 사용합니다. 
D. AWS Glue Catalog 를 사용하여 데이터를 저장합니다. 데이터 거버넌스 및 액세스 제어를 
위해 AWS Glue DataBrew 를 사용합니다. 
Answer: C 
설명: 
* A. RDS: 관계형 데이터베이스에 적합하지만 데이터 레이크 또는 행 수준 액세스에 대한 
기본 지원을 제공하지 않습니다. 
* B. Redshift: 주로 분석용으로, 대규모 데이터 레이크 거버넌스에는 적합하지 않습니다. 
* C. S3 + Lake Formation: 행 수준 권한을 포함하여 세분화된 액세스 제어를 통해 데이터 
레이크에 대한 기본 지원을 제공합니다. 
* D. Glue Catalog + DataBrew: 행 수준 액세스 제어가 아닌 데이터 준비 및 메타데이터 
관리에 중점을 둡니다. 
Q72 
회사는 기계 학습 및 보고를 위해 차량의 원격 측정 데이터를 대규모로 수집하고 분석해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon Timestream for LiveAnalytics 를 사용하여 데이터 포인트를 저장합니다. Amazon 
SageMaker 에 데이터 액세스 권한을 부여합니다. Amazon QuickSight 를 사용하여 데이터를 
시각화합니다. 
B. Amazon DynamoDB 를 사용하여 데이터 포인트를 저장합니다. DynamoDB Connector 를 
사용하여 데이터를 Amazon EMR 에 수집하여 처리합니다. Amazon QuickSight 를 사용하여 
데이터를 시각화합니다. 
C. Amazon Neptune 을 사용하여 데이터 포인트를 저장합니다. Amazon Kinesis Data 
Streams 를 사용하여 데이터를 Lambda 함수에 수집하여 처리합니다. Amazon QuickSight 를 
사용하여 데이터를 시각화합니다. 
D. Amazon Timestream for LiveAnalytics 를 사용하여 데이터 포인트를 저장합니다. Amazon 
SageMaker 에 데이터 액세스 권한을 부여합니다. Amazon Athena 를 사용하여 데이터를 
시각화합니다. 
Answer: A 
* Amazon Timestream 은 원격 측정과 같은 시계열 데이터를 저장하고 분석하도록 특별히 
제작되었습니다. 
* 옵션 A 는 Timestream, ML 용 SageMaker, 시각화용 QuickSight 를 활용하여 최소한의 
복잡성으로 모든 요구 사항을 충족합니다. 
* 옵션 B 는 더 복잡한 DynamoDB-EMR 통합을 포함합니다. 
* 옵션 C 는 원격 측정 데이터가 아닌 그래프 데이터베이스용으로 설계된 Neptune 을 
사용합니다. 
* 옵션 D 는 QuickSight 대신 시각화용으로 Athena 를 잘못 사용합니다. 
Q73 
게임 회사에서 사용자 데이터를 저장하기 위해 데이터베이스를 사용하는 애플리케이션을 
구축하고 있습니다. 이 회사는 보조 AWS 지역에 데이터를 쓸 수 있는 활성-활성 구성을 
데이터베이스에 적용하고자 합니다. 데이터베이스는 1 초 미만의 복구 지점 목표(RPO)를 
달성해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon ElastiCache(Redis OSS) 클러스터를 배포합니다. 재해 복구를 위한 글로벌 
데이터 저장소를 구성합니다. 기본 지역에 배포된 Amazon RDS 데이터베이스의 데이터를 
캐시하도록 ElastiCache 클러스터를 구성합니다. 
B. 기본 지역과 보조 지역에 Amazon DynamoDB 테이블을 배포합니다. Amazon 
DynamoDB Streams 를 구성하여 AWS Lambda 함수를 호출하여 기본 지역의 테이블에서 
보조 지역의 테이블에 변경 사항을 씁니다. 
C. 기본 지역에 Amazon Aurora MySQL 데이터베이스를 배포합니다. 보조 지역에 글로벌 
데이터베이스를 구성합니다. 
D. 기본 지역에 Amazon DynamoDB 테이블을 배포합니다. 보조 지역에 글로벌 테이블을 
구성합니다. 
Answer: D 
설명: 
* A. ElastiCache: 메모리 내 캐싱을 제공하지만 지속적이고 확장 가능한 데이터베이스에는 
적합하지 않습니다. 
* B. DynamoDB Streams + Lambda: 복제를 수동으로 관리하여 대기 시간과 운영 복잡성을 
증가시킵니다. 
* C. Aurora Global Database: 고가용성을 제공하지만 액티브-액티브 구성을 지원하지 
않습니다. 
* D. DynamoDB Global Tables: 액티브-액티브 구성과 1 초 미만의 RPO 를 제공합니다. 
Q74 
회사에서 암호화 키 자료 제어를 유지하면서 백업, 복구 및 보관을 위한 클라우드 기반 
솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (2 개 선택) 
A. 키 자료 없이 AWS Key Management Service(AWS KMS) 키를 만듭니다. 회사의 키 
자료를 KMS 키로 가져옵니다. 
B. AWS KMS 에서 생성한 키 자료가 포함된 AWS KMS 암호화 키를 만듭니다. 
C. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. AWS 
KMS 키와 함께 S3 버킷 키를 사용합니다. 
D. Amazon S3 Glacier 스토리지 클래스에 데이터를 저장합니다. 고객 제공 키(SSE-C)로 
서버 측 암호화를 사용합니다. 
E. AWS Snowball 디바이스에 데이터를 저장합니다. AWS KMS 키(SSEKMS)로 서버 측 
암호화를 사용합니다. 
Answer: A, D 
* 옵션 A 를 사용하면 자체 암호화 키를 AWS KMS 로 가져와 키 자료에 대한 제어를 보장할 
수 있습니다. 
* 옵션 D 는 SSE-C 가 있는 S3 Glacier 를 사용하는데, 여기서는 고객이 암호화 키를 
제어하여 규정 준수 요구 사항을 충족합니다. 
* 옵션 B는 AWS 에서 관리하는 키 자료를 사용하여 키 자료 제어 요구 사항을 위반합니다. 
* 옵션 C 와 E 는 제어 요구 사항을 완벽하게 준수하지 않습니다. 
Q75 
여러 AWS 계정이 있는 회사에서 온프레미스 Microsoft Active Directory를 유지 관리합니다. 
이 회사에는 직원을 위한 Single Sign-On 을 구현하기 위한 솔루션이 필요합니다. 이 
회사는 AWS IAM Identity Center 를 사용하려고 합니다. 
솔루션은 다음 요구 사항을 충족해야 합니다. 
* 기존 Active Directory 자격 증명을 사용하여 사용자가 AWS 계정 및 타사 애플리케이션에 
액세스할 수 있도록 허용합니다. 
* AWS 계정에 액세스하기 위해 다중 요소 인증(MFA)을 적용합니다. 
* AWS 계정 및 애플리케이션에 대한 액세스 권한을 중앙에서 관리합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? 
A. 각 AWS 계정에서 Active Directory 에 대한 IAM ID 공급자를 만듭니다. Active Directory 
사용자 및 그룹이 IAM 역할을 통해 AWS 계정에 직접 액세스하도록 합니다. IAM Identity 
Center 를 사용하여 모든 사용자에 대해 각 계정에서 MFA 를 적용합니다. 
B. AWS Directory Service 를 사용하여 새 AWS Managed Microsoft AD Active Directory 를 
만듭니다. 
각 계정에서 IAM Identity Center 를 구성하여 새 AWS Managed Microsoft AD Active 
Directory 를 ID 소스로 사용합니다. IAM Identity Center 를 사용하여 모든 사용자에 대해 
MFA 를 적용합니다. 
C. 기존 Active Directory 와 함께 IAM Identity Center 를 ID 소스로 사용합니다. 모든 
사용자에게 MFA 를 적용합니다. AWS Organizations 및 Active Directory 그룹을 사용하여 
AWS 계정 및 애플리케이션 액세스에 대한 액세스 권한을 관리합니다. 
D. AWS Lambda 함수를 사용하여 Active Directory 사용자 및 그룹을 각 AWS 계정의 IAM 
사용자 및 그룹과 주기적으로 동기화합니다. IAM 역할 및 정책을 사용하여 애플리케이션 
액세스를 관리합니다. MFA 를 적용하기 위한 두 번째 Lambda 함수를 만듭니다. 
Answer: C 
설명: 
* A. IAM ID 공급자: 여러 계정에서 중앙 집중식 관리를 지원하지 않습니다. 
* B. AWS 관리형 AD: 온프레미스 Active Directory 가 이미 있는 경우 불필요합니다. 
* C. IAM Identity Center + 기존 AD: SSO 를 위해 기존 Active Directory 를 통합하고 MFA 및 
중앙 집중식 권한을 사용하는 가장 좋은 방법입니다. 
* D. 동기화를 위한 Lambda: 복잡성을 추가하고 IAM Identity Center 기능을 활용하지 
않습니다. 
Q76 
한 회사가 새 VPC 의 프라이빗 서브넷에 Amazon EC2 인스턴스를 호스팅합니다. VPC 에는 
기본 경로가 인터넷 게이트웨이로 설정된 퍼블릭 서브넷도 있습니다. 프라이빗 서브넷에는 
아웃바운드 인터넷 액세스가 없습니다. 
EC2 인스턴스에는 외부 공급업체에서 월별 보안 업데이트를 다운로드할 수 있는 기능이 
있어야 합니다. 
그러나 회사는 인터넷에서 시작된 모든 연결을 차단해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 인터넷 게이트웨이를 기본 경로로 사용하도록 프라이빗 서브넷 경로 테이블을 
구성합니다. 
B. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. NAT 게이트웨이를 기본 경로로 
사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. 
C. 프라이빗 서브넷에 NAT 인스턴스를 만듭니다. NAT 인스턴스를 기본 경로로 사용하도록 
프라이빗 서브넷 경로 테이블을 구성합니다. 
D. 프라이빗 서브넷에 NAT 인스턴스를 만듭니다. 인터넷 게이트웨이를 기본 경로로 
사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. 
Answer: B 
Q77 
한 회사에서 정적 웹사이트를 재설계하고 있습니다. 이 회사에는 회사의 AWS 계정에서 새 
웹사이트를 호스팅할 솔루션이 필요합니다. 솔루션은 안전하고 확장 가능해야 합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (3 개 선택) 
A. Amazon CloudFront 배포를 구성합니다. Amazon S3 버킷을 원본으로 설정합니다. 
B. AWS Certificate Manager(ACM) TLS 인증서를 Amazon CloudFront 배포에 연결합니다. 
C. Amazon S3 버킷에 대한 정적 웹사이트 호스팅을 활성화합니다. 
D. 정적 웹사이트 콘텐츠를 저장할 Amazon S3 버킷을 만듭니다. 
E. AWS Certificate Manager(ACM)에서 웹사이트의 SSL/TLS 인증서를 Amazon S3 버킷의 
루트로 내보냅니다. 
F. Amazon S3 버킷에 대한 퍼블릭 액세스 차단을 끕니다. 
Answer: A, B, D 
Q78 
한 회사에서 결제 처리 애플리케이션을 만들고자 합니다. 애플리케이션은 기존 Amazon S3 
버킷에 결제 레코드가 도착하면 실행되어야 합니다. 애플리케이션은 각 결제 레코드를 
정확히 한 번만 처리해야 합니다. 회사는 AWS Lambda 함수를 사용하여 결제를 처리하려고 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 기존 S3 버킷을 구성하여 객체 생성 이벤트를 Amazon EventBridge 로 전송합니다. 
EventBridge 를 구성하여 이벤트를 Amazon Simple Queue Service(Amazon SQS) FIFO 
대기열로 라우팅합니다. Lambda 함수를 구성하여 SQS 대기열에 새 이벤트가 도착하면 
실행되도록 합니다. 
B. 기존 S3 버킷을 구성하여 객체 생성 이벤트를 Amazon Simple Notification 
Service(Amazon SNS) 주제로 전송합니다. Lambda 함수를 구성하여 SNS 주제에 새 
이벤트가 도착하면 실행되도록 합니다. 
C. 기존 S3 버킷을 구성하여 객체 생성 이벤트를 Amazon Simple Queue Service(Amazon 
SQS) 대기열로 전송합니다. Lambda 함수를 구성하여 SQS 대기열에 새 이벤트가 도착하면 
실행되도록 합니다. 
D. 기존 S3 버킷을 구성하여 객체 생성 이벤트를 Lambda 함수로 직접 전송합니다. 객체 
생성 이벤트를 처리하고 결제를 처리하도록 Lambda 함수를 구성합니다. 
Answer: B 
Q79 
한 회사에서 IPv4 클라이언트의 TLS 연결을 지원하는 저지연 결제 처리 애플리케이션을 
만들고 있습니다. 이 애플리케이션에는 퍼블릭 인터넷에 대한 아웃바운드 액세스가 
필요합니다. 사용자는 단일 진입점에서 애플리케이션에 액세스해야 합니다. 
은행은 Amazon Elastic Container Service(Amazon ECS) 작업을 사용하여 애플리케이션을 
배포하려고 합니다. 이 회사는 AWSVPC 네트워크 모드를 활성화하려고 합니다. 
이러한 요구 사항을 가장 안전하게 충족하는 솔루션은 무엇입니까? 
A. 인터넷 게이트웨이, 퍼블릭 서브넷, 프라이빗 서브넷이 있는 VPC 를 만듭니다. 퍼블릭 
서브넷에 네트워크 로드 밸런서와 NAT 게이트웨이를 배포합니다. 프라이빗 서브넷에 ECS 
작업을 배포합니다. 
B. 아웃바운드 전용 인터넷 게이트웨이, 퍼블릭 서브넷, 프라이빗 서브넷이 있는 VPC 를 
만듭니다. 퍼블릭 서브넷에 애플리케이션 로드 밸런서와 NAT 게이트웨이를 배포합니다. 
프라이빗 서브넷에 ECS 작업을 배포합니다. 
C. 인터넷 게이트웨이, 퍼블릭 서브넷, 프라이빗 서브넷이 있는 VPC 를 만듭니다. 퍼블릭 
서브넷에 애플리케이션 로드 밸런서를 배포합니다. 퍼블릭 서브넷에 ECS 작업을 
배포합니다. 
D. 아웃바운드 전용 인터넷 게이트웨이, 퍼블릭 서브넷, 프라이빗 서브넷이 있는 VPC 를 
만듭니다. 퍼블릭 서브넷에 네트워크 로드 밸런서를 배포합니다. 퍼블릭 서브넷에 ECS 
작업을 배포합니다. 
Answer: A 
Q80 
한 회사에서 JSON 웹 토큰(JWT)을 사용하여 사용자를 승인하는 API 를 만들고자 합니다. 
이 회사는 경로 기반 라우팅을 사용하여 여러 AWS 서비스에 대한 동적 액세스를 지원해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon API Gateway REST API 뒤에 애플리케이션 로드 밸런서를 배포합니다. IAM 
승인을 구성합니다. 
B. Amazon API Gateway HTTP API 뒤에 애플리케이션 로드 밸런서를 배포합니다. Amazon 
Cognito 를 사용하여 승인을 받습니다. 
C. Amazon API Gateway REST API 뒤에 네트워크 로드 밸런서를 배포합니다. AWS Lambda 
함수를 사용자 지정 승인자로 사용합니다. 
D. Amazon API Gateway HTTP API 뒤에 네트워크 로드 밸런서를 배포합니다. Amazon 
Cognito 를 사용하여 승인을 받습니다. 
Answer: C 
Q81 
한 회사에서 Amazon S3 버킷에 객체를 읽고 쓸 수 있는 AWS Lambda 함수를 배포하려고 
합니다. Lambda 함수는 회사의 VPC 에 연결되어야 합니다. 회사는 Lambda 함수를 VPC 의 
프라이빗 서브넷에만 배포해야 합니다. Lambda 함수는 인터넷에 액세스할 수 없어야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? (2 개 선택) 
A. S3 버킷에 액세스하기 위한 프라이빗 NAT 게이트웨이를 만듭니다. 
B. NAT 게이트웨이에 탄력적 IP 주소를 연결합니다. 
C. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 만듭니다. 
D. S3 버킷에 대한 인터페이스 VPC 엔드포인트를 만듭니다. 
E. S3 버킷에 액세스하기 위한 퍼블릭 NAT 게이트웨이를 만듭니다. 
Answer: C, D 
Q82 
한 회사가 VPC 의 여러 프라이빗 및 퍼블릭 서브넷에 애플리케이션을 호스팅합니다. 
프라이빗 서브넷의 애플리케이션은 API 에 액세스해야 합니다. API 는 인터넷에서 사용할 수 
있으며 회사의 온프레미스 데이터 센터에 호스팅됩니다. 솔루션 아키텍트는 프라이빗 
서브넷의 애플리케이션에 대한 연결을 설정해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요? 
A. VPC 를 온프레미스 네트워크에 연결하기 위한 전송 게이트웨이를 만듭니다. 전송 
게이트웨이를 사용하여 프라이빗 서브넷에서 온프레미스 데이터 센터로 API 호출을 
라우팅합니다. 
B. VPC 의 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. NAT 게이트웨이를 사용하여 
프라이빗 서브넷이 인터넷을 통해 API 에 액세스할 수 있도록 합니다. 
C. AWS PrivateLink 연결을 설정하여 VPC 를 온프레미스 네트워크에 연결합니다. 
PrivateLink 를 사용하여 프라이빗 서브넷에서 온프레미스 데이터 센터로 API 호출을 
합니다. 
D. VPC 와 온프레미스 데이터 센터 간에 AWS 사이트 간 VPN 연결을 구현합니다. VPN 
연결을 사용하여 프라이빗 서브넷에서 온프레미스 데이터 센터로 API 호출을 합니다. 
Answer: D 
Q83 
한 회사가 민감한 고객 데이터를 Amazon DynamoDB 테이블에 저장합니다. 이 회사는 
데이터를 자주 업데이트합니다. 이 회사는 이 데이터를 사용하여 고객에게 맞춤형 상품을 
제공하려고 합니다. 
이 회사의 분석 팀은 자체 AWS 계정을 가지고 있습니다. 분석 팀은 DynamoDB 테이블의 
데이터를 처리해야 하는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 이 회사는 
보안 모범 사례를 따라 DynamoDB 에서 분석 팀으로 데이터를 정기적으로 공유하는 
프로세스를 만들어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. DynamoDB 테이블에서 필요한 데이터를 여러 JSON 파일로 Amazon S3 버킷으로 
내보냅니다. 분석 팀에 S3 버킷에 액세스하는 데 필요한 IAM 권한을 제공합니다. 
B. DynamoDB 테이블에 대한 퍼블릭 액세스를 허용합니다. DynamoDB 에 액세스할 수 있는 
권한이 있는 IAM 사용자를 만듭니다. IAM 사용자를 분석 팀과 공유합니다. 
C. DynamoDB 테이블에 대한 퍼블릭 액세스를 허용합니다. DynamoDB 에 대한 읽기 전용 
권한이 있는 IAM 사용자를 만듭니다. IAM 사용자를 분석 팀과 공유합니다. 
D. 교차 계정 IAM 역할을 만듭니다. 분석 팀의 AWS 계정 ID 가 DynamoDB 테이블에 
액세스할 수 있도록 허용하는 IAM 정책을 만듭니다. IAM 정책을 IAM 역할에 연결합니다. 
계정 간에 신뢰 관계를 설정합니다. 
Answer: D 
설명: 
* 교차 계정 IAM 역할을 사용하는 것은 AWS 계정 간에 데이터를 공유하는 가장 안전하고 
확장 가능한 방법입니다. 
* 신뢰 관계를 사용하면 분석 팀의 계정이 주 계정의 역할을 맡고 DynamoDB 테이블에 
직접 액세스할 수 있습니다. 
* A 는 가능하지만 데이터 복제와 S3 에 JSON 파일을 저장하는 데 추가 비용이 발생합니다. 
* B 와 C 는 민감한 데이터에 대한 공개 액세스를 허용하고 자격 증명을 공유하여 보안 모범 
사례를 위반하므로 이는 매우 권장되지 않습니다. 
Q84 
한 회사에서 AWS 환경의 보안을 강화하기 위한 새로운 정책을 구현하고 있습니다. 이 
정책은 사용자가 AWS Management Console 에서 수행하는 모든 관리 작업을 다중 요소 
인증(MFA)으로 보호하도록 요구합니다. 
어떤 솔루션을 사용하면 회사에서 가장 운영 효율적인 방식으로 이 정책을 시행할 수 
있을까요? 
A. 루트 계정에서 MFA 를 활성화합니다. 모든 관리자가 루트 계정을 사용하여 관리 작업을 
수행하도록 합니다. 
B. 관리자가 관리 작업을 수행하는 IAM 역할에 대해 MFA 를 활성화해야 하는 IAM 정책을 
만듭니다. 
C. 관리자가 MFA 없이 관리 작업을 수행할 때 이메일 알림을 보내는 Amazon CloudWatch 
알람을 구성합니다. 
D. AWS Config 를 사용하여 IAM 사용자를 주기적으로 감사하고 AWS Config 가 관리 작업을 
감지하면 MFA 가 필요한 IAM 정책을 자동으로 연결합니다. 
Answer: B 
Q85 
한 글로벌 기업이 온프레미스 데이터 센터에서 AWS 로 워크로드를 마이그레이션하고 
있습니다. AWS 환경에는 여러 AWS 계정, IAM 역할, AWS Config 규칙, VPC 가 포함됩니다. 
이 회사는 회사의 사업부에 새 계정이 필요할 때 필요에 따라 새 계정을 프로비저닝하는 
자동화된 프로세스를 원합니다. 
어떤 솔루션이 최소한의 노력으로 이러한 요구 사항을 충족할 수 있을까요? 
A. AWS Control Tower 를 사용하여 AWS Organizations 에서 조직을 설정합니다. AWS 
Control Tower Account Factory for Terraform(AFT)을 사용하여 새 AWS 계정을 
프로비저닝합니다. 
B. AWS Organizations 에서 조직을 만듭니다. AWS CLI CreateAccount API 작업을 사용하여 
새 AWS 계정을 프로비저닝합니다. 사업부를 조직 단위(OU)로 구성합니다. 
C. AWS Organizations API 를 사용하여 새 계정을 만드는 AWS Lambda 함수를 만듭니다. 
AWS Service Catalog 의 AWS CloudFormation 템플릿에서 Lambda 함수를 호출합니다. 
D. AWS Organizations 에서 조직을 만듭니다. AWS Step Functions 를 사용하여 계정 생성 
프로세스를 조정합니다. Amazon API Gateway API 엔드포인트에 계정 생성 요청을 보내 새 
계정을 만드는 AWS Lambda 함수를 호출합니다. 
Answer: A 
Q86 
솔루션 아키텍트가 중요한 분석 애플리케이션에 대한 컴퓨팅 옵션을 조사하고 있습니다. 이 
애플리케이션은 장기 실행 프로세스를 사용하여 데이터를 준비하고 집계합니다. 프로세스는 
중단될 수 없습니다. 이 애플리케이션에는 알려진 기준 부하가 있습니다. 이 
애플리케이션은 가끔씩 증가하는 사용량을 처리해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요? 
A. Amazon EC2 자동 확장 그룹을 만듭니다. 최소 용량 및 원하는 용량 매개변수를 기준 
부하를 처리하는 데 필요한 인스턴스 수로 설정합니다. 자동 확장 그룹에 대한 예약 
인스턴스를 구매합니다. 
B. Amazon EC2 자동 확장 그룹을 만듭니다. 최소 용량, 최대 용량 및 원하는 용량 
매개변수를 기준 부하를 처리하는 데 필요한 인스턴스 수로 설정합니다. 온디맨드 
인스턴스를 사용하여 가끔씩 증가하는 사용량을 처리합니다. 
C. Amazon EC2 자동 확장 그룹을 만듭니다. 최소 용량 및 원하는 용량 매개변수를 기준 
부하를 처리하는 데 필요한 인스턴스 수로 설정합니다. 자동 확장 그룹에 대한 예약 
인스턴스를 구매합니다. OnDemandPercentageAboveBaseCapacity 매개변수를 사용하여 
Spot 인스턴스를 시작하기 위한 시작 템플릿을 구성합니다. 
D. Amazon EC2 인스턴스 대신 AWS Lambda 함수를 사용하도록 애플리케이션을 
재구성합니다. Lambda 사용 비용을 줄이려면 1 년 Compute Savings Plan 을 구매합니다. 
Answer: C 
Q87 
한 회사에서 Amazon EMR API 사용에 대한 보안 검토를 수행하고 있습니다. 이 회사의 
개발자는 Amazon EC2 인스턴스에 호스팅된 통합 개발 환경(IDE)을 사용합니다. 이 IDE 는 
액세스 키를 사용하여 사용자를 AWS 에 인증하도록 구성되어 있습니다. 이 회사의 EC2 
인스턴스와 EMR 클러스터 간의 트래픽은 공용 IP 주소를 사용합니다. 
솔루션 아키텍트는 회사의 전반적인 보안 태세를 개선해야 합니다. 이 솔루션 아키텍트는 
회사의 장기 자격 증명 사용을 줄이고 공용 IP 주소를 사용하는 통신 양을 제한해야 
합니다. 
다음 중 어떤 단계 조합이 회사 아키텍처의 보안을 가장 많이 개선할까요? (2 개 선택) 
A. EMR 클러스터에 게이트웨이 엔드포인트를 설정합니다. 
B. EMR 클러스터에 연결할 인터페이스 VPC 엔드포인트를 설정합니다. 
C. EMR 클러스터에 연결할 개인 NAT 게이트웨이를 설정합니다. 
D. 개발자가 Amazon EMR API 에 연결하는 데 사용할 IAM 역할을 설정합니다. 
E. 각 개발자의 액세스 키를 저장하기 위해 AWS Systems Manager Parameter Store 를 
설정합니다. 
Answer: B, D 
Q88 
한 회사에서 애플리케이션에 대한 마이크로서비스 아키텍처를 설계하려고 합니다. 각 
마이크로서비스는 30 초 이내에 완료할 수 있는 작업을 수행해야 합니다. 
마이크로서비스는 RESTful API 를 노출해야 하며 다양한 부하에 따라 자동으로 확장되어야 
합니다. 
API 는 또한 공평한 사용과 서비스 가용성을 유지하기 위해 클라이언트 액세스 제어 및 
속도 제한을 제공해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. Amazon EC2 에서 Amazon Elastic Container Service(Amazon ECS)를 사용하여 각 
마이크로서비스를 호스팅합니다. Amazon API Gateway 를 사용하여 RESTful API 요청을 
관리합니다. 
B. 각 마이크로서비스를 AWS Lambda 함수 세트로 배포합니다. Amazon API Gateway 를 
사용하여 RESTful API 요청을 관리합니다. 
C. Elastic Load Balancing(ELB) 로드 밸런서 뒤의 Auto Scaling 그룹에서 Amazon EC2 
인스턴스에 각 마이크로서비스를 호스팅합니다. ELB 를 사용하여 RESTful API 요청을 
관리합니다. 
D. Amazon Elastic Beanstalk 에 각 마이크로서비스를 배포합니다. Amazon CloudFront 를 
사용하여 RESTful API 요청을 관리합니다. 
Answer: C 
Q89 
한 회사에서 새로운 게임 애플리케이션을 출시합니다. 이 회사는 Amazon EC2 Auto Scaling 
그룹을 사용하여 애플리케이션을 배포합니다. 이 애플리케이션은 관계형 데이터베이스에 
사용자 데이터를 저장합니다. 이 회사는 전 세계에 사무실이 있으며, 이 사무실에서는 
데이터베이스의 사용자 데이터에 대한 분석을 실행해야 합니다. 이 회사는 AWS 지역에서 
저지연 읽기 성능으로 지역 간 재해 복구를 제공하는 비용 효율적인 데이터베이스 솔루션이 
필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. 애플리케이션이 배포된 지역에 Amazon ElastiCache for Redis 클러스터를 만듭니다. 
회사 사무실이 있는 지역에 읽기 복제본을 만듭니다. 회사 사무실에서 읽기 복제본 
인스턴스에서 읽을 수 있도록 합니다. 
B. Amazon DynamoDB 글로벌 테이블을 만듭니다. 회사 사무실이 있는 지역과 
애플리케이션이 배포된 지역에 테이블을 배포합니다. 각 회사 사무실에서 사무실과 같은 
지역에 있는 테이블에서 읽을 수 있도록 합니다. 
C. Amazon Aurora 글로벌 데이터베이스를 만듭니다. 애플리케이션이 배포된 지역에 기본 
클러스터를 구성합니다. 보조 Aurora 복제본을 회사 사무실이 있는 지역에 있도록 
구성합니다. 회사 사무실이 Aurora 복제본에서 읽도록 합니다. 
D. 애플리케이션이 배포된 지역에 Amazon RDS Multi-AZ DB 클러스터 배포를 만듭니다. 
회사 사무실이 읽기 복제본 인스턴스에서 읽도록 합니다. 
Answer: A 
Q90 
개발자는 AWS SDK 를 사용하여 10 개 서비스에 대한 로그 레코드를 집계하고 생성하는 
애플리케이션을 만들었습니다. 이 애플리케이션은 Amazon Kinesis Data Streams 스트림에 
데이터를 전달합니다. 
각 레코드에는 서비스 이름, 생성 타임스탬프 및 기타 로그 정보가 포함된 로그 메시지가 
포함됩니다. 스트림에는 프로비저닝된 용량 모드의 샤드가 15 개 있습니다. 스트림은 서비스 
이름을 파티션 키로 사용합니다. 
개발자는 모든 서비스가 로그를 생성할 때 
PutRecord 요청 중에 ProvisionedThroughputExceededException 오류가 발생한다는 것을 
알아챘습니다. 스트림 메트릭은 애플리케이션에서 사용하는 쓰기 용량이 프로비저닝된 
용량보다 낮음을 보여줍니다. 
개발자는 이 문제를 어떻게 해결해야 합니까? 
A. 용량 모드를 프로비저닝에서 온디맨드로 변경합니다. 
B. 제한 오류가 발생하지 않을 때까지 샤드 수를 두 배로 늘립니다. 
C. 파티션 키를 서비스 이름에서 생성 타임스탬프로 변경합니다. 
D. 각 서비스에 대해 별도의 Kinesis 스트림을 사용하여 로그를 생성합니다. 
Answer: C 
Q91 
개발자가 비디오 인코딩을 수행하는 서버리스 애플리케이션을 만들고 있습니다. 인코딩 
프로세스는 백그라운드 작업으로 실행되며 각 비디오를 인코딩하는 데 몇 분이 걸립니다. 
이 프로세스는 사용자에게 즉각적인 결과를 보내서는 안 됩니다. 
개발자는 Amazon API Gateway 를 사용하여 애플리케이션의 API 를 관리합니다. 개발자는 
테스트 호출을 실행하고 검증을 요청해야 합니다. 개발자는 API 에 대한 액세스를 제어하기 
위해 API 키를 배포해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. HTTP API 를 만듭니다. 인코딩 작업을 처리하는 AWS Lambda 함수를 만듭니다. 함수를 
HTTP API 와 통합합니다. 이벤트 호출 유형을 사용하여 Lambda 함수를 호출합니다. 
B. 기본 엔드포인트 유형으로 REST API 를 만듭니다. 인코딩 작업을 처리하는 AWS Lambda 
함수를 만듭니다. 함수를 REST API 와 통합합니다. 이벤트 호출 유형을 사용하여 Lambda 
함수를 호출합니다. 
C. HTTP API 를 만듭니다. 인코딩 작업을 처리하는 AWS Lambda 함수를 만듭니다. 함수를 
HTTP API 와 통합합니다. RequestResponse 호출 유형을 사용하여 Lambda 함수를 
호출합니다. 
D. 기본 엔드포인트 유형으로 REST API 를 만듭니다. 인코딩 작업을 처리할 AWS Lambda 
함수를 만듭니다. 함수를 REST API 와 통합합니다. RequestResponse 호출 유형을 사용하여 
Lambda 함수를 호출합니다. 
Answer: B 
Q92 
한 회사에서 Amazon RDS for MySQL 을 사용하여 중요한 애플리케이션을 배포하고 
있습니다. 애플리케이션은 고가용성이어야 하며 자동으로 복구되어야 합니다. 이 회사는 
최대 4 시간 지연으로 대화형 사용자(트랜잭션 쿼리)와 일괄 보고(분석 쿼리)를 지원해야 
합니다. 분석 쿼리는 트랜잭션 쿼리의 성능에 영향을 미치지 않아야 합니다. 
A. 하나의 대기 인스턴스가 있는 다중 AZ DB 인스턴스 배포에서 Amazon RDS for 
MySQL 을 구성합니다. 트랜잭션 쿼리를 기본 DB 인스턴스로 지정합니다. 분석 쿼리를 다른 
가용성 영역에서 실행되는 보조 DB 인스턴스로 지정합니다. 
B. 두 개의 대기 인스턴스가 있는 다중 AZ DB 클러스터 배포에서 Amazon RDS for 
MySQL 을 구성합니다. 트랜잭션 쿼리를 기본 DB 인스턴스로 지정합니다. 분석 쿼리를 리더 
엔드포인트로 지정합니다. 
C. 여러 가용성 영역에서 여러 읽기 복제본을 사용하도록 Amazon RDS for MySQL 을 
구성합니다. 트랜잭션 쿼리를 기본 DB 인스턴스로 지정합니다. 분석 쿼리를 다른 가용성 
영역의 복제본 중 하나로 지정합니다. 
D. 자동 백업이 활성화된 트랜잭션 쿼리의 기본 데이터베이스로 Amazon RDS for MySQL 을 
구성합니다. 자동 백업을 구성합니다. 매일 밤, 가장 최근의 스냅샷에서 분석 쿼리를 
지원하기 위한 읽기 전용 데이터베이스를 만듭니다. 이전에 만든 데이터베이스를 
종료합니다. 
Answer: C 
Q93 
금융 서비스 회사에 2 계층 소비자 뱅킹 애플리케이션이 있습니다. 프런트엔드는 정적 웹 
콘텐츠를 제공합니다. 백엔드는 API 로 구성됩니다. 회사는 프런트엔드 구성 요소를 AWS 로 
마이그레이션해야 합니다. 애플리케이션의 백엔드는 온프레미스에 유지됩니다. 회사는 
애플리케이션을 일반적인 웹 취약성 및 공격으로부터 보호해야 합니다. 
A. 프런트엔드를 Amazon EC2 인스턴스로 마이그레이션합니다. 인스턴스 앞에 
애플리케이션 로드 밸런서(ALB)를 배포합니다. 인스턴스를 사용하여 온프레미스 API 를 
호출합니다. AWS WAF 규칙을 인스턴스와 연결합니다. 
B. 프런트엔드를 여러 출처가 있는 Amazon CloudFront 배포로 배포합니다. 한 출처를 정적 
웹 콘텐츠를 제공하는 Amazon S3 버킷으로 구성합니다. 두 번째 출처를 URL 패턴에 따라 
온프레미스 API 로 트래픽을 라우팅하도록 구성합니다. AWS WAF 규칙을 배포와 
연결합니다. 
C. 프런트엔드를 Amazon EC2 인스턴스로 마이그레이션합니다. 인스턴스 앞에 네트워크 
로드 밸런서(NLB)를 배포합니다. 인스턴스를 사용하여 온프레미스 API 를 호출합니다. AWS 
네트워크 방화벽 인스턴스를 만듭니다. 모든 트래픽을 네트워크 방화벽 인스턴스를 통해 
라우팅합니다. 
D. 프런트엔드를 Amazon S3 버킷을 기반으로 하는 정적 웹사이트로 배포합니다. Amazon 
API Gateway REST API 와 Amazon EC2 인스턴스 세트를 사용하여 온프레미스 API 를 
호출합니다. AWS WAF 규칙을 REST API 와 S3 버킷에 연결합니다. 
Answer: B 
Q94 
개발자는 회사 데이터 규정을 준수하기 위해 여러 Amazon DynamoDB 테이블의 내용을 
Amazon S3 버킷으로 내보내야 합니다. 개발자는 AWS CLI 를 사용하여 각 테이블에서 
적절한 S3 버킷으로 내보내는 명령을 실행합니다. 개발자는 AWS 자격 증명을 올바르게 
설정하고 리소스에 적절한 권한을 부여합니다. 그러나 일부 테이블의 내보내기가 
실패합니다. 
개발자는 이 문제를 해결하기 위해 무엇을 해야 합니까? 
A. DynamoDB 테이블에서 시점 복구가 활성화되었는지 확인합니다. 
B. 대상 S3 버킷이 DynamoDB 테이블과 동일한 AWS 리전에 있는지 확인합니다. 
C. 테이블에 대해 DynamoDB 스트리밍이 활성화되었는지 확인합니다. 
D. DynamoDB Accelerator(DAX)가 활성화되었는지 확인합니다. 
Answer: A 
Q95 
전자상거래 회사에 프로비저닝된 용량으로 구성된 Amazon DynamoDB 테이블을 사용하는 
애플리케이션이 있습니다. 주문 데이터는 Orders 라는 테이블에 저장됩니다. Orders 
테이블에는 주문 ID 의 기본 키와 제품 ID 의 정렬 키가 있습니다. 이 회사는 Orders 
테이블에서 DynamoDB 스트림을 수신하고 Inventory 라는 테이블을 업데이트하도록 AWS 
Lambda 함수를 구성했습니다. 
이 회사는 매출이 가장 많은 기간에는 Inventory 테이블을 업데이트하는 데 회사가 허용할 
수 있는 것보다 더 오래 걸린다는 것을 알게 되었습니다. 
어떤 솔루션이 느린 테이블 업데이트를 해결할 수 있을까요? (두 가지 선택) 
A. Orders 테이블에 글로벌 보조 인덱스를 추가합니다. 제품 ID 속성을 포함합니다. 
B. DynamoDB 스트림의 배치 크기 속성을 Orders 테이블의 항목 크기에 따라 설정합니다. 
C. DynamoDB 테이블 프로비저닝 용량을 1,000 개의 쓰기 용량 단위(WCU)로 늘립니다. 
D. DynamoDB 테이블 프로비저닝 용량을 1,000 개의 읽기 용량 단위(RCU)로 늘립니다. 
E. Lambda 함수의 타임아웃을 15 분으로 늘리세요. 
Answer: B, C 
Q96 
한 회사에 전자상거래 사이트가 있습니다. 이 사이트는 하나의 AWS Organizations 조직에 
속한 여러 AWS 계정에서 호스팅되는 분산 웹 애플리케이션으로 설계되었습니다. 이 웹 
애플리케이션은 여러 마이크로서비스로 구성되어 있습니다. 모든 마이크로서비스는 
Amazon CloudFront 배포판 또는 퍼블릭 애플리케이션 로드 밸런서(ALB)를 통해 AWS 
서비스를 노출합니다. 이 회사는 퍼블릭 엔드포인트를 악의적인 공격으로부터 보호하고 
보안 구성을 모니터링하려고 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. AWS WAF 를 사용하여 퍼블릭 엔드포인트를 보호합니다. 전용 보안 계정에서 AWS 
Firewall Manager 를 사용하여 AWS WAF 의 규칙을 관리합니다. AWS Config 규칙을 
사용하여 리전 및 글로벌 WAF 구성을 모니터링합니다. 
B. AWS WAF 를 사용하여 퍼블릭 엔드포인트를 보호합니다. 각 계정에 AWS WAF 규칙을 
적용합니다. AWS Config 규칙과 AWS Security Hub 를 사용하여 ALB 와 CloudFront 
배포판의 WAF 구성을 모니터링합니다. 
C. AWS WAF 를 사용하여 퍼블릭 엔드포인트를 보호합니다. 전용 보안 계정에서 AWS 
Firewall Manager 를 사용하여 AWS WAF 의 규칙을 관리합니다. Amazon Inspector 와 AWS 
Security Hub 를 사용하여 ALB 와 CloudFront 배포의 WAF 구성을 모니터링합니다. 
D. AWS Shield Advanced 를 사용하여 퍼블릭 엔드포인트를 보호합니다. AWS Config 규칙을 
사용하여 각 계정의 Shield Advanced 구성을 모니터링합니다. 
Answer: A 
Q97 
개발자가 HTTP 작업 상태를 포함하는 AWS Step Functions 상태 머신에서 전자상거래 
워크플로를 만들고 있습니다. 이 작업은 배송 정보와 주문 세부 정보를 엔드포인트로 
전달합니다. 개발자는 HTTP 헤더와 본문이 올바르고 응답이 기대에 부합하는지 확인하기 
위해 워크플로를 테스트해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. TestState API 를 사용하여 HTTP 작업만 호출합니다. 검사 수준을 TRACE 로 설정합니다. 
B. TestState API 를 사용하여 상태 머신을 호출합니다. 검사 수준을 DEBUG 로 설정합니다. 
C. 데이터 흐름 시뮬레이터를 사용하여 HTTP 작업만 호출합니다. 요청 및 응답 데이터를 
확인합니다. 
D. 상태 머신의 로그 수준을 ALL 로 변경합니다. 상태 머신을 실행합니다. 
Answer: D 
Q98 
한 회사에서 기존 Amazon EC2 인스턴스의 VPC 에 새 애플리케이션을 배포하고 있습니다. 
이 애플리케이션에는 EC2 인스턴스의 자동 확장 그룹을 사용하는 프레젠테이션 계층이 
있습니다. 이 애플리케이션에는 Amazon RDS Multi-AZ 데이터베이스를 사용하는 
데이터베이스 계층도 있습니다. 
VPC 에는 두 개의 가용성 영역으로 분할된 두 개의 퍼블릭 서브넷이 있습니다. 솔루션 
아키텍트는 RDS 데이터베이스의 각 가용성 영역에 하나의 프라이빗 서브넷을 추가합니다. 
솔루션 아키텍트는 새 애플리케이션을 호스팅하지 않는 EC2 인스턴스의 액세스를 차단하기 
위해 RDS 데이터베이스에 대한 네트워크 액세스를 제한하려고 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 새 애플리케이션을 호스팅하는 EC2 인스턴스의 IP 주소가 포함된 CIDR 범위에서 
트래픽을 허용하도록 RDS 데이터베이스 보안 그룹을 수정합니다. 
B. 프라이빗 서브넷에 새 ACL 을 연결합니다. 새 애플리케이션을 호스팅하지 않는 모든 
EC2 인스턴스에 속하는 IP 주소에서 들어오는 모든 트래픽을 거부합니다. 
C. 새 애플리케이션을 호스팅하는 EC2 인스턴스와 연결된 보안 그룹에서 트래픽을 
허용하도록 RDS 데이터베이스 보안 그룹을 수정합니다. 
D. 개인 서브넷에 새 ACL 을 연결합니다. 새 애플리케이션을 호스팅하는 EC2 인스턴스의 
IP 주소를 포함하는 CIDR 범위의 트래픽을 제외한 모든 수신 트래픽을 거부합니다. 
Answer: C 
Q99 
금융 서비스 회사에 2 계층 소비자 뱅킹 애플리케이션이 있습니다. 프런트엔드는 정적 웹 
콘텐츠를 제공합니다. 백엔드는 API 로 구성됩니다. 회사는 프런트엔드 구성 요소를 AWS 로 
마이그레이션해야 합니다. 애플리케이션의 백엔드는 온프레미스에 유지됩니다. 회사는 
애플리케이션을 일반적인 웹 취약성 및 공격으로부터 보호해야 합니다. 
어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? 
A. 프런트엔드를 Amazon EC2 인스턴스로 마이그레이션합니다. 인스턴스 앞에 
애플리케이션 로드 밸런서(ALB)를 배포합니다. 인스턴스를 사용하여 온프레미스 API 를 
호출합니다. AWS WAF 규칙을 인스턴스와 연결합니다. 
B. 프런트엔드를 여러 출처가 있는 Amazon CloudFront 배포로 배포합니다. 한 출처를 정적 
웹 콘텐츠를 제공하는 Amazon S3 버킷으로 구성합니다. URL 패턴을 기반으로 온프레미스 
API 로 트래픽을 라우팅하도록 두 번째 출처를 구성합니다. AWS WAF 규칙을 배포와 
연결합니다. 
C. 프런트엔드를 Amazon EC2 인스턴스로 마이그레이션합니다. 인스턴스 앞에 네트워크 
로드 밸런서(NLB)를 배포합니다. 인스턴스를 사용하여 온프레미스 API 를 호출합니다. AWS 
네트워크 방화벽 인스턴스를 만듭니다. 모든 트래픽을 네트워크 방화벽 인스턴스를 통해 
라우팅합니다. 
D. 프런트엔드를 Amazon S3 버킷을 기반으로 하는 정적 웹사이트로 배포합니다. Amazon 
API Gateway REST API 와 Amazon EC2 인스턴스 세트를 사용하여 온프레미스 API 를 
호출합니다. AWS WAF 규칙을 REST API 와 S3 버킷에 연결합니다. 
Answer: B 
Q100 
한 회사에 AWS Lambda 함수로 구성된 서버리스 웹 애플리케이션이 있습니다. 이 
애플리케이션은 콜드 스타트로 인해 지연 시간이 증가하는 트래픽 급증을 경험합니다. 이 
회사는 애플리케이션의 트래픽 급증 처리 기능을 개선하고 지연 시간을 최소화하고자 
합니다. 이 솔루션은 트래픽이 적은 기간 동안 비용을 최적화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Lambda 함수에 대한 프로비저닝된 동시성을 구성합니다. AWS Application Auto 
Scaling 을 사용하여 프로비저닝된 동시성을 조정합니다. 
B. Auto Scaling 그룹에서 Amazon EC2 인스턴스를 시작합니다. 예약된 확장 정책을 
추가하여 트래픽이 많은 기간 동안 추가 EC2 인스턴스를 시작합니다. 
C. Lambda 함수에 대한 프로비저닝된 동시성을 구성합니다. 예상되는 최대 트래픽을 
처리하도록 고정된 동시성 수준을 설정합니다. 
D. Amazon EventBridge Scheduler 에서 반복 일정을 만듭니다. 이 일정을 사용하여 
Lambda 함수를 주기적으로 호출하여 함수를 워밍업합니다. 
Answer: A 
Q96 
한 미디어 회사에서 음악을 판매하는 전자상거래 웹사이트를 운영하고 있습니다. 각 음악 
파일은 MP3 파일로 저장됩니다. 웹사이트의 프리미엄 사용자는 음악 파일을 구매하고 
다운로드합니다. 이 회사는 AWS 에 음악 파일을 저장하려고 합니다. 이 회사는 프리미엄 
사용자에게만 액세스를 제공하려고 합니다. 이 회사는 모든 프리미엄 사용자에게 동일한 
URL 을 사용하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족할까요? 
A. Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 Amazon EC2 인스턴스 세트에 
MP3 파일을 저장합니다. 각 프리미엄 사용자에 대한 IAM 사용자와 IAM 정책을 만들어 
파일에 대한 액세스를 관리합니다. 
B. 모든 MP3 파일을 Amazon S3 버킷에 저장합니다. 각 MP3 파일에 대해 미리 서명된 
URL 을 만듭니다. 미리 서명된 URL 을 프리미엄 사용자와 공유합니다. 
C. 모든 MP3 파일을 Amazon S3 버킷에 저장합니다. S3 버킷을 원본으로 사용하는 
Amazon CloudFront 배포를 만듭니다. 음악 파일에 대한 CloudFront 서명 쿠키를 
생성합니다. 서명된 쿠키를 프리미엄 사용자와 공유합니다. 
D. 모든 MP3 파일을 Amazon S3 버킷에 저장합니다. S3 버킷을 출처로 사용하는 Amazon 
CloudFront 배포를 만듭니다. 각 음악 파일에 대해 CloudFront 서명 URL 을 사용합니다. 
서명된 URL 을 프리미엄 사용자와 공유합니다. 
Answer: C