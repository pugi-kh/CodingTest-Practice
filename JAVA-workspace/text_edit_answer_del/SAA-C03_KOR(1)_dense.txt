Exam : SAA-C03-KOR(1) 
Title : Amazon AWS Certified Solutions Architect - Associate (SAA-C03 Korean Version) 
Version : Examtopics(Q1~Q500) 
Ps. 정답이 애매한 문제들은 (?? 마크가 있는문제) 있는 문제는 링크를 통해 정답을 다시 한번 꼭 
확인해서 공부하세요. 
한글 시험이 덤프 적중률이 높습니다. 다만 한글 시험의 경우 번역기가 달라서 덤프 번역과 실제 
시험 번역이 상의 할 수 있습니다. 
Q1 
회사는 여러 대륙에 걸쳐 도시의 온도, 습도 및 대기압에 대한 데이터를 수집합니다. 회사가 매일 
각 사이트에서 수집하는 데이터의 평균 볼륨은 500GB 입니다. 각 사이트에는 고속 인터넷 연결이 
있습니다. 
이 회사는 이러한 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리 
집계하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 대상 S3 버킷에서 S3 Transfer Acceleration 을 켭니다. 멀티파트 업로드를 사용하여 사이트 
데이터를 대상 S3 버킷에 직접 업로드합니다. 
B. 각 사이트의 데이터를 가장 가까운 리전의 S3 버킷에 업로드합니다. S3 교차 리전 복제를 
사용하여 대상 S3 버킷에 객체를 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다. 
C. AWS Snowball Edge Storage Optimized 디바이스 작업을 매일 예약하여 각 사이트에서 가장 
가까운 리전으로 데이터를 전송합니다. S3 교차 리전 복제를 사용하여 대상 S3 버킷에 객체를 
복사합니다. 
D. 각 사이트의 데이터를 가장 가까운 리전의 Amazon EC2 인스턴스로 업로드합니다. Amazon 
Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 정기적으로 EBS 스냅샷을 만들어 
대상 S3 버킷이 포함된 리전에 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/84973-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
여러 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리 집계하는 동시에 운영 
복잡성을 최소화하려면 가장 적합한 솔루션은 옵션 A: 대상 S3 버킷에서 S3 전송 가속화를 
설정하고 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드하는 
것입니다. 
요약하면 옵션 A 는 여러 글로벌 사이트의 데이터를 단일 Amazon S3 버킷으로 신속하게 집계하는 
가장 효율적이고 운영상 간단한 솔루션을 제공합니다. S3 Transfer Acceleration 및 멀티파트 
업로드를 활용하여 회사는 복잡성을 최소화하면서 빠른 데이터 수집을 달성할 수 있습니다. 
Q2 
회사는 독점 애플리케이션의 로그 파일을 분석할 수 있는 능력이 필요합니다. 로그는 Amazon S3 
버킷에 JSON 형식으로 저장됩니다. 쿼리는 간단하고 주문형으로 실행됩니다. 솔루션 설계자는 
기존 아키텍처에 대한 최소한의 변경으로 분석을 수행해야 합니다. 
솔루션 설계자는 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 무엇을 해야 
합니까? 
A. Amazon Redshift 를 사용하여 모든 콘텐츠를 한 곳에 로드하고 필요에 따라 SQL 쿼리를 
실행합니다. 
B. Amazon CloudWatch Logs 를 사용하여 로그를 저장합니다. Amazon CloudWatch 콘솔에서 
필요에 따라 SQL 쿼리를 실행합니다. 
C. Amazon S3 와 함께 Amazon Athena 를 직접 사용하여 필요에 따라 쿼리를 실행합니다. 
D. AWS Glue 를 사용하여 로그를 분류합니다. Amazon EMR 에서 임시 Apache Spark 클러스터를 
사용하여 필요에 따라 SQL 쿼리를 실행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/84848-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
S3 에 쿼리하는 건 Athena. 
Athena 가 사용 가능한 모든 리전에서 Amazon Athena 를 사용하여 표준 SQL 로 Amazon S3 
인벤토리를 쿼리할 수 있습니다.  
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-inventory-athena-quer
y.html 
Athena 로 JSON 쿼리 가능. 
Amazon Athena 를 사용하면 JSON 인코딩 값을 구문 분석하고, JSON 에서 데이터를 추출하고, 
값을 검색하고, JSON 배열의 길이와 크기를 찾을 수 있습니다. 
https://docs.aws.amazon.com/athena/latest/ug/querying-JSON.html 
Q3 
회사는 AWS Organizations 를 사용하여 여러 부서의 여러 AWS 계정을 관리합니다. 관리 계정에는 
프로젝트 보고서가 포함된 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 대한 액세스를 
AWS Organizations 의 조직 내 계정 사용자로만 제한하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 조직 ID 에 대한 참조와 함께 aws PrincipalOrgID 전역 조건 키를 S3 버킷 정책에 추가합니다. 
B. 각 부서에 대한 조직 단위(OU)를 만듭니다. aws:PrincipalOrgPaths 전역 조건 키를 S3 버킷 
정책에 추가합니다. 
C. AWS CloudTrail 을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 
및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. 그에 따라 S3 버킷 정책을 
업데이트합니다. 
D. S3 버킷에 액세스해야 하는 각 사용자에 태그를 지정합니다. aws:PrincipalTag 전역 조건 키를 
S3 버킷 정책에 추가합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/84838-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A(O) : aws:PrincipalOrgID 라는 새로운 조건 키를 권한 정책에 사용하여 조직 내의 계정에 
해당하는 IAM 보안 주체(사용자 및 역할)만 리소스에 액세스할 수 있도록 합니다. 
https://aws.amazon.com/ko/about-aws/whats-new/2018/05/principal-org-id/ 
B(X) : aws:PrincipalOrgPaths 는 다중 값 조건 키입니다. 다중 값 키에는 하나 이상의 값이 목록 
형식으로 포함됩니다. 결과는 논리적 OR 입니다. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_condition-keys.ht
ml 
C(X) : CloudTrail 은 리소스 내역을 기록/전송하는 서비스로 지문에서 요구하는 사항에 불필요. 
D(X) : 각 사용자마다 태그를 달아야 하므로 최소 운영 오버헤드라는 조건 불충족. 
aws:PrincipalTag/tag-key : 문자열 연산자를 사용합니다. 이 키를 사용하여 요청한 보안 주체에 
연결된 태그를 정책에서 지정한 태그와 비교합니다. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_condition-keys.ht
ml 
Q4 
애플리케이션은 VPC 의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon S3 
버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷 연결 없이 S3 버킷에 액세스해야 
합니다. 
Amazon S3 에 대한 프라이빗 네트워크 연결을 제공하는 솔루션은 무엇입니까? 
A. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다. 
B. Amazon CloudWatch Logs 로 로그를 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다. 
C. Amazon EC2 에 인스턴스 프로파일을 생성하여 S3 액세스를 허용합니다. 
D. S3 엔드포인트에 액세스하기 위한 프라이빗 링크가 있는 Amazon API Gateway API 를 
생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/84980-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
VPC-S3 간 인터넷을 통하지 않는 연결 = S3 VPC Gateway Endpoint. 정답은 A. 
설명 2: 
VPC 종단점을 사용하면 공용 인터넷을 사용하는 대신 사설 네트워크를 사용하여 AWS 서비스에 
연결할 수 있습니다. 
Q5 
회사는 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 
사용하여 AWS 에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 위해 이 
회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하여 
Application Load Balancer 뒤에 배치했습니다. 이 변경을 완료한 후 사용자는 웹 사이트를 새로 
고칠 때마다 문서의 일부 또는 다른 하위 집합을 볼 수 있지만 모든 문서를 동시에 볼 수는 
없다고 보고했습니다. 
솔루션 설계자는 사용자가 모든 문서를 한 번에 볼 수 있도록 무엇을 제안해야 합니까? 
A. 두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다. 
B. 문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer 를 구성합니다. 
C. 두 EBS 볼륨의 데이터를 Amazon EFS 로 복사합니다. 새 문서를 Amazon EFS 에 저장하도록 
애플리케이션을 수정합니다. 
D. 두 서버 모두에 요청을 보내도록 Application Load Balancer 를 구성합니다. 올바른 서버에서 각 
문서를 반환합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/84981-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
EBS 와 EFS 의 가장 큰 차이점 중 하나는 EBS 는 단일 AZ 안에서만 접근이 가능한 저장소인 반면, 
EFS 는 다중 AZ 안에서도 접근이 가능한 저장소라는 점입니다. 위 문제에서는 초기 단일 AZ 에서 
운영하던 EC2 및 EBS 를 복제한뒤 AZ 를 2 중화하여 멀티 EC2 및 EBS 시스템으로 구성하였지만, 
각 AZ 내에서 공유되지 않는 EBS 저장소를 별도로 운영하였기때문에 고객들에게 일관성있는 
데이터를 제공할 수 없었던 것으로 보입니다. 이는 각 AZ 의 EC2 인스턴스가 동일한 저장소를 
공유하도록 함으로써 해결할 수 있을 것 같습니다. 초기 EBS 에 저장되어있던 데이터들을 
일관성있게 보정하여 EFS 로 일회성 마이그레이션을 수행한뒤 EC2 어플리케이션 서버 인스턴스가 
EBS 가 아닌 EFS 에 데이터를 저장하도록 변경하는 것이 바람직해보입니다. 
설명 2: 
Amazon EFS 는 AWS 클라우드에서 파일 스토리지를 제공합니다. Amazon EFS 를 사용하면 파일 
시스템을 생성하고 파일 시스템을 Amazon EC2 인스턴스에 탑재한 다음 파일 시스템에서 
데이터를 읽고 쓸 수 있습니다. Network File System 버전 4.0 및 4.1(NFSv4) 프로토콜을 통해 
VPC 에 Amazon EFS 파일 시스템을 탑재할 수 있습니다. Amazon EFS Mount Helper 와 함께 최신 
Amazon Linux, Redhat 및 Ubuntu AMI 에 있는 것과 같은 현재 세대 Linux NFSv4.1 클라이언트를 
사용하는 것이 좋습니다. 지침은 amazon-efs-utils 도구 사용 단원을 참조하십시오. 
이 프로토콜을 지원하는 Amazon EC2 Linux Amazon 머신 이미지(AMI) 목록은 NFS 지원을 
참조하십시오. 일부 AMI 의 경우 파일 시스템을 Amazon EC2 인스턴스에 탑재하려면 NFS 
클라이언트를 설치해야 합니다. 지침은 NFS 클라이언트 설치를 참조하십시오. 
여러 NFS 클라이언트에서 동시에 Amazon EFS 파일 시스템에 액세스할 수 있으므로 단일 연결 
이상으로 확장되는 애플리케이션이 파일 시스템에 액세스할 수 있습니다. 동일한 AWS 리전 내의 
여러 가용 영역에서 실행되는 Amazon EC2 인스턴스는 파일 시스템에 액세스할 수 있으므로 많은 
사용자가 공통 데이터 원본에 액세스하고 공유할 수 있습니다. 
https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2 
Q6 
회사는 NFS 를 사용하여 온프레미스 네트워크 연결 스토리지에 대용량 비디오 파일을 저장합니다. 
각 비디오 파일의 크기 범위는 1MB 에서 500GB 입니다. 총 스토리지는 70TB 이며 더 이상 
증가하지 않습니다. 회사는 비디오 파일을 Amazon S3 로 마이그레이션하기로 결정합니다. 회사는 
가능한 한 최소한의 네트워크 대역폭을 사용하면서 가능한 한 빨리 비디오 파일을 
마이그레이션해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. S3 버킷을 생성합니다. S3 버킷에 대한 쓰기 권한이 있는 IAM 역할을 생성합니다. AWS CLI 를 
사용하여 모든 파일을 S3 버킷에 로컬로 복사합니다. 
B. AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 장치를 받습니다. 
Snowball Edge 클라이언트를 사용하여 장치로 데이터를 전송합니다. AWS 가 데이터를 Amazon 
S3 로 가져올 수 있도록 디바이스를 반환합니다.  
C. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 서비스 
엔드포인트를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 
생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 
게이트웨이로 데이터를 전송합니다. 
D. 온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 
파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 공용 VIF(가상 인터페이스)를 
생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 생성합니다. 새 
파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 
데이터를 전송합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/84875-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
가능한 한 최소한의 네트워크 대역폭을 사용하라 했으니 아예 오프라인에서 Snowball Edge 로 
올리는 게 맞음. 
AWS Snowball 및 AWS Snowball Edge 는 기존 저장소에서 네트워크 대역폭이 충분하지 않을 때, 
대용량 데이터 세트를 클라우드로 이전하는데 도움이 됩니다. 
Snowball 장치는 80TB, Snowball Edge 는 100TB 까지 한번에 이동 가능합니다. 
https://aws.amazon.com/ko/blogs/korea/aws-snowball-and-aws-snowball-edge-available-in-
asia-pacific-seoul-region/ 
설명 2: 
Snowball 과 Snowball Edge 의 기본적인 차이점은 제공하는 용량입니다. Snowball 은 총 50TB 또는 
80TB 를 제공하며 그 중 42TB 또는 72TB 를 사용할 수 있고 Amazon Snowball Edge 는 100TB 를 
제공하며 그 중 83TB 를 사용할 수 있습니다. 
Q7 
회사에 들어오는 메시지를 수집하는 응용 프로그램이 있습니다. 그러면 수십 개의 다른 
애플리케이션과 마이크로서비스가 이러한 메시지를 빠르게 소비합니다. 메시지 수는 급격하게 
변하며 때로는 초당 100,000 개로 갑자기 증가하기도 합니다. 이 회사는 솔루션을 분리하고 
확장성을 높이고자 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Kinesis Data Analytics 에 대한 메시지를 유지합니다. 메시지를 읽고 처리하도록 소비자 
애플리케이션을 구성합니다. 
B. Auto Scaling 그룹의 Amazon EC2 인스턴스에 수집 애플리케이션을 배포하여 CPU 지표를 
기반으로 EC2 인스턴스 수를 확장합니다. 
C. 단일 샤드를 사용하여 Amazon Kinesis Data Streams 에 메시지를 씁니다. AWS Lambda 함수를 
사용하여 메시지를 사전 처리하고 Amazon DynamoDB 에 저장합니다. 메시지를 처리하기 위해 
DynamoDB 에서 읽도록 소비자 애플리케이션을 구성합니다. 
D. 여러 Amazon Simple Queue Service(Amazon SOS) 구독이 있는 Amazon Simple Notification 
Service(Amazon SNS) 주제에 메시지를 게시합니다. 대기열의 메시지를 처리하도록 소비자 
애플리케이션을 구성합니다.  
Answer: D 
https://www.examtopics.com/discussions/amazon/view/84721-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
https://aws.amazon.com/sqs/features/ 
들어오는 요청을 Amazon SQS 로 라우팅함으로써 회사는 처리 인스턴스에서 작업 요청을 분리할 
수 있습니다. 이를 통해 대기열 크기에 따라 인스턴스 수를 확장하여 필요할 때 더 많은 리소스를 
제공할 수 있습니다. 또한 대기열 크기를 기반으로 하는 Auto Scaling 그룹을 사용하면 워크로드에 
따라 자동으로 인스턴스 수를 늘리거나 줄일 수 있습니다. 대기열에서 읽을 수 있도록 
소프트웨어를 업데이트하면 보다 효율적인 방식으로 작업 요청을 처리할 수 있어 시스템 성능이 
향상됩니다. 
솔루션을 분리 = SQS. 
Q8 
회사에서 분산 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 애플리케이션은 다양한 
워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 
구성됩니다. 이 회사는 탄력성과 확장성을 극대화하는 솔루션으로 애플리케이션을 현대화하려고 
합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까? 
A. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto 
Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 예약된 조정을 
사용하도록 EC2 Auto Scaling 을 구성합니다. 
B. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto 
Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 대기열 크기에 
따라 EC2 Auto Scaling 을 구성합니다.  
C. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 
구현합니다. 작업의 대상으로 AWS CloudTrail 을 구성합니다. 기본 서버의 부하를 기반으로 EC2 
Auto Scaling 을 구성합니다. 
D. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 
구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 
컴퓨팅 노드의 부하를 기반으로 EC2 Auto Scaling 을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/84679-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : Scheduled Scaling 은 실시간 현황에 맞춰 적용되는 탄력성이 부족. 
B(O) : SQS Queue 로 갑작스레 작업이 몰려도 추후 처리하도록 보관 가능. Auto Scaling 그룹으로 
여러 EC2 인스턴스의 확장/축소를 적절하게 지원. 
C(X) : CloudTrail 은 리소스 내역을 기록/전송하는 서비스. 
D(X) : CPU 사용률에 따라 EC2 Auto Scaling 하려면 Target Tracking Policy 를 사용하면 됨. 
대상 추적 조정 정책을 사용하여 Application Load Balancer 의 RequestCountPerTarget 지표 또는 
평균 CPU 사용률 같은 지표에 따라 확장하는 것이 좋습니다. 용량이 증가할 때 감소하고 용량이 
감소할 때 증가하는 지표를 사용하여 비례적으로 확장하거나 대상 추적을 사용하여 인스턴스 수를 
늘릴 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/as-scaling-simple-step.html 
설명 2: 
복원력과 확장성을 극대화하기 위한 최상의 솔루션은 Amazon SQS 대기열을 작업의 대상으로 
사용하는 것입니다. 이렇게 하면 컴퓨팅 노드에서 기본 서버가 분리되어 독립적으로 확장할 수 
있습니다. 이는 또한 실패 시 일자리 손실을 방지하는 데 도움이 됩니다. 컴퓨팅 노드에 대해 
Amazon EC2 인스턴스의 Auto Scaling 그룹을 사용하면 워크로드에 따라 자동 조정이 가능합니다. 
이 경우 Amazon SQS 대기열의 크기를 기반으로 Auto Scaling 그룹을 구성하는 것이 좋습니다. 
이는 기본 서버 또는 컴퓨팅 노드의 로드보다 실제 워크로드를 더 잘 나타내는 지표입니다. 이 
접근 방식은 애플리케이션이 가변 워크로드를 처리할 수 있도록 하는 동시에 필요에 따라 컴퓨팅 
노드를 자동으로 확장 또는 축소하여 비용을 최소화합니다. 
Q9 
회사는 데이터 센터에서 SMB 파일 서버를 실행하고 있습니다. 파일 서버는 파일이 생성된 후 
처음 며칠 동안 자주 액세스하는 대용량 파일을 저장합니다. 7 일이 지나면 파일에 거의 액세스하지 
않습니다. 
총 데이터 크기가 증가하고 있으며 회사의 총 저장 용량에 가깝습니다. 솔루션 설계자는 가장 
최근에 액세스한 파일에 대한 저지연 액세스를 잃지 않으면서 회사의 사용 가능한 저장 공간을 
늘려야 합니다. 솔루션 설계자는 향후 스토리지 문제를 방지하기 위해 파일 수명 주기 관리도 
제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS DataSync 를 사용하여 SMB 파일 서버에서 AWS 로 7 일이 지난 데이터를 복사합니다. 
B. Amazon S3 파일 게이트웨이를 생성하여 회사의 스토리지 공간을 확장합니다. S3 수명 주기 
정책을 생성하여 7 일 후에 데이터를 S3 Glacier Deep Archive 로 전환합니다.  
C. Windows 파일 서버용 Amazon FSx 파일 시스템을 생성하여 회사의 저장 공간을 확장합니다. 
D. 각 사용자의 컴퓨터에 유틸리티를 설치하여 Amazon S3 에 액세스합니다. S3 수명 주기 정책을 
생성하여 7 일 후 데이터를 S3 Glacier Flexible Retrieval 로 전환합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/84680-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
사용 가능한 스토리지 공간을 늘림 = Storage Gateway. 답은 B. 
A(X) : AWS 에서 무슨 스토리지를 사용할 건지에 대한 언급이 없음. 또한 하이브리드 스토리지인 
Storage Gateway 가 더 적절한 방식임. 
B(O) : 정답. 스토리지 게이트웨이는 온프레미스 스토리지와 AWS 스토리지를 합쳐 사실상 
무제한의 스토리지를 향유하는 것을 목적으로 하는 서비스. 
Amazon S3 File Gateway 의 사용 사례로는 (a) 최근에 액세스한 데이터에 대해 빠른 로컬 액세스를 
유지하면서 온프레미스 파일 데이터를 Amazon S3 로 마이그레이션. SMB(서버 메시지 블록) 버전 2 
및 3 을 사용하여 게이트웨이에 연결하는 Windows 클라이언트를 지원합니다. 
https://aws.amazon.com/ko/storagegateway/faqs/?nc=sn&loc=6 
C(X) : A 와 같은 이유로 오답. 
D(X) : SMB 사용 여부 불투명. 
설명 2: 
Amazon S3 File Gateway 는 온프레미스 애플리케이션이 Amazon S3 클라우드 스토리지를 원활하게 
사용할 수 있도록 하는 하이브리드 클라우드 스토리지 서비스입니다. Amazon S3 에 대한 파일 
인터페이스를 제공하고 SMB 및 NFS 프로토콜을 지원합니다. 또한 지정된 기간이 지나면 데이터를 
S3 Standard 에서 S3 Glacier Deep Archive 로 자동 전환할 수 있는 S3 수명 주기 정책을 
지원합니다. 이 솔루션은 짧은 대기 시간 액세스를 유지하면서 회사의 사용 가능한 저장 공간을 
늘리는 요구 사항을 충족합니다. 
가장 최근에 액세스한 파일에 저장하고 파일 수명 주기 관리를 제공하여 향후 스토리지 문제를 
방지합니다. 
Q10 
회사는 AWS 에서 전자 상거래 웹 애플리케이션을 구축하고 있습니다. 애플리케이션은 처리할 
Amazon API Gateway REST API 에 새 주문에 대한 정보를 보냅니다. 회사는 주문이 접수된 
순서대로 처리되기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Notification 
Service(Amazon SNS) 주제에 메시지를 게시합니다. AWS Lambda 함수를 주제에 구독하여 처리를 
수행합니다. 
B. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Queue 
Service(Amazon SQS) FIFO 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 
호출하도록 SQS FIFO 대기열을 구성합니다.  
C. API Gateway 권한 부여자를 사용하여 애플리케이션이 주문을 처리하는 동안 모든 요청을 
차단합니다. 
D. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Queue 
Service(Amazon SQS) 표준 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 
호출하도록 SQS 표준 대기열을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/84681-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
주문이 접수된 순서대로 처리되도록 하기 위한 최상의 솔루션은 Amazon SQS FIFO(선입선출) 
대기열을 사용하는 것입니다. 이 유형의 대기열은 메시지를 보내고 받는 정확한 순서를 유지합니다. 
이 경우 애플리케이션은 새 주문에 대한 정보를 Amazon API Gateway REST API 로 보낼 수 
있습니다. 그런 다음 API Gateway 통합을 사용하여 처리를 위해 메시지를 Amazon SQS FIFO 
대기열로 보낼 수 있습니다. 그런 다음 AWS Lambda 함수를 호출하여 각 주문에 필요한 처리를 
수행하도록 대기열을 구성할 수 있습니다. 이렇게 하면 주문이 접수된 정확한 순서대로 
처리됩니다. 
즉. 주문한 순서대로 = FIFO 
Q11 
회사에 Amazon EC2 인스턴스에서 실행되고 Amazon Aurora 데이터베이스를 사용하는 
애플리케이션이 있습니다. EC2 인스턴스는 파일에 로컬로 저장된 사용자 이름과 암호를 사용하여 
데이터베이스에 연결합니다. 회사는 자격 증명 관리의 운영 오버헤드를 최소화하려고 합니다. 
솔루션 설계자는 이 목표를 달성하기 위해 무엇을 해야 합니까? 
A. AWS Secrets Manager 를 사용합니다. 자동 회전을 켭니다.  
B. AWS Systems Manager Parameter Store 를 사용합니다. 자동 회전을 켭니다. 
C. AWS Key Management Service(AWS KMS) 암호화 키로 암호화된 객체를 저장할 Amazon S3 
버킷을 생성합니다. 자격 증명 파일을 S3 버킷으로 마이그레이션합니다. 애플리케이션이 S3 
버킷을 가리키도록 합니다. 
D. 각 EC2 인스턴스에 대해 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 
생성합니다. 새 EBS 볼륨을 각 EC2 인스턴스에 연결합니다. 자격 증명 파일을 새 EBS 볼륨으로 
마이그레이션합니다. 애플리케이션이 새 EBS 볼륨을 가리키도록 합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/84682-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A(O) : Secrets Manager 는 자격증명을 저장해두고 관리할 수 있는 서비스. 
AWS Secrets Manager 는 애플리케이션, 서비스 및 IT 리소스에 대한 액세스를 보호하는 데 도움이 
되는 보안 정보 관리 서비스입니다. 이 서비스를 사용하면 수명 주기 동안 데이터베이스 자격 증명, 
API 키 및 기타 보안 정보를 손쉽게 교체, 관리 및 검색할 수 있습니다. 
https://aws.amazon.com/ko/secrets-manager/faqs/ 
Secrets Manager 에서 보안 암호에 대한 자동 교체를 설정할 수 있습니다. 
https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html 
B(X) : Systems Manager Parameter Store 는 구성 데이터 같은 걸 코드와 분리하여 원치 않는 
노출을 막는 것. 
Q:AWS Systems Manager parameter store 란 무엇입니까? AWS Systems Manager 는 데이터베이스 
문자열과 같은 평문 데이터든 암호와 같은 비밀이든 관계없이 구성 데이터를 관리할 수 있는 중앙 
스토어를 제공합니다. 따라서 비밀과 구성 데이터를 코드와 분리할 수 있습니다. 
https://aws.amazon.com/ko/systems-manager/faq/ 
C(X) : KMS 키는 S3 버킷에 저장하는 것이 아니라 Secrets Manager 등을 이용해 관리. 
D(X) : C 와 비슷한 이유로 오답." 
Q12 
글로벌 회사는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 웹 
애플리케이션을 호스팅합니다. 웹 애플리케이션에는 정적 데이터와 동적 데이터가 있습니다. 
회사는 정적 데이터를 Amazon S3 버킷에 저장합니다. 회사는 정적 데이터 및 동적 데이터의 
성능을 개선하고 대기 시간을 줄이기를 원합니다. 회사는 Amazon Route 53 에 등록된 자체 도메인 
이름을 사용하고 있습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. S3 버킷과 ALB 를 오리진으로 포함하는 Amazon CloudFront 배포를 생성합니다. CloudFront 
배포로 트래픽을 라우팅하도록 Route 53 을 구성합니다.  
B. ALB 가 오리진인 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 포함하는 
AWS Global Accelerator 표준 액셀러레이터를 생성합니다. CloudFront 배포로 트래픽을 
라우팅하도록 Route 53 을 구성합니다. 
C. S3 버킷을 오리진으로 포함하는 Amazon CloudFront 배포를 생성합니다. ALB 및 CloudFront 
배포를 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. 가속기 
DNS 이름을 가리키는 사용자 지정 도메인 이름을 만듭니다. 사용자 지정 도메인 이름을 웹 
애플리케이션의 끝점으로 사용합니다. 
D. ALB 가 오리진인 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 포함하는 
AWS Global Accelerator 표준 액셀러레이터를 생성합니다. 두 개의 도메인 이름을 만듭니다. 
하나의 도메인 이름이 동적 콘텐츠의 CloudFront DNS 이름을 가리키도록 합니다. 다른 도메인 
이름이 정적 콘텐츠에 대한 가속기 DNS 이름을 가리키도록 합니다. 도메인 이름을 웹 
애플리케이션의 끝점으로 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85010-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(O) : 배포를 만들 때 CloudFront 가 파일에 대한 요청을 보내는 원본을 지정합니다. 
CloudFront 에서 여러 원본을 사용할 수 있습니다. 예를 들어 Amazon S3 버킷, MediaStore 
컨테이너, MediaPackage 채널, Application Load Balancer 또는 AWS Lambda 함수 URL 을 사용할 
수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3
AndCustomOrigins.html 
Amazon Route 53 을 구성하여 CloudFront 배포로 트래픽을 라우팅합니다. 이하 항목 참고 
https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/routing-to-cloudfront-distri
bution.html 
B(X) : 지문의 상황은 애플리케이션 계층에서 벌어지는 일이므로 TCP/UDP 를 사용하는 AWS 
Global Accelerator 는 부적절. 
C(X) : B 와 같은 이유로 오답. 
D(X) : B 와 같은 이유로 오답. 
설명 2: 
정적 콘텐츠는 S3 의 클라우드 프런트 엣지 위치와 ALB 뒤의 동적 콘텐츠 EC2 에서 캐싱할 수 
있습니다. 그 성능은 하나의 엔드포인트가 ALB 이고 다른 클라우드 프런트인 Global Accelerator 에 
의해 개선될 수 있습니다. 
따라서 사용자 지정 도메인 이름 끝점과 관련하여 웹 응용 프로그램은 웹 응용 프로그램에 대한 
사용자 지정 도메인 지점에 대한 R53 별칭 레코드입니다. 
https://aws.amazon.com/blogs/networking-and-content-delivery/improving-availability-andperf
ormance-for-app 
Q13 
회사는 AWS 인프라에 대한 월별 유지 관리를 수행합니다. 이러한 유지 관리 활동 중에 회사는 
여러 AWS 리전에서 MySQL 용 Amazon RDS 데이터베이스에 대한 자격 증명을 교체해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 자격 증명을 AWS Secrets Manager 에 암호로 저장합니다. 필요한 리전에 대해 다중 리전 비밀 
복제를 사용합니다. 일정에 따라 보안 암호를 교체하도록 Secrets Manager 를 구성합니다.  
B. 보안 문자열 파라미터를 생성하여 AWS Systems Manager 에 자격 증명을 보안 암호로 
저장합니다. 필요한 리전에 대해 다중 리전 비밀 복제를 사용합니다. 일정에 따라 암호를 
교체하도록 Systems Manager 를 구성합니다. 
C. 서버 측 암호화(SSE)가 활성화된 Amazon S3 버킷에 자격 증명을 저장합니다. Amazon 
EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 호출하여 자격 증명을 
교체합니다. 
D. AWS Key Management Service(AWS KMS) 다중 리전 고객 관리형 키를 사용하여 자격 증명을 
비밀로 암호화합니다. Amazon DynamoDB 전역 테이블에 암호를 저장합니다. AWS Lambda 함수를 
사용하여 DynamoDB 에서 암호를 검색합니다. RDS API 를 사용하여 비밀을 교체합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/84728-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
다중 리전 애플리케이션에 필수 리전의 복제된 암호에 대한 액세스 권한을 부여하고 Secrets 
Manager 를 사용하여 복제본이 기본 암호와 동기화된 상태를 유지할 수 있습니다. Secrets 
Manager 를 사용하면 데이터베이스 자격 증명, API 키 및 기타 비밀을 포함한 비밀을 저장, 검색, 
관리 및 교체할 수 있습니다. 
https://aws.amazon.com/ko/blogs/security/how-to-replicate-secrets-aws-secrets-manager-m
ultiple-regions/ 
Q14 
회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 전자 상거래 애플리케이션을 
실행합니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 
Auto Scaling 그룹은 CPU 사용률 메트릭을 기반으로 확장됩니다. 전자 상거래 애플리케이션은 
대규모 EC2 인스턴스에서 호스팅되는 MySQL 8.0 데이터베이스에 트랜잭션 데이터를 저장합니다. 
애플리케이션 로드가 증가하면 데이터베이스의 성능이 빠르게 저하됩니다. 애플리케이션은 쓰기 
트랜잭션보다 더 많은 읽기 요청을 처리합니다. 이 회사는 고가용성을 유지하면서 예측할 수 없는 
읽기 워크로드의 수요를 충족하도록 데이터베이스를 자동으로 확장하는 솔루션을 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 리더 및 컴퓨팅 기능을 위해 단일 노드와 함께 Amazon Redshift 를 사용하십시오. 
B. 단일 AZ 배포와 함께 Amazon RDS 사용 다른 가용 영역에 리더 인스턴스를 추가하도록 
Amazon RDS 를 구성합니다. 
C. 다중 AZ 배포와 함께 Amazon Aurora 를 사용합니다. Aurora 복제본을 사용하여 Aurora Auto 
Scaling 을 구성합니다.  
D. EC2 스팟 인스턴스와 함께 Memcached 용 Amazon ElastiCache 를 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85019-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : 단일 노드에서 고가용성 불만족. RedShift 는 MySQL 과 같은 관계형 데이터베이스 서비스가 
아니라 데이터 웨어하우스 서비스. 
B(X) : 단일 AZ 이기 때문에 고가용성 불만족. 
C(O) : Aurora 는 자동으로 3 개의 AZ 에 6 개의 복제본을 생성. 이러한 복제본은 읽기 부하 분산 
효과가 있음. 
D(X) : 스팟 인스턴스를 사용할 때는 언제든 중지될 위험에 대비해야 함이 기본임. 즉, 중지될 수 
있는 위험이 높은 인스턴스라는 이야기. 그리고 다중 AZ 를 사용하지 않으므로 고가용성을 
만족하지 못했음. 
설명 2: 
Aurora 는 RDS 에서 MySQL 보다 5 배 향상된 성능을 제공하며 쓰기보다 더 많은 읽기 요청을 
처리합니다. 고가용성 유지 = 다중 AZ 배포. 
Q15 
최근에 AWS 로 마이그레이션한 회사가 프로덕션 VPC 로 들어오고 나가는 트래픽을 보호하는 
솔루션을 구현하려고 합니다. 이 회사는 사내 데이터 센터에 검사 서버를 가지고 있었습니다. 검사 
서버는 트래픽 흐름 검사 및 트래픽 필터링과 같은 특정 작업을 수행했습니다. 회사는 AWS 
클라우드에서 동일한 기능을 갖기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 프로덕션 VPC 에서 트래픽 검사 및 트래픽 필터링에 Amazon GuardDuty 를 사용합니다. 
B. 트래픽 미러링을 사용하여 트래픽 검사 및 필터링을 위해 프로덕션 VPC 의 트래픽을 
미러링합니다. 
C. AWS 네트워크 방화벽을 사용하여 프로덕션 VPC 에 대한 트래픽 검사 및 트래픽 필터링에 
필요한 규칙을 생성합니다. 
D. AWS Firewall Manager 를 사용하여 프로덕션 VPC 에 대한 트래픽 검사 및 트래픽 필터링에 
필요한 규칙을 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/84731-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
AWS Network Firewall 은 필요에 따라 검사와 필터링을 모두 지원합니다. 
설명 2: 
A(X) : GuardDuty 는 계정 보호 서비스. 
Amazon GuardDuty 는 AWS 계정 및 워크로드에서 악의적 활동을 모니터링하고 상세한 보안 
결과를 제공하여 가시성 및 해결을 촉진하는 위협 탐지 서비스입니다. 
https://aws.amazon.com/ko/guardduty/ 
B(X) : 트래픽 미러링은 네트워크 트래픽 복사 서비스. 
트래픽 미러링은 유형의 탄력적 네트워크 인터페이스에서 네트워크 트래픽을 복사하는 데 사용할 
수 있는 Amazon VPC 기능입니다. 
https://docs.aws.amazon.com/vpc/latest/mirroring/what-is-traffic-mirroring.html 
C(O) : AWS Network Firewall 을 사용하면 VPC 경계에서 네트워크 트래픽을 필터링할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/network-firewall.html 
D(X) : Firewall Manager 는 중앙에서 방화벽 규칙 관리하는 서비스. 
AWS Firewall Manager 는 AWS Organization 의 여러 계정과 애플리케이션에서 방화벽 규칙을 
중앙에서 구성 및 관리할 수 있는 보안 관리 서비스입니다. AWS Firewall Manager 를 사용하면 
조직의 여러 계정 및 리소스에 대한 AWS WAF 규칙, AWS Shield Advanced 보호, Amazon Virtual 
Private Cloud(VPC) 보안 그룹 및 AWS Network Firewall 및 Amazon Route 53 Resolver DNS 
Firewall 규칙을 중앙에서 구성할 수 있습니다. 
https://aws.amazon.com/ko/firewall-manager/faqs/ 
Q16 
회사는 AWS 에서 데이터 레이크를 호스팅합니다. 데이터 레이크는 Amazon S3 및 PostgreSQL 용 
Amazon RDS 의 데이터로 구성됩니다. 이 회사는 데이터 시각화를 제공하고 데이터 레이크 내의 
모든 데이터 소스를 포함하는 보고 솔루션이 필요합니다. 회사의 관리 팀만 모든 시각화에 대한 
전체 액세스 권한을 가져야 합니다. 나머지 회사는 제한된 액세스 권한만 가져야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon QuickSight 에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 
만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 IAM 역할과 대시보드를 
공유합니다. 
B. Amazon QuickSight 에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 
만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 사용자 및 그룹과 대시보드를 
공유합니다. 
C. Amazon S3 의 데이터에 대한 AWS Glue 테이블 및 크롤러를 생성합니다. AWS Glue 추출, 변환 
및 로드(ETL) 작업을 생성하여 보고서를 생성합니다. 보고서를 Amazon S3 에 게시합니다. S3 버킷 
정책을 사용하여 보고서에 대한 액세스를 제한합니다. 
D. Amazon S3 의 데이터에 대한 AWS Glue 테이블과 크롤러를 생성합니다. Amazon Athena 연합 
쿼리를 사용하여 PostgreSQL 용 Amazon RDS 내의 데이터에 액세스합니다. Amazon Athena 를 
사용하여 보고서를 생성합니다. 보고서를 Amazon S3 에 게시합니다. S3 버킷 정책을 사용하여 
보고서에 대한 액세스를 제한합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/84732-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
시각화 = QuickSight. A,B 둘 중 하나가 정답. 대시보드를 그룹과 사용자와 공유해야하므로 정답은 
B. 
기본적으로 Amazon QuickSight 의 대시보드는 누구와도 공유되지 않으며 소유자만 액세스할 수 
있습니다. 그러나 대시보드를 게시한 후에는 QuickSight 계정의 다른 사용자 또는 그룹과 공유할 
수 있습니다. 
https://docs.aws.amazon.com/quicksight/latest/user/sharing-a-dashboard.html 
설명 2: 
Amazon QuickSight 는 PostgreSQL 용 Amazon S3 및 Amazon RDS 를 비롯한 다양한 데이터 
소스에서 대화형 대시보드 및 보고서를 생성할 수 있는 데이터 시각화 서비스입니다. 모든 데이터 
소스를 연결하고 QuickSight 에서 새 데이터 세트를 만든 다음 대시보드를 게시하여 데이터를 
시각화할 수 있습니다. 또한 적절한 사용자 및 그룹과 대시보드를 공유하고 IAM 역할 및 권한을 
사용하여 액세스 수준을 제어할 수 있습니다. 
Q17 
회사에서 새로운 비즈니스 애플리케이션을 구현하고 있습니다. 이 애플리케이션은 두 개의 
Amazon EC2 인스턴스에서 실행되며 문서 저장을 위해 Amazon S3 버킷을 사용합니다. 솔루션 
설계자는 EC2 인스턴스가 S3 버킷에 액세스할 수 있는지 확인해야 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. S3 버킷에 대한 액세스 권한을 부여하는 IAM 역할을 생성합니다. 역할을 EC2 인스턴스에 
연결합니다. 
B. S3 버킷에 대한 액세스 권한을 부여하는 IAM 정책을 생성합니다. 정책을 EC2 인스턴스에 
연결합니다. 
C. S3 버킷에 대한 액세스 권한을 부여하는 IAM 그룹을 생성합니다. 그룹을 EC2 인스턴스에 
연결합니다. 
D. S3 버킷에 대한 액세스 권한을 부여하는 IAM 사용자를 생성합니다. 사용자 계정을 EC2 
인스턴스에 연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85032-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
https://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-access-s3-bucket/ 
설명 2: 
EC2 인스턴스가 S3 버킷에 액세스할 수 있는 권한이 있어야 하므로 IAM 역할을 부여해야 함. 
EC2 인스턴스에서 S3 버킷에 연결하려면 다음을 실행해야 합니다. 
1. Amazon S3 에 대한 액세스 권한을 부여하는 AWS Identity and Access Management(IAM) 
프로파일 역할을 생성합니다. 
2. 인스턴스에 IAM 인스턴스 프로파일을 연결합니다. 
3. S3 버킷에 대한 권한을 확인합니다. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/ec2-instance-access-s3-buck
et/ 
Q18 
애플리케이션 개발 팀은 큰 이미지를 더 작은 압축 이미지로 변환하는 마이크로서비스를 설계하고 
있습니다. 사용자가 웹 인터페이스를 통해 이미지를 업로드하면 마이크로 서비스는 이미지를 
Amazon S3 버킷에 저장하고, AWS Lambda 함수로 이미지를 처리 및 압축하고, 다른 S3 버킷에 
압축된 형태로 이미지를 저장해야 합니다. 
솔루션 설계자는 내구성이 있는 상태 비저장 구성 요소를 사용하여 이미지를 자동으로 처리하는 
솔루션을 설계해야 합니다. 
이러한 요구 사항을 충족하는 작업 조합은 무엇입니까? (2 개를 선택하세요.) 
A. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 이미지가 S3 버킷에 
업로드될 때 SQS 대기열에 알림을 보내도록 S3 버킷을 구성합니다. 
B. Amazon Simple Queue Service(Amazon SQS) 대기열을 호출 소스로 사용하도록 Lambda 함수를 
구성합니다. SQS 메시지가 성공적으로 처리되면 대기열에서 메시지를 삭제합니다. 
C. 새 업로드에 대해 S3 버킷을 모니터링하도록 Lambda 함수를 구성합니다. 업로드된 이미지가 
감지되면 메모리의 텍스트 파일에 파일 이름을 쓰고 텍스트 파일을 사용하여 처리된 이미지를 
추적합니다. 
D. Amazon EC2 인스턴스를 시작하여 Amazon Simple Queue Service(Amazon SQS) 대기열을 
모니터링합니다. 항목이 대기열에 추가되면 EC2 인스턴스의 텍스트 파일에 파일 이름을 기록하고 
Lambda 함수를 호출합니다. 
E. Amazon EventBridge(Amazon CloudWatch Events) 이벤트를 구성하여 S3 버킷을 
모니터링합니다. 이미지가 업로드되면 추가 처리를 위해 애플리케이션 소유자의 이메일 주소와 
함께 Amazon ample Notification Service(Amazon SNS) 주제에 알림을 보냅니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/85033-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A,E 조합으로 S3버킷->EventBridge->SNS Topic->SQS->Lambda 프로세스도 가능하긴 한데, A,B 
조합으로 S3->SQS->Lambda 가 훨씬 운영 및 비용 효율적. 
・S3 Events -> SQS Queue 
Amazon S3 은 다음과 같은 대상으로 이벤트 알림 메시지를 보낼 수 있습니다....◎Amazon Simple 
Queue Service(Amazon SQS) 대기열 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/NotificationHowTo.html 
・SQS Queue -> Lambda 
Lambda 함수를 사용하여 Amazon Simple Queue Service(Amazon SQS) 대기열의 메시지를 처리할 
수 있습니다. 
https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/with-sqs.html 
설명 2: 
Amazon Simple Queue Service(SQS) 대기열을 생성하고 이미지가 S3 버킷에 업로드될 때 SQS 
대기열에 알림을 보내도록 S3 버킷을 구성하면 Lambda 함수가 상태 비저장 및 내구성 방식으로 
트리거됩니다. 
SQS 대기열을 호출 소스로 사용하도록 Lambda 함수를 구성하고 성공적으로 처리된 후 
대기열에서 메시지를 삭제하면 Lambda 함수가 상태 비저장 및 내구성 방식으로 이미지를 
처리합니다. 
Amazon SQS 는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 
있는 완전관리형 메시지 대기열 서비스입니다. SQS 는 메시지 지향 미들웨어 관리 및 운영과 
관련된 복잡성과 오버헤드를 제거하고 개발자가 차별화 작업에 집중할 수 있도록 합니다. 새 
이미지가 S3 버킷에 업로드되면 SQS 는 Lambda 함수를 트리거하여 이미지를 처리하고 
압축합니다. 이미지가 처리되면 SQS 메시지가 삭제되어 Lambda 함수가 상태 비저장 및 내구성이 
보장됩니다. 
Q19 
회사에 AWS 에 배포된 3 계층 웹 애플리케이션이 있습니다. 웹 서버는 VPC 의 퍼블릭 서브넷에 
배포됩니다. 애플리케이션 서버와 데이터베이스 서버는 동일한 VPC 의 프라이빗 서브넷에 
배포됩니다. 이 회사는 AWS Marketplace 의 타사 가상 방화벽 어플라이언스를 검사 VPC 에 
배포했습니다. 어플라이언스는 IP 패킷을 수락할 수 있는 IP 인터페이스로 구성됩니다. 
솔루션 설계자는 트래픽이 웹 서버에 도달하기 전에 애플리케이션에 대한 모든 트래픽을 검사하기 
위해 웹 애플리케이션을 어플라이언스와 통합해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 애플리케이션 VPC 의 퍼블릭 서브넷에 Network Load Balancer 를 생성하여 패킷 검사를 위해 
어플라이언스로 트래픽을 라우팅합니다. 
B. 애플리케이션 VPC 의 퍼블릭 서브넷에 Application Load Balancer 를 생성하여 패킷 검사를 위해 
어플라이언스로 트래픽을 라우팅합니다. 
C. 전송 게이트웨이를 통해 들어오는 패킷을 라우팅하도록 라우팅 테이블을 구성하는 검사 VPC 에 
전송 게이트웨이를 배포합니다. 
D. 검사 VPC 에 게이트웨이 로드 밸런서를 배포합니다. 게이트웨이 로드 밸런서 엔드포인트를 
생성하여 수신 패킷을 수신하고 패킷을 어플라이언스로 전달합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/84727-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
Gateway Load Balancer 를 사용하면 방화벽, 침입 탐지 및 방지 시스템, 심층 패킷 검사 시스템과 
같은 가상 어플라이언스를 배포, 확장 및 관리할 수 있습니다. Gateway Load Balancer 는 Gateway 
Load Balancer 엔드포인트를 사용하여 VPC 경계 전체에서 트래픽을 안전하게 교환합니다. 
https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/gateway/introduction.html 
오늘 AWS Gateway Load Balancer(GWLB)가 정식 출시되었다는 소식을 알려드리고자 합니다. 이를 
통해 타사 가상 어플라이언스의 가용성을 쉽고 비용 효율적으로 배포, 확장 및 관리 할 수있는 
서비스 방화벽 , 침입 감지 및 방지 시스템과 클라우드의 심층 패킷 검사 시스템. AWS 파트너 
네트워크 및 AWS Marketplace 파트너는 규모, 가용성 및 서비스 제공이라는 복잡한 문제를 
해결하지 않고도 AWS 고객에게 가상 어플라이언스를 서비스로 제공 할 수도 있습니다. 
https://aws.amazon.com/ko/blogs/korea/introducing-aws-gateway-load-balancer-easy-deploy
ment-scalability-and-high-availability-for-partner-appliances/ 
Q20 
회사에서 동일한 AWS 리전의 테스트 환경에 대량의 프로덕션 데이터를 복제하는 기능을 
개선하려고 합니다. 데이터는 Amazon Elastic Block Store(Amazon EBS) 볼륨의 Amazon EC2 
인스턴스에 저장됩니다. 복제된 데이터를 수정해도 프로덕션 환경에 영향을 주지 않아야 합니다. 
이 데이터에 액세스하는 소프트웨어는 일관되게 높은 I/O 성능을 요구합니다. 
솔루션 설계자는 프로덕션 데이터를 테스트 환경에 복제하는 데 필요한 시간을 최소화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. 테스트 환경의 EC2 인스턴스 스토어 볼륨에 
스냅샷을 복원합니다. 
B. EBS 다중 연결 기능을 사용하도록 프로덕션 EBS 볼륨을 구성합니다. 프로덕션 EBS 볼륨의 
EBS 스냅샷을 만듭니다. 테스트 환경의 EC2 인스턴스에 프로덕션 EBS 볼륨을 연결합니다. 
C. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. 새 EBS 볼륨을 생성하고 초기화합니다. 
프로덕션 EBS 스냅샷에서 볼륨을 복원하기 전에 테스트 환경의 EC2 인스턴스에 새 EBS 볼륨을 
연결합니다. 
D. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. EBS 스냅샷에서 EBS 빠른 스냅샷 복원 기능을 
켭니다. 스냅샷을 새 EBS 볼륨으로 복원합니다. 테스트 환경의 EC2 인스턴스에 새 EBS 볼륨을 
연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85226-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
A(X) : 인스턴스 스토어 볼륨은 휘발성이라 꺼지면 데이터 날라감. 
B(X) : EBS 다중 연결을 사용하게 되면 복제된 데이터를 수정할 때 프로덕션 환경에 영향을 주게 
됨. 이는 지문에서 요구한 사항과 위배됨. 
C(X) : 스냅샷으로 새로운 볼륨을 만드는 것이지 만들어진 볼륨에 스냅샷을 복원하는 게 아님. 
D(O) : 정답. 
Q21 
전자 상거래 회사는 AWS 에서 하루 1 회 웹 사이트를 시작하려고 합니다. 매일 24 시간 동안 
정확히 하나의 제품을 판매합니다. 회사는 피크 시간 동안 밀리초 지연 시간으로 시간당 수백만 
개의 요청을 처리할 수 있기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon S3 를 사용하여 다른 S3 버킷에 전체 웹 사이트를 호스팅합니다. Amazon CloudFront 
배포를 추가합니다. S3 버킷을 배포의 오리진으로 설정합니다. Amazon S3 에 주문 데이터를 
저장합니다. 
B. 여러 가용 영역의 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스에 전체 웹 사이트를 
배포합니다. ALB(Application Load Balancer)를 추가하여 웹 사이트 트래픽을 분산합니다. 백엔드 
API 에 대해 다른 ALB 를 추가하십시오. MySQL 용 Amazon RDS 에 데이터를 저장합니다. 
C. 컨테이너에서 실행되도록 전체 애플리케이션을 마이그레이션합니다. Amazon Elastic Kubernetes 
Service(Amazon EKS)에서 컨테이너를 호스팅합니다. Kubernetes 클러스터 자동 확장 처리를 
사용하여 트래픽 버스트를 처리할 포드 수를 늘리거나 줄입니다. MySQL 용 Amazon RDS 에 
데이터를 저장합니다. 
D. Amazon S3 버킷을 사용하여 웹 사이트의 정적 콘텐츠를 호스팅합니다. Amazon CloudFront 
배포를 배포합니다. S3 버킷을 오리진으로 설정합니다. 백엔드 API 에 Amazon API Gateway 및 
AWS Lambda 함수를 사용합니다. Amazon DynamoDB 에 데이터를 저장합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85195-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : 전체 웹사이트를 호스팅하기에는 동적인 요소들이 들어가 있을 수 있는데 S3+CloudFront 
조합은 정적 웹사이트 호스팅을 위한 것임. 
B(X) : RDS 는 기본적으로 Auto Scaling 을 사용하지 않음. 따로 켜야하는데 해당 선택지엔 Auto 
Scaling 을 사용한단 언급이 없음. 
워크로드를 예측할 수 없는 경우 Amazon RDS DB 인스턴스에 대해 스토리지 Autoscaling 을 
활성화할 수 있습니다. 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#U
SER_PIOPS.Autoscaling 
C(X) : B 와 동일한 이유로 오답. 
D(O) : 정적인 웹사이트 요소들은 S3 + CloudFront 로 빠르게 제공하고, API Gateway 에서 Lambda 
함수를 호출해 DynamoDB 에 데이터 저장 가능. DynamoDB 는 확장성이 뛰어나고 밀리초 단위 
액세스를 지원하는 데이터베이스 유형. 
・S3 + CloudFront 조합의 정적 웹사이트 호스팅 :  
https://aws.amazon.com/ko/premiumsupport/knowledge-center/cloudfront-serve-static-website
/ 
・즉, HTTPS 엔드포인트를 통해 API 를 호출하면 API Gateway 가 Lambda 함수를 호출합니다. 
https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/services-apigateway-tutorial.html 
・개발자는 DynamoDB 를 사용해 최신 서버리스 애플리케이션을 구축하여 우선 작은 규모에서 
시작했다가 전역적으로 확장하여 초당 페타바이트 단위의 데이터와 수천만 건의 읽기 및 쓰기 
요청을 지원하도록 할 수 있습니다.....DynamoDB 는 용량에 맞게 테이블을 자동으로 조정하므로 
별도로 관리하지 않아도 성능을 유지합니다. 
https://aws.amazon.com/ko/dynamodb/features/#Enterprise_ready 
설명 2: 
사용량이 많은 시간 동안 지연 시간이 밀리초이고 운영 오버헤드가 최소인 AWS 에서 하루 1 회 
거래 웹 사이트를 시작하려면 가장 좋은 옵션은 Amazon S3 버킷을 사용하여 웹 사이트의 정적 
콘텐츠를 호스팅하고 Amazon CloudFront 배포를 배포하는 것입니다. 
S3 버킷을 오리진으로 설정하고 백엔드 API 에 Amazon API Gateway 및 AWS Lambda 함수를 
사용하고 데이터를 Amazon DynamoDB 에 저장합니다. 
이 옵션은 최소한의 운영 오버헤드가 필요하며 사용량이 많은 시간 동안 밀리초 대기 시간으로 
시간당 수백만 건의 요청을 처리할 수 있습니다. 따라서 보기 D 가 정답입니다. 
Q22 
솔루션 설계자는 Amazon S3 를 사용하여 새로운 디지털 미디어 애플리케이션의 스토리지 
아키텍처를 설계하고 있습니다. 미디어 파일은 가용 영역 손실에 대한 복원력이 있어야 합니다. 
일부 파일은 자주 액세스되는 반면 다른 파일은 예측할 수 없는 패턴으로 거의 액세스되지 
않습니다. 솔루션 설계자는 미디어 파일을 저장하고 검색하는 비용을 최소화해야 합니다. 
이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까? 
A. S3 Standard (S3 표준) 
B. S3 Intelligent-Tiering (S3 지능형 계층화) 
C. S3 Standard-Infrequent Access(S3 Standard-IA) 
D. S3 One Zone-Infrequent Access(S3 One Zone-IA) 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/84943-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
S3 Intelligent-Tiering - 액세스 빈도 또는 불규칙한 사용 패턴을 모를 때 완벽한 사용 사례입니다. 
Amazon S3 는 다양한 사용 사례를 위해 설계된 다양한 스토리지 클래스를 제공합니다. 여기에는 
자주 액세스하는 데이터의 범용 스토리지를 위한 S3 Standard 가 포함됩니다. 액세스 패턴을 알 수 
없거나 변경하는 데이터를 위한 S3 Intelligent-Tiering; S3 Standard-Infrequent Access(S3 
Standard-IA) 및 S3 One Zone-Infrequent Access(S3 One Zone-IA)는 수명이 길지만 액세스 
빈도가 낮은 데이터를 위한 것입니다. 장기 아카이브 및 디지털 보존을 위한 Amazon S3 
Glacier(S3 Glacier) 및 Amazon S3 Glacier Deep Archive(S3 Glacier Deep Archive). 기존 AWS 
리전에서 충족할 수 없는 데이터 레지던시 요구 사항이 있는 경우 S3 Outposts 스토리지 클래스를 
사용하여 S3 데이터를 온프레미스에 저장할 수 있습니다. 
Amazon S3 는 수명 주기 동안 데이터를 관리하는 기능도 제공합니다. S3 수명 주기 정책이 
설정되면 애플리케이션을 변경하지 않고도 데이터가 자동으로 다른 스토리지 클래스로 전송됩니다. 
https://aws.amazon.com/getting-started/hands-on/getting-started-using-amazon-s3-intelligen
t-tiering/?nc1=h_ls 
예측할 수 없는 패턴 = S3 Intelligent Tiering. 
Q23 
회사에서 Amazon S3 Standard 스토리지를 사용하여 백업 파일을 저장하고 있습니다. 1 개월 동안 
파일에 자주 액세스합니다. 단, 1 개월 이후에는 파일에 접근하지 않습니다. 회사는 파일을 무기한 
보관해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까? 
A. 객체를 자동으로 마이그레이션하도록 S3 Intelligent-Tiering 을 구성합니다. 
B. S3 수명 주기 구성을 생성하여 1 개월 후에 S3 Standard 에서 S3 Glacier Deep Archive 로 객체를 
전환합니다. 
C. S3 수명 주기 구성을 생성하여 1 개월 후에 객체를 S3 Standard 에서 S3 Standard-Infrequent 
Access(S3 Standard-IA)로 전환합니다. 
D. S3 수명 주기 구성을 생성하여 1 개월 후에 객체를 S3 Standard 에서 S3 One Zone-Infrequent 
Access(S3 One Zone-IA)로 전환합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85092-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 B 입니다. 
1 개월 후에 객체를 S3 Standard 에서 S3 Glacier Deep Archive 로 전환하는 S3 수명 주기 구성을 
생성합니다. Amazon S3 Glacier Deep Archive 는 거의 액세스하지 않고 몇 시간의 검색 시간이 
허용되는 데이터의 장기 보존을 위한 안전하고 내구성이 있으며 매우 저렴한 Amazon S3 스토리지 
클래스입니다. Amazon S3 에서 가장 저렴한 스토리지 옵션이므로 1 개월 후에 액세스하지 않는 
백업 파일을 저장하는 데 비용 효율적인 선택입니다. S3 수명 주기 구성을 사용하여 1 개월 후에 
객체를 S3 Standard 에서 S3 Glacier Deep Archive 로 자동 전환할 수 있습니다. 이렇게 하면 자주 
액세스하지 않는 백업 파일의 저장 비용이 최소화됩니다. 
1 개월 이후 파일에 접근하지 않음 = S3 Glacier Deep Archive. 답은 B. 
Q24 
회사는 가장 최근 청구서에서 Amazon EC2 비용 증가를 관찰했습니다. 청구 팀은 몇 개의 EC2 
인스턴스에 대한 인스턴스 유형의 원치 않는 수직적 확장을 발견했습니다. 솔루션 설계자는 지난 
2 개월간의 EC2 비용을 비교하는 그래프를 생성하고 심층 분석을 수행하여 수직적 확장의 근본 
원인을 식별해야 합니다. 
솔루션 설계자는 운영 오버헤드가 가장 적은 정보를 어떻게 생성해야 합니까? 
A. AWS 예산을 사용하여 예산 보고서를 생성하고 인스턴스 유형에 따라 EC2 비용을 비교합니다. 
B. Cost Explorer 의 세분화된 필터링 기능을 사용하여 인스턴스 유형을 기반으로 EC2 비용에 대한 
심층 분석을 수행합니다. 
C. AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2 개월 동안의 인스턴스 
유형을 기준으로 EC2 비용을 비교합니다. 
D. AWS 비용 및 사용 보고서를 사용하여 보고서를 생성하고 Amazon S3 버킷으로 보냅니다. 
Amazon S3 와 함께 Amazon QuickSight 를 소스로 사용하여 인스턴스 유형을 기반으로 대화형 
그래프를 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85038-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
AWS Cost Explorer 는 비용과 사용량을 보고 분석할 수 있는 도구입니다. 기본 그래프, Cost 
Explorer 비용 및 사용량 보고서 또는 Cost Explorer RI 보고서를 사용하여 사용량 및 비용을 
탐색할 수 있습니다. 최대 지난 12 개월 동안의 데이터를 보고 향후 12 개월 동안 지출할 가능성이 
있는 금액을 예측하고 구매할 예약 인스턴스에 대한 추천을 받을 수 있습니다. 비용 탐색기를 
사용하여 추가 조사가 필요한 영역을 식별하고 비용을 이해하는 데 사용할 수 있는 추세를 볼 수 
있습니다. 
https://docs.aws.amazon.com/cost-management/latest/userguide/ce-what-is.html 
Q25 
회사에서 응용 프로그램을 설계하고 있습니다. 애플리케이션은 AWS Lambda 함수를 사용하여 
Amazon API Gateway 를 통해 정보를 수신하고 Amazon Aurora PostgreSQL 데이터베이스에 정보를 
저장합니다. 
개념 증명 단계에서 회사는 데이터베이스에 로드해야 하는 대용량 데이터를 처리하기 위해 
Lambda 할당량을 크게 늘려야 합니다. 솔루션 설계자는 확장성을 개선하고 구성 노력을 
최소화하기 위해 새로운 설계를 권장해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Lambda 함수 코드를 Amazon EC2 인스턴스에서 실행되는 Apache Tomcat 코드로 
리팩터링합니다. 네이티브 JDBC(Java Database Connectivity) 드라이버를 사용하여 
데이터베이스를 연결합니다. 
B. 플랫폼을 Aurora 에서 Amazon DynamoDProvision a DynamoDB Accelerator(DAX) 클러스터로 
변경합니다. DAX 클라이언트 SDK 를 사용하여 DAX 클러스터에서 기존 DynamoDB API 호출을 
가리킵니다. 
C. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. 정보를 
데이터베이스에 로드하도록 다른 기능을 구성하십시오. Amazon Simple Notification 
Service(Amazon SNS)를 사용하여 Lambda 함수를 통합합니다. 
D. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. 정보를 
데이터베이스에 로드하도록 다른 기능을 구성하십시오. Amazon Simple Queue Service(Amazon 
SQS) 대기열을 사용하여 Lambda 함수를 통합합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85197-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
대기열(SQS)로 병목 현상을 방지할 수 있습니다. 
대량의 데이터 처리 + 확장성 개선 = SQS queue + Lambda 조합. 
Q26 
회사는 AWS 클라우드 배포를 검토하여 Amazon S3 버킷에 무단 구성 변경이 없는지 확인해야 
합니다. 
솔루션 설계자는 이 목표를 달성하기 위해 무엇을 해야 합니까? 
A. 적절한 규칙으로 AWS Config 를 켭니다. 
B. 적절한 검사를 통해 AWS Trusted Advisor 를 켭니다. 
C. 적절한 평가 템플릿으로 Amazon Inspector 를 켭니다. 
D. Amazon S3 서버 액세스 로깅을 켭니다. Amazon EventBridge(Amazon Cloud Watch Events)를 
구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/84940-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
AWS Config 는 AWS 리소스 구성을 측정, 감사 및 평가할 수 있는 서비스입니다. Config 는 AWS 
리소스 구성을 지속적으로 모니터링 및 기록하고, 원하는 구성을 기준으로 기록된 구성을 자동으로 
평가해 줍니다.  
https://aws.amazon.com/ko/config/ 
설명 2: 
Amazon S3 버킷에 무단 구성 변경이 없도록 하려면 솔루션 설계자가 적절한 규칙으로 AWS 
Config 를 켜야 합니다. AWS Config 는 사용자가 업계 표준 및 내부 정책을 준수하는지 AWS 
리소스 구성을 감사하고 평가할 수 있는 서비스입니다. 리소스가 서로 어떻게 관련되어 있는지에 
대한 정보를 포함하여 리소스 및 해당 구성에 대한 자세한 보기를 제공합니다. 적절한 규칙으로 
AWS Config 를 켜면 사용자는 Amazon S3 버킷에 대한 무단 구성 변경을 식별하고 수정할 수 
있습니다. 
Q27 
회사에서 새 애플리케이션을 시작하고 Amazon CloudWatch 대시보드에 애플리케이션 지표를 
표시합니다. 회사의 제품 관리자는 이 대시보드에 주기적으로 액세스해야 합니다. 제품 관리자에게 
AWS 계정이 없습니다. 솔루션 설계자는 최소 권한 원칙에 따라 제품 관리자에 대한 액세스를 
제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. CloudWatch 콘솔에서 대시보드를 공유합니다. 제품 관리자의 이메일 주소를 입력하고 공유 
단계를 완료합니다. 대시보드에 대한 공유 가능한 링크를 제품 관리자에게 제공하십시오. 
B. 특히 제품 관리자를 위한 IAM 사용자를 생성합니다. CloudWatchReadOnlyAccess AWS 관리형 
정책을 사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오. 올바른 
대시보드의 브라우저 URL 을 제품 관리자와 공유하십시오. 
C. 회사 직원을 위한 IAM 사용자를 생성합니다. ViewOnlyAccess AWS 관리형 정책을 IAM 
사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오. 제품 관리자에게 
CloudWatch 콘솔로 이동하여 대시보드 섹션에서 이름으로 대시보드를 찾으라고 요청합니다. 
D. 퍼블릭 서브넷에 배스천 서버를 배포합니다. 제품 관리자가 대시보드에 액세스해야 하는 경우 
서버를 시작하고 RDP 자격 증명을 공유합니다. 배스천 서버에서 대시보드를 볼 수 있는 적절한 
권한이 있는 캐시된 AWS 자격 증명으로 대시보드 URL 을 열도록 브라우저가 구성되어 있는지 
확인합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85227-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
AWS 계정에 직접 액세스할 수 없는 사람들과 CloudWatch 대시보드를 공유할 수 있습니다. 
대시보드를 공유할 때 다음 세 가지 방법으로 대시보드를 볼 수 있는 사람을 지정할 수 있습니다. 
◎하나의 대시보드를 공유하고 대시보드를 볼 수 있는 사람들의 특정 이메일 주소를 지정합니다. 
이러한 각 사용자는 대시보드를 보기 위해 입력해야 하는 고유한 암호를 만듭니다. 
◎링크가 있는 모든 사용자가 대시보드를 볼 수 있도록 단일 대시보드를 공개적으로 공유합니다. 
◎계정의 모든 CloudWatch 대시보드를 공유하고 대시보드 액세스를 위한 타사 SSO(Single 
Sign-On) 공급자를 지정합니다. 이 SSO 공급자 목록의 구성원인 모든 사용자는 계정의 모든 
대시보드에 액세스할 수 있습니다. 이를 활성화하려면 SSO 공급자를 Amazon Cognito 와 
통합합니다. SSO 공급자는 SAML(Security Assertion Markup Language)을 지원해야 합니다. 
https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-dashboard-sh
aring.html 
Q28 
회사에서 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 응용 프로그램은 다른 계정에 
배포됩니다. 회사는 AWS Organizations 를 사용하여 중앙에서 계정을 관리합니다. 회사의 보안 
팀은 회사의 모든 계정에 SSO(Single Sign-On) 솔루션이 필요합니다. 회사는 사내 자체 관리 
Microsoft Active Directory 에서 사용자 및 그룹을 계속 관리해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. 단방향 포리스트 트러스트 
또는 단방향 도메인 트러스트를 생성하여 Microsoft Active Directory 용 AWS Directory Service 를 
사용하여 회사의 자체 관리형 Microsoft Active Directory 를 AWS SSO 와 연결합니다. 
B. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. Microsoft Active 
Directory 용 AWS Directory Service 를 사용하여 회사의 자체 관리형 Microsoft Active Directory 를 
AWS SSO 와 연결하는 양방향 포리스트 트러스트를 생성합니다. 
C. AWS 디렉터리 서비스를 사용합니다. 회사의 자체 관리 Microsoft Active Directory 와 양방향 
신뢰 관계를 만드십시오. 
D. 온프레미스에 ID 공급자(IdP)를 배포합니다. AWS SSO 콘솔에서 AWS Single Sign-On(AWS 
SSO)을 활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85231-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
・AWS Organizations 로 SSO 설정하여 Active Directory 사용 가능. 
AWS IAM Identity Center(AWS SSO 의 후속 서비스)를 설정하여 Active Directory 를 통해 AWS 계정 
및 리소스에 대한 액세스를 제공하며, 별도의 작업 역할에 따라 권한을 사용자 지정합니다. 
https://aws.amazon.com/ko/organizations/features/ 
・AWS Directory Service 를 사용하여 AWS Managed Microsoft AD 디렉터리에 연결 가능. 
IAM Identity Center 는 AWS Identity and Access Management(IAM)를 기반으로 구축된 서비스로, 
여러 AWS 계정, AWS 애플리케이션 및 다른 SAML 사용 클라우드 애플리케이션에 대한 액세스 
관리를 간소화합니다. AWS Directory Service 를 사용하여 IAM Identity Center 를 온프레미스 Active 
Directory(AD) 또는 AWS Managed Microsoft AD 디렉터리에 연결할 수 있습니다. 
https://aws.amazon.com/ko/iam/identity-center/faqs/ 
A(X) : SSO, AWS 관리 콘솔에는 양방향 트러스트가 필요. 
AWS Managed Microsoft AD 는 수신, 발신 및 양방향(양방향)의 세 가지 신뢰 관계 방향을 모두 
지원합니다. AWS Managed Microsoft AD 는 외부 및 포리스트 트러스트를 모두 지원합니다. 
Amazon Chime, Amazon Connect, Amazon QuickSight, AWS IAM Identity Center(AWS Single 
Sign-On 의 후속 제품), Amazon WorkDocs, Amazon WorkMail, Amazon WorkSpaces 및 AWS 
Management Console 과 같은 AWS 엔터프라이즈 앱에는 양방향 신뢰가 필요합니다. Amazon EC2, 
Amazon RDS 및 Amazon FSx 는 단방향 또는 양방향 신뢰로 작동합니다. 
https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_setup_trust.html 
B(O) : A 와 같은 이유로 정답. 
C(X) : SSO 는 온프레미스 Active Directory 나 AWS 관리형 Microsoft AD Directory 에 연결할 수 
있지, 온프레미스 Microsoft AD Direcotry 에 연결할 수는 없음. ▲위의 설명 참고 
D(X) : IdP 는 외부 자격 증명 서비스. 
자격 증명 공급자(IdP)를 사용하면 AWS 외부의 사용자 자격 증명을 관리할 수 있고 이 외부 
사용자 자격 증명에 계정의 AWS 리소스에 대한 사용 권한을 부여할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles_providers.html 
Q29 
회사는 UDP 연결을 사용하는 VoIP(Voice over Internet Protocol) 서비스를 제공합니다. 이 
서비스는 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성됩니다. 회사는 여러 AWS 
리전에 배포하고 있습니다. 
회사는 지연 시간이 가장 짧은 리전으로 사용자를 라우팅해야 합니다. 이 회사는 또한 지역 간 
자동 장애 조치가 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 
그룹과 연결합니다. 각 리전에서 NLB 를 AWS Global Accelerator 엔드포인트로 사용합니다. 
B. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 
그룹과 연결합니다. 각 리전에서 ALB 를 AWS Global Accelerator 엔드포인트로 사용합니다. 
C. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 
그룹과 연결합니다. 각 NLB 의 별칭을 가리키는 Amazon Route 53 지연 시간 레코드를 생성합니다. 
지연 시간 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 생성합니다. 
D. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 
그룹과 연결합니다. 각 ALB 의 별칭을 가리키는 Amazon Route 53 가중치 레코드를 생성합니다. 
가중 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 배포합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85029-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
UDP 연결을 사용한다고 했으므로 NLB. 대기 시간이 가장 짧은 리전으로 라우팅 + UDP 사용 = 
AWS Global Accelerator. 
AWS Global Accelerator 에서 제공하는 고정 IP 주소와 AWS 엣지 로케이션의 애니캐스트를 리전별 
AWS 리소스 또는 엔드포인트(예: Network Load Balancer, Application Load Balancer EC2 인스턴스 
및 탄력적 IP 주소)에 연결할 수 있습니다. IP 주소는 AWS 엣지 로케이션에서 애니캐스트 되므로 
사용자와 가까운 AWS 글로벌 네트워크에 온보딩 기능을 제공합니다. 
https://aws.amazon.com/ko/global-accelerator/faqs/ 
https://aws.amazon.com/global-accelerator/faqs/ 
HTTP /HTTPS - ALB ; TCP and UDP - NLB; Lowest latency routing and more throughput. Also 
supports failover, uses Anycast Ip addressing - Global Accelerator Caching at Egde Locations - 
CloudFront WS Global Accelerator automatically checks the health of your applications and routes 
user traffic only to healthy application endpoints. If the health status changes or you make 
configuration updates, AWS Global Accelerator reacts instantaneously to route your users to the 
next available endpoint. 
Q30 
개발 팀은 성능 개선 도우미가 활성화된 MySQL DB 인스턴스용 범용 Amazon RDS 에서 매월 
리소스 집약적 테스트를 실행합니다. 테스트는 한 달에 한 번 48 시간 동안 지속되며 
데이터베이스를 사용하는 유일한 프로세스입니다. 팀은 DB 인스턴스의 컴퓨팅 및 메모리 속성을 
줄이지 않고 테스트 실행 비용을 줄이려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? 
A. 테스트가 완료되면 DB 인스턴스를 중지합니다. 필요한 경우 DB 인스턴스를 다시 시작합니다. 
B. DB 인스턴스와 함께 Auto Scaling 정책을 사용하여 테스트가 완료되면 자동으로 확장합니다. 
C. 테스트가 완료되면 스냅샷을 만듭니다. DB 인스턴스를 종료하고 필요한 경우 스냅샷을 
복원합니다. 
D. 테스트가 완료되면 DB 인스턴스를 저용량 인스턴스로 수정합니다. 필요한 경우 DB 인스턴스를 
다시 수정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85030-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
한 달에 한 번 48 시간 동안만 사용하고, 가장 비용 효율적인 방법을 사용해야하므로 스냅샷이 
제일 저렴. 
A(X) : DB 인스턴스를 중지해도 DB 인스턴스가 돌아가는 EBS 볼륨이나 이런 건 사용하지 않아도 
보유 중인 용량에 따라 요금이 부과됨. 
B(X) : Auto Scaling 을 사용하게 되면 사용하지 않을 때에도 인스턴스가 실행 상태가 되므로 스냅샷 
보관보다 비용이 더 부과됨 
C(O) : 스냅샷으로 보관해서 저장하면 스냅샷 용량만큼만 비용이 부과됨. 
D(X) : 사용 중이 아닐 때도 인스턴스가 실행 상태이므로 스냅샷 보관보다 비용이 더 부과됨 
Q31 
AWS 에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스를 보장하기를 
원합니다. Amazon RDS DB 인스턴스. Amazon Redshift 클러스터는 태그로 구성됩니다. 회사는 이 
검사를 구성하고 운영하는 노력을 최소화하기를 원합니다. 
솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까? 
A. AWS Config 규칙을 사용하여 적절하게 태그가 지정되지 않은 리소스를 정의하고 감지합니다. 
B. 비용 탐색기를 사용하여 제대로 태그가 지정되지 않은 리소스를 표시합니다. 해당 리소스에 
수동으로 태그를 지정합니다. 
C. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. EC2 인스턴스에서 
주기적으로 코드를 실행합니다. 
D. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. Amazon 
CloudWatch 를 통해 AWS Lambda 함수를 예약하여 코드를 주기적으로 실행합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85198-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
사후 대응적 거버넌스는 Resource Groups Tagging API, AWS Config Rules, 사용자 지정 스크립트 
등의 도구를 사용하여 제대로 태그가 지정되지 않은 리소스를 찾습니다. 
https://docs.aws.amazon.com/ko_kr/general/latest/gr/aws_tagging.html 
설명 2: 
모든 Amazon EC2 인스턴스, Amazon RDS DB 인스턴스 및 Amazon Redshift 클러스터가 태그로 
구성되도록 하려면 솔루션 설계자가 AWS Config 규칙을 사용하여 적절하게 태그가 지정되지 않은 
리소스를 정의하고 감지해야 합니다. AWS Config 규칙은 AWS Config 가 모범 사례 및 회사 정책을 
준수하는지 AWS 리소스 구성을 평가하는 데 사용하는 사용자 지정 가능한 규칙 세트입니다. AWS 
Config 규칙을 사용하면 비준수 리소스를 식별하고 담당 팀에 알리는 프로세스를 자동화하므로 이 
검사를 구성하고 운영하는 노력을 최소화할 수 있습니다. 
참조: AWS Config 규칙: 
(https://docs.aws.amazon.com/ko_kr/config/latest/developerguide/evaluate-config_use-manage
d-rules.html) 
Q32 
개발 팀은 다른 팀이 액세스할 웹사이트를 호스팅해야 합니다. 웹사이트 콘텐츠는 HTML, CSS, 
클라이언트 측 JavaScript 및 이미지로 구성됩니다. 
웹 사이트 호스팅에 가장 비용 효율적인 방법은 무엇입니까? 
A. 웹 사이트를 컨테이너화하고 AWS Fargate 에서 호스팅합니다. 
B. Amazon S3 버킷을 생성하고 거기에서 웹 사이트를 호스팅합니다. 
C. Amazon EC2 인스턴스에 웹 서버를 배포하여 웹 사이트를 호스팅합니다. 
D. Express.js 프레임워크를 사용하는 AWS Lambda 대상으로 Application Load Balancer 를 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85199-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
정적 웹 사이트에서 웹 페이지는 사전 구축된 서버에 의해 반환됩니다. HTML, CSS 또는 
JavaScript 와 같은 간단한 언어를 사용합니다. 정적 웹 사이트에서는 서버에서(사용자에 따라) 
콘텐츠를 처리하지 않습니다. 웹 페이지는 변경 없이 서버에 의해 반환되므로 정적 웹 사이트는 
빠릅니다. 데이터베이스와의 상호 작용이 없습니다. 
또한 호스트가 다른 언어로 서버 측 처리를 지원할 필요가 없기 때문에 비용이 적게 듭니다. 동적 
웹 사이트에서 웹 페이지는 런타임 중에 처리되는 서버에 의해 반환됩니다. 즉, 사전 구축된 웹 
페이지가 아니라 사용자의 요구에 따라 런타임 중에 구축됩니다. 이들은 PHP, Node.js, ASP.NET 
및 서버에서 지원하는 더 많은 것과 같은 서버 측 스크립팅 언어를 사용합니다. 따라서 정적 웹 
사이트보다 느리지만 업데이트 및 데이터베이스와의 상호 작용이 가능합니다. 
설명 2: 
모두 정적 웹사이트 콘텐츠 유형에 해당. 
Amazon S3 를 사용하여 웹 서버를 구성하거나 관리할 필요 없이 정적 웹 사이트를 호스팅할 수 
있습니다. 다음 단계를 완료하여 웹사이트에 모든 고정 자산을 호스팅할 새 Amazon S3 버킷을 
생성합니다. 이 자산에는 HTML, CSS, JavaScript, 이미지 파일이 포함됩니다. 
https://aws.amazon.com/ko/getting-started/hands-on/app-onboarding/module-5/ 
Q33 
회사는 AWS 에서 온라인 마켓플레이스 웹 애플리케이션을 실행합니다. 이 애플리케이션은 피크 
시간에 수십만 명의 사용자에게 서비스를 제공합니다. 이 회사는 수백만 건의 금융 거래 세부 
정보를 다른 여러 내부 애플리케이션과 공유할 수 있는 확장 가능한 거의 실시간 솔루션이 
필요합니다. 또한 지연 시간이 짧은 검색을 위해 문서 데이터베이스에 저장하기 전에 민감한 
데이터를 제거하기 위해 트랜잭션을 처리해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. 트랜잭션 데이터를 Amazon DynamoDB 에 저장합니다. 쓰기 시 모든 트랜잭션에서 민감한 
데이터를 제거하도록 DynamoDB 에서 규칙을 설정합니다. DynamoDB 스트림을 사용하여 다른 
애플리케이션과 트랜잭션 데이터를 공유합니다. 
B. 트랜잭션 데이터를 Amazon Kinesis Data Firehose 로 스트리밍하여 Amazon DynamoDB 및 
Amazon S3 에 데이터를 저장합니다. Kinesis Data Firehose 와 AWS Lambda 통합을 사용하여 
민감한 데이터를 제거하십시오. 다른 애플리케이션은 Amazon S3 에 저장된 데이터를 사용할 수 
있습니다. 
C. 트랜잭션 데이터를 Amazon Kinesis Data Streams 로 스트리밍합니다. AWS Lambda 통합을 
사용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 Amazon DynamoDB 에 트랜잭션 
데이터를 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림의 트랜잭션 데이터를 사용할 수 
있습니다. 
D. 일괄 처리된 트랜잭션 데이터를 Amazon S3 에 파일로 저장합니다. Amazon S3 에서 파일을 
업데이트하기 전에 AWS Lambda 를 사용하여 모든 파일을 처리하고 민감한 데이터를 제거하십시오. 
그러면 Lambda 함수가 Amazon DynamoDB 에 데이터를 저장합니다. 다른 애플리케이션은 
Amazon S3 에 저장된 트랜잭션 파일을 사용할 수 있습니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85201-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
피크 시간에 수십만 명의 사용자에게 서비스 제공 = Kinesis 사용. B,C 둘 중 하나가 답. 
B(X) : Kinesis Data Firehose 는 데이터 변환 및 전송 서비스. 데이터 수집을 하려면 Kinesis Data 
Streams 가 필요. 
Kinesis Data Firehose 로 데이터를 보내도록 데이터 생산자를 구성하면 지정한 대상으로 데이터가 
자동으로 전달됩니다. 데이터를 전송하기 전에 변환하도록 Kinesis Data Firehose 를 구성할 수도 
있습니다. 
https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html 
C(O) : Amazon Kinesis Data Streams 를 사용하면 특수 요구에 맞춰 스트리밍 데이터를 처리 또는 
분석하는 사용자 지정 애플리케이션을 구축할 수 있습니다. 수십 만개의 소스에서 클릭 스트림, 
애플리케이션 로그, 소셜 미디어와 같은 다양한 유형의 데이터를 Kinesis 데이터 스트림에 추가할 
수 있습니다. 그러면 몇 초 안에 애플리케이션에서 스트림의 해당 데이터를 읽고 처리할 수 
있습니다. 
https://aws.amazon.com/ko/kinesis/data-streams/faqs/?nc=sn&loc=6 
설명 2: 
Kinesis Data Firehose 전송 스트림의 대상입니다. Kinesis Data Firehose 는 Amazon Simple Storage 
Service(Amazon S3), Amazon 을 비롯한 다양한 대상으로 데이터 레코드를 보낼 수 있습니다. 
Redshift, Amazon OpenSearch Service 및 귀하 또는 귀하의 제 3 자 서비스 공급자가 소유한 모든 
HTTP 엔드포인트. 
다음은 지원되는 대상입니다. 
* Amazon 오픈서치 서비스(Amazon OpenSearch Service) 
* Amazon S3 
* 데이터독(Datadog) 
* 다이나트레이스(Dynatrace) 
* 벌집(Honeycomb) 
* HTTP 끝점(Endpoint) 
* 로직 모니터(Logic Monitor) 
* 몽고디비 클라우드(MongoDB Cloud) 
* 새로운 유물(New Relic) 
* 스플렁크(Splunk) 
* 스모 로직(Sumo Logic) 
https://docs.aws.amazon.com/firehose/latest/dev/create-name.html 
https://aws.amazon.com/kinesis/data-streams/ 
Amazon Kinesis Data Streams(KDS)는 확장성과 내구성이 뛰어난 실시간 데이터 스트리밍 
서비스입니다. 
KDS 는 웹사이트 클릭 스트림, 데이터베이스 이벤트 스트림, 금융 거래, 소셜 미디어 피드, IT 로그 
및 위치 추적 이벤트와 같은 수십만 개의 소스에서 초당 기가바이트의 데이터를 지속적으로 
캡처할 수 있습니다. 
Q34 
회사는 AWS 에서 다중 계층 애플리케이션을 호스팅합니다. 규정 준수, 거버넌스, 감사 및 보안을 
위해 회사는 AWS 리소스의 구성 변경 사항을 추적하고 이러한 리소스에 대한 API 호출 기록을 
기록해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS CloudTrail 을 사용하여 구성 변경을 추적하고 AWS Config 를 사용하여 API 호출을 
기록하십시오. 
B. AWS Config 를 사용하여 구성 변경을 추적하고 AWS CloudTrail 을 사용하여 API 호출을 
기록합니다. 
C. AWS Config 를 사용하여 구성 변경을 추적하고 Amazon CloudWatch 를 사용하여 API 호출을 
기록합니다. 
D. AWS CloudTrail을 사용하여 구성 변경을 추적하고 Amazon CloudWatch 를 사용하여 API 호출을 
기록합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85202-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
리소스 구성 사항 변경 추적 = AWS Config / 리소스 내역 기록 = CloudTrail 
AWS Config 는 AWS 리소스 인벤토리, 구성 기록, 구성 변경 알림을 제공하여 보안 및 거버넌스를 
실현하는 완벽한 관리형 서비스입니다. 
https://aws.amazon.com/ko/config/faq/ 
AWS Cloudtrail 은 사용자 활동 및 API 사용을 추적하여 감사, 보안 모니터링 및 운영 문제 해결을 
지원합니다. CloudTrail 은 AWS 인프라 전체에서 작업과 관련된 계정 활동을 로그하고 지속적으로 
모니터링하고 보존하여 스토리지, 분석 및 해결 작업을 제어할 수 있도록 합니다. 
https://aws.amazon.com/ko/cloudtrail/faqs/ 
설명 2: 
AWS Config 는 회사가 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있는 완전관리형 
서비스입니다. 사용 중인 리소스에 대한 자세한 인벤토리를 제공하고 리소스 구성에 대한 변경 
사항을 추적합니다. AWS Config 는 구성 변경을 감지하고 변경이 발생하면 회사에 알릴 수 
있습니다. 또한 규정 준수 및 거버넌스 목적에 필수적인 변경 기록 보기를 제공합니다. AWS 
CloudTrail 은 회사의 AWS 리소스에 대한 자세한 API 호출 기록을 제공하는 완전 관리형 
서비스입니다. API 호출을 한 사람, 호출한 시간, 호출의 영향을 받은 리소스를 포함하여 AWS 
계정의 모든 API 활동을 기록합니다. 이 정보를 통해 회사는 AWS 리소스에서 발생할 수 있는 
의심스러운 활동을 조사할 수 있으므로 보안 및 감사 목적에 매우 중요합니다. 
Q35 
한 회사가 AWS 클라우드에서 공개 웹 애플리케이션 출시를 준비하고 있습니다. 아키텍처는 
Elastic Load Balancer(ELB) 뒤의 VPC 내 Amazon EC2 인스턴스로 구성됩니다. DNS 에는 타사 
서비스가 사용됩니다. 회사의 솔루션 설계자는 대규모 DDoS 공격을 감지하고 보호하기 위한 
솔루션을 권장해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 계정에서 Amazon GuardDuty 를 활성화합니다. 
B. EC2 인스턴스에서 Amazon Inspector 를 활성화합니다. 
C. AWS Shield 를 활성화하고 여기에 Amazon Route 53 을 할당합니다. 
D. AWS Shield Advanced 를 활성화하고 ELB 를 할당합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85203-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
A(X) : GuardDuty 는 계정 보호 서비스. 
Amazon GuardDuty 는 AWS 계정 및 워크로드에서 악의적 활동을 모니터링하고 상세한 보안 
결과를 제공하여 가시성 및 해결을 촉진하는 위협 탐지 서비스입니다. 
https://aws.amazon.com/ko/guardduty/ 
B(X) : Amazon Inspector 는 취약점 스캔 서비스. 
Amazon Inspector 는 지속적으로 스캔하는 취약성 관리 서비스입니다. 
https://docs.aws.amazon.com/ko_kr/inspector/latest/user/what-is-inspector.html 
C(X) : 대규모 DDoS 방어는 AWS Shield Advanced 가 더 적합. 
D(O) : AWS Shield Advanced 는 정교한 대규모 DDoS 공격에 대한 추가 보호 및 완화, 실시간에 
가까운 공격에 대한 가시성, 웹 애플리케이션 방화벽 AWS WAF 와의 통합을 제공합니다. DDoS 
관련 급증 시 Amazon Elastic Compute Cloud(EC2), Elastic Load Balancing(ELB), Amazon 
CloudFront, AWS Global Accelerator 및 Amazon Route 53 요금 보호를 제공합니다. 
https://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.postDateTi
me&whats-new-cards.sort-order=desc 
Q36 
회사는 AWS 클라우드에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 AWS 리전의 
Amazon S3 버킷에 데이터를 저장합니다. 회사는 AWS Key Management Service(AWS KMS) 고객 
관리형 키를 사용하여 S3 버킷에 저장된 모든 데이터를 암호화해야 합니다. 두 S3 버킷의 
데이터는 동일한 KMS 키로 암호화 및 복호화해야 합니다. 데이터와 키는 두 지역 각각에 
저장되어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 각 리전에서 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)와 함께 서버 측 
암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다. 
B. 고객 관리형 다중 지역 KMS 키를 생성합니다. 각 리전에서 S3 버킷을 생성합니다. S3 버킷 
간의 복제를 구성합니다. 클라이언트 측 암호화와 함께 KMS 키를 사용하도록 애플리케이션을 
구성합니다. 
C. 각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 
키(SSE-S3)와 함께 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 
구성합니다. 
D. 각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. AWS KMS 키(SSE-KMS)로 서버 측 
암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/84747-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
D?? 
설명 1: 
https://docs.aws.amazon.com/kms/latest/developerguide/custom-key-store-overview.html 
대부분의 사용자는 FIPS 140-2 인증 암호화 모듈로 보호되는 기본 AWS KMS 키 스토어가 보안 
요구 사항을 충족합니다. 추가 유지 관리 책임 계층이나 추가 서비스에 대한 종속성을 추가할 
필요가 없습니다. 그러나 조직에 다음과 같은 요구 사항이 있는 경우 사용자 지정 키 스토어 
생성을 고려할 수 있습니다. 키 자료는 공유 환경에 저장할 수 없습니다. 키 자료는 독립적인 보조 
감사 경로를 따라야 합니다. 키 자료를 생성하고 저장하는 HSM 은 FIPS 140-2 레벨 3 에서 인증을 
받아야 합니다. 
https://docs.aws.amazon.com/kms/latest/developerguide/custom-key-store-overview.html 
https://docs.aws.amazon.com/kms/latest/developerguide/multi-region-keys-overview.html 
설명 2: 
A(X) : SSE-S3 은 AWS 에서 데이터 키와 마스터 키 모두 관리하기 때문에 고객 관리형 키가 
사용되지 않음. 
참고: AWS KMS 키로 암호화된 개체를 업로드하려면 키와 S3 버킷이 동일한 AWS 리전에 있어야 
합니다. 
Note: To upload an object encrypted by an AWS KMS key, the key and the S3 bucket must be in the 
same AWS Region. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/s3-bucket-store-kms-encrypte
d-objects/ 
B(O) : 고객 관리형 다중 리전 KMS 키 생성. 각 리전에 S3 버킷 생성. S3 버킷 간 복제 설정. 
클라이언트 측 암호화로 KMS 키 사용하도록 애플리케이션 설정 
C(X) : A 와 같은 이유로 오답. 
D(X) : 각 리전에 고객 관리형 KMS 키 및 S3 버킷 생성. AWS KMS keys(SSE-KMS)로 KMS 
키(SSE-KMS)로 서버 측 암호화 사용하도록 S3 버킷 설정. S3 버킷 간 복제 설정. 
Q37 
한 회사는 최근 AWS 계정의 Amazon EC2 인스턴스에서 다양한 새로운 워크로드를 출시했습니다. 
회사는 인스턴스에 원격으로 안전하게 액세스하고 관리하는 전략을 수립해야 합니다. 회사는 기본 
AWS 서비스와 함께 작동하고 AWS Well-Architected 프레임워크를 따르는 반복 가능한 
프로세스를 구현해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EC2 직렬 콘솔을 사용하여 관리를 위해 각 인스턴스의 터미널 인터페이스에 직접 
액세스합니다. 
B. 각 기존 인스턴스와 새 인스턴스에 적절한 IAM 역할을 연결합니다. AWS Systems Manager 
Session Manager 를 사용하여 원격 SSH 세션을 설정합니다. 
C. 관리 SSH 키 쌍을 만듭니다. 퍼블릭 키를 각 EC2 인스턴스에 로드합니다. 퍼블릭 서브넷에 
배스천 호스트를 배포하여 각 인스턴스의 관리를 위한 터널을 제공합니다. 
D. AWS Site-to-Site VPN 연결을 설정합니다. 관리자에게 로컬 온프레미스 머신을 사용하여 VPN 
터널에서 SSH 키를 사용하여 인스턴스에 직접 연결하도록 지시합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85037-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A(X) : 물리적으로 케이블 갖다 꽂는 것이기 때문에 원격 접속이 아님. 
B(O) : 세션 관리자는 사용자 인스턴스에 SSH 키 또는 인증서를 유지하거나 인바운드 포트를 
열도록 요구하지 않고 보안 태세를 강화합니다. 또한, AWS IAM 을 사용하여 인스턴스 액세스를 
중앙에서 관리합니다. 세션 관리자를 사용하면 Linux 또는 Windows EC2 인스턴스와 연결하여 각 
인스턴스에서 세션을 시작한 각 사용자를 추적할 수 있습니다. 인스턴스에 액세스한 사용자와 
AWS CloudTrail 을 사용한 시점을 감사할 수 있으며, 인스턴스에서 실행된 각 명령을 Amazon S3 
또는 Amazon CloudWatch Logs 에 기록할 수 있습니다. 끝으로 Session Manager 를 사용하면 
배스쳔 호스트를 운영하고 관리하기 위한 초기 투자 비용이 들지 않습니다.  
https://aws.amazon.com/ko/systems-manager/faq/ 
C(X) : SSH 키 쌍이 필요하므로 B 보다 운영 오버헤드가 많이 발생함. 
D(X) : C 와 동일한 이유로 오답. 
참고 
https://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/setup-instance-permis
sions.html 
Q38 
회사는 Amazon S3 에서 정적 웹 사이트를 호스팅하고 DNS 에 Amazon Route 53 을 사용하고 
있습니다. 웹 사이트는 전 세계적으로 수요가 증가하고 있습니다. 회사는 웹 사이트에 액세스하는 
사용자의 대기 시간을 줄여야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? 
A. 웹 사이트가 포함된 S3 버킷을 모든 AWS 리전에 복제합니다. Route 53 지리적 위치 라우팅 
항목을 추가합니다. 
B. AWS Global Accelerator 에서 액셀러레이터를 프로비저닝합니다. 제공된 IP 주소를 S3 버킷과 
연결합니다. 액셀러레이터의 IP 주소를 가리키도록 Route 53 항목을 편집합니다. 
C. S3 버킷 앞에 Amazon CloudFront 배포를 추가합니다. CloudFront 배포를 가리키도록 Route 53 
항목을 편집합니다. 
D. 버킷에서 S3 Transfer Acceleration 을 활성화합니다. 새 엔드포인트를 가리키도록 Route 53 
항목을 편집합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85238-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : S3 버킷을 각 리전마다 복제하면 콘텐츠가 업로드될 때마다 각 리전의 버킷에 
복제해야하므로 낭비임. CloudFront 를 사용하는 것이 훨씬 더 효율적이고 경제적. 
B(X) : AWS Global Accelerator 는 TCP/UDP 를 사용하는 네트워크 계층에서 동작하는데, 지문에서 
사용된 Route 53 은 DNS 서비스로서, 애플리케이션 계층에서 동작. 
C(O) : Route 53 으로 CloudFront 배포를 가리킬 수 있음. 
S3 를 사용해 정적 콘텐츠를 저장하면 다양한 이점이 있습니다. 하지만 비용을 효과적으로 
관리하는 동시에 애플리케이션의 성능과 보안까지 최적화하려면 Amazon CloudFront 를 설정해 S3 
버킷과 함께 사용하면서 콘텐츠를 제공하고 보호하는 것이 좋습니다. CloudFront 는 전 세계의 
정적/동적 웹 콘텐츠, 비디오 스트림 및 API 를 안전하게 대규모로 전송할 수 있는 콘텐츠 전송 
네트워크(CDN) 서비스입니다. CloudFront 에서 데이터를 전송하면 설계상 S3 에서 직접 사용자에게 
전송하는 것보다 더욱 비용 효율적입니다.  
https://aws.amazon.com/ko/blogs/korea/amazon-s3-amazon-cloudfront-a-match-made-in-th
e-cloud/ 
자체 도메인 이름을 사용하려는 경우 Amazon Route 53 을 사용하여 CloudFront 배포를 가리키는 
별칭 레코드(alias record)를 생성합니다 
https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/routing-to-cloudfront-distri
bution.html 
D(X) : S3 Transfer Acceleration 은 각지에서 중앙 S3 버킷으로 업로드하는 서비스. 
S3 Transfer Acceleration 은 전 세계에서 S3 버킷으로 전송되는 속도를 최적화하도록 
설계되었습니다. 지리적으로 분산된 위치에서 중앙 집중식 버킷으로 데이터를 업로드하거나, 대륙 
간에 GB 또는 TB 규모의 데이터를 정기적으로 전송하는 경우, S3 Transfer Acceleration 을 
사용하면 몇 시간 또는 며칠의 데이터 전송 시간을 절약할 수 있습니다.  
https://aws.amazon.com/ko/s3/faqs/#s3ta 
설명 2: 
Amazon CloudFront 는 전 세계 엣지 로케이션에서 콘텐츠를 캐싱하여 콘텐츠에 액세스하는 
사용자에게 짧은 지연 시간과 빠른 전송 속도를 제공하는 콘텐츠 전송 네트워크(CDN)입니다. S3 
버킷 앞에 CloudFront 배포를 추가하면 전 세계 엣지 위치에서 정적 웹 사이트의 콘텐츠를 
캐싱하여 웹 사이트에 액세스하는 사용자의 지연 시간을 줄입니다. 또한 이 솔루션은 CloudFront 
엣지 로케이션에서 콘텐츠에 액세스하는 사용자의 데이터 전송 및 요청에 대해서만 비용을 
청구하므로 비용 효율적입니다. 또한 이 솔루션은 CloudFront 가 자동으로 확장하여 수요 증가를 
처리하고 웹 사이트에 고가용성을 제공할 수 있으므로 확장성과 안정성 이점을 제공합니다. 
Q39 
회사는 웹 사이트에서 검색 가능한 항목 저장소를 유지 관리합니다. 데이터는 천만 개 이상의 행이 
포함된 Amazon RDS for MySQL 데이터베이스 테이블에 저장됩니다. 데이터베이스에는 2TB 의 범용 
SSD 스토리지가 있습니다. 회사 웹 사이트를 통해 이 데이터에 대한 수백만 건의 업데이트가 매일 
있습니다. 
이 회사는 일부 삽입 작업이 10 초 이상 걸리는 것을 확인했습니다. 회사는 데이터베이스 스토리지 
성능이 문제라고 판단했습니다. 
이 성능 문제를 해결하는 솔루션은 무엇입니까? 
A. 스토리지 유형을 프로비저닝된 IOPS SSD 로 변경합니다. 
B. DB 인스턴스를 메모리 최적화 인스턴스 클래스로 변경합니다. 
C. DB 인스턴스를 버스트 가능한 성능 인스턴스 클래스로 변경합니다. 
D. MySQL 기본 비동기 복제로 다중 AZ RDS 읽기 전용 복제본을 활성화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/84748-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
https://aws.amazon.com/ebs/features/ 
프로비저닝된 IOPS 볼륨은 솔리드 스테이트 드라이브(SSD)로 지원되며 중요한 I/O 집약적인 
데이터베이스 애플리케이션을 위해 설계된 최고 성능의 EBS 볼륨입니다. 
이러한 볼륨은 극히 짧은 대기 시간이 필요한 IOPS 집약적 워크로드와 처리량 집약적 워크로드 
모두에 이상적입니다. 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html 
설명 2: 
'삽입' 작업이라고 했으므로 I/O 성능과 관련되어있음을 유추할 수 있음. 그리고 '저장소 성능'이 
문제라고 판단했고, 범용 'SSD' 스토리지가 있다고 했으므로 A 가 정답. 
D(X) : 버스트 가능한 성능 인스턴스는 잠시 I/O 성능을 끌어올리는 것일 뿐 근본적인 I/O 성능 
개선은 하지 못함. 
획득한 크레딧이 남아 있지 않으면 인스턴스가 기준 CPU 사용률로 점진적으로 저하되고 크레딧이 
더 많이 적립될 때까지 기준 이상으로 버스트할 수 없습니다. 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/burstable-credits-baseline-con
cepts.html 
Q40 
회사에는 매일 1TB 의 상태 알림을 집합적으로 생성하는 수천 개의 에지 장치가 있습니다. 각 
경고의 크기는 약 2KB 입니다. 솔루션 설계자는 향후 분석을 위해 경고를 수집하고 저장하는 
솔루션을 구현해야 합니다. 
회사는 고가용성 솔루션을 원합니다. 그러나 회사는 비용을 최소화해야 하며 추가 인프라 관리를 
원하지 않습니다. 또한 회사는 즉각적인 분석을 위해 14일 동안의 데이터를 유지하고 14일이 지난 
데이터를 보관하기를 원합니다. 
이러한 요구 사항을 충족하는 가장 운영 효율성이 높은 솔루션은 무엇입니까? 
A. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon S3 버킷에 
알림을 전달하도록 Kinesis Data Firehose 스트림을 구성합니다. 14 일 후에 데이터를 Amazon S3 
Glacier 로 전환하도록 S3 수명 주기 구성을 설정합니다. 
B. 두 가용 영역에서 Amazon EC2 인스턴스를 시작하고 Elastic Load Balancer 뒤에 배치하여 
알림을 수집합니다. Amazon S3 버킷에 경고를 저장할 EC2 인스턴스에 대한 스크립트를 
생성합니다. 14 일 후에 데이터를 Amazon S3 Glacier 로 전환하도록 S3 수명 주기 구성을 
설정합니다. 
C. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon 
OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 알림을 전달하도록 Kinesis Data 
Firehose 스트림을 구성합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 
클러스터를 설정하여 매일 수동 스냅샷을 만들고 클러스터에서 14 일이 지난 데이터를 삭제합니다. 
D. Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 생성하여 알림을 수집하고 메시지 
보존 기간을 14 일로 설정합니다. SQS 대기열을 폴링하고, 메시지의 수명을 확인하고, 필요에 따라 
메시지 데이터를 분석하도록 소비자를 구성합니다. 메시지가 14 일이 지난 경우 소비자는 메시지를 
Amazon S3 버킷에 복사하고 SQS 대기열에서 메시지를 삭제해야 합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85204-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
수 천 개의 Edge 장치로부터 경고 수집 및 저장 = Kinesis. A,C 둘 중 하나가 답. 
A(O) : 정답. 
・Kinesis Firehose Delivery Stream 에서 데이터 수집 
다양한 유형의 소스를 사용하여 Kinesis Data Firehose 전송 스트림으로 데이터를 보낼 수 
있습니다. https://docs.aws.amazon.com/firehose/latest/dev/basic-write.html 
・Kinesis Firehose 에서 S3 로 데이터 전송 
Kinesis Data Firehose 전송 스트림을 설정할 때 데이터의 최종 대상을 선택합니다. 대상 옵션은 
Amazon Simple Storage Service(Amazon S3), Amazon OpenSearch Service 및 Amazon 
Redshift 입니다.  
https://docs.aws.amazon.com/ko_kr/ses/latest/dg/event-publishing-kinesis-analytics-firehose-
stream.html 
・S3 에서 Life Cycle Policy 를 사용해 S3 Glacier 로 객체 이전 
수명 주기 규칙을 사용하여 객체 수명 주기 동안 Amazon S3 에서 수행하려는 작업을 정의할 수 
있습니다(예: 객체를 다른 스토리지 클래스로 이전, 객체 보관, 지정된 기간이 경과한 후 객체 
삭제). 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/how-to-set-lifecycle-configur
ation-intro.html) 
C(X) : 14 일이 지난 데이터를 보관하길 원한다고 했는데 삭제해버리므로 오답. 
참고: 
https://aws.amazon.com/ko/kinesis/data-firehose/features/?nc=sn&loc=2#:~:text=into%20Amaz
on%20S3%2C%20 
Q41 
회사의 애플리케이션은 데이터 수집을 위해 여러 SaaS(Software-as-a-Service) 소스와 
통합됩니다. 이 회사는 Amazon EC2 인스턴스를 실행하여 데이터를 수신하고 분석을 위해 
데이터를 Amazon S3 버킷에 업로드합니다. 데이터를 수신하고 업로드하는 동일한 EC2 
인스턴스도 업로드가 완료되면 사용자에게 알림을 보냅니다. 회사는 느린 응용 프로그램 성능을 
발견했으며 가능한 한 성능을 개선하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EC2 인스턴스가 확장할 수 있도록 Auto Scaling 그룹을 생성합니다. S3 버킷에 업로드가 
완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 보내도록 S3 이벤트 
알림을 구성합니다. 
B. Amazon AppFlow 흐름을 생성하여 각 SaaS 소스와 S3 버킷 간에 데이터를 전송합니다. S3 
버킷에 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 
보내도록 S3 이벤트 알림을 구성합니다. 
C. 각 SaaS 소스에 대해 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 출력 
데이터를 보냅니다. S3 버킷을 규칙의 대상으로 구성합니다. S3 버킷에 업로드가 완료되면 
이벤트를 전송하는 두 번째 EventBridge(Cloud Watch Events) 규칙을 생성합니다. Amazon Simple 
Notification Service(Amazon SNS) 주제를 두 번째 규칙의 대상으로 구성합니다. 
D. EC2 인스턴스 대신 사용할 Docker 컨테이너를 생성합니다. Amazon Elastic Container 
Service(Amazon ECS)에서 컨테이너화된 애플리케이션을 호스팅합니다. S3 버킷에 업로드가 
완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 보내도록 Amazon 
CloudWatch Container Insights 를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85446-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
Amazon AppFlow 는 Salesforce, SAP, Zendesk, Slack 및 ServiceNow 와 같은 
SaaS(Software-as-a-Service) 애플리케이션과 Amazon S3 및 Amazon Redshift 와 같은 AWS 
서비스 간에 데이터를 안전하게 전송할 수 있는 완전 관리형 통합 서비스입니다. 클릭 몇 번이면 
됩니다. 
https://aws.amazon.com/appflow/ 
설명 2: 
SaaS = Appflow. Appflow 는 완전 관리형 통합 서비스이기 때문에 운영 오버헤드가 적음. 
Amazon AppFlow 는 클릭 몇 번으로 Salesforce, Marketo, Slack 및 ServiceNow 와 같은 
SaaS(Software-as-a-Service) 애플리케이션과 Amazon S3 및 Amazon Redshift 와 같은 AWS 
서비스 간에 데이터를 안전하게 전송할 수 있게 해 주는 완전관리형 통합 서비스. 
https://aws.amazon.com/ko/appflow/faqs/ 
Q42 
회사는 단일 VPC 의 Amazon EC2 인스턴스에서 고가용성 이미지 처리 애플리케이션을 실행합니다. 
EC2 인스턴스는 여러 가용 영역의 여러 서브넷 내에서 실행됩니다. EC2 인스턴스는 서로 통신하지 
않습니다. 그러나 EC2 인스턴스는 Amazon S3 에서 이미지를 다운로드하고 단일 NAT 
게이트웨이를 통해 Amazon S3 에 이미지를 업로드합니다. 회사는 데이터 전송 요금에 대해 
우려하고 있습니다. 
회사가 지역 데이터 전송 요금을 피할 수 있는 가장 비용 효율적인 방법은 무엇입니까? 
A. 각 가용 영역에서 NAT 게이트웨이를 시작합니다. 
B. NAT 게이트웨이를 NAT 인스턴스로 교체합니다. 
C. Amazon S3 용 게이트웨이 VPC 엔드포인트를 배포합니다. 
D. EC2 인스턴스를 실행할 EC2 전용 호스트를 프로비저닝합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85205-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설 1:・ 
데이터 전송 요금이 걱정되니 전용 전송 통로를 뚫으면 됨. VPC-S3 간 전용 통로는 S3 VPC 
Gateway Endpoint. 답은 C. 
해설 2: 
S3 용 게이트웨이 VPC 엔드포인트를 배포함으로써 회사는 인터넷 게이트웨이나 NAT 게이트웨이를 
거치지 않고 VPC 와 S3 사이에 직접 연결을 설정할 수 있습니다. 이렇게 하면 EC2 와 S3 사이의 
트래픽이 Amazon 네트워크 내에 머물면서 지역 데이터 전송 요금을 피할 수 있습니다. 
A 는 각 AZ 에서 NAT 게이트웨이를 시작할 것을 제안합니다. 이는 가용성과 중복성에 도움이 될 
수 있지만 트래픽이 여전히 NAT 게이트웨이를 통과하고 데이터 전송 요금이 발생하므로 데이터 
전송 요금 문제를 해결하지 못합니다. 
B는 NAT 게이트웨이를 NAT 인스턴스로 교체할 것을 제안합니다. 그러나 이 솔루션은 여전히 NAT 
인스턴스를 통해 인스턴스와 S3 간에 데이터를 전송하므로 데이터 전송 요금이 발생합니다. 
D 는 EC2 를 실행하기 위해 EC2 전용 호스트를 프로비저닝할 것을 제안합니다. 이는 인스턴스 
전용 하드웨어를 제공할 수 있지만 데이터 전송 요금 문제를 직접적으로 해결하지는 않습니다. 
Q43 
회사에 Amazon S3 에 백업되는 시간에 민감한 대량의 데이터를 생성하는 온프레미스 
애플리케이션이 있습니다. 애플리케이션이 성장했고 인터넷 대역폭 제한에 대한 사용자 불만이 
있습니다. 솔루션 설계자는 Amazon S3 에 대한 적시 백업을 허용하고 내부 사용자의 인터넷 
연결에 미치는 영향을 최소화하는 장기 솔루션을 설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS VPN 연결을 설정하고 VPC 게이트웨이 엔드포인트를 통해 모든 트래픽을 프록시합니다. 
B. 새 AWS Direct Connect 연결을 설정하고 이 새 연결을 통해 백업 트래픽을 직접 연결합니다. 
C. 매일 AWS Snowball 디바이스를 주문합니다. Snowball 디바이스에 데이터를 로드하고 
디바이스를 매일 AWS 로 반환합니다. 
D. AWS Management 콘솔을 통해 지원 티켓을 제출합니다. 계정에서 S3 서비스 제한 제거를 
요청합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85206-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : VPN 은 인터넷을 통과하는데다가, VPC Gateway Endpoint 는 VPC-S3,Dynamo 간 전송을 
담당. 
B(O) : Direct Connect 는 전용선을 통과하기 때문에 인터넷에 전송중인 데이터가 노출되지 않음 
C(X) : Snowball Device 는 배송기간까지 합하면 보통 7 일 정도 걸리는데 이를 매일 주문한다는 
것은 무리수. 
D(X) : 한도 증가만 가능. 한도 제거 옵션은 없음. 
https://docs.aws.amazon.com/ko_kr/general/latest/gr/aws_service_limits.html 
설명 2: 
회사의 온프레미스 애플리케이션에 대한 대역폭 제한 문제를 해결하고 내부 사용자 연결에 대한 
영향을 최소화하려면 이 새로운 연결을 통해 백업 트래픽을 전달하도록 새로운 AWS Direct 
Connect 연결을 설정해야 합니다. 이 솔루션은 회사의 데이터 센터와 AWS 간에 안전한 고속 
연결을 제공하여 회사가 인터넷 대역폭을 사용하지 않고 데이터를 빠르게 전송할 수 있도록 
합니다. 
참조: 
AWS Direct Connect 설명서: https://aws.amazon.com/directconnect/ 
Q44 
회사에 중요한 데이터가 포함된 Amazon S3 버킷이 있습니다. 회사는 우발적인 삭제로부터 
데이터를 보호해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 취해야 합니까? (2 개를 
선택하세요.) 
A. S3 버킷에서 버전 관리를 활성화합니다. 
B. S3 버킷에서 MFA 삭제를 활성화합니다. 
C. S3 버킷에 버킷 정책을 생성합니다. 
D. S3 버킷에서 기본 암호화를 활성화합니다. 
E. S3 버킷의 객체에 대한 수명 주기 정책을 생성합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/84750-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(O) : 버전 관리는 실수로 삭제했을 때 이전 버전의 파일을 불러올 수 있도록 해줌. 
Amazon S3 의 버전 관리는 동일 버킷 내에 여러 개의 객체 변형을 보유하는 수단입니다. S3 버전 
관리를 사용하면 버킷에 저장된 모든 버전의 객체를 모두 보존, 검색 및 복원할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Versioning.html 
B(O) : MFA Delete 는 함부로 삭제하지 못하도록 막음. 
MFA Delete 는 다음 작업에 대해 추가 인증을 요구합니다. ◎버킷의 버전 관리 상태 변경 ◎객체 
버전 영구 삭제 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/MultiFactorAuthenticationDelete
.html 
C(X) : 버킷 정책은 액세스 권한에 관련된 것. 버킷 정책은 버킷과 해당 버킷의 객체에 대한 
액세스 권한을 부여할 수 있는 리소스 기반 정책입니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/bucket-policies.html 
D(X) : 암호화는 파일 내용을 함부로 볼 수 없게하는 등의 기능은 있지만 기본적으로 삭제는 막지 
못함. 우리가 직장에서 DRM 걸린 문서는 열람 못해도 액세스 권한이 있다면 삭제할 수 있는 거랑 
비슷함. 
E(X) : 객체 수명 주기 정책은 객체를 언제 이동하고 삭제할 거냐의 문제. 
설명 2: 
S3 버킷의 데이터를 실수로 삭제하지 않도록 보호하려면 S3 버킷에 있는 모든 객체의 모든 버전을 
보존, 검색 및 복원할 수 있는 버전 관리를 활성화해야 합니다. 
또한 S3 버킷에서 MFA(다단계 인증) 삭제를 활성화하면 버킷의 객체를 삭제하기 위해 사용자의 
액세스 키 외에 인증 토큰을 요구함으로써 추가 보호 계층이 추가됩니다. 
참조: 
AWS S3 버전 관리 설명서: 
https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html 
AWS S3 MFA 문서 삭제:  
https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMFADelete.html 
Q45 
회사에는 다음으로 구성된 데이터 수집 워크플로가 있습니다. 
• 새로운 데이터 전송에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 주제 
• 데이터를 처리하고 메타데이터를 기록하는 AWS Lambda 함수 
회사는 네트워크 연결 문제로 인해 수집 워크플로가 때때로 실패하는 것을 관찰했습니다. 이러한 
장애가 발생하면 회사에서 수동으로 작업을 다시 실행하지 않는 한 Lambda 함수는 해당 데이터를 
수집하지 않습니다. 
Lambda 함수가 향후 모든 데이터를 수집하도록 하려면 솔루션 설계자가 취해야 하는 작업 조합은 
무엇입니까? (2 개를 선택하세요.) 
A. 여러 가용 영역에 Lambda 함수를 배포합니다. 
B. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성하고 SNS 주제를 구독합니다. 
C. Lambda 함수에 할당된 CPU 와 메모리를 늘립니다. 
D. Lambda 함수에 대해 프로비저닝된 처리량을 늘립니다. 
E. Amazon Simple Queue Service(Amazon SQS) 대기열에서 읽도록 Lambda 함수를 수정합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/85408-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
네트워크 연결 문제로 데이터 수집이 잠시 실패하는 현상이 일어남. 이런 경우 데이터 손실이 
일어날 위험성이 크므로 데이터를 보관해둘 곳이 필요하고, 대책으로는 SQS Queue 가 적절. 또한 
SQS Queue 에 머물러 있는 작업들은 Lambda 로 처리 가능. 답은 BE. 
SQS 를 사용하면 메시지 손실 위험을 감수하거나 다른 서비스를 가동할 필요 없이 소프트웨어 
구성 요소 간에 모든 볼륨의 메시지를 전송, 저장 및 수신할 수 있습니다.  
https://aws.amazon.com/ko/sqs/ 
Lambda 함수를 사용하여 Amazon Simple Queue Service(Amazon SQS) 대기열의 메시지를 처리할 
수 있습니다. 
https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/with-sqs.html 
설명 2: 
간헐적인 네트워크 연결 문제에도 불구하고 Lambda 함수가 향후 모든 데이터를 수집하도록 
하려면 다음 조치를 취해야 합니다. 
Amazon Simple Queue Service(SQS) 대기열을 생성하고 SNS 주제를 구독합니다. 이를 통해 
알림과 처리를 분리할 수 있으므로 처리 Lambda 함수가 실패하더라도 나중에 추가 처리를 위해 
메시지가 대기열에 남아 있습니다. 
SNS 에서 직접 읽지 않고 SQS 대기열에서 읽도록 Lambda 함수를 수정합니다. 이 분리는 재시도 
및 내결함성을 허용하고 모든 메시지가 Lambda 함수에 의해 처리되도록 합니다. 
참조: 
AWS SNS 설명서: https://aws.amazon.com/sns/ 
AWS SQS 설명서: https://aws.amazon.com/sqs/ 
AWS Lambda 설명서: https://aws.amazon.com/lambda/ 
Q46 
회사에 매장에 마케팅 서비스를 제공하는 애플리케이션이 있습니다. 서비스는 매장 고객의 이전 
구매를 기반으로 합니다. 상점은 SFTP를 통해 거래 데이터를 회사에 업로드하고 데이터를 처리 및 
분석하여 새로운 마케팅 제안을 생성합니다. 일부 파일의 크기는 200GB 를 초과할 수 있습니다. 
최근에 회사는 일부 상점에서 포함되어서는 안 되는 개인 식별 정보(PII)가 포함된 파일을 
업로드했음을 발견했습니다. 회사는 PII 가 다시 공유될 경우 관리자에게 경고를 주기를 원합니다. 
회사는 또한 문제 해결을 자동화하기를 원합니다. 
최소한의 개발 노력으로 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. Amazon S3 버킷을 보안 전송 지점으로 사용하십시오. Amazon Inspector 를 사용하여 버킷의 
객체를 스캔합니다. 객체에 PII 가 포함된 경우 S3 수명 주기 정책을 트리거하여 PII 가 포함된 
객체를 제거합니다. 
B. Amazon S3 버킷을 보안 전송 지점으로 사용합니다. Amazon Macie 를 사용하여 버킷의 객체를 
스캔합니다. 객체에 PII 가 포함된 경우 Amazon Simple Notification Service(Amazon SNS)를 
사용하여 관리자에게 PII 가 포함된 객체를 제거하라는 알림을 트리거합니다. 
C. AWS Lambda 함수에서 사용자 지정 스캔 알고리즘을 구현합니다. 객체가 버킷에 로드될 때 
함수를 트리거합니다. 객체에 PII 가 포함된 경우 Amazon Simple Notification Service(Amazon 
SNS)를 사용하여 관리자에게 PII 가 포함된 객체를 제거하라는 알림을 트리거합니다. 
D. AWS Lambda 함수에서 사용자 지정 스캔 알고리즘을 구현합니다. 객체가 버킷에 로드될 때 
함수를 트리거합니다. 객체에 PII 가 포함된 경우 Amazon Simple Email Service(Amazon SES)를 
사용하여 관리자에게 알림을 트리거하고 S3 수명 주기 정책을 트리거하여 PII 가 포함된 고기를 
제거합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85264-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Amazon Macie 는 AWS 에서 PII 와 같은 민감한 데이터를 자동으로 검색, 분류 및 보호하는 관리형 
서비스입니다. S3 에서 Macie 를 활성화하면 업로드된 객체에서 PII 를 검색할 수 있습니다. 
A. Amazon Inspector 를 사용하여 S3 의 객체를 스캔하는 것은 PII 데이터 스캔을 위한 최적의 
선택이 아닙니다. Amazon Inspector 는 콘텐츠 스캔이 아닌 호스트 수준 취약성 평가를 위해 
설계되었습니다. 
C. AWS Lambda 함수에서 사용자 지정 검색 알고리즘을 구현하려면 대용량 파일 검색을 처리하기 
위해 상당한 개발 노력이 필요합니다. 
D. 알림에 SES 를 사용하고 S3 수명 주기 정책을 트리거하면 솔루션에 불필요한 복잡성이 추가될 
수 있습니다. 
따라서 최소한의 개발 노력으로 요구 사항을 충족하는 최상의 옵션은 S3 를 안전한 전송 지점으로 
사용하고 Amazon Macie를 PII 스캔에 활용하고 관리자에게 SNS 알림을 트리거하는 것입니다(옵션 
B). 
설명 2: 
최소한의 개발 노력으로 PII 가 공유될 때 관리자에게 탐지 및 경고하고 수정을 자동화하는 요구 
사항을 충족하려면 Amazon S3 버킷을 안전한 전송 지점으로 사용하고 Amazon Macie 로 버킷의 
객체를 스캔하는 것이 가장 좋습니다. 
Amazon Macie 는 기계 학습 및 패턴 일치를 사용하여 Amazon S3 에 저장된 중요한 데이터를 
검색하고 보호하는 완전 관리형 데이터 보안 및 데이터 개인 정보 보호 서비스입니다. 민감한 
데이터를 분류하고, 민감한 데이터에 대한 액세스를 모니터링하고, 수정 작업을 자동화하는 데 
사용할 수 있습니다. 
이 시나리오에서는 파일을 Amazon S3 버킷에 업로드한 후 Amazon Macie 에서 객체를 스캔하여 
PII 를 찾을 수 있으며, PII 가 감지되면 Amazon Simple Notification Service(SNS) 알림을 트리거하여 
관리자에게 제거하도록 알릴 수 있습니다. PII 를 포함하는 객체. Amazon Macie 에는 이미 다양한 
형식의 PII 를 탐지할 수 있는 사전 구축된 데이터 분류 규칙이 있으므로 이 접근 방식은 최소한의 
개발 노력이 필요합니다. 
개인정보 = Macie. 정답은 B. 
참조: 
html AWS Well-Architected 프레임워크 - 보안 기반: 
https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/welcome.html 
Q47 
회사는 1 주일 동안 진행될 예정된 이벤트를 위해 특정 AWS 리전의 3 개의 특정 가용 영역에서 
보장된 Amazon EC2 용량이 필요합니다. 
EC2 용량을 보장하기 위해 회사는 무엇을 해야 합니까? 
A. 필요한 리전을 지정하는 예약 인스턴스를 구매합니다. 
B. 필요한 지역을 지정하는 온디맨드 용량 예약을 생성합니다. 
C. 필요한 리전과 3 개의 가용 영역을 지정하는 예약 인스턴스를 구매합니다. 
D. 필요한 지역과 3 개의 가용 영역을 지정하는 온디맨드 용량 예약을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85529-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 예약 인스턴스는 1 년 또는 3 년 단위 약정 방식. 
예약 인스턴스(RI)는 1 년 또는 3 년 기간으로 약정하는 경우 EC2 사용 요금을 상당히 할인해 주는 
EC2 상품입니다. https://aws.amazon.com/ko/ec2/faqs/ 
B(X) : 용량 예약을 생성할 때 다음을 지정합니다. ◎용량을 예약할 가용 영역 
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html 
C(X) : 예약 인스턴스는 1 년 또는 3 년 단위 약정 방식. 
D(O) : B 번 참조. 
설명 2: 
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html 
예비 인스턴스: 비용 효율적이지 않은 전체 기간(1 년 또는 3 년)에 대해 비용을 지불해야 합니다. 
Q48 
회사 웹 사이트는 항목 카탈로그에 Amazon EC2 인스턴스 스토어를 사용합니다. 회사는 
카탈로그의 가용성이 높고 카탈로그가 내구성 있는 위치에 저장되기를 원합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 카탈로그를 Redis 용 Amazon ElastiCache 로 이동합니다. 
B. 더 큰 인스턴스 스토어로 더 큰 EC2 인스턴스를 배포합니다. 
C. 인스턴스 스토어에서 Amazon S3 Glacier Deep Archive 로 카탈로그를 이동합니다. 
D. 카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85119-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : ElastiCache 는 캐시 서비스. 
B(X) : 인스턴스 스토어는 휘발성 스토리지. 내구성 불충족. 
C(X) : Amazon S3 Glacier Deep Archive 는 콜드 스토리지. 가용성 불충족. 
D(O) : 정답. 
설명 2: 
카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동하면 고가용성과 
내구성이 모두 제공됩니다. Amazon EFS 는 필요에 따라 확장할 수 있도록 구축된 완전 관리형, 
가용성 및 내구성이 뛰어난 파일 시스템입니다. Amazon EFS 를 사용하면 다양한 가용 영역에 있는 
여러 EC2 인스턴스에서 카탈로그 데이터를 저장하고 액세스할 수 있으므로 고가용성이 보장됩니다. 
또한 Amazon EFS 는 여러 가용 영역 내에서 파일을 자동으로 중복 저장하므로 내구성 있는 
스토리지 옵션이 됩니다. 
Q49 
회사는 매월 통화 기록 파일을 저장합니다. 사용자는 통화 후 1 년 이내에 파일에 무작위로 
액세스하지만 1 년 이후에는 파일에 자주 액세스하지 않습니다. 이 회사는 사용자에게 1 년 미만의 
파일을 가능한 한 빨리 쿼리하고 검색할 수 있는 기능을 제공하여 솔루션을 최적화하려고 합니다. 
오래된 파일을 검색하는 데 있어 지연은 허용됩니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? 
A. Amazon S3 Glacier Instant Retrieval 에 태그가 있는 개별 파일을 저장합니다. 태그를 쿼리하여 
S3 Glacier Instant Retrieval 에서 파일을 검색합니다. 
B. Amazon S3 Intelligent-Tiering 에 개별 파일을 저장합니다. S3 수명 주기 정책을 사용하여 1 년 
후 파일을 S3 Glacier Flexible Retrieval 로 이동합니다. Amazon Athena 를 사용하여 Amazon S3 에 
있는 파일을 쿼리하고 검색합니다. S3 Glacier Select 를 사용하여 S3 Glacier 에 있는 파일을 
쿼리하고 검색합니다. 
C. Amazon S3 Standard 스토리지에 태그가 있는 개별 파일을 저장합니다. Amazon S3 Standard 
스토리지의 각 아카이브에 대한 검색 메타데이터를 저장합니다. S3 수명 주기 정책을 사용하여 
1 년 후에 파일을 S3 Glacier Instant Retrieval 로 이동합니다. Amazon S3 에서 메타데이터를 
검색하여 파일을 쿼리하고 검색합니다. 
D. Amazon S3 Standard 스토리지에 개별 파일을 저장합니다. S3 수명 주기 정책을 사용하여 1 년 
후에 파일을 S3 Glacier Deep Archive 로 이동합니다. Amazon RDS 에 검색 메타데이터를 
저장합니다. Amazon RDS에서 파일을 쿼리합니다. S3 Glacier Deep Archive에서 파일을 검색합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85211-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설: 
의료 이미지, 뉴스 미디어 자산 또는 유전체학 데이터와 같이 즉각적인 액세스가 필요한 아카이브 
데이터의 경우 S3 Glacier Instant Retrieve 스토리지 클래스를 선택하십시오. S3 Glacier Instant 
Retrieve 스토리지 클래스는 밀리초 검색으로 최저 비용의 스토리지를 제공합니다.  
즉각적인 액세스가 필요하지는 않지만 백업 또는 재해 복구 사용 사례와 같이 비용 없이 대용량 
데이터 세트를 검색할 수 있는 유연성이 필요한 아카이브 데이터의 경우 S3 Glacier Flexible 
Retrieve(이전의 S3 Glacier)를 선택하고, 몇 분 내에 검색하거나 5-12 시간 내에 대량 검색을 
무료로 제공합니다. 
Q50 
회사에 1,000 개의 Amazon EC2 Linux 인스턴스에서 실행되는 프로덕션 워크로드가 있습니다. 
워크로드는 타사 소프트웨어에 의해 구동됩니다. 회사는 중요한 보안 취약성을 수정하기 위해 
가능한 한 빨리 모든 EC2 인스턴스에서 타사 소프트웨어를 패치해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Lambda 함수를 생성하여 모든 EC2 인스턴스에 패치를 적용합니다. 
B. 모든 EC2 인스턴스에 패치를 적용하도록 AWS Systems Manager Patch Manager 를 구성합니다. 
C. AWS Systems Manager 유지 관리 기간을 예약하여 모든 EC2 인스턴스에 패치를 적용합니다. 
D. AWS Systems Manager Run Command 를 사용하여 모든 EC2 인스턴스에 패치를 적용하는 
사용자 지정 명령을 실행합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85026-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
A(X) : 1000 개의 인스턴스에 일일이 다 Lambda 로 패치 적용한다는 것은 비효율적이고 번거로움 
B(X) : 자동 업데이트에는 시간이 좀 걸림. ""패치 관리자는 승인 및 거부된 패치 목록과 함께 
릴리스 후 며칠 이내에 패치를 자동 승인하기 위한 규칙을 포함 하는 패치 기준선 을 사용합니다. 
https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-patch.html 
C(X) : 가능한 빨리 패치해야한다고 했는데 예약을 하고 있어서 안 됨.  
D(O) : 리소스 그룹을 통해 한 번에 여러 인스턴스를 업데이트 가능. 리소스 그룹이 명령 대상으로 
지원됨에 따라 해당 리소스 그룹에 속한 모든 관리형 인스턴스에서 관리 및 임시 작업을 자동화할 
수 있습니다. 
https://aws.amazon.com/ko/about-aws/whats-new/2019/08/now-select-resource-groups-as-t
argets-for-aws-systems-manager-run-command/ 
참고: 
https://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/about-windows-app-p
atching.html 
Q51 
회사는 REST API 로 검색하기 위해 주문 배송 통계를 제공하는 애플리케이션을 개발 중입니다. 이 
회사는 배송 통계를 추출하고 데이터를 읽기 쉬운 HTML 형식으로 구성하고 매일 아침 여러 
이메일 주소로 보고서를 보내려고 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 취해야 합니까? (2 개를 
선택하세요.) 
A. 데이터를 Amazon Kinesis Data Firehose 로 보내도록 애플리케이션을 구성합니다. 
B. Amazon Simple Email Service(Amazon SES)를 사용하여 데이터 형식을 지정하고 보고서를 
이메일로 보냅니다. 
C. AWS Glue 작업을 호출하여 데이터에 대한 애플리케이션의 API 를 쿼리하는 Amazon 
EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다. 
D. AWS Lambda 함수를 호출하여 데이터에 대한 애플리케이션의 API 를 쿼리하는 Amazon 
EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다. 
E. Amazon S3 에 애플리케이션 데이터를 저장합니다. 보고서를 이메일로 보낼 S3 이벤트 대상으로 
Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/85557-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
https://docs.aws.amazon.com/ses/latest/dg/send-email-formatted.html 
1. 데이터에 대한 애플리케이션의 API 를 쿼리하기 위해 AWS Lambda 함수를 호출하는 Amazon 
EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다. 이 단계는 AWS Lambda 를 
사용하여 배송 통계를 추출하고 데이터를 HTML 형식으로 구성할 수 있습니다. 
2. Amazon Simple Email Service(Amazon SES)를 사용하여 데이터 형식을 지정하고 이메일로 
보고서를 보냅니다. 
이 단계는 Amazon SES 를 사용하여 매일 아침 동시에 여러 이메일 주소로 보고서를 전송함으로써 
수행할 수 있습니다. 
따라서 옵션 D와 B는 이 질문에 대한 올바른 선택입니다. Kinesis Data Firehose 가 이 사용 사례에 
필요하지 않기 때문에 옵션 A 는 올바르지 않습니다. 애플리케이션의 API 를 쿼리하는 데 AWS 
Glue 가 필요하지 않기 때문에 옵션 C 는 올바르지 않습니다. S3 이벤트 알림을 사용하여 이메일로 
보고서를 보낼 수 없기 때문에 옵션 E 는 올바르지 않습니다. 
설명 2: 
B(O) : HTML 형식의 이메일 요구사항을 충족 
D(O) : 매일 아침 일정 이벤트 요구사항 충족 
Q52 
회사에서 온프레미스 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 애플리케이션은 수십 
기가바이트에서 수백 테라바이트까지 다양한 크기의 출력 파일을 생성합니다. 애플리케이션 
데이터는 표준 파일 시스템 구조로 저장되어야 합니다. 회사는 자동으로 확장되는 솔루션을 
원합니다. 고가용성이며 최소한의 운영 오버헤드가 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Elastic Container Service(Amazon ECS)에서 컨테이너로 실행되도록 애플리케이션을 
마이그레이션합니다. 스토리지에 Amazon S3 를 사용합니다. 
B. Amazon Elastic Kubernetes Service(Amazon EKS)에서 컨테이너로 실행되도록 애플리케이션을 
마이그레이션합니다. 스토리지에 Amazon Elastic Block Store(Amazon EBS)를 사용합니다. 
C. 다중 AZ Auto Scaling 그룹의 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션합니다. 
스토리지에 Amazon Elastic File System(Amazon EFS)을 사용합니다. 
D. 다중 AZ Auto Scaling 그룹의 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션합니다. 
스토리지에 Amazon Elastic Block Store(Amazon EBS)를 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85265-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
EFS 는 표준 파일 시스템으로 자동 확장되며 가용성이 높습니다. 
설명 2: 
고가용성이므로 Auto Scaling 이 들어간 C,D 둘 중 하나가 정답. EFS vs EBS 를 비교해보면 보통은 
EFS 가 정답인 경우가 많음. 일단 EBS 는 여러 EC2 인스턴스에서 동시 접속할 수 없다는 단점이 
치명적이기 때문. 
Amazon Elastic File System 은 전체 파일 시스템 액세스 의미 체계를 지원하는 표준 파일 시스템 
인터페이스를 제공합니다. 
https://docs.aws.amazon.com/efs/latest/ug/using-fs.html 
EBS 다중 연결 볼륨에서 표준 파일 시스템 작업은 지원되는 구성이 아닙니다. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/ebs-access-volumes-using-m
ulti-attach/ 
Q53 
회사는 Amazon S3 에 회계 기록을 저장해야 합니다. 기록은 1 년 동안 즉시 액세스할 수 있어야 
하며 그 후 추가로 9 년 동안 보관해야 합니다. 관리자 및 루트 사용자를 포함하여 회사의 그 
누구도 전체 10 년 동안 기록을 삭제할 수 없습니다. 기록은 최대한의 복원력으로 저장해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 전체 10 년 동안 S3 Glacier 에 기록을 저장합니다. 접근통제 정책을 사용하여 10 년 동안 기록 
삭제를 거부합니다. 
B. S3 Intelligent-Tiering 을 사용하여 레코드를 저장합니다. IAM 정책을 사용하여 레코드 삭제를 
거부합니다. 10 년 후 삭제를 허용하도록 IAM 정책을 변경합니다. 
C. S3 수명 주기 정책을 사용하여 1 년 후에 S3 Standard 에서 S3 Glacier Deep Archive 로 레코드를 
전환합니다. 10 년 동안 규정 준수 모드에서 S3 Object Lock 을 사용합니다. 
D. S3 수명 주기 정책을 사용하여 1 년 후 레코드를 S3 Standard 에서 S3 One Zone-Infrequent 
Access(S3 One Zone-IA)로 전환합니다. 10 년 동안 거버넌스 모드에서 S3 Object Lock 을 
사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85532-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : 1 년 동안 즉시 액세스할 수 있어야 한다고 했으므로 액세스 시간이 1 분 이상 걸리는 S3 
Glacier 는 오답. 
B(X) : 특정 기간동안 즉시 액세스할 수 있어야 하므로 Intelligent Tiering 이 아니라 Life Cycle 
Policy 가 적합. 
C(O) : S3 Standard = 즉시 액세스 가능 / S3 Glacier Deep Archive = 콜드 스토리지. 보관용으로 
사용됨. Object Lock 으로 객체 삭제 방지. 
S3 객체 잠금을 사용하면 write-once-read-many(WORM) 모델을 사용하여 객체를 저장할 수 
있습니다. 객체 잠금은 고정된 시간 동안 또는 무기한으로 객체의 삭제 또는 덮어쓰기를 방지하는 
데 도움이 될 수 있습니다.  
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lock.html 
D(X) : 기록은 최대한의 복원력으로 저장해야한다고 했으므로 One Zone-IA 는 적합하지 않음. 
설명 2: 
1 년 동안 즉시 액세스 가능한 레코드의 요구 사항을 충족한 다음 최대 복원력으로 추가 9 년 동안 
보관하기 위해 S3 수명 주기 정책을 사용하여 1 년 후 S3 Standard 에서 S3 Glacier Deep 
Archive로 레코드를 전환할 수 있습니다. 또한 관리자 및 루트 사용자를 포함하여 누구도 레코드를 
삭제할 수 없도록 10 년 동안 규정 준수 모드에서 S3 객체 잠금을 사용할 수 있습니다. 따라서 
정답은 옵션 C 입니다. 
Q54 
회사는 AWS 에서 여러 Windows 워크로드를 실행합니다. 회사 직원은 두 개의 Amazon EC2 
인스턴스에서 호스팅되는 Windows 파일 공유를 사용합니다. 파일 공유는 서로 간에 데이터를 
동기화하고 중복 복사본을 유지합니다. 이 회사는 사용자가 현재 파일에 액세스하는 방식을 
보존하는 고가용성 및 내구성 스토리지 솔루션을 원합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 모든 데이터를 Amazon S3 로 마이그레이션합니다. 사용자가 파일에 액세스할 수 있도록 IAM 
인증을 설정합니다. 
B. Amazon S3 파일 게이트웨이를 설정합니다. 기존 EC2 인스턴스에 S3 파일 게이트웨이를 
탑재합니다. 
C. 다중 AZ 구성을 사용하여 파일 공유 환경을 Windows 파일 서버용 Amazon FSx 로 확장합니다. 
모든 데이터를 Windows 파일 서버용 FSx 로 마이그레이션합니다. 
D. 다중 AZ 구성을 사용하여 파일 공유 환경을 Amazon Elastic File System(Amazon EFS)으로 
확장합니다. 모든 데이터를 Amazon EFS 로 마이그레이션합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85574-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
Windows File 공유가 핵심 키워드. 답은 C. 
설명 2: 
https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonEFS.html 
Amazon FSx for Windows File Server 는 완전히 네이티브로 지원되는 완전히 관리되는 Microsoft 
Windows 파일 서버를 제공합니다. 
윈도우 파일 시스템. 
https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html 
Q55 
솔루션 설계자는 여러 서브넷을 포함하는 VPC 아키텍처를 개발 중입니다. 아키텍처는 Amazon 
EC2 인스턴스 및 Amazon RDS DB 인스턴스를 사용하는 애플리케이션을 호스팅합니다. 
아키텍처는 2 개의 가용 영역에 있는 6 개의 서브넷으로 구성됩니다. 각 가용 영역에는 퍼블릭 
서브넷, 프라이빗 서브넷 및 데이터베이스용 전용 서브넷이 포함됩니다. 프라이빗 서브넷에서 
실행되는 EC2 인스턴스만 RDS 데이터베이스에 액세스할 수 있습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 새 라우팅 테이블을 생성합니다. 라우팅 
테이블을 데이터베이스 서브넷과 연결합니다. 
B. 퍼블릭 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 거부하는 보안 그룹을 
생성합니다. 보안 그룹을 DB 인스턴스에 연결합니다. 
C. 프라이빗 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 허용하는 보안 그룹을 
생성합니다. 보안 그룹을 DB 인스턴스에 연결합니다. 
D. 퍼블릭 서브넷과 프라이빗 서브넷 사이에 새로운 피어링 연결을 생성합니다. 프라이빗 서브넷과 
데이터베이스 서브넷 간에 다른 피어링 연결을 만듭니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85409-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
프라이빗 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 허용하는 보안 그룹을 
생성하면 프라이빗 서브넷에서 실행되는 EC2 만 RDS 데이터베이스에 액세스할 수 있습니다. 보안 
그룹을 DB 와 연결하여 지정된 보안 그룹에 속한 인스턴스로만 접근을 제한합니다. 
질문에 설명된 요구 사항을 충족하는 솔루션은 옵션 C 입니다. 프라이빗 서브넷의 인스턴스에 
할당된 보안 그룹에서 인바운드 트래픽을 허용하는 보안 그룹을 생성합니다. 보안 그룹을 DB 
인스턴스에 연결합니다. 
이 솔루션에서 DB 인스턴스에 적용된 보안 그룹은 프라이빗 서브넷의 인스턴스에 할당된 보안 
그룹의 인바운드 트래픽을 허용합니다. 이렇게 하면 프라이빗 서브넷에서 실행되는 EC2 
인스턴스만 RDS 데이터베이스에 액세스할 수 있습니다. 
Q56 
회사는 Amazon Route 53 에 도메인 이름을 등록했습니다. 이 회사는 ca-central-1 리전의 
Amazon API Gateway 를 백엔드 마이크로서비스 API 의 공용 인터페이스로 사용합니다. 타사 
서비스는 API 를 안전하게 사용합니다. 회사는 타사 서비스에서 HTTPS 를 사용할 수 있도록 회사의 
도메인 이름 및 해당 인증서로 API 게이트웨이 URL 을 설계하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. API Gateway 에서 Name="Endpoint-URL" 및 Value="Company Domain Name"으로 단계 변수를 
생성하여 기본 URL 을 덮어씁니다. 회사의 도메인 이름과 연결된 공인 인증서를 AWS Certificate 
Manager(ACM)로 가져옵니다. 
B. 회사의 도메인 이름으로 Route 53 DNS 레코드를 생성합니다. 별칭 레코드가 리전 API 
게이트웨이 단계 엔드포인트를 가리키도록 합니다. 회사의 도메인 이름과 연결된 공인 인증서를 
us-east-1 리전의 AWS Certificate Manager(ACM)로 가져옵니다. 
C. 리전 API 게이트웨이 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사의 도메인 
이름과 연결합니다. 회사의 도메인 이름과 연결된 공인 인증서를 동일한 리전의 AWS Certificate 
Manager(ACM)로 가져옵니다. API Gateway 엔드포인트에 인증서를 연결합니다. API Gateway 
엔드포인트로 트래픽을 라우팅하도록 Route 53 을 구성합니다. 
D. 리전 API 게이트웨이 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사의 도메인 
이름과 연결합니다. 회사의 도메인 이름과 연결된 공인 인증서를 us-east-1 리전의 AWS 
Certificate Manager(ACM)로 가져옵니다. API Gateway API 에 인증서를 연결합니다. 회사의 도메인 
이름으로 Route 53 DNS 레코드를 생성합니다. A 레코드가 회사의 도메인 이름을 가리키도록 
합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85266-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
사용자 정의 도메인 이름 은 API 사용자에게 제공할 수 있는 더 간단하고 직관적인 URL 입니다. 
API 를 배포한 후 귀하(및 귀하의 고객)는 다음 형식의 기본 기본 URL 을 사용하여 API 를 호출할 
수 있습니다. 
https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html 
리전 사용자 지정 도메인 이름은 API 와 동일한 AWS 리전에 있는 SSL/TLS 인증서를 사용해야 
합니다. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/custom-domain-name-amazon
-api-gateway/ 
・여기서 API Gateway URL 이란, Route 53 에 등록된 도메인 이름으로, 이를 통해 API 를 호출할 수 
있음. 
・인증서는 HTTPS 에 사용됨. HTTPS=HTTL + SSL 인데, SSL 에 인증서가 필요하기 때문. 
인증서는 ACM 으로 가져올 수 있음. 
1. 리전 API 게이트웨이 엔드포인트 생성 및 회사 도메인 이름과 연결 
또한 API Gateway REST API, Amazon CLI 또는 Amazon SDK 중 하나를 호출하여 사용자 지정 
도메인 이름을 호스트 이름으로 사용하여 API 의 기본 경로 매핑을 설정할 수 있습니다. 
https://docs.amazonaws.cn/en_us/apigateway/latest/developerguide/how-to-edge-optimized-c
ustom-domain-name.html#how-to-custom-domains-mapping-console 
2. 회사 도메인 이름과 연결된 공인 인증서를 동일 리전의 ACM 으로 가져옴 
API Gateway 리전 사용자 지정 도메인 이름의 경우 API 와 동일한 리전에서 인증서를 요청하거나 
가져와야 합니다......도메인 이름에 대한 인증서를 ACM 으로 가져오려면.... 
https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains-prer
equisites.html 
3. API 게이트웨이 엔드포인트에 인증서 연결 
ACM 인증서로 리전 사용자 지정 도메인 이름을 생성(또는 마이그레이션)하면 API Gateway 는 해당 
계정에 서비스 연결 역할을 생성합니다(이 역할이 아직 없는 경우). 서비스 연결 역할은 ACM 
인증서를 해당 리전 엔드포인트에 연결하는 데 필요합니다. 
https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/apigateway-regional-api
-custom-domain-create.html 
4. API 게이트웨이 엔드포인트로 트래픽 라우팅 하도록 Route 53 설정 
API Gateway 리전 사용자 지정 도메인 이름의 경우 API 와 동일한 리전에서 인증서를 요청하거나 
가져와야 합니다. 그리하여 회사의 도메인 이름과 연결된 공인 인증서는 동일 리전의 ACM 으로 
가져와야됩니다. 따라서 정답은 C 에 한표 입니다. 
도메인 이름을 사용하여 Amazon API Gateway API 로 트래픽 라우팅  
・리전 API 엔드포인트(Regional API endpoint): 리전 API 엔드포인트로 트래픽을 라우팅하는 Route 
53 별칭 레코드를 생성합니다. 
https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/routing-to-api-gateway.ht
ml 
설명 2 
회사의 도메인 이름과 해당 인증서로 API Gateway URL 을 설계하려면 회사에서 다음을 수행해야 
합니다. 
1. 지역 API 게이트웨이 엔드포인트 생성: 이를 통해 회사는 지역에 특정한 엔드포인트를 생성할 
수 있습니다. 
2. API 게이트웨이 엔드포인트를 회사의 도메인 이름과 연결: 이렇게 하면 회사에서 API 
게이트웨이 URL 에 자체 도메인 이름을 사용할 수 있습니다. 
3. 회사의 도메인 이름과 연결된 공인 인증서를 동일한 리전의 AWS Certificate Manager(ACM)로 
가져옵니다. 이렇게 하면 회사에서 API 와의 보안 통신을 위해 HTTPS 를 사용할 수 있습니다. 
4. API Gateway 엔드포인트에 인증서 첨부: 회사에서 API Gateway URL 보안을 위해 인증서를 
사용할 수 있습니다. 
5. 트래픽을 API 게이트웨이 엔드포인트로 라우팅하도록 Route 53 구성: 이를 통해 회사는 Route 
53 을 사용하여 회사의 도메인 이름을 사용하는 API 게이트웨이 URL 로 트래픽을 라우팅할 수 
있습니다. 
Q57 
한 회사에서 인기 있는 소셜 미디어 웹사이트를 운영하고 있습니다. 웹사이트는 사용자에게 
이미지를 업로드하여 다른 사용자와 공유할 수 있는 기능을 제공합니다. 회사는 이미지에 부적절한 
콘텐츠가 포함되지 않았는지 확인하고 싶습니다. 회사는 개발 노력을 최소화하는 솔루션이 
필요합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon Comprehend 를 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 예측에는 인적 
검토를 사용합니다. 
B. Amazon Rekognition 을 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 예측에는 인적 
검토를 사용합니다. 
C. Amazon SageMaker를 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 예측에 레이블을 
지정하려면 정답을 사용합니다. 
D. AWS Fargate 를 사용하여 사용자 지정 기계 학습 모델을 배포하여 부적절한 콘텐츠를 
감지합니다. 신뢰도가 낮은 예측에 레이블을 지정하려면 정답을 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85452-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
Amazon Rekognition 을 사용하여 부적절하거나 원치 않거나 불쾌감을 주는 콘텐츠를 감지할 수 
있습니다. 
https://docs.aws.amazon.com/rekognition/latest/dg/moderation.html 
참조 
https://docs.aws.amazon.com/rekognition/latest/dg/moderation.html?pg=ln&sec=ft 
https://docs.aws.amazon.com/rekognition/latest/dg/a2i-rekognition.html 
Q58 
회사는 확장성 및 가용성에 대한 요구 사항을 충족하기 위해 컨테이너에서 중요한 응용 
프로그램을 실행하려고 합니다. 회사는 중요한 응용 프로그램의 유지 관리에 집중하는 것을 
선호합니다. 회사는 컨테이너화된 워크로드를 실행하는 기본 인프라의 프로비저닝 및 관리에 대한 
책임을 원하지 않습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon EC2 인스턴스를 사용하고 인스턴스에 Docker 를 설치합니다. 
B. Amazon EC2 작업자 노드에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다. 
C. AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다. 
D. Amazon Elastic Container Service(Amazon ECS)에 최적화된 Amazon 머신 이미지(AMI)의 
Amazon EC2 인스턴스를 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85453-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
AWS 에서 컨테이너라고 하면 ECS, ECS 라고 하면 일단 Fargate 부터 떠올리면 됨. AWS Fargate 
Fargate 는 Amazon EC2 인스턴스의 서버나 클러스터를 관리할 필요 없이 컨테이너를 실행하기 
위해 Amazon ECS 에 사용할 수 있는 기술입니다. 
https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/AWS_Fargate.html 
설명 2: 
요구 사항은 컨테이너화된 워크로드를 실행하기 위해 기본 인프라를 프로비저닝하고 관리할 필요 
없이 확장성과 가용성을 위한 것이므로 AWS Fargate 에서 AWS ECS 를 사용합니다. 
https://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html 
Q59 
회사는 300 개 이상의 글로벌 웹사이트 및 애플리케이션을 호스팅합니다. 이 회사는 매일 30TB 
이상의 클릭스트림 데이터를 분석할 플랫폼이 필요합니다. 
솔루션 설계자는 클릭스트림 데이터를 전송하고 처리하기 위해 무엇을 해야 합니까? 
A. AWS Data Pipeline 을 설계하여 데이터를 Amazon S3 버킷에 보관하고 데이터로 Amazon EMR 
클러스터를 실행하여 분석을 생성합니다. 
B. Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하여 데이터를 처리하고 Amazon Redshift 가 
분석에 사용할 수 있도록 Amazon S3 데이터 레이크로 보냅니다. 
C. 데이터를 Amazon CloudFront 에 캐시합니다. Amazon S3 버킷에 데이터를 저장합니다. 객체가 
S3 버킷에 추가될 때. AWS Lambda 함수를 실행하여 분석용 데이터를 처리합니다. 
D. Amazon Kinesis Data Streams 에서 데이터를 수집합니다. Amazon Kinesis Data Firehose 를 
사용하여 Amazon S3 데이터 레이크로 데이터를 전송합니다. 분석을 위해 Amazon Redshift 에 
데이터를 로드합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85793-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
대량의 스트림 데이터 수집 = Kinesis Data Streams. 정답은 D. 
※실제 사례가 있음. 
◎전 세계 300 개 이상의 Hearst 웹사이트에서 스트리밍되는 하루 30 테라바이트 이상의 
클릭스트림 데이터를 전송하고 처리하는 클릭스트림 분석 플랫폼을 구축했습니다. 
◎Amazon Kinesis Firehose 는 버퍼링된 데이터를 Amazon Kinesis Data Streams 에서 Amazon 
Simple Storage Service (Amazon S3) 의 영구 스토리지로 자동 이동합니다. 이는 팀이 이전에 
관리해야 했던 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스를 대체합니다. 
◎변환된 클릭스트림 데이터는 Hearst 데이터 레이크에서 가져와 분석 쿼리 및 복잡한 데이터 
과학 작업을 위해 Amazon Redshift 로 전송됩니다. 
◎Amazon Redshift 에서 데이터는 API 를 통해 회사의 콘텐츠 관리 시스템으로 최종 사용자에게 
푸시됩니다. 
https://aws.amazon.com/ko/solutions/case-studies/hearst-data-analytics/ 
Q60 
회사에 AWS 에서 호스팅되는 웹 사이트가 있습니다. 웹 사이트는 HTTP 와 HTTPS 를 별도로 
처리하도록 구성된 ALB(Application Load Balancer) 뒤에 있습니다. 회사는 요청이 HTTPS 를 
사용하도록 모든 요청을 웹사이트로 전달하려고 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. HTTPS 트래픽만 허용하도록 ALB 의 네트워크 ACL 을 업데이트합니다. 
B. URL 의 HTTP 를 HTTPS 로 바꾸는 규칙을 만듭니다. 
C. ALB 에서 리스너 규칙을 생성하여 HTTP 트래픽을 HTTPS 로 리디렉션합니다. 
D. ALB 를 SNI(서버 이름 표시)를 사용하도록 구성된 Network Load Balancer 로 교체합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85121-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
Application Load Balancer 를 위한 리스너…..쿼리 문자열 조건을 사용하여 쿼리 문자열의 키/값 
페어 또는 값을 기반으로 요청을 라우팅하는 규칙을 구성할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/load-balancer-listen
ers.html 
Application Load Balancer 리스너 규칙을 사용하여 HTTP 요청을 HTTPS 로 리디렉션하려고 
합니다. 어떻게 해야 하나요? 
①HTTP 요청을 HTTPS 로 리디렉션하는 HTTP 리스너 규칙 생성. 
②HTTPS 리스너 생성. 
③Application Load Balancer 의 보안 그룹이 443 의 트래픽을 허용하는지 확인 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/elb-redirect-http-to-https-usin
g-alb/ 
참조 
https://aws.amazon.com/premiumsupport/knowledge-center/elb-redirect-http-to-https-using-
alb/ 
https://repost.aws/ko/knowledge-center/elb-redirect-http-to-https-using-alb 
Q61 
한 회사가 AWS 에서 2 계층 웹 애플리케이션을 개발하고 있습니다. 회사 개발자는 백엔드 Amazon 
RDS 데이터베이스에 직접 연결되는 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. 
회사는 애플리케이션에 데이터베이스 자격 증명을 하드코딩해서는 안 됩니다. 또한 회사는 
정기적으로 데이터베이스 자격 증명을 자동으로 교체하는 솔루션을 구현해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 인스턴스 메타데이터에 데이터베이스 자격 증명을 저장합니다. Amazon EventBridge(Amazon 
CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 인스턴스 메타데이터를 동시에 
업데이트하는 예약된 AWS Lambda 함수를 실행합니다. 
B. 암호화된 Amazon S3 버킷의 구성 파일에 데이터베이스 자격 증명을 저장합니다. Amazon 
EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 구성 파일의 자격 
증명을 동시에 업데이트하는 예약된 AWS Lambda 함수를 실행합니다. S3 버전 관리를 사용하여 
이전 값으로 폴백하는 기능을 보장합니다. 
C. 데이터베이스 자격 증명을 AWS Secrets Manager 에 암호로 저장합니다. 보안 비밀에 대한 자동 
순환을 켭니다. EC2 역할에 필요한 권한을 연결하여 보안 암호에 대한 액세스 권한을 부여합니다. 
D. 데이터베이스 자격 증명을 AWS Systems Manager Parameter Store 에 암호화된 파라미터로 
저장합니다. 암호화된 매개변수에 대해 자동 회전을 켭니다. EC2 역할에 필요한 권한을 연결하여 
암호화된 파라미터에 대한 액세스 권한을 부여합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85580-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
애플리케이션에 자격증명 하드코딩 안 됨 = Secrets Manager. 
Secrets Manager 를 사용하면 애플리케이션 소스 코드에서 하드 코딩된 자격 증명을 제거하고 
애플리케이션 자체에 자격 증명을 저장하지 않음으로써 보안 태세를 개선할 수 있습니다. 사용자의 
개입 없이 지정한 일정에 따라 자동으로 보안 암호를 교체하도록 Secrets Manager 를 구성할 수 
있습니다. 교체는 AWS Lambda 함수를 사용하여 정하고 실행합니다. 
https://docs.aws.amazon.com/ko_kr/secretsmanager/latest/userguide/intro.html 
참고: 
https://docs.aws.amazon.com/secretsmanager/latest/userguide/create_database_secret.html 
Q62 
회사에서 AWS 에 새로운 공개 웹 애플리케이션을 배포하고 있습니다. 애플리케이션은 
ALB(Application Load Balancer) 뒤에서 실행됩니다. 애플리케이션은 외부 CA(인증 기관)에서 
발급한 SSL/TLS 인증서를 사용하여 에지에서 암호화해야 합니다. 인증서가 만료되기 전에 매년 
인증서를 교체해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. 인증서를 ALB 에 
적용합니다. 관리형 갱신 기능을 사용하여 인증서를 자동으로 교체합니다. 
B. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. 인증서에서 키 
자료를 가져옵니다. AL 에 인증서 적용 관리되는 갱신 기능을 사용하여 인증서를 자동으로 
교체합니다. 
C. AWS Certificate Manager(ACM) 사설 인증 기관을 사용하여 루트 CA 에서 SSL/TLS 인증서를 
발급합니다. 인증서를 ALB 에 적용합니다. 관리형 갱신 기능을 사용하여 인증서를 자동으로 
교체합니다. 
D. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 가져옵니다. 인증서를 ALB 에 
적용합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 인증서가 만료될 때 
알림을 보냅니다. 인증서를 수동으로 교체합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85524-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
외부 인증기관에서 발급한 SSL/TLS 인증서가 이미 있고 이를 사용해야하므로 ACM 쪽에서 
SSL/TLS 인증서를 발급하는 A,B 는 모두 오답. 
C(X) : 인증서가 있는데 또 발급받을 필요가 없음. 
https://www.amazonaws.cn/en/certificate-manager/faqs/#Managed_renewal_and_deployment 
Q63 
회사는 AWS 에서 인프라를 실행하고 문서 관리 애플리케이션에 대해 700,000 명의 등록 기반을 
보유하고 있습니다. 회사는 큰 .pdf 파일을 .jpg 이미지 파일로 변환하는 제품을 만들려고 
합니다. .pdf 파일의 크기는 평균 5MB 입니다. 회사는 원본 파일과 변환 파일을 보관해야 합니다. 
솔루션 설계자는 시간이 지남에 따라 빠르게 증가할 수요를 수용할 수 있는 확장 가능한 솔루션을 
설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? 
A. .pdf 파일을 Amazon S3 에 저장합니다. AWS Lambda 함수를 호출하여 파일을 .jpg 형식으로 
변환하고 Amazon S3 에 다시 저장하도록 S3 PUT 이벤트를 구성합니다. 
B. .pdf 파일을 Amazon DynamoD 에 저장 DynamoDB 스트림 기능을 사용하여 AWS Lambda 
함수를 호출하여 파일을 .jpg 형식으로 변환하고 DynamoDB 에 다시 저장합니다. 
C. Amazon EC2 인스턴스, Amazon Elastic Block Store(Amazon EBS) 스토리지 및 Auto Scaling 
그룹이 포함된 AWS Elastic Beanstalk 애플리케이션에 .pdf 파일을 업로드합니다. EC2 인스턴스의 
프로그램을 사용하여 파일을 .jpg 형식으로 변환합니다. .pdf 파일과 .jpg 파일을 EBS 스토어에 
저장합니다. 
D. .pdf 파일을 Amazon EC2 인스턴스, Amazon Elastic File System(Amazon EFS) 스토리지 및 
Auto Scaling 그룹이 포함된 AWS Elastic Beanstalk 애플리케이션에 업로드합니다. EC2 인스턴스의 
프로그램을 사용하여 파일을 .jpg 형식으로 변환합니다. .pdf 파일과 .jpg 파일을 EBS 스토어에 
저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85795-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(O) : S3 에 넣으면 Lambda 를 통해 자동으로 처리가 되도록 하는 거라 OK. S3 는 저렴함. 
B(X) : dynamodb 는 이미지 저장용으론… 
C(X) : 저렴한 S3 가 있는데 굳이... 인스턴스 비용도 나감. 
D(x) : C 와 마찬가지. 
설명 2: 
Elastic BeanStalk 는 비싸고 DocumentDB 는 최대 400KB 의 파일을 업로드할 수 있습니다. 따라서 
Lambda 와 S3 가 하나여야 합니다. 
Q64 
회사는 온프레미스에서 실행되는 Windows 파일 서버에 5TB 이상의 파일 데이터를 가지고 
있습니다. 사용자와 애플리케이션은 매일 데이터와 상호 작용합니다. 
이 회사는 Windows 워크로드를 AWS 로 이전하고 있습니다. 회사가 이 프로세스를 계속함에 따라 
회사는 최소 지연 시간으로 AWS 및 온프레미스 파일 스토리지에 액세스할 수 있어야 합니다. 
회사는 운영 오버헤드를 최소화하고 기존 파일 액세스 패턴을 크게 변경할 필요가 없는 솔루션이 
필요합니다. 회사는 AWS 연결을 위해 AWS Site-to-Site VPN 연결을 사용합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS 에서 Windows 파일 서버용 Amazon FSx 를 배포 및 구성합니다. 온-프레미스 파일 
데이터를 Windows 파일 서버용 FSx 로 이동합니다. AWS 에서 Windows 파일 서버용 FSx 를 
사용하도록 워크로드를 재구성합니다. 
B. 온프레미스에 Amazon S3 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 
S3 파일 게이트웨이로 이동합니다. S3 파일 게이트웨이를 사용하도록 온프레미스 워크로드 및 
클라우드 워크로드를 재구성합니다. 
C. 온프레미스에 Amazon S3 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 
Amazon S3 로 이동합니다. Amazon S3 를 직접 사용하거나 S3 파일 게이트웨이를 사용하도록 
워크로드를 재구성합니다. 각 워크로드의 위치에 따라 다릅니다. 
D. AWS 에서 Windows 파일 서버용 Amazon FSx 를 배포 및 구성합니다. 온프레미스에 Amazon 
FSx 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 FSx 파일 게이트웨이로 
이동합니다. AWS 의 Windows 파일 서버용 FSx 를 사용하도록 클라우드 워크로드를 구성합니다. 
FSx 파일 게이트웨이를 사용하도록 온프레미스 워크로드를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85173-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
Windows File Server + AWS 로 이동 = Amazon FSx File Gateway. 
Amazon FSx 파일 게이트웨이는 Amazon FSx 의 Windows 파일 공유에 대한 온프레미스 액세스를 
최적화하여 사용자가 짧은 지연 시간과 공유 대역폭을 유지하면서 Windows 파일 서버용 FSx 
데이터에 쉽게 액세스할 수 있도록 합니다. 사용자는 액세스할 수 있는 자주 사용하는 데이터의 
로컬 캐시를 활용하여 성능을 높이고 데이터 전송 트래픽을 줄일 수 있습니다. 파일 읽기 및 
쓰기와 같은 파일 시스템 작업은 모두 로컬 캐시에 대해 수행되는 반면 Amazon FSx 파일 
게이트웨이는 변경된 데이터를 백그라운드에서 Windows 파일 서버용 FSx와 동기화합니다. 이러한 
기능을 사용하면 Windows 파일 서버용 FSx 에서 AWS 의 모든 온프레미스 파일 공유 데이터를 
통합하고 보호되고 탄력적인 완전 관리형 파일 시스템의 이점을 누릴 수 있습니다. 
https://aws.amazon.com/storagegateway/faqs/?nc1=h_ls 
설명 2: 
https://docs.aws.amazon.com/filegateway/latest/filefsxw/what-is-file-fsxw.html 
대기 시간을 최소화하면서 AWS 와 온프레미스 파일 스토리지 모두에 액세스해야 하는 회사의 요구 
사항을 충족하기 위해 하이브리드 클라우드 아키텍처를 사용할 수 있습니다. 한 가지 솔루션은 
완벽하게 관리되는 Windows 파일 서버를 제공하는 AWS 에서 Windows 파일 서버용 Amazon 
FSx 를 배포 및 구성하는 것입니다. 
온프레미스 파일 데이터는 온프레미스와 AWS 파일 스토리지 간의 브리지 역할을 할 수 있는 FSx 
파일 게이트웨이로 이동할 수 있습니다. 클라우드 워크로드는 AWS 에서 Windows File Server 용 
FSx 를 사용하도록 구성할 수 있으며 온프레미스 워크로드는 FSx 파일 게이트웨이를 사용하도록 
구성할 수 있습니다. 
이 솔루션은 운영 오버헤드를 최소화하고 기존 파일 액세스 패턴을 크게 변경할 필요가 없습니다. 
온프레미스와 AWS 간의 연결은 AWS Site-to-Site VPN 연결을 사용하여 설정할 수 있습니다. 
참조: 
Windows 파일 서버용 AWS FSx: https://aws.amazon.com/fsx/windows/ 
AWS FSx 파일 게이트웨이: https://aws.amazon.com/fsx/file-gateway/ 
AWS 사이트 간 VPN: https://aws.amazon.com/vpn/site-to-site-vpn/ 
Q65 
병원은 최근 Amazon API Gateway 및 AWS Lambda 와 함께 RESTful API 를 배포했습니다. 병원은 
API Gateway 및 Lambda 를 사용하여 PDF 형식 및 JPEG 형식의 보고서를 업로드합니다. 병원은 
보고서에서 보호되는 건강 정보(PHI)를 식별하기 위해 Lambda 코드를 수정해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 기존 Python 라이브러리를 사용하여 보고서에서 텍스트를 추출하고 추출된 텍스트에서 PHI 를 
식별합니다. 
B. Amazon Textract 를 사용하여 보고서에서 텍스트를 추출합니다. Amazon SageMaker 를 사용하여 
추출된 텍스트에서 PHI 를 식별합니다. 
C. Amazon Textract 를 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical 을 
사용하여 추출된 텍스트에서 PHI 를 식별합니다. 
D. Amazon Rekognition 을 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend 
Medical 을 사용하여 추출된 텍스트에서 PHI 를 식별합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85367-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
・Textract 로 텍스트 추출, Comprehend Medical 을 통해 식별 
A(X) : Textract 와 Comprehend Medical 을 사용하는 것이 파이썬 코드를 별도로 관리할 필요가 
없어서 운영하기 편함. 
B(X) : SageMaker 는 기계 학습 모델 서비스. 
Amazon SageMaker 는 완전관리형 인프라, 도구 및 워크플로를 사용하여 모든 사용 사례에 대해 
기계 학습(ML) 모델을 구축, 훈련 및 배포하는 완전관리형 서비스입니다.  
https://aws.amazon.com/ko/sagemaker/faqs/ 
C(O) : Textract 는 OCR 같은 서비스. Comprehend 는 의료용 텍스트 식별 서비스. 
Amazon Textract 는 스캔한 문서에서 텍스트, 필기 및 데이터를 자동으로 추출하는 기계 학습(ML) 
서비스입니다. 단순한 광학 문자 인식(OCR) 이상으로 양식 및 표의 데이터를 식별하고 이해하며 
추출합니다. 
https://aws.amazon.com/ko/textract/ 
Amazon Comprehend Medical 은 HIPAA 적격 자연어 처리(NLP) 서비스로, 미리 학습된 기계 
학습을 사용하여 처방전, 처치, 진단과 같은 의료 텍스트에서 의료 데이터를 파악하고 추출합니다.  
https://aws.amazon.com/ko/comprehend/medical/ 
D(X) : Rekognition 은 이미지나 비디오 분석 서비스지 텍스트 추출 서비스가 아님. 
Amazon Rekognition 은 애플리케이션에 강력한 시각 분석 기능을 쉽게 추가할 수 있게 해 주는 
서비스입니다. Rekognition Image 를 통해 수백만 개의 이미지를 검색, 확인 및 구성할 수 있는 
강력한 애플리케이션을 쉽게 구축할 수 있습니다. Rekognition Video 를 통해 저장된 동영상 또는 
실시간 스트림 동영상에서 동작 기반 컨텍스트를 추출하고 이를 분석할 수 있습니다.  
https://aws.amazon.com/ko/rekognition/faqs/?nc=sn&loc=7 
설명 2: 
대기 시간을 최소화하면서 AWS 와 온프레미스 파일 스토리지 모두에 액세스해야 하는 회사의 요구 
사항을 충족하기 위해 하이브리드 클라우드 아키텍처를 사용할 수 있습니다. 한 가지 솔루션은 
완벽하게 관리되는 Windows 파일 서버를 제공하는 AWS 에서 Windows 파일 서버용 Amazon 
FSx 를 배포 및 구성하는 것입니다. 온프레미스 파일 데이터는 온프레미스와 AWS 파일 스토리지 
간의 브리지 역할을 할 수 있는 FSx 파일 게이트웨이로 이동할 수 있습니다. 클라우드 워크로드는 
AWS 에서 Windows File Server 용 FSx 를 사용하도록 구성할 수 있으며 온프레미스 워크로드는 FSx 
파일 게이트웨이를 사용하도록 구성할 수 있습니다. 이 솔루션은 운영 오버헤드를 최소화하고 기존 
파일 액세스 패턴을 크게 변경할 필요가 없습니다. 온프레미스와 AWS 간의 연결은 AWS 
Site-to-Site VPN 연결을 사용하여 설정할 수 있습니다. 
참조: 
AWS FSx for Windows File Server: https://aws.amazon.com/fsx/windows/ 
AWS FSx File Gateway: https://aws.amazon.com/fsx/file-gateway/ 
AWS Site-to-Site VPN: https://aws.amazon.com/vpn/site-to-site-vpn/ 
Q66 
회사에 각각 크기가 약 5MB 인 많은 수의 파일을 생성하는 응용 프로그램이 있습니다. 파일은 
Amazon S3 에 저장됩니다. 회사 정책에 따라 파일을 삭제하려면 4 년 동안 보관해야 합니다. 
파일에는 재생산하기 쉽지 않은 중요한 비즈니스 데이터가 포함되어 있으므로 즉각적인 액세스가 
항상 필요합니다. 파일은 객체 생성 후 처음 30일 동안 자주 액세스되지만 처음 30일 후에는 거의 
액세스되지 않습니다. 
가장 비용 효율적인 스토리지 솔루션은 무엇입니까? 
A. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 Glacier 로 파일을 이동하는 S3 버킷 수명 주기 
정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 삭제합니다. 
B. 객체 생성 후 30일 동안 S3 Standard에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 
파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 
삭제합니다. 
C. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 
파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 
삭제합니다. 
D. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 
파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 4 년 후 파일을 S3 Glacier 로 
이동합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85310-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A(X) : 즉각적인 액세스가 항상 필요하다고 했기 때문에 S3 Glacier 사용은 적합하지 않음. 
B(X) : 재생산하기 쉽지 않은 중요한 비즈니스 데이터라고 했기 때문에 One Zone-IA 보다는 S3 
Standard-IA 가 더 적합 
C(O) : 30 일 동안은 자주 액세스하므로 S3 Standard, 30 일 이후에는 자주 액세스하진 않지만 
즉각적인 액세스가 필요하므로 S3 Standard-IA, 4 년이 지나면 중요한 비즈니스 데이터므로 함부로 
보관해서는 안됨. 따라서 삭제. 
D(X) : 중요한 비즈니스 데이터라고 했으므로 보관기간인 4 년이 지나고 나서는 함부로 보관해서는 
안되며 삭제해야 함. 
참고: 
https://aws.amazon.com/ko/s3/storage-classes/?trk=66264cd8-3b73-416c-9693-ea7cf4fe846
a&sc_channel=ps&s_kw 
Q67 
회사는 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 애플리케이션은 Amazon 
SQS 대기열의 메시지를 처리하고 Amazon RDS 테이블에 쓰고 대기열에서 메시지를 삭제합니다. 
RDS 테이블에서 가끔 중복 레코드가 발견됩니다. SQS 대기열에는 중복 메시지가 없습니다. 
메시지가 한 번만 처리되도록 솔루션 설계자는 무엇을 해야 합니까? 
A. CreateQueue API 호출을 사용하여 새 대기열을 만듭니다. 
B. AddPermission API 호출을 사용하여 적절한 권한을 추가합니다. 
C. ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다. 
D. ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과를 늘립니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85583-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
가시성 제한 시간은 Amazon SQS 가 메시지를 반환할 때 시작됩니다. 이 시간 동안 소비자는 
메시지를 처리하고 삭제합니다. 그러나 메시지를 삭제하기 전에 소비자가 실패하고 가시성 제한 
시간이 만료되기 전에 시스템에서 해당 메시지에 대한 DeleteMessage 작업을 호출하지 않으면 
메시지가 다른 소비자에게 표시되고 메시지가 다시 수신됩니다. 메시지를 한 번만 수신해야 하는 
경우 소비자는 가시성 제한 시간 내에 메시지를 삭제해야 합니다. 
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-vi
sibility-timeout.html 
키워드: Amazon RDS 에 대한 SQS 대기열 쓰기 여기에서 옵션 D 최상의 기타 옵션 제외[옵션 A - 
기존 대기열에 하나 이상의 대기열을 도입할 수 없습니다. 옵션 B - 권한만 허용; 옵션 C - 
메시지만 검색] FIFO 대기열은 중복 메시지를 도입하지 않도록 설계되었습니다. 그러나 메시지 
생성자는 특정 시나리오에서 중복을 생성할 수 있습니다. 예를 들어 생성자가 메시지를 보내고 
응답을 받지 못한 다음 동일한 메시지를 다시 보내는 경우입니다. Amazon SQS API 는 메시지 
생성자가 중복 전송을 방지하는 중복 제거 기능을 제공합니다. 메시지 생성자에 의해 도입된 모든 
중복 항목은 5 분 중복 제거 간격 내에 제거됩니다. 표준 대기열의 경우 때때로 메시지의 복제본을 
받을 수 있습니다(최소 1 회 전달). 표준 대기열을 사용하는 경우 애플리케이션을 멱등적으로 
설계해야 합니다(즉, 동일한 메시지를 두 번 이상 처리할 때 부정적인 영향을 받지 않아야 함). 
설명 2: 
메시지를 수신한 직후에는 메시지가 대기열에 그대로 있습니다. 다른 소비자가 메시지를 다시 
처리하지 못하게 Amazon SQS 에서는 다른 소비자가 메시지를 수신하고 처리할 수 없도록 막는 
기간인 Visibility timeout 을 설정합니다. 
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-vi
sibility-timeout.html 
Q68 
솔루션 설계자는 회사의 온프레미스 인프라를 AWS 로 확장하기 위해 새로운 하이브리드 
아키텍처를 설계하고 있습니다. 이 회사는 AWS 리전에 대해 일관되게 짧은 지연 시간과 고가용성 
연결이 필요합니다. 회사는 비용을 최소화해야 하며 기본 연결이 실패할 경우 더 느린 트래픽을 
기꺼이 받아들입니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 연결이 
실패하는 경우 백업으로 VPN 연결을 프로비저닝합니다. 
B. 개인 연결을 위해 지역에 VPN 터널 연결을 프로비저닝합니다. 기본 VPN 연결이 실패할 경우 
개인 연결 및 백업으로 두 번째 VPN 터널을 프로비저닝합니다. 
C. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 연결이 
실패하는 경우 백업과 동일한 지역에 두 번째 Direct Connect 연결을 프로비저닝합니다. 
D. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. AWS CLI 에서 Direct Connect 장애 
조치 속성을 사용하여 기본 Direct Connect 연결이 실패할 경우 백업 연결을 자동으로 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85593-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
어떤 경우에는 이 연결만으로는 충분하지 않습니다. 항상 DX 의 백업으로 폴백 연결을 보장하는 
것이 좋습니다. 여러 옵션이 있지만 AWS Site-To-Site VPN 으로 구현하는 것이 비용 효율적입니다. 
비용을 줄이기 위해 활용하거나 그 동안 두 번째 DX 설정을 기다릴 수 있는 솔루션입니다. 
https://blog.besharp.it/hybrid-cloud-networking-backup-aws-direct-connect-network-connecti
on-with-aws-site-to-site-vpn/ 
설명 2: 
VPN 과 Direct Connect 는 같이 사용할 수 있음.  
https://docs.aws.amazon.com/ko_kr/whitepapers/latest/aws-vpc-connectivity-options/aws-dire
ct-connect-vpn.html 
Q69 
회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 비즈니스 크리티컬 웹 
애플리케이션을 실행하고 있습니다. EC2 인스턴스는 Auto Scaling 그룹에 있습니다. 
애플리케이션은 단일 가용 영역에 배포된 Amazon Aurora PostgreSQL 데이터베이스를 사용합니다. 
회사는 다운타임과 데이터 손실을 최소화하면서 애플리케이션의 고가용성을 원합니다. 
최소한의 운영 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EC2 인스턴스를 다른 AWS 리전에 배치합니다. Amazon Route 53 상태 확인을 사용하여 
트래픽을 리디렉션합니다. Aurora PostgreSQL 교차 리전 복제를 사용합니다. 
B. 여러 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스를 다중 AZ 로 
구성합니다. 데이터베이스에 대한 Amazon RDS 프록시 인스턴스를 구성합니다. 
C. 하나의 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스의 시간별 
스냅샷을 생성합니다. 장애가 발생한 경우 스냅샷에서 데이터베이스를 복구합니다. 
D. 여러 AWS 리전을 사용하도록 Auto Scaling 그룹을 구성합니다. 애플리케이션의 데이터를 
Amazon S3 에 씁니다. S3 이벤트 알림을 사용하여 AWS Lambda 함수를 시작하여 데이터베이스에 
데이터를 씁니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85594-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : 다중 AZ 사용이 더 바람직. 게다가 뜬금없이 잘 쓰고 있던 EC2 인스턴스를 다른 AZ 도 
아니고 다른 리전에 배치하는 건 무리수. 
B(O) : 다중 AZ + Auto Scaling 으로 고가용성 확보. 
C(X) : 하나의 가용영역을 사용하므로 고가용성 불충족. 
D(X) : 다중 AZ 가 더 바람직할 뿐더러 굳이 불필요하게 S3 를 거쳐가고 있음. 
설명 2: 
최소한의 가동 중지 시간과 최소한의 데이터 손실로 고가용성을 달성하려면 단일 장애 지점이 
없도록 여러 가용 영역을 사용하도록 Auto Scaling 그룹을 구성해야 합니다. 기본 가용 영역에서 
정전이 발생한 경우 자동 장애 조치를 활성화하려면 데이터베이스를 다중 AZ 로 구성해야 합니다. 
또한 Amazon RDS Proxy 인스턴스를 사용하여 연결 실패를 줄이고 장애 조치 시간을 개선하여 
데이터베이스의 확장성과 가용성을 개선할 수 있습니다. 
Q70 
회사의 HTTP 애플리케이션은 NLB(Network Load Balancer) 뒤에 있습니다. NLB 의 대상 그룹은 웹 
서비스를 실행하는 여러 EC2 인스턴스와 함께 Amazon EC2 Auto Scaling 그룹을 사용하도록 
구성됩니다. 
회사는 NLB 가 애플리케이션에 대한 HTTP 오류를 감지하지 못한다는 것을 알게 되었습니다. 
이러한 오류는 웹 서비스를 실행하는 EC2 인스턴스를 수동으로 다시 시작해야 합니다. 회사는 
사용자 정의 스크립트나 코드를 작성하지 않고 애플리케이션의 가용성을 개선해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. NLB 에서 HTTP 상태 확인을 활성화하고 회사 응용 프로그램의 URL 을 제공합니다. 
B. EC2 인스턴스에 cron 작업을 추가하여 1 분에 한 번씩 로컬 애플리케이션의 로그를 확인합니다. 
HTTP 오류가 감지된 경우. 응용 프로그램이 다시 시작됩니다. 
C. NLB 를 Application Load Balancer 로 교체합니다. 회사 애플리케이션의 URL 을 제공하여 HTTP 
상태 확인을 활성화합니다. 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 구성합니다. 
D. NLB 에 대한 UnhealthyHostCount 지표를 모니터링하는 Amazon Cloud Watch 경보를 
생성합니다. 경보가 ALARM 상태일 때 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 
구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85734-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
이 회사는 NLB 가 응용 프로그램에 대한 HTTP 오류를 감지하지 못한다고 알고 있습니다'라는 
대목에서 응용프로그램에 대한 HTTP 오류를 감지하려면 ALB(Applicaton Load Balancer)가 
필요함을 유추할 수 있음. 
A(X) : 응용프로그램에 대한 HTTP 오류를 감지해야하므로 NLB 는 부적절. 
B(X) : 자동이 아니라 정기적으로 로그를 확인하는 것이므로 오답. 
C(O) : Application Load Balancer 는 등록된 대상으로 요청을 주기적으로 전송하여 상태를 
확인합니다. 이러한 테스트를 바로 상태 확인이라고 합니다....◎HealthCheckProtocol : 대상에 
대한 상태 확인을 수행할 때 로드 밸런서가 사용하는 프로토콜입니다. HTTP, HTTPS 등의 
프로토콜이 여기에 해당됩니다. HTTP 프로토콜이 기본 설정값입니다. ◎HealthCheckPath : 대상에 
대한 상태 확인을 위한 대상입니다. 프로토콜 버전이 HTTP/1.1 또는 HTTP/2 인 경우 유효한 
URI(/path?query)를 참조하세요. 기본값은 /입니다. 프로토콜 버전이 gRPC 인 경우, 사용자 지정 
상태 확인 방법의 경로를 /package.service/method 형식으로 지정합니다. 기본값은 
/AWS.ALB/healthcheck 입니다. 
https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/target-group-health
-checks.html 
D(X) : A 와 같은 이유로 오답. 
설명 2: 
애플리케이션 가용성: NLB는 애플리케이션의 가용성을 보장할 수 없습니다. 이는 네트워크 및 TCP 
계층 변수에만 의존하여 결정을 내리며 애플리케이션을 전혀 인식하지 못하기 때문입니다. 
일반적으로 NLB 는 ICMP ping 에 응답하거나 3 방향 TCP 핸드셰이크를 올바르게 완료하는 서버의 
기능을 기반으로 가용성을 결정합니다. ALB 는 훨씬 더 깊이 들어가 특정 페이지의 성공적인 HTTP 
GET 뿐만 아니라 콘텐츠가 입력 매개변수를 기반으로 예상한 대로라는 확인을 기반으로 가용성을 
결정할 수 있습니다. 
Q71 
한 회사는 Amazon DynamoDB 를 사용하여 고객 정보를 저장하는 쇼핑 애플리케이션을 실행합니다. 
데이터 손상의 경우 솔루션 설계자는 15 분의 RPO(복구 시점 목표)와 1 시간의 RTO(복구 시간 
목표)를 충족하는 솔루션을 설계해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. DynamoDB 전역 테이블을 구성합니다. RPO 복구의 경우 애플리케이션이 다른 AWS 리전을 
가리키도록 합니다. 
B. DynamoDB 지정 시간 복구를 구성합니다. RPO 복구의 경우 원하는 시점으로 복원합니다. 
C. DynamoDB 데이터를 매일 Amazon S3 Glacier 로 내보냅니다. RPO 복구의 경우 S3 Glacier 에서 
DynamoDB 로 데이터를 가져옵니다. 
D. DynamoDB 테이블에 대한 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 15 분마다 
예약합니다. RPO 복구의 경우 EBS 스냅샷을 사용하여 DynamoDB 테이블을 복원합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85603-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・  
A(X) : 리전 장애 발생 시 리디렉션에는 탁월하나 데이터 손상에는 취약함. 글로벌 테이블에서 
새로 작성된 항목은 1 초 이내에 모든 복제본 테이블에 전파되는데, 이는 데이터를 잘못 건드리면 
1 초 이내에 모든 복제본 테이블에 해당 변경 사항이 적용되기 때문. 
전역 테이블에서 새로 작성된 항목은 일반적으로 1 초 이내에 모든 복제본 테이블에 전파됩니다. 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_HowItWo
rks.html 
B(O) : DynamoDB 는 주문형 백업 기능을 제공합니다. 이를 통해 규정 준수 요구 사항에 대한 장기 
보존 및 보관을 위해 테이블의 전체 백업을 생성할 수 있습니다. 주문형 백업을 생성하고 Amazon 
DynamoDB 테이블에 대한 특정 시점 복구를 활성화할 수 있습니다. 지정 시간 복구는 우발적인 
쓰기 또는 삭제 작업으로부터 테이블을 보호하는 데 도움이 됩니다. 특정 시점 복구를 사용하면 
지난 35 일 동안의 특정 시점으로 테이블을 복원할 수 있습니다. 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html 
C(X) : S3 Glacier 는 콜드 스토리지로 액세스 시간이 더 김. 괜히 RTO 만 늘어남. 
D(X) : DynamoDB 는 서버리스라 EBS 스냅샷을 찍을 수 있는지도 의문이고 애초에 PITR(특정 
시점으로 복구)이 더 좋은 옵션임. 
참조 
https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/PointInTimeRecov
ery.html 
Q72 
회사는 동일한 AWS 리전에 있는 Amazon S3 버킷에서 사진을 자주 업로드 및 다운로드해야 하는 
사진 처리 애플리케이션을 실행합니다. 솔루션 설계자는 데이터 전송 비용이 증가한다는 사실을 
알게 되었고 이러한 비용을 줄이기 위한 솔루션을 구현해야 합니다. 
솔루션 설계자는 이 요구 사항을 어떻게 충족할 수 있습니까? 
A. Amazon API Gateway 를 퍼블릭 서브넷에 배포하고 이를 통해 S3 호출을 라우팅하도록 라우팅 
테이블을 조정합니다. 
B. NAT 게이트웨이를 퍼블릭 서브넷에 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드포인트 
정책을 연결합니다. 
C. 애플리케이션을 퍼블릭 서브넷에 배포하고 S3 버킷에 액세스하기 위해 인터넷 게이트웨이를 
통해 라우팅하도록 허용합니다. 
D. S3 VPC 게이트웨이 엔드포인트를 VPC 에 배포하고 S3 버킷에 대한 액세스를 허용하는 
엔드포인트 정책을 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85604-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : VPC-온프레미스 간 통신은 이루어지나 VPC 간 통신은 이루어지지 않고 있음. 
B(X) : A 와 같은 이유로 오답. 
C(X) : A 와 같은 이유로 오답. 
D(O) : Transit Gateway 는 동일한 리전 내에 있는 여러 VPC 들을 연결하는 전송 '허브'이므로 
Transit Gateway 를 거쳐 VPC 끼리 통신이 가능 
AWS Transit Gateway 는 동일한 리전의 VPC 를 상호 연결하여 Amazon VPC 라우팅 구성을 한 
곳에 통합하는 네트워크 전송 허브입니다. 
https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-co
nnect-aws-transit-gateway.html 
설명 2: 
정답은 옵션 D 입니다. S3 VPC 게이트웨이 엔드포인트를 VPC 에 배포하고 S3 버킷에 대한 
액세스를 허용하는 엔드포인트 정책을 연결합니다. S3 VPC 게이트웨이 엔드포인트를 배포하면 
애플리케이션이 VPC 내의 프라이빗 네트워크 연결을 통해 S3 버킷에 액세스할 수 있으므로 
인터넷을 통한 데이터 전송이 필요하지 않습니다. 이를 통해 데이터 전송 비용을 줄이고 
애플리케이션의 성능을 향상시킬 수 있습니다. 엔드포인트 정책을 사용하여 애플리케이션이 
액세스할 수 있는 S3 버킷을 지정할 수 있습니다. 
Q73 
한 회사는 최근 프라이빗 서브넷의 Amazon EC2 에서 Linux 기반 애플리케이션 인스턴스를 
시작하고 VPC 의 퍼블릭 서브넷에 있는 Amazon EC2 인스턴스에서 Linux 기반 배스천 호스트를 
시작했습니다. 솔루션 설계자는 사내 네트워크에서 회사의 인터넷 연결을 통해 배스천 호스트 및 
애플리케이션 서버에 연결해야 합니다. 솔루션 설계자는 모든 EC2 인스턴스의 보안 그룹이 해당 
액세스를 허용하는지 확인해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (2 개를 
선택하세요.) 
A. 배스천 호스트의 현재 보안 그룹을 애플리케이션 인스턴스의 인바운드 액세스만 허용하는 보안 
그룹으로 교체합니다. 
B. 배스천 호스트의 현재 보안 그룹을 회사의 내부 IP 범위에서만 인바운드 액세스를 허용하는 
보안 그룹으로 교체합니다. 
C. 배스천 호스트의 현재 보안 그룹을 회사의 외부 IP 범위에서만 인바운드 액세스를 허용하는 
보안 그룹으로 교체합니다. 
D. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 개인 IP 주소에서만 인바운드 
SSH 액세스를 허용하는 보안 그룹으로 교체합니다. 
E. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 공용 IP 주소에서만 인바운드 SSH 
액세스를 허용하는 보안 그룹으로 교체합니다. 
Answer: C, D 
https://www.examtopics.com/discussions/amazon/view/85613-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
전체적인 프로세스는 사내네트워크 -> 외부 인터넷 -> Bastion Host(퍼블릭서브넷 내에 
NAT 게이트웨이와 함께 위치) -> Application(프라이빗서브넷 내에 위치)으로 이루어짐. 
Bastion Host 는 내부네트워크(여기서는 Application 이 있는 곳)에 접속할 수 있는 유일한 창구로, 
SSH 접속도 여길 통과해야만 가능함. 
일단 Bastion Host에 오는 트래픽(인바운드 트래픽)은 외부 인터넷을 통해서 온 회사의 IP(즉, 외부 
IP)이므로 C 가 정답. 
그 다음으로는 Bastion Host 로부터 Application 으로 오는 트래픽(인바운드 트래픽)을 
허용해야하는데 이미 Bastion Host 에서 안쪽의 내부 네트워크와 통신하려고 프라이빗 IP 를 들고 
온 상태임. 따라서 D 가 정답이며 최종적으로는 C,D 가 정답. 
내부 아이피는 온프레미스 환경 사내 안에서 쓰는 아이피를 보통 뜻하고 인터넷으로 나오는 IP 는 
외부 IP 개념이라 사내 네트워크에서 외부인터넷으로 나온 external ip 범위의 대역에서 인바운드 
액세스만 허용하는 C 가 B 보다 더 적절한 답으로 보임. 
Q74 
솔루션 설계자는 2 계층 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 퍼블릭 서브넷의 
Amazon EC2 에서 호스팅되는 퍼블릭 웹 티어로 구성됩니다. 데이터베이스 계층은 프라이빗 
서브넷의 Amazon EC2 에서 실행되는 Microsoft SQL Server 로 구성됩니다. 보안은 회사의 최우선 
과제입니다. 
이 상황에서 보안 그룹을 어떻게 구성해야 합니까? (2 개를 선택하세요.) 
A. 0.0.0.0/0 에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 
구성합니다. 
B. 0.0.0.0/0 에서 포트 443 의 아웃바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 
구성합니다. 
C. 웹 계층에 대한 보안 그룹에서 포트 1433 의 인바운드 트래픽을 허용하도록 데이터베이스 
계층에 대한 보안 그룹을 구성합니다. 
D. 데이터베이스 계층의 보안 그룹을 구성하여 포트 443 및 1433 의 아웃바운드 트래픽을 웹 
계층의 보안 그룹으로 보냅니다. 
E. 웹 계층에 대한 보안 그룹의 포트 443 및 1433 에서 인바운드 트래픽을 허용하도록 
데이터베이스 계층에 대한 보안 그룹을 구성합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/85346-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
전체적인 구조는 EC2 인스턴스에서 실행되는 웹 애플리케이션(퍼블릭 서브넷 내에 
위치)---->EC2 인스턴스에서 실행되는 데이터베이스(프라이빗 서브넷 내에 위치)으로 되어있고, 
인스턴스 단위의 보안은 보안 그룹이 담당. 
보안 그룹은 기본적으로 인바운드 트래픽에 관해서는 허용만 지정할 수 있고, 허용하지 않은 건 
기본적으로 모두 차단하기 때문에 외부 인터넷->웹 애플리케이션으로의 액세스를 허용하려면 
0.0.0.0/0 으로부터 온 포트 443(HTTPS)를 허용해야 함. 
그 다음으로 웹 애플리케이션->데이터베이스로의 액세스를 허용하려면 웹 애플리케이션이 있는 웹 
계층에서 오는 포트 1433(MySQL) 인바운드 트래픽을 허용하도록 보안 그룹 설정을 해야 함. 
따라서 정답은 A,C. 
설명 2: 
"보안 그룹은 모든 인바운드 규칙에 대한 아웃바운드 규칙을 생성합니다." 완전히 옳지 않습니다. 
Statefull 은 인바운드(또는 아웃바운드) 규칙을 생성하는 경우 아웃바운드(또는 인바운드) 규칙을 
생성한다는 의미가 아닙니다. 이것이 의미하는 바는 다음과 같습니다. X IP 에 대한 포트 443 에서 
인바운드 규칙을 생성한다고 가정합니다. 요청이 X ip 에서 포트 443 으로 들어오면 포트 443 에서 
해당 요청에 대한 트래픽 아웃을 허용합니다. 
그러나 아웃바운드 규칙을 보면 명시적으로 생성하지 않는 한 포트 443 에 대한 아웃바운드 규칙이 
없을 것입니다. 상태 비저장 ACL 에서는 들어오는 요청을 허용하는 인바운드 규칙과 
애플리케이션이 이러한 들어오는 요청에 응답할 수 있도록 하는 아웃바운드 규칙을 만들어야 
합니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGro
upRules 
Q75 
한 회사에서 애플리케이션의 성능을 개선하기 위해 다계층 애플리케이션을 온프레미스에서 AWS 
클라우드로 이동하려고 합니다. 애플리케이션은 RESTful 서비스를 통해 서로 통신하는 
애플리케이션 계층으로 구성됩니다. 한 계층이 오버로드되면 트랜잭션이 삭제됩니다. 솔루션 
설계자는 이러한 문제를 해결하고 애플리케이션을 현대화하는 솔루션을 설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? 
A. Amazon API Gateway 를 사용하고 애플리케이션 계층으로 AWS Lambda 함수에 트랜잭션을 
전달합니다. Amazon Simple Queue Service(Amazon SQS)를 애플리케이션 서비스 간의 통신 
계층으로 사용합니다. 
B. Amazon CloudWatch 지표를 사용하여 애플리케이션 성능 기록을 분석하여 성능 장애 동안 
서버의 최대 사용률을 결정합니다. 최대 요구 사항을 충족하도록 애플리케이션 서버의 Amazon 
EC2 인스턴스 크기를 늘립니다. 
C. Amazon Simple Notification Service(Amazon SNS)를 사용하여 Auto Scaling 그룹의 Amazon 
EC2에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch를 사용하여 
SNS 대기열 길이를 모니터링하고 필요에 따라 확장 및 축소합니다. 
D. Amazon Simple Queue Service(Amazon SQS)를 사용하여 Auto Scaling 그룹의 Amazon 
EC2에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch를 사용하여 
SQS 대기열 길이를 모니터링하고 통신 오류가 감지되면 확장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/86120-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
AWS Lambda, Amazon API Gateway, AWS Amplify, Amazon DynamoDB 및 Amazon Cognito 를 
사용하여 서버리스 웹 애플리케이션을 구축하십시오. 이 예에서는 AWS Lambda, Amazon API 
Gateway, AWS Amplify, Amazon DynamoDB 및 Amazon Cognito 를 사용하여 서버리스 웹 
애플리케이션 구축 질문과 유사한 설정을 보여줍니다. 
RESTful API = API Gateway 사용. 
트랜잭션 삭제되는 문제 = SQS. 
Q76 
회사는 단일 공장에 있는 여러 기계에서 매일 10TB 의 계측 데이터를 수신합니다. 데이터는 공장 
내에 위치한 온프레미스 데이터 센터의 SAN(Storage Area Network)에 저장된 JSON 파일로 
구성됩니다. 회사는 이 데이터를 Amazon S3 로 전송하여 중요한 실시간에 가까운 분석을 제공하는 
여러 추가 시스템에서 액세스할 수 있기를 원합니다. 데이터가 민감한 것으로 간주되기 때문에 
안전한 전송이 중요합니다. 
가장 안정적인 데이터 전송을 제공하는 솔루션은 무엇입니까? 
A. 공용 인터넷을 통한 AWS DataSync 
B. AWS Direct Connect 를 통한 AWS DataSync 
C. 공용 인터넷을 통한 AWS Database Migration Service(AWS DMS) 
D. AWS Direct Connect 를 통한 AWS Database Migration Service(AWS DMS) 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85801-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : 퍼블릭 인터넷으로 전송하면 노출 위험이 큼. 심지어는 VPN 도 안 했음. 
B(O) : Direct Connect 는 전용선 연결로 온프레미스-AWS 간 통신하는 것이고, DataSync 는 데이터 
전송/마이그레이션에 사용되는 서비스. 
AWS DataSync 는 온프레미스와 AWS 스토리지 서비스 사이에서 데이터 이동을 자동화 및 
가속화하는 안전한 온라인 서비스입니다. Amazon Simple Storage Service(S3) 버킷 간에 데이터를 
복사할 수 있습니다. https://aws.amazon.com/ko/datasync/ 
C(X) : A 와 마찬가지 이유로 오답. 
D(X) : DMS 는 데이터베이스 마이그레이션 서비스로 S3 로 데이터를 전송해야하는 지문 상황과는 
맞지 않음. 
설명 2: 
다음은 AWS DataSync 의 주요 사용 사례 중 일부입니다. * 데이터 마이그레이션 - 활성 데이터 
세트를 네트워크를 통해 Amazon S3, Amazon EFS 또는 FSx for Windows File Server 로 빠르게 
이동합니다. DataSync 에는 자동 암호화 및 데이터 무결성 검증이 포함되어 데이터가 안전하고 
온전하며 사용할 준비가 되었는지 확인하는 데 도움이 됩니다. 
"DataSync 에는 암호화 및 무결성 검증이 포함되어 있어 데이터가 안전하고 온전하며 사용할 
준비가 되었는지 확인하는 데 도움이 됩니다." 
https://aws.amazon.com/datasync/faqs/ 
Q77 
회사는 애플리케이션에 대한 실시간 데이터 수집 아키텍처를 구성해야 합니다. 회사에는 데이터가 
스트리밍될 때 데이터를 변환하는 프로세스인 API 와 데이터를 위한 스토리지 솔루션이 
필요합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon EC2 인스턴스를 배포하여 Amazon Kinesis 데이터 스트림으로 데이터를 전송하는 
API 를 호스팅합니다. Kinesis 데이터 스트림을 데이터 원본으로 사용하는 Amazon Kinesis Data 
Firehose 전송 스트림을 생성합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. Kinesis 
Data Firehose 전송 스트림을 사용하여 데이터를 Amazon S3 로 보냅니다. 
B. Amazon EC2 인스턴스를 배포하여 AWS Glue 에 데이터를 전송하는 API 를 호스팅합니다. EC2 
인스턴스에서 소스/대상 확인을 중지합니다. AWS Glue 를 사용하여 데이터를 변환하고 데이터를 
Amazon S3 로 보냅니다. 
C. Amazon Kinesis 데이터 스트림으로 데이터를 보내도록 Amazon API Gateway API 를 구성합니다. 
Kinesis 데이터 스트림을 데이터 원본으로 사용하는 Amazon Kinesis Data Firehose 전송 스트림을 
생성합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. Kinesis Data Firehose 전송 
스트림을 사용하여 데이터를 Amazon S3 로 보냅니다. 
D. 데이터를 AWS Glue 로 보내도록 Amazon API Gateway API 를 구성합니다. AWS Lambda 함수를 
사용하여 데이터를 변환합니다. AWS Glue 를 사용하여 데이터를 Amazon S3 로 보냅니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85740-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
실시간 데이터 수집 = Kinesis Data Streams. A,C 둘 중 하나가 답. 
A(X) : API 는 API Gateway 를 사용하여 전송. 
Amazon API Gateway 는 어떤 규모에서든 개발자가 API 를 손쉽게 생성, 게시, 유지 관리, 모니터링 
및 보안 유지할 수 있도록 하는 완전관리형 서비스입니다. API 는 애플리케이션이 백엔드 서비스의 
데이터, 비즈니스 로직 또는 기능에 액세스할 수 있는 "정문" 역할을 합니다. 
https://aws.amazon.com/ko/api-gateway/ 
C(O) :  
・API Gateway API 를 Kinesis Data Streams 와 같이 사용 가능 
API Gateway API 를 Kinesis 와 통합하려면 API Gateway 와 Kinesis 서비스를 모두 사용할 수 있는 
리전을 선택해야 합니다. 
https://docs.aws.amazon.com/apigateway/latest/developerguide/integrating-api-with-aws-servi
ces-kinesis.html 
・Kinesis Data Streams 로 데이터 수집. 
Amazon Kinesis Data Streams 를 사용하면 특수 요구에 맞춰 스트리밍 데이터를 처리 또는 
분석하는 사용자 지정 애플리케이션을 구축할 수 있습니다. 수십 만개의 소스에서 클릭 스트림, 
애플리케이션 로그, 소셜 미디어와 같은 다양한 유형의 데이터를 Kinesis 데이터 스트림에 추가할 
수 있습니다. 
https://aws.amazon.com/ko/kinesis/data-streams/faqs/ 
・Kinesis Data Streams -> Kinesis Data Firehose 
Amazon Kinesis Data Firehose 전송 스트림에 정보를 전송하도록 Amazon Kinesis Data Streams 를 
구성할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/writing-with-kinesis-streams.html 
・Lambda 로 데이터 변환 
Kinesis Data Firehose Firehose 는 Lambda 함수를 호출하여 수신되는 소스 데이터를 변환하고 
변환된 데이터를 대상으로 전송할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/data-transformation.html 
・S3 로 전송 
Amazon Kinesis Data Firehose 는 실시간 스트리밍 데이터를 Amazon S3, Amazon RedShift, 
Amazon OpenSearch Service, Splunk 및 사용자 지정 HTTP 엔드포인트 또는 Datadog, Dynatrace, 
LogicMonitor, MongoDB, New Relic, Sumo Logic 을 포함한 지원되는 서드파티 소유의 HTTP 
엔드포인트 대상에 전달하기 위한 완전관리형 서비스입니다. 
https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html 
Q78 
회사는 사용자 트랜잭션 데이터를 Amazon DynamoDB 테이블에 보관해야 합니다. 회사는 
데이터를 7 년간 보관해야 합니다. 
이러한 요구 사항을 충족하는 가장 운영 효율성이 높은 솔루션은 무엇입니까? 
A. DynamoDB 지정 시간 복구를 사용하여 테이블을 지속적으로 백업합니다. 
B. AWS Backup 을 사용하여 테이블에 대한 백업 일정 및 보존 정책을 생성합니다. 
C. DynamoDB 콘솔을 사용하여 테이블의 주문형 백업을 생성합니다. 백업을 Amazon S3 버킷에 
저장합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다. 
D. AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 
생성합니다. 테이블을 백업하고 Amazon S3 버킷에 백업을 저장하도록 Lambda 함수를 구성합니다. 
S3 버킷에 대한 S3 수명 주기 구성을 설정합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/85742-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A(X) : 35 일 제한이 있습니다. ""특정 시점으로 복구가 설정되어 있으면 최근 35 일 중 원하는 
시점으로 테이블을 복원할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/PointInTimeRecov
ery.html 
B(O) : 한 곳에서 백업 현황 모니터링 및 콜드 스토리지에 저장, 예약 저장 가능합니다. AWS 
Backup 을 사용하면 백업 정책을 구성하고 AWS 리소스 및 온프레미스 워크로드에 대한 활동을 한 
곳에서 모니터링할 수 있습니다. AWS Backup 과 함께 DynamoDB 를 사용하면 AWS 계정 및 
리전에서 온디맨드 백업을 복사하고, 온디맨드 백업에 비용 할당 태그를 추가하고, 온디맨드 
백업을 콜드 스토리지로 전환하여 비용을 절감할 수 있습니다. 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/BackupRestore.html 
AWS Backup 을 사용하여 DynamoDB 온디맨드 백업을 자동으로 예약, 복사, 태그 지정 및 수명 
주기를 수행할 수 있습니다. DynamoDB 콘솔에서 이러한 백업을 계속 보고 복원할 수 있습니다. 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/backuprestore_HowItWo
rksAWS.html 
C(X) : 불가능한 건 아닌데, B 가 더 유리합니다. 운영 측면에서는 한 곳에서 모니터링하는 게 
편하고, S3 버킷에 저장한다고 했는데 7 년 동안 보관할 거면 S3 콜드 스토리지에 보관하는 게 
비용이 더 저렴합니다. 
D(X) : 너무 단계가 많습니다. 아마존에서는 DynamoDB 테이블 백업에 AWS Backup 또는 
DynamoDB 콘솔을 사용할 것을 언급하고 있습니다. ""DynamoDB 온디맨드 백업을 생성하고 
관리하는 데 사용할 수 있는 두 가지 옵션이 있습니다. AWS 백업 서비스 다이나모 DB 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/BackupRestore.html 
Q79 
회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 비용 
최적화에 대해 우려하고 있습니다. 대부분의 아침에는 테이블을 사용하지 않습니다. 저녁에는 읽기 
및 쓰기 트래픽이 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 
발생합니다. 
솔루션 아키텍트는 무엇을 추천해야 합니까? 
A. 온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다. 
B. 글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다. 
C. 프로비저닝된 용량 및 Auto Scaling 을 사용하여 DynamoDB 테이블을 생성합니다. 
D. 프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 전역 테이블로 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85743-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
사용량 예측이 안 되므로 프로비저닝은 무의미. 따라서 C,D 는 제외되고 A,B 둘 중 하나가 정답. 
A(O) : 온디맨드 모드를 사용하는 테이블의 경우 DynamoDB 는 이전에 관찰된 트래픽 수준까지 
상승하거나 하락할 때 고객의 워크로드를 즉시 수용할 수 있습니다. 트래픽 수준이 새로운 고점에 
도달하면 DynamoDB 는 신속하게 대응하여 워크로드를 수용합니다. 
https://aws.amazon.com/ko/blogs/korea/amazon-dynamodb-on-demand-no-capacity-plannin
g-and-pay-per-request-pricing/ 
B(X) : 고가용성 언급이 없고 비용 최적화를 언급하고 있으므로 B 보다는 A 가 적합. 
Q80 
한 회사는 최근 애플리케이션 마이그레이션 이니셔티브에 대한 지원을 위해 AWS 관리형 서비스 
공급자(MSP) 파트너와 계약을 체결했습니다. 솔루션 설계자는 기존 AWS 계정의 Amazon 머신 
이미지(AMI)를 MSP 파트너의 AWS 계정과 공유해야 합니다. AMI 는 Amazon Elastic Block 
Store(Amazon EBS)의 지원을 받으며 AWS Key Management Service(AWS KMS) 고객 관리형 키를 
사용하여 EBS 볼륨 스냅샷을 암호화합니다. 
솔루션 설계자가 MSP 파트너의 AWS 계정과 AMI 를 공유하는 가장 안전한 방법은 무엇입니까? 
A. 암호화된 AMI 및 스냅샷을 공개적으로 사용할 수 있도록 합니다. MSP 파트너의 AWS 계정이 
키를 사용할 수 있도록 키 정책을 수정합니다. 
B. AMI 의 launchPermission 속성을 수정합니다. MSP 파트너의 AWS 계정과만 AMI 를 
공유하십시오. MSP 파트너의 AWS 계정이 키를 사용할 수 있도록 키 정책을 수정합니다. 
C. AMI 의 launchPermission 속성을 수정합니다. MSP 파트너의 AWS 계정과만 AMI 를 
공유하십시오. 암호화를 위해 MSP 파트너가 소유한 새 KMS 키를 신뢰하도록 키 정책을 
수정합니다. 
D. 원본 계정에서 MSP 파트너의 AWS 계정에 있는 Amazon S3 버킷으로 AMI 를 내보내고 MSP 
파트너가 소유한 새 KMS 키로 S3 버킷을 암호화합니다. MSP 파트너의 AWS 계정에서 AMI 를 
복사하고 시작합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85606-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : '공개적'이라는 키워드가 애초에 보안과는 거리가 멈. 
B(O) : 기존 KMS 키는 스냅샷을 암호화하는 데 사용되었기 때문에 MSP 파트너와 공유해도 
괜찮음. 
C(X) : 파트너의 KMS 키를 신뢰하면 파트너가 해당 키를 가지고 악의적인 용도로 사용할 때 
문제가 됨. 
D(X) : 파트너와 공유해야 하는데 파트너가 S3 버킷을 암호화하도록 냅둬버리면 파트너가 공유받는 
입장이 아니라 내가 공유받는 입장이 되어버리는 역전현상이 벌어짐. 
설명 2: 
AMI 스냅샷을 암호화하는 데 이미 사용되었기 때문에 기존 KMS 키를 MSP 외부 계정과 
공유합니다. 
https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/key-policy-modifying-external-
accounts.html 
Q81 
솔루션 설계자는 AWS 에 배포되는 새 애플리케이션을 위한 클라우드 아키텍처를 설계하고 
있습니다. 처리할 작업 수에 따라 필요에 따라 애플리케이션 노드를 추가 및 제거하면서 
프로세스가 병렬로 실행되어야 합니다. 프로세서 응용 프로그램은 상태 비저장입니다. 솔루션 
설계자는 응용 프로그램이 느슨하게 연결되어 있고 작업 항목이 영구적으로 저장되어 있는지 
확인해야 합니다. 
솔루션 설계자는 어떤 디자인을 사용해야 합니까? 
A. 처리해야 하는 작업을 보낼 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 
구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 구성을 생성합니다. 시작 
구성을 사용하여 Auto Scaling 그룹을 생성합니다. CPU 사용량에 따라 노드를 추가 및 제거하도록 
Auto Scaling 그룹에 대한 조정 정책을 설정합니다. 
B. 처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. 프로세서 애플리케이션으로 
구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 구성을 생성합니다. 시작 
구성을 사용하여 Auto Scaling 그룹을 생성합니다. Auto Scaling 그룹의 조정 정책을 설정하여 
네트워크 사용량에 따라 노드를 추가 및 제거합니다. 
C. 처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. 프로세서 애플리케이션으로 
구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 템플릿을 생성합니다. 시작 
템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SQS 대기열의 항목 수에 따라 노드를 추가 
및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다. 
D. 처리해야 하는 작업을 보낼 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 
구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 템플릿을 생성합니다. 시작 
템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SNS 주제에 게시된 메시지 수에 따라 노드를 
추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/86621-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
"처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. 
컴퓨팅 애플리케이션에 대한 Amazon EC2 Auto Scaling 그룹을 생성합니다. SQS 대기열의 항목 
수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다. 
Amazon SQS 는 이 사용 사례에 이상적이며 대기열에서 대기 중인 작업 수에 따라 동적 조정을 
사용하도록 구성할 수 있습니다. 이 조정을 구성하려면 유지 관리할 인스턴스당 허용되는 백로그인 
대상 값과 함께 인스턴스당 백로그 메트릭을 사용할 수 있습니다. 
이러한 수치는 다음과 같이 계산할 수 있습니다.  
인스턴스당 백로그: 
인스턴스당 백로그를 계산하려면 ApproximateNumberOfMessages 대기열 속성으로 시작하여 SQS 
대기열의 길이를 결정합니다. 
Q82 
회사는 AWS 클라우드에서 웹 애플리케이션을 호스팅합니다. 회사는 AWS Certificate 
Manager(ACM)로 가져온 인증서를 사용하도록 Elastic Load Balancer 를 구성합니다. 각 인증서가 
만료되기 30 일 전에 회사 보안팀에 알려야 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 권장해야 합니까? 
A. ACM 에 규칙을 추가하여 인증서가 만료되기 30 일 전부터 매일 Amazon Simple Notification 
Service(Amazon SNS) 주제에 사용자 지정 메시지를 게시합니다. 
B. 30 일 이내에 만료되는 인증서를 확인하는 AWS Config 규칙을 생성합니다. AWS Config 가 
비준수 리소스를 보고할 때 Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 
알림을 호출하도록 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 
C. AWS Trusted Advisor 를 사용하여 30 일 이내에 만료되는 인증서를 확인합니다. 상태 변경 
확인에 대한 Trusted Advisor 지표를 기반으로 하는 Amazon CloudWatch 경보를 생성합니다. 
Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 보내도록 경보를 
구성합니다. 
D. 30 일 이내에 만료되는 모든 인증서를 감지하는 Amazon EventBridge(Amazon CloudWatch 
Events) 규칙을 생성합니다. AWS Lambda 함수를 호출하도록 규칙을 구성합니다. Amazon Simple 
Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 보내도록 Lambda 함수를 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85615-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
D?? 
설명: 
A(X) : 30 일 전에 통보하랬지 맨날 통보하란 이야기는 없었음. 
B(O) : AWS Config 를 사용하여 만료 날짜가 가까워지는 인증서를 확인할 수 있습니다. 인증서 
만료 날짜가 가까워지면 Amazon EventBridge 를 사용하여 이메일 알림을 받을 수도 있습니다. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/acm-certificate-expiration/ 
C(X) : Trusted Advisor 는 ""AWS 환경을 검사한 후 비용 절감, 시스템 가용성 및 성능 향상 또는 
보안 격차를 해결할 기회가 있을 때 권장 사항을 제시 
https://docs.aws.amazon.com/ko_kr/awssupport/latest/user/trusted-advisor.html  
하는 서비스로 이 경우엔 해당 사항이 없음. 
D(X) : EventBridge 는 이벤트 발생을 감지해서 뭔가를 하는 서비스이지 이벤트 발생 전에 뭔가 
감지해서 하는 게 아님 
참고 
https://repost.aws/ko/knowledge-center/acm-certificate-expiration 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/acm-certificate-expiration/ 
Q83 
회사의 동적 웹 사이트는 미국의 온프레미스 서버를 사용하여 호스팅됩니다. 이 회사는 유럽에서 
제품을 출시하고 있으며 새로운 유럽 사용자를 위해 사이트 로딩 시간을 최적화하려고 합니다. 
사이트의 백엔드는 미국에 있어야 합니다. 제품이 며칠 안에 출시되며 즉각적인 솔루션이 
필요합니다. 
솔루션 설계자는 무엇을 권장해야 합니까? 
A. us-east-1 에서 Amazon EC2 인스턴스를 시작하고 사이트를 마이그레이션합니다. 
B. 웹사이트를 Amazon S3 로 이동합니다. 지역 간 교차 지역 복제를 사용합니다. 
C. 온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront 를 사용합니다. 
D. 온프레미스 서버를 가리키는 Amazon Route 53 지리 근접 라우팅 정책을 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85902-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
https://aws.amazon.com/pt/blogs/aws/amazon-cloudfront-support-for-custom-origins/ 
이제 사용자 지정 오리진을 사용하여 CloudFront 배포를 생성할 수 있습니다. 각 배포는 S3 또는 
사용자 지정 오리진을 가리킬 수 있습니다. 이것은 다른 스토리지 서비스일 수도 있고 EC2 
인스턴스 또는 Elastic Load Balancer 와 같이 더 흥미롭고 동적인 것일 수도 있습니다. 
설명 2: 
A(X) : 유럽과 가까워야 하므로 us-east-1 은 오답. 
B(X) : 동적 웹 사이트라고 했으므로 S3 가 들어가지 않음. 
C(O) : CloudFront 는 사용자 지정 오리진으로 온프레미스 서버를 가리킬 수 있음. 
사용자 지정 출처는 웹 서버와 같은 HTTP 서버입니다. HTTP 서버는 Amazon EC2 인스턴스이거나 
다른 곳에서 호스팅하는 HTTP 서버일 수 있습니다. 웹 사이트 엔드포인트로 구성된 Amazon S3 
오리진도 사용자 지정 오리진으로 간주됩니다.자체 HTTP 서버를 사용자 지정 오리진으로 사용하는 
경우 오리진에서 객체를 가져올 때 CloudFront 에서 사용할 HTTP 및 HTTPS 포트 및 프로토콜과 
함께 서버의 DNS 이름을 지정합니다. 
https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCu
stomOrigins.html#concept_CustomOrigin 
D(X) : 웹 사이트엔 CDN 서비스인 CloudFront 가 필요. 
Q84 
회사는 기존 3 계층 웹 아키텍처의 비용을 절감하려고 합니다. 웹, 애플리케이션 및 데이터베이스 
서버는 개발, 테스트 및 프로덕션 환경을 위한 Amazon EC2 인스턴스에서 실행됩니다. EC2 
인스턴스의 평균 CPU 사용률은 사용량이 많은 시간에는 30%이고 사용량이 많지 않은 시간에는 
10%입니다. 
프로덕션 EC2 인스턴스는 하루 24 시간 실행됩니다. 개발 및 테스트 EC2 인스턴스는 매일 최소 
8 시간 동안 실행됩니다. 회사는 개발을 중지하고 사용하지 않을 때 EC2 인스턴스를 테스트하는 
자동화를 구현할 계획입니다. 
어떤 EC2 인스턴스 구매 솔루션이 가장 비용 효율적으로 회사의 요구 사항을 충족합니까? 
A. 프로덕션 EC2 인스턴스에 스팟 인스턴스를 사용합니다. EC2 인스턴스 개발 및 테스트에 예약 
인스턴스를 사용합니다. 
B. 프로덕션 EC2 인스턴스에 예약 인스턴스를 사용합니다. 개발 및 테스트 EC2 인스턴스에 
온디맨드 인스턴스를 사용합니다. 
C. 프로덕션 EC2 인스턴스에 스팟 블록을 사용합니다. EC2 인스턴스 개발 및 테스트에 예약 
인스턴스를 사용합니다. 
D. 프로덕션 EC2 인스턴스에 온디맨드 인스턴스를 사용합니다. 개발 및 테스트 EC2 인스턴스에 
스팟 블록을 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85665-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
A(X) : 하루 24 시간 실행하는 프로덕션 EC2 인스턴스에 스팟 인스턴스는 적절치 않음. 스팟 
인스턴스는 도중에 중지될 가능성이 높은 인스턴스에 더 적합. 
B(O) : 1 년 또는 3 년 단위로 예약 인스턴스를 계약해서 사용하면 비용이 절감됨. 개발 및 테스트용 
EC2 인스턴스는 매일 최소 8 시간 이상 실행된다고 했으므로 그 이상 사용될 수 있어 Scheduled 
Reserved 인스턴스보다는 온디맨드 인스턴스를 사용하는 것이 더 적절함 
C(X) : 스팟 블록은 기간이 정의된 스팟 인스턴스로 A 와 같은 이유로 오답. 
""기간이 정의된 스팟 인스턴스(스팟 블록이라고도 함)는 2021 년 7 월 1 일부로 신규 고객이 더 
이상 사용할 수 없습니다. 
https://aws.amazon.com/ko/blogs/aws/new-ec2-spot-blocks-for-defined-duration-workloads/ 
D(X) : 24 시간 동안 사용할 EC2 인스턴스에는 예약 인스턴스 방식을 사용해 비용을 더 절감할 수 
있음. 
Q85 
회사에 사용자가 웹 인터페이스 또는 모바일 앱을 통해 문서를 업로드하는 프로덕션 웹 
애플리케이션이 있습니다. 새로운 규제 요구 사항에 따라. 새 문서는 저장 후에 수정하거나 삭제할 
수 없습니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 업로드된 문서를 S3 버전 관리 및 S3 객체 잠금이 활성화된 Amazon S3 버킷에 저장합니다. 
B. 업로드된 문서를 Amazon S3 버킷에 저장합니다. 문서를 주기적으로 보관하도록 S3 수명 주기 
정책을 구성합니다. 
C. 업로드된 문서를 S3 버전 관리가 활성화된 Amazon S3 버킷에 저장합니다. 모든 액세스를 읽기 
전용으로 제한하도록 ACL 을 구성합니다. 
D. 업로드된 문서를 Amazon Elastic File System(Amazon EFS) 볼륨에 저장합니다. 읽기 전용 
모드에서 볼륨을 마운트하여 데이터에 액세스합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85751-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
수정하거나 삭제할 수 없음 = S3 Object Lock. 
S3 객체 잠금을 사용하면 write-once-read-many(WORM) 모델을 사용하여 객체를 저장할 수 
있습니다. 객체 잠금은 고정된 시간 동안 또는 무기한으로 객체의 삭제 또는 덮어쓰기를 방지하는 
데 도움이 될 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lock.html 
Q86 
회사에는 공통 Amazon RDS MySQL 다중 AZ DB 인스턴스에 자주 액세스해야 하는 여러 웹 
서버가 있습니다. 회사는 사용자 자격 증명을 자주 교체해야 하는 보안 요구 사항을 충족하면서 웹 
서버가 데이터베이스에 연결할 수 있는 안전한 방법을 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Secrets Manager 에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 AWS Secrets 
Manager 에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다. 
B. AWS Systems Manager OpsCenter 에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 
OpsCenter 에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다. 
C. 안전한 Amazon S3 버킷에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 자격 
증명을 검색하고 데이터베이스에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다. 
D. 웹 서버 파일 시스템의 AWS Key Management Service(AWS KMS)로 암호화된 파일에 
데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버는 파일을 해독하고 데이터베이스에 
액세스할 수 있어야 합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85753-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
AWS Secrets Manager 는 애플리케이션, 서비스 및 IT 리소스에 액세스하는 데 필요한 암호를 
보호하는 데 도움이 됩니다. 이 서비스를 사용하면 수명 주기 동안 데이터베이스 자격 증명, API 
키 및 기타 암호를 쉽게 교체, 관리 및 검색할 수 있습니다. 
https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html 
Secrets Manager 를 사용하면 암호를 포함하여 코드의 하드코딩된 자격 증명을 Secrets Manager 에 
대한 API 호출로 대체하여 프로그래밍 방식으로 암호를 검색할 수 있습니다. 이렇게 하면 비밀이 
코드에 더 이상 존재하지 않기 때문에 코드를 검사하는 누군가가 비밀을 손상시킬 수 없습니다. 
또한 지정된 일정에 따라 암호를 자동으로 교체하도록 Secrets Manager 를 구성할 수 있습니다. 
이를 통해 장기 비밀을 단기 비밀로 대체하여 손상 위험을 크게 줄일 수 있습니다. 
설명 2: 
사용자 자격 증명을 자주 바꿈 + 안전한 방법 = Secrets Manager. 
Secrets Manager 를 사용하면 애플리케이션 소스 코드에서 하드 코딩된 자격 증명을 제거하고 
애플리케이션 자체에 자격 증명을 저장하지 않음으로써 보안 태세를 개선할 수 있습니다. 사용자의 
개입 없이 지정한 일정에 따라 자동으로 보안 암호를 교체하도록 Secrets Manager 를 구성할 수 
있습니다. 교체는 AWS Lambda 함수를 사용하여 정하고 실행합니다. 
https://docs.aws.amazon.com/ko_kr/secretsmanager/latest/userguide/intro.html 
또한 여러 리전과 여러 AZ 에 걸쳐 작동.  
https://docs.aws.amazon.com/ko_kr/secretsmanager/latest/userguide/disaster-recovery-resilien
cy.html 
Q87 
회사는 Amazon API Gateway API 에 의해 호출되는 AWS Lambda 함수에서 애플리케이션을 
호스팅합니다. Lambda 함수는 고객 데이터를 Amazon Aurora MySQL 데이터베이스에 저장합니다. 
회사에서 데이터베이스를 업그레이드할 때마다 Lambda 함수는 업그레이드가 완료될 때까지 
데이터베이스 연결을 설정하지 못합니다. 그 결과 일부 이벤트에 대한 고객 데이터가 기록되지 
않습니다. 
솔루션 설계자는 데이터베이스 업그레이드 중에 생성되는 고객 데이터를 저장하는 솔루션을 
설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Lambda 함수와 데이터베이스 사이에 위치하도록 Amazon RDS 프록시를 프로비저닝합니다. 
RDS 프록시에 연결하도록 Lambda 함수를 구성합니다. 
B. Lambda 함수의 실행 시간을 최대로 늘립니다. 데이터베이스에 고객 데이터를 저장하는 
코드에서 재시도 메커니즘을 만듭니다. 
C. 고객 데이터를 Lambda 로컬 스토리지에 유지합니다. 고객 데이터를 데이터베이스에 저장하기 
위해 로컬 스토리지를 스캔하도록 새로운 Lambda 함수를 구성합니다. 
D. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 고객 데이터를 저장합니다. 
대기열을 폴링하고 고객 데이터를 데이터베이스에 저장하는 새 Lambda 함수를 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85319-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
잠시 고객 데이터를 저장하는 솔루션 = SQS. 손실될 위험이 있는 처리 대상 데이터를 잠시 
보관하는 용도로는 SQS 가 주로 쓰인다고 보면 됨. 답은 D. 
설명 2: 
https://www.learnaws.org/2020/12/13/aws-rds-proxy-deep-dive/ 
RDS 프록시는 새 데이터베이스 인스턴스가 작동할 때까지 대기하고 이 시간 동안 
애플리케이션에서 받은 모든 요청을 유지함으로써 이러한 상황에서 애플리케이션 가용성을 
향상시킬 수 있습니다. 최종 결과는 응용 프로그램이 기본 데이터베이스의 문제에 대해 더 
탄력적이라는 것입니다. 이렇게 하면 DB 가 정상으로 돌아올 때까지 솔루션이 데이터를 보유할 수 
있습니다. RDS 프록시는 Lambda 와 DB 간의 연결을 최적으로 활용하기 위한 것입니다. Lambda 는 
DB 컴퓨팅 리소스에 부담을 줄 수 있는 여러 연결을 동시에 열 수 있습니다. 
Q88 
설문 조사 회사는 미국 지역에서 수년 동안 데이터를 수집했습니다. 이 회사는 크기가 3TB 이고 
계속 증가하는 Amazon S3 버킷에 데이터를 호스팅합니다. 이 회사는 S3 버킷이 있는 유럽 마케팅 
회사와 데이터를 공유하기 시작했습니다. 회사는 데이터 전송 비용이 가능한 한 낮게 유지되기를 
원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 회사의 S3 버킷에서 요청자 지불 기능을 구성합니다. 
B. 회사의 S3 버킷에서 마케팅 회사의 S3 버킷 중 하나로 S3 교차 리전 복제를 구성합니다. 
C. 마케팅 회사가 회사의 S3 버킷에 액세스할 수 있도록 마케팅 회사에 대한 교차 계정 액세스를 
구성합니다. 
D. S3 Intelligent-Tiering 을 사용하도록 회사의 S3 버킷을 구성합니다. S3 버킷을 마케팅 회사의 S3 
버킷 중 하나와 동기화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85738-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
요청자 지불 버킷을 사용하면 버킷 소유자 대신 요청자가 버킷에서 데이터 다운로드 및 요청 
비용을 지불합니다. 버킷 소유자는 항상 데이터 저장 비용을 지불합니다. 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html 
설명 2: 
"일반적으로 데이터를 공유하고 싶지만 데이터에 액세스하는 다른 사람과 관련된 요금을 부과하지 
않으려면 버킷을 요청자 지불 버킷으로 구성합니다. 
예를 들어 우편 번호 디렉터리, 참조 데이터 지리 공간 정보 또는 웹 크롤링 데이터와 같은 대용량 
데이터 세트를 만들 때 요청자 지불 버킷을 사용할 수 있습니다." 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html 
Q89 
회사는 Amazon S3 를 사용하여 기밀 감사 문서를 저장합니다. S3 버킷은 버킷 정책을 사용하여 
최소 권한 원칙에 따라 감사 팀 IAM 사용자 자격 증명에 대한 액세스를 제한합니다. 회사 
관리자는 S3 버킷에서 실수로 문서가 삭제되는 것을 걱정하고 더 안전한 솔루션을 원합니다. 
솔루션 설계자는 감사 문서를 보호하기 위해 무엇을 해야 합니까? 
A. S3 버킷에서 버전 관리 및 MFA 삭제 기능을 활성화합니다. 
B. 각 감사 팀 IAM 사용자 계정의 IAM 사용자 자격 증명에 대해 다단계 인증(MFA)을 
활성화합니다. 
C. 감사 날짜 동안 s3:DeleteObject 작업을 거부하도록 감사 팀의 IAM 사용자 계정에 S3 수명 
주기 정책을 추가합니다. 
D. AWS Key Management Service(AWS KMS)를 사용하여 S3 버킷을 암호화하고 감사 팀 IAM 
사용자 계정이 KMS 키에 액세스하지 못하도록 제한합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85808-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
・버전 관리는 실수로 삭제했을 때 이전 버전의 파일을 불러올 수 있도록 해줌. 
Amazon S3 의 버전 관리는 동일 버킷 내에 여러 개의 객체 변형을 보유하는 수단입니다. S3 버전 
관리를 사용하면 버킷에 저장된 모든 버전의 객체를 모두 보존, 검색 및 복원할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Versioning.html 
・MFA Delete 는 함부로 삭제하지 못하도록 막음. 
MFA Delete 는 다음 작업에 대해 추가 인증을 요구합니다. ◎버킷의 버전 관리 상태 변경 ◎객체 
버전 영구 삭제 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/MultiFactorAuthenticationDelete
.html 
Q90 
회사에서 SQL 데이터베이스를 사용하여 공개적으로 액세스할 수 있는 영화 데이터를 저장하고 
있습니다. 데이터베이스는 Amazon RDS 단일 AZ DB 인스턴스에서 실행됩니다. 스크립트는 
데이터베이스에 추가된 새로운 영화의 수를 기록하기 위해 매일 임의의 간격으로 쿼리를 
실행합니다. 스크립트는 업무 시간 동안의 최종 합계를 보고해야 합니다. 
회사의 개발 팀은 스크립트가 실행 중일 때 데이터베이스 성능이 개발 작업에 부적절하다는 것을 
알아차렸습니다. 솔루션 설계자는 이 문제를 해결하기 위한 솔루션을 권장해야 합니다. 
최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. DB 인스턴스를 다중 AZ 배포로 수정합니다. 
B. 데이터베이스의 읽기 전용 복제본을 생성합니다. 읽기 전용 복제본만 쿼리하도록 스크립트를 
구성합니다. 
C. 개발 팀에게 매일 일과가 끝날 때 데이터베이스의 항목을 수동으로 내보내도록 지시합니다. 
D. Amazon ElastiCache 를 사용하여 스크립트가 데이터베이스에 대해 실행하는 일반적인 쿼리를 
캐시합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85339-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
・스크립트는 데이터베이스에 추가된 새로운 영화의 수를 기록하기 위해 매일 임의의 간격으로 
쿼리를 실행합니다. = 스크립트는 쿼리를 수행하고 있음 
・'회사의 개발 팀은 스크립트가 실행 중일 때 데이터베이스 성능이 개발 작업에 부적절하다는 
것을 알아차렸습니다.' = 스크립트 때문에 데이터베이스 성능이 떨어지고 있음. 
따라서 쿼리가 너무 많이 수행되어서 데이터베이스 성능에 영향이 가는 상황입니다. 이런 경우 
read replica 를 통해 쿼리 부하를 분산할 수 있습니다. 
B(O) : 애플리케이션에서 읽기 전용 복제본으로 읽기 쿼리를 라우팅하여 기본 DB 인스턴스의 
로드를 줄일 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html 
D(X) : ElastiCache 는 웹 애플리케이션 성능 향상 용도로 주로 사용됨. 
Amazon ElastiCache 는 더 느린 디스크 기반 데이터베이스에 전적으로 의존하기보다는 신속한 
관리형 인 메모리 시스템에서 정보를 검색할 수 있는 기능을 지원함으로써 웹 애플리케이션의 
성능을 향상합니다. https://aws.amazon.com/ko/elasticache/faqs/ 
Q91 
회사에 VPC 의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 애플리케이션 중 
하나는 Amazon S3 API 를 호출하여 객체를 저장하고 읽어야 합니다. 회사의 보안 규정에 따라 
응용 프로그램의 트래픽은 인터넷을 통해 이동할 수 없습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. S3 게이트웨이 엔드포인트를 구성합니다. 
B. 프라이빗 서브넷에 S3 버킷을 생성합니다. 
C. EC2 인스턴스와 동일한 AWS 리전에 S3 버킷을 생성합니다. 
D. EC2 인스턴스와 동일한 서브넷에 NAT 게이트웨이를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85667-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
B. 프라이빗 서브넷에서 S3를 생성하면 버킷에 대한 직접적인 인터넷 액세스가 제한되지만 EC2와 
S3 간의 직접적이고 안전한 연결은 제공되지 않습니다. 애플리케이션은 여전히 S3 API 에 
액세스하기 위해 인터넷을 통과해야 합니다. 
C. EC2 와 동일한 지역에 S3 를 생성한다고 해서 본질적으로 트래픽이 인터넷을 통과하는 것을 
막지는 않습니다. 
D. NAT 게이트웨이를 구성하면 프라이빗 서브넷의 리소스에 대한 아웃바운드 인터넷 연결이 
허용되지만 S3 서비스에 대한 직접적이고 안전한 연결은 제공되지 않습니다. EC2 에서 S3 API 로의 
트래픽은 여전히 인터넷을 통과합니다. 
가장 적합한 솔루션은 S3 게이트웨이 엔드포인트를 구성하는 것입니다(옵션 A). 트래픽이 
인터넷을 통과할 필요 없이 VPC 와 S3 서비스 간에 안전한 비공개 연결을 제공합니다. S3 
게이트웨이 엔드포인트를 통해 EC2 는 VPC 내에서 직접 S3 API 에 액세스할 수 있으므로 트래픽이 
인터넷을 통해 이동하지 못하도록 하는 보안 요구 사항을 충족합니다. 
참고: 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/privatelink-interface-endpoints.
html#types-of-vpc-endpoints-for-s3 
https://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpc-endpoints-s3.html 
Q92 
회사에서 Amazon S3 버킷에 민감한 사용자 정보를 저장하고 있습니다. 회사는 VPC 내부의 
Amazon EC2 인스턴스에서 실행되는 애플리케이션 계층에서 이 버킷에 대한 보안 액세스를 
제공하려고 합니다. 
솔루션 설계자는 이를 달성하기 위해 어떤 단계 조합을 취해야 합니까? (2 개를 선택하세요.) 
A. VPC 내에서 Amazon S3 용 VPC 게이트웨이 엔드포인트를 구성합니다. 
B. S3 버킷의 객체를 퍼블릭으로 만들기 위한 버킷 정책을 생성합니다. 
C. VPC 에서 실행되는 애플리케이션 계층으로만 액세스를 제한하는 버킷 정책을 생성합니다. 
D. S3 액세스 정책으로 IAM 사용자를 생성하고 IAM 자격 증명을 EC2 인스턴스에 복사합니다. 
E. NAT 인스턴스를 생성하고 EC2 인스턴스가 NAT 인스턴스를 사용하여 S3 버킷에 액세스하도록 
합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/85903-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A(O) : Gateway Endpoint 는 퍼블릭 인터넷망을 통과하지 않는 전용 연결. 
게이트웨이 엔드포인트는 VPC 용 인터넷 게이트웨이 또는 NAT 디바이스가 없어도 Amazon S3 및 
DynamoDB 에 대한 안정적인 연결을 제공합니다. 게이트웨이 엔드포인트는 AWS PrivateLink 를 
활성화하지 않습니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpce-gateway.html 
B(X) : 객체를 퍼블릭으로 만드는 것은 보안과는 거리가 멈. 
C(O) : 버킷 정책으로 버킷에 대한 액세스 제어. 
버킷 정책은 버킷과 해당 버킷의 객체에 대한 액세스 권한을 부여할 수 있는 리소스 기반 
정책입니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/example-bucket-policies.html 
D(X) : 차라리 IAM 사용자 정책을 사용하는 것이 더 나음. 
Amazon S3 에 대한 사용자 액세스를 제어하는 IAM 사용자 정책을 생성하고 구성할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/user-policies.html 
E(X) : Gateway Endpoint 가 더 좋은 선택임. 
Q93 
회사는 MySQL 데이터베이스로 구동되는 온프레미스 애플리케이션을 실행합니다. 이 회사는 
애플리케이션의 탄력성과 가용성을 높이기 위해 애플리케이션을 AWS 로 마이그레이션하고 
있습니다. 
현재 아키텍처는 정상 작동 시간 동안 데이터베이스에서 많은 읽기 활동을 보여줍니다. 회사의 
개발 팀은 4 시간마다 프로덕션 데이터베이스의 전체 내보내기를 가져와 준비 환경의 
데이터베이스를 채웁니다. 이 기간 동안 사용자는 허용할 수 없는 애플리케이션 대기 시간을 
경험합니다. 개발 팀은 절차가 완료될 때까지 스테이징 환경을 사용할 수 없습니다. 
솔루션 설계자는 애플리케이션 지연 문제를 완화하는 대체 아키텍처를 권장해야 합니다. 또한 대체 
아키텍처는 개발 팀이 지연 없이 스테이징 환경을 계속 사용할 수 있는 능력을 제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 프로덕션용 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL 을 사용합니다. mysqldump 
유틸리티를 사용하는 백업 및 복원 프로세스를 구현하여 스테이징 데이터베이스를 채웁니다. 
B. 프로덕션용 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL 을 사용합니다. 데이터베이스 
복제를 사용하여 요청 시 스테이징 데이터베이스를 생성합니다. 
C. 다중 AZ 배포 및 프로덕션용 읽기 전용 복제본과 함께 MySQL 용 Amazon RDS 를 사용합니다. 
스테이징 데이터베이스에 대해 대기 인스턴스를 사용합니다. 
D. 다중 AZ 배포 및 프로덕션용 읽기 전용 복제본과 함께 MySQL 용 Amazon RDS 를 사용합니다. 
mysqldump 유틸리티를 사용하는 백업 및 복원 프로세스를 구현하여 스테이징 데이터베이스를 
채웁니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85729-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
RDS 에 비해 Aurora 는 항상 3 개의 AZ 에 6 개의 복제본(Replica)를 보유하고 있으므로 
애플리케이션 가용성에 더 유리. A,B 둘 중 하나가 답.여기서 mysqldump 가 문젠데,  
Q: MySQL 에서 Amazon Aurora 로 또는 그 반대로 마이그레이션하려면 어떻게 해야 하나요? 여러 
가지 옵션이 있습니다. 표준 mysqldump 유틸리티를 사용하여 MySQL 에서 데이터를 내보내고 
mysqlimport 유틸리티를 사용하여 Amazon Aurora 로 데이터를 가져올 수 있습니다. 그 반대도 
마찬가지입니다. 또한, AWS 관리 콘솔에서 Amazon RDS 의 DB 스냅샷 마이그레이션 기능을 
이용하여 Amazon RDS for MySQL DB 스냅샷을 Amazon Aurora 로 마이그레이션할 수 있습니다. 
대부분 고객은 [1 시간 이내]에 마이그레이션을 완료하지만 
https://aws.amazon.com/ko/rds/aurora/faqs/ 
최대 1GB 정도의 소규모 데이터베이스라면 mysqldump 를 실행 
https://aws.amazon.com/ko/rds/mysql/features/ 
이걸로 봤을 때 mysqldump 는 데이터백업에 많은 시간이 소요되는 방법으로 보이므로 A 제외. 
답은 B. 
참고 
https://aws.amazon.com/blogs/aws/amazon-aurora-fast-database-cloning/ 
Q94 
한 회사에서 사용자가 Amazon S3 에 작은 파일을 업로드하는 애플리케이션을 설계하고 있습니다. 
사용자가 파일을 업로드한 후 데이터를 변환하고 나중에 분석할 수 있도록 데이터를 JSON 
형식으로 저장하려면 파일에 일회성 단순 처리가 필요합니다. 
각 파일은 업로드 후 최대한 빨리 처리해야 합니다. 수요는 다양할 것입니다. 어떤 날에는 
사용자가 많은 수의 파일을 업로드합니다. 다른 날에는 사용자가 몇 개의 파일을 업로드하거나 
파일을 업로드하지 않습니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon S3 에서 텍스트 파일을 읽도록 Amazon EMR 을 구성합니다. 처리 스크립트를 실행하여 
데이터를 변환합니다. 결과 JSON 파일을 Amazon Aurora DB 클러스터에 저장합니다. 
B. Amazon SQS(Amazon Simple Queue Service) 대기열에 이벤트 알림을 보내도록 Amazon S3 를 
구성합니다. Amazon EC2 인스턴스를 사용하여 대기열에서 읽고 데이터를 처리합니다. 결과 JSON 
파일을 Amazon DynamoDB 에 저장합니다. 
C. 이벤트 알림을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내도록 Amazon S3 를 
구성합니다. AWS Lambda 함수를 사용하여 대기열에서 읽고 데이터를 처리합니다. 결과 JSON 
파일을 Amazon DynamoDB 에 저장합니다. 
D. 새 파일이 업로드될 때 Amazon Kinesis Data Streams 에 이벤트를 보내도록 Amazon 
EventBridge(Amazon CloudWatch Events)를 구성합니다. AWS Lambda 함수를 사용하여 
스트림에서 이벤트를 소비하고 데이터를 처리합니다. 결과 JSON 파일을 Amazon Aurora DB 
클러스터에 저장합니다. 
Answer: C  
https://www.examtopics.com/discussions/amazon/view/86676-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1:・ 
A(X) : EMR 은 빅데이터 플랫폼 서비스라 사용 분야가 좀 다르고, 파일을 업로드하지 않는 날이나 
업로드가 거의 없는 날에는 과도한 지출이 발생할 우려가 있음. 
B(X) : 파일에 일회성 단순 처리가 필요하다고 했으므로 EC2 인스턴스로 처리하는 것보다는 
Lambda 가 더 지문 요구사항에 부합. 
C(O) : 유일하게 마음에 걸리는 게 '업로드 후 최대한 빨리 처리'해야한다는 건데 가장 정답에 
가까운 선택지로 보임. 업로드하는 파일 숫자도 변동이 심한데 이를 SQS 대기열에 집어넣음으로서 
대처할 수 있고, Lambda 함수로 파일에 일회성 단순 처리가 가능하며 추가적인 
SQS->Lambda->DynamoDB 에 저장이라는 단순한 프로세스로 인해 운영 오버헤드도 매우 적음. 
DynamoDB 는 JSON 파일을 지원 
DynamoDB 는 JSON 을 사용하여 문서에 대한 기본 지원을 제공합니다. 따라서 DynamoDB 는 
Tags 같은 반정형 데이터를 저장하는 데 적합합니다. JSON 문서 안에서 데이터를 가져오고 
조작할 수도 있습니다. 
https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/SQLtoNoSQL.Writ
eData.html 
D(X) : 파일에 일회성 단순 처리가 필요하다고 했으므로 Kinesis Data Streams 로 처리하는 
것보다는 Lambda 가 더 지문 요구사항에 부합. 또한 파일 업로드가 없거나 거의 없는 날에는 
Kinesis 사용은 과도한 지출을 야기할 우려가 있음. 
설명 2: 
Amazon S3 는 S3 버킷(예: 객체 생성, 객체 제거 또는 객체 복원)에 대한 이벤트 알림을 동일한 
리전의 SNS 주제로 보냅니다. 
SNS 주제는 중앙 리전의 SQS 대기열에 이벤트를 게시합니다. 
SQS 대기열은 Lambda 함수의 이벤트 소스로 구성되며 Lambda 함수의 이벤트 메시지를 
버퍼링합니다. 
Lambda 함수는 메시지에 대한 SQS 대기열을 폴링하고 애플리케이션의 요구 사항에 따라 
Amazon S3 이벤트 알림을 처리합니다. 
https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/patterns/subscribe-a-lambda
-function-to-event-notifications-from-s3-buckets-in-different-aws-regions.html 
Q95 
응용 프로그램을 사용하면 회사 본사의 사용자가 제품 데이터에 액세스할 수 있습니다. 제품 
데이터는 Amazon RDS MySQL DB 인스턴스에 저장됩니다. 운영 팀은 애플리케이션 성능 저하를 
격리하고 쓰기 트래픽에서 읽기 트래픽을 분리하려고 합니다. 솔루션 설계자는 애플리케이션의 
성능을 신속하게 최적화해야 합니다. 
솔루션 설계자는 무엇을 권장해야 합니까? 
A. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 기본 가용 영역에서 읽기 요청을 제공합니다. 
B. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 보조 가용 영역에서 읽기 요청을 
제공합니다. 
C. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 컴퓨팅 및 스토리지 리소스의 절반을 
원본 데이터베이스로 사용하여 읽기 전용 복제본을 구성합니다. 
D. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 원본 데이터베이스와 동일한 컴퓨팅 및 
스토리지 리소스로 읽기 전용 복제본을 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85906-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설:・ 
복제가 효과적으로 작동하려면 각 읽기 전용 복제본에 원본 DB 인스턴스와 동일한 양의 컴퓨팅 및 
스토리지 리소스가 있어야 합니다. 원본 DB 인스턴스를 확장하는 경우 읽기 전용 복제본도 
확장합니다. 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MySQL.Replication.ReadRep
licas.html 
참조 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MySQL.Replication.ReadRep
licas.html 
Q96 
Amazon EC2 관리자는 여러 사용자가 포함된 IAM 그룹과 연결된 다음 정책을 생성했습니다. 
이 정책의 효과는 무엇입니까? 
A. 사용자는 us-east-1 을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다. 
B. 사용자는 us-east-1 리전에서 IP 주소가 10.100.100.1 인 EC2 인스턴스를 종료할 수 있습니다. 
C. 사용자는 사용자의 소스 IP 가 10.100.100.254 일 때 us-east-1 리전에서 EC2 인스턴스를 
종료할 수 있습니다. 
D. 사용자의 소스 IP 가 10.100.100.254 인 경우 사용자는 us-east-1 리전에서 EC2 인스턴스를 
종료할 수 없습니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/86460-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Allow 문 해석 : 소스 IP 가 10.100.100.0/24 인 모든 리소스(*)에 대해 ec2 인스턴스 종료를 허용. 
Deny 문 해석 : ec2 리전이 us-east-1 이 아닌 모든 리소스(*)에 대해 ec2 의 모든 작업을 불허. 
따라서 정답은 C. 
설명 2: 
정책은 us-east-1 을 제외한 모든 지역에서 EC2 작업을 수행하는 것을 금지하고 소스 IP 가 
10.100.100.0/24 인 사용자만 인스턴스를 종료하도록 허용하기 때문입니다. 따라서 소스 IP 가 
10.100.100.254 인 사용자는 us-east-1 지역의 인스턴스를 종료할 수 있습니다. 
Q97 
회사에는 Microsoft Windows 공유 파일 저장소가 필요한 온프레미스에서 실행되는 대규모 
Microsoft SharePoint 배포가 있습니다. 회사는 이 워크로드를 AWS 클라우드로 
마이그레이션하기를 원하며 다양한 스토리지 옵션을 고려하고 있습니다. 저장소 솔루션은 액세스 
제어를 위해 고가용성 및 Active Directory 와 통합되어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon EFS 스토리지를 구성하고 인증을 위해 Active Directory 도메인을 설정합니다. 
B. 두 가용 영역의 AWS Storage Gateway 파일 게이트웨이에 SMB 파일 공유를 생성합니다. 
C. Amazon S3 버킷을 생성하고 볼륨으로 탑재하도록 Microsoft Windows Server 를 구성합니다. 
D. AWS 에서 Windows 파일 서버용 Amazon FSx 파일 시스템을 생성하고 인증을 위해 Active 
Directory 도메인을 설정합니다. 
Answer: D  
https://www.examtopics.com/discussions/amazon/view/86626-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Mcrosoft Active Directory 용 AWS Directory Service : 
AWS Managed Microsoft AD에 대한 패치 및 유지 관리. 기본적으로 각 디렉터리는 서로 다른 가용 
영역에 설치된 두 개의 DC 로 구성됩니다. 
https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_key_concepts_mainte
nance.html 
Windows 파일 서버용 FSx 를 AWS Managed Microsoft AD 와 통합하면 Windows 기반 
애플리케이션 및 클라이언트(공유 파일 스토리지 활용)를 AWS 로 쉽게 이동할 수 있는 완전 
관리형 기본 Microsoft Windows 기반 서버 메시지 블록(SMB) 프로토콜 파일 시스템을 
제공합니다. 
https://docs.aws.amazon.com/directoryservice/latest/admin-guide/usecase1.html 
Q98 
이미지 처리 회사에는 사용자가 이미지를 업로드하는 데 사용하는 웹 응용 프로그램이 있습니다. 
애플리케이션은 이미지를 Amazon S3 버킷에 업로드합니다. 회사는 객체 생성 이벤트를 Amazon 
Simple Queue Service(Amazon SQS) 표준 대기열에 게시하도록 S3 이벤트 알림을 설정했습니다. 
SQS 대기열은 이미지를 처리하고 결과를 이메일을 통해 사용자에게 보내는 AWS Lambda 함수의 
이벤트 소스 역할을 합니다. 
사용자는 업로드된 모든 이미지에 대해 여러 이메일 메시지를 수신하고 있다고 보고합니다. 솔루션 
설계자는 SQS 메시지가 Lambda 함수를 두 번 이상 호출하여 여러 이메일 메시지를 생성한다고 
판단합니다. 
솔루션 설계자는 이 문제를 최소한의 운영 오버헤드로 해결하기 위해 무엇을 해야 합니까? 
A. ReceiveMessage 대기 시간을 30 초로 늘려 SQS 대기열에서 긴 폴링을 설정합니다. 
B. SQS 표준 대기열을 SQS FIFO 대기열로 변경합니다. 메시지 중복 제거 ID 를 사용하여 중복 
메시지를 버리십시오. 
C. SQS 대기열의 가시성 제한 시간을 함수 제한 시간과 일괄 처리 창 제한 시간의 합계보다 큰 
값으로 늘립니다. 
D. 처리 전에 메시지를 읽은 직후 SQS 대기열에서 각 메시지를 삭제하도록 Lambda 함수를 
수정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85185-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A(X) : 긴 폴링 대기 시간의 최대값은 20 초입니다. 
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/workin
g-with-messages.html 
B(X) : 솔루션 설계자는 SQS 메시지가 Lambda 함수를 두 번 이상 호출하여 여러 이메일 메시지를 
생성하는 것이 문제의 원인이라고 보고 있음. 즉, SQS 쪽 문제이지 이미지 생성 및 업로드까지는 
문제가 없다는 것. 중복 ID 제거는 생산자가 중복 메시지를 발생시키는 문제를 SQS FIFO 
Queue 에서 해결하는 서비스 유형이므로 지문의 상황에는 적합하지 않음. 더군다나 모든 이미지 
업로드 시마다 같은 문제가 계속 발생한다는 건 가끔 중복 메시지가 유입되는 정도가 아니라 SQS 
대기열 쪽에서 처리가 이루어질 때 문제가 발생했을 가능성이 더 높음. 
FIFO 대기열은 중복 메시지가 절대 유입되지 않도록 설계되었습니다. 다만 일부 시나리오에서는 
메시지 생산자가 중복 메시지를 유입할 수도 있습니다. 
https://aws.amazon.com/ko/sqs/faqs/ 
C(O) : 하지만 소비자가 메시지를 삭제하기 전에 실패할 경우 제한 시간 초과가 만료되기 전에 
시스템에서 해당 메시지에 대한 DeleteMessage 작업을 호출하지 않으면 다른 소비자가 메시지를 
볼 수 있게 되고 메시지가 다시 수신됩니다. 일반적으로 애플리케이션에서 대기열의 메시지를 
처리하고 삭제하는 데 소요되는 최대 시간으로 제한 시간 초과를 설정해야 합니다. 메시지의 제한 
시간을 단축하거나 늘리기 위해 ChangeMessageVisibility 작업을 사용하여 새 제한 시간 값을 
지정할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-vi
sibility-timeout.html#configuring-visibility-timeout 
D(X) : Lambda 함수가 메시지 처리 및 삭제까지 담당하게 되므로 Lambda 비용이 추가로 발생하여 
다른 방법보다 더 비용이 발생. 굳이 이 방법을 사용할 이유가 없음. 
Q99 
회사는 온프레미스 데이터 센터에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 
솔루션을 구현하고 있습니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스할 수 있는 
기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하는 
파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다. 
B. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 
설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다. 
C. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성하고 Lustre 를 지원하도록 
구성합니다. 파일 시스템을 원본 서버에 연결합니다. 응용 프로그램 서버를 파일 시스템에 
연결합니다. 
D. Lustre 파일 시스템용 Amazon FSx 를 생성합니다. 파일 시스템을 원본 서버에 연결합니다. 응용 
프로그램 서버를 파일 시스템에 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85811-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
A. AWS Storage Gateway 파일 게이트웨이는 Lustre 클라이언트 액세스를 지원하지 않습니다. 
B. EC2 Windows 인스턴스에서 Windows 파일 공유를 생성하는 것은 Windows 기반 파일 공유에 
적합하지만 필요한 Lustre 클라이언트 액세스를 제공하지 않습니다. Lustre 는 고성능 컴퓨팅(HPC) 
환경에서 주로 사용되는 고성능 병렬 파일 시스템입니다. 
C. EFS 는 기본적으로 Lustre 클라이언트 액세스를 지원하지 않습니다. EFS 는 관리형 파일 
스토리지 서비스이지만 범용 파일 스토리지용으로 설계되었으며 Lustre 워크로드에 최적화되어 
있지 않습니다. 
D. Amazon FSx for Lustre 는 Lustre 클라이언트를 포함하여 고성능 컴퓨팅 워크로드에 최적화된 
완전관리형 파일 시스템입니다. Lustre 클라이언트를 사용하여 관리되고 확장 가능한 방식으로 
데이터에 액세스할 수 있는 기능을 제공합니다. 이 옵션을 선택함으로써 회사는 Lustre 클라이언트 
액세스 요구 사항을 충족하면서 Amazon FSx for Lustre 의 성능 및 관리 용이성으로부터 이점을 
얻을 수 있습니다. 
Q100 
회사의 컨테이너화된 애플리케이션은 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 다른 
비즈니스 애플리케이션과 통신하기 전에 보안 인증서를 다운로드해야 합니다. 회사는 거의 
실시간으로 인증서를 암호화하고 해독할 수 있는 매우 안전한 솔루션을 원합니다. 또한 솔루션은 
데이터가 암호화된 후 고가용성 스토리지에 데이터를 저장해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 암호화된 인증서에 대한 AWS Secrets Manager 암호를 생성합니다. 필요에 따라 인증서를 
수동으로 업데이트합니다. 세분화된 IAM 액세스를 사용하여 데이터에 대한 액세스를 제어합니다. 
B. Python 암호화 라이브러리를 사용하여 암호화 작업을 수신하고 수행하는 AWS Lambda 함수를 
생성합니다. 함수를 Amazon S3 버킷에 저장합니다. 
C. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. EC2 역할이 암호화 
작업에 KMS 키를 사용하도록 허용합니다. 암호화된 데이터를 Amazon S3 에 저장합니다. 
D. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. EC2 역할이 암호화 
작업에 KMS 키를 사용하도록 허용합니다. 암호화된 데이터를 Amazon Elastic Block Store(Amazon 
EBS) 볼륨에 저장합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85186-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
고가용성 저장소 = S3. B,C 둘 중 하나가 답. 
Lambda 보다 KMS 가 암호화 및 해독에 적합. 정답은 C. 
Q101 
솔루션 설계자는 퍼블릭 및 프라이빗 서브넷이 있는 VPC 를 설계하고 있습니다. VPC 와 서브넷은 
IPv4 CIDR 블록을 사용합니다. 고가용성을 위해 세 개의 가용 영역(AZ) 각각에 하나의 퍼블릭 
서브넷과 하나의 프라이빗 서브넷이 있습니다. 인터넷 게이트웨이는 퍼블릭 서브넷에 대한 인터넷 
액세스를 제공하는 데 사용됩니다. 프라이빗 서브넷은 Amazon EC2 인스턴스가 소프트웨어 
업데이트를 다운로드할 수 있도록 인터넷에 액세스할 수 있어야 합니다. 
솔루션 설계자는 프라이빗 서브넷에 대한 인터넷 액세스를 활성화하기 위해 무엇을 해야 합니까? 
A. 각 AZ 의 각 퍼블릭 서브넷에 대해 하나씩 3 개의 NAT 게이트웨이를 생성합니다. 비 VPC 
트래픽을 해당 AZ 의 NAT 게이트웨이로 전달하는 각 AZ 에 대한 프라이빗 라우팅 테이블을 
생성합니다. 
B. 각 AZ 의 프라이빗 서브넷마다 하나씩 3 개의 NAT 인스턴스를 생성합니다. 비 VPC 트래픽을 
해당 AZ 의 NAT 인스턴스로 전달하는 각 AZ 에 대한 프라이빗 라우팅 테이블을 생성합니다. 
C. 프라이빗 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 생성합니다. VPC 가 아닌 트래픽을 
프라이빗 인터넷 게이트웨이로 전달하는 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다. 
D. 퍼블릭 서브넷 중 하나에 송신 전용 인터넷 게이트웨이를 생성합니다. VPC 가 아닌 트래픽을 
외부 전용 인터넷 게이트웨이로 전달하는 프라이빗 서브넷에 대한 라우팅 테이블을 
업데이트합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/86019-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
프라이빗 서브넷에 있는 인스턴스가 외부 인터넷과 통신하기 위해선 NAT 게이트웨이가 필요. 
A(O) : 각 가용 영역의 퍼블릭 서브넷마다 NAT 게이트웨이를 두어야 함. 프라이빗 서브넷의 
인스턴스는 퍼블릭 NAT 게이트웨이를 통해 인터넷에 연결. 퍼블릭 서브넷에서 퍼블릭 NAT 
게이트웨이를 생성하고 생성 시 탄력적 IP 주소를 NAT 게이트웨이와 연결해야 합니다. 여러 가용 
영역에 리소스가 있고 NAT 게이트웨이 하나를 공유하는 경우, NAT 게이트웨이의 가용 영역이 
다운되면 다른 가용 영역의 리소스도 인터넷에 액세스할 수 없게 됩니다. 가용 영역과 독립적인 
아키텍처를 만들려면 각 가용 영역에 NAT 게이트웨이를 만들고 리소스가 동일한 가용 영역의 NAT 
게이트웨이를 사용하도록 라우팅을 구성합니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-gateway.html 
B(X) : NAT 인스턴스는 더 이상 권장되지 않음 
C(X) : 인터넷 게이트웨이는 프라이빗 서브넷과 외부 인터넷을 연결할 수 없음. 
D(X) : NAT 게이트웨이가 필요한 상황임.  
참고: 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-comparison.html 
Q102 
회사에서 온프레미스 데이터 센터를 AWS 로 마이그레이션하려고 합니다. 데이터 센터는 NFS 기반 
파일 시스템에 데이터를 저장하는 SFTP 서버를 호스팅합니다. 서버에는 전송해야 하는 200GB 의 
데이터가 있습니다. 서버는 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용하는 
Amazon EC2 인스턴스에서 호스팅되어야 합니다. 
솔루션 설계자는 이 작업을 자동화하기 위해 어떤 단계 조합을 취해야 합니까? (2 개를 
선택하세요.) 
A. EFS 파일 시스템과 동일한 가용 영역에서 EC2 인스턴스를 시작합니다. 
B. 온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치합니다. 
C. 데이터에 대한 EC2 인스턴스에 보조 Amazon Elastic Block Store(Amazon EBS) 볼륨을 
생성합니다. 
D. 수동으로 운영 체제 복사 명령을 사용하여 데이터를 EC2 인스턴스로 푸시합니다. 
E. AWS DataSync 를 사용하여 온프레미스 SFTP 서버에 적합한 위치 구성을 생성합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/85814-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(O) 
EFS 파일 시스템과 동일한 가용 영역으로 EC2 인스턴스 시작하는건 문제 없어보입니다.  
B(O) : DataSync Agent 는 AWS 로 전송할 떄 필요 
에이전트 는 AWS DataSync 가 스토리지 시스템에서 읽거나 쓰는 데 사용하는 가상 머신(VM) 또는 
Amazon EC2 인스턴스입니다 . 에이전트는 온프레미스 스토리지에서 AWS 로 데이터를 복사할 때 
일반적으로 사용됩니다. 
https://docs.aws.amazon.com/datasync/latest/userguide/working-with-agents.html 
DataSync 는 DataSync 위치와 같이 사용됨 
대부분의 워크로드의 경우 각 자체 관리 위치에 대해 하나의 AWS DataSync 에이전트를 사용하는 
것이 좋습니다. 
https://docs.aws.amazon.com/datasync/latest/userguide/multiple-agents.html 
C(X) : EBS 가 아니라 EFS 가 NFS 지원. 
D(X) : 수동으로 할 필요가 없이 DataSync 같은 대안을 사용하면 됨. 
E(X) : 온프레미스 SFTP 에 좀 더 적합한 건 DataSync 보다 Transfer Family 가 더 
적합해보입니다. 
Q103 
회사에 매일 같은 시간에 실행되는 AWS Glue 추출, 변환 및 로드(ETL) 작업이 있습니다. 작업은 
Amazon S3 버킷에 있는 XML 데이터를 처리합니다. 매일 새로운 데이터가 S3 버킷에 추가됩니다. 
솔루션 설계자는 AWS Glue 가 각 실행 중에 모든 데이터를 처리하고 있음을 알아차렸습니다. 
솔루션 아키텍트는 AWS Glue 가 오래된 데이터를 재처리하지 못하도록 하려면 어떻게 해야 
합니까? 
A. 작업 북마크를 사용하도록 작업을 편집합니다. 
B. 데이터가 처리된 후 데이터를 삭제하도록 작업을 편집합니다. 
C. NumberOfWorkers 필드를 1 로 설정하여 작업을 편집합니다. 
D. FindMatches 기계 학습(ML) 변환을 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85781-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
이것이 북마크의 목적입니다. "AWS Glue 는 작업 실행의 상태 정보를 유지하여 ETL 작업의 이전 
실행 중에 이미 처리된 데이터를 추적합니다. 이 지속된 상태 정보를 작업 북마크라고 합니다. 
작업 북마크는 AWS Glue 가 유지 관리하는 데 도움이 됩니다. 상태 정보를 제공하고 오래된 
데이터의 재처리를 방지합니다." 
https://docs.aws.amazon.com/glue/latest/dg/monitorcontinuations.html 
설명 2: 
A(O) : AWS Glue 는 작업 실행의 상태 정보를 유지하여 이전에 ETL 작업을 실행할 때 이미 처리된 
데이터를 추적합니다. 이와 같은 지속 상태 정보를 작업 북마크라고 합니다.  
https://docs.aws.amazon.com/ko_kr/glue/latest/dg/monitor-continuations.html 
B(X) : 처리한 데이터를 어디에 쓸 줄 알고 삭제하는지...? 
C(X) : ""NumberOfWorkers – 숫자(정수) : 작업이 실행될 때 할당되는 정의된 workerType 의 작업자 
수입니다. 
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-jobs-job.html 
D(X) : 기계 변환 학습은 전혀 관계 없음. 
Q104 
솔루션 설계자는 웹사이트를 위한 고가용성 인프라를 설계해야 합니다. 웹 사이트는 Amazon EC2 
인스턴스에서 실행되는 Windows 웹 서버에 의해 구동됩니다. 솔루션 설계자는 수천 개의 IP 
주소에서 시작되는 대규모 DDoS 공격을 완화할 수 있는 솔루션을 구현해야 합니다. 다운타임은 
웹사이트에 허용되지 않습니다. 
솔루션 설계자는 이러한 공격으로부터 웹사이트를 보호하기 위해 어떤 조치를 취해야 합니까? 
(2 개를 선택하세요.) 
A. AWS Shield Advanced 를 사용하여 DDoS 공격을 차단하십시오. 
B. 공격자를 자동으로 차단하도록 Amazon GuardDuty 를 구성합니다. 
C. 정적 및 동적 콘텐츠 모두에 Amazon CloudFront 를 사용하도록 웹 사이트를 구성합니다. 
D. AWS Lambda 함수를 사용하여 VPC 네트워크 ACL 에 공격자 IP 주소를 자동으로 추가합니다. 
E. 80% CPU 사용률로 설정된 대상 추적 조정 정책과 함께 Auto Scaling 그룹의 EC2 스팟 
인스턴스를 사용합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/85342-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(O) : AWS Shield Advanced 보호는 네트워크 트래픽에 대한 상시 작동, 흐름 기반 모니터링과 
적극적인 애플리케이션 모니터링을 통해 의심되는 DDoS 공격에 대한 거의 실시간 알림을 
제공합니다. 또한 AWS Shield Advanced 는 공격을 자동으로 완화하기 위해 첨단 공격 완화 및 
라우팅 기법을 적용합니다. https://aws.amazon.com/ko/shield/faqs/ 
B(X) : GuardDuty 는 AWS 계정 보호 서비스. 
Amazon GuardDuty 는 AWS 계정 및 워크로드에서 악의적 활동을 모니터링하고 상세한 보안 
결과를 제공하여 가시성 및 해결을 촉진하는 위협 탐지 서비스입니다. 
https://aws.amazon.com/ko/guardduty/ 
C(O) : CloudFront 로도 DDoS 에 대처 가능. CloudFront 는 정적 및 동적 콘텐츠 모두에 작동. 또한 
Amazon CloudFront, AWS Global Accelerator 및 Amazon Route 53 과 같은 엣지 로케이션에서 
작동하는 AWS 서비스를 활용하여 알려진 모든 인프라 계층 공격에 대한 포괄적인 가용성 보호를 
구축할 수 있습니다. 이러한 서비스는 AWS 글로벌 엣지 네트워크의 일부이며 전 세계에 분산된 
엣지 로케이션에서 모든 유형의 애플리케이션 트래픽을 처리할 때 애플리케이션의 DDoS 복원력을 
향상할 수 있습니다. 
https://d1.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf 
일반적으로 이미지나 동영상 파일 같은 정적 콘텐츠 전송을 위해서 Amazon CloudFront 를 많이 
활용하고 있지만...TTL 을 0 으로 설정하여 매번 원본 저장소에 접속하여 동적 콘텐츠를 
제공하더라도, CloudFront 를 프록시로 사용함으로써 전송 성능을 향상 시킬 수 있습니다. 
https://aws.amazon.com/ko/blogs/korea/how-to-improve-dynamic-contents-delievery-using-a
mazon-cloudfront/ 
D(X) : DDoS 는 수많은 좀비 PC 를 동원하는데, 그런 PC 들의 IP 를 일일히 차단하여 막기는 
비효율적. 
E(X) : DDoS 로 발생하는 대규모 트래픽은 Auto Scaling 으로 막을 수 있는 스케일이 아님. 
Q105 
회사에서 새로운 서버리스 워크로드를 배포할 준비를 하고 있습니다. 솔루션 설계자는 최소 권한 
원칙을 사용하여 AWS Lambda 함수를 실행하는 데 사용할 권한을 구성해야 합니다. Amazon 
EventBridge(Amazon CloudWatch Events) 규칙이 함수를 호출합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. lambda:InvokeFunction 을 작업으로, *를 보안 주체로 사용하여 함수에 실행 역할을 추가합니다. 
B. 작업으로 lambda:InvokeFunction 을 사용하고 보안 주체로 Service: lambda.amazonaws.com 을 
사용하여 함수에 실행 역할을 추가합니다. 
C. 작업으로 lambda:*를 사용하고 보안 주체로 Service: events.amazonaws.com 을 사용하여 
리소스 기반 정책을 함수에 추가합니다. 
D. lambda:InvokeFunction 을 작업으로, Service: events.amazonaws.com 을 보안 주체로 사용하여 
리소스 기반 정책을 함수에 추가합니다. 
Answer: D  
https://www.examtopics.com/discussions/amazon/view/85816-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
・Lambda의 전체 기능이 아닌 lambda 함수 호출 기능(lambda:InvokeFunction)만 사용하도록 하고, 
전체 보안 주체(*)가 아닌 아마존 이벤트 서비스만 보안 주체로 설정하여야 하므로 B,D 둘 중 
하나가 답. 
・서버리스 워크로드를 '배포'한다고 했으므로 다른 계정에서도 쓸 수 있는 D 가 유리함. 
리소스 기반 정책은 해당 리소스에 액세스할 수 있는 사용자(보안 주체)를 지정합니다. 리소스 
기반 정책을 사용한 교차 계정 액세스는 역할을 사용한 교차 계정 액세스에 비해 몇 가지 이점이 
있습니다. 리소스 기반 정책을 통해 액세스한 리소스로 인해 보안 주체는 여전히 신뢰할 수 있는 
계정에서 작업을 할 수 있고, 역할 권한을 수신하기 위해 자신의 권한을 포기할 필요가 없습니다. 
즉, 보안 주체는 신뢰하는 계정의 리소스에 액세스하는 동시에 신뢰할 수 있는 계정의 리소스에 
계속 액세스할 수 있습니다. 다른 계정의 공유 리소스로 정보를 복사하거나 공유 리소스의 정보를 
복사하는 등의 작업에서 이는 특히 유용합니다. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles_compare-resource-policies.
html 
https://docs.aws.amazon.com/ko_kr/eventbridge/latest/userguide/eb-use-resource-based.html
#lambda-per 
Q106 
회사에서 Amazon S3 에 기밀 데이터를 저장할 준비를 하고 있습니다. 규정 준수를 위해 미사용 
데이터를 암호화해야 합니다. 암호화 키 사용은 감사 목적으로 기록되어야 합니다. 키는 매년 
순환해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? 
A. 고객 제공 키를 사용한 서버 측 암호화(SSE-C) 
B. Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3) 
C. 수동 교체가 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화 
D. 자동 교체 기능이 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화 
Answer: D  
https://www.examtopics.com/discussions/amazon/view/85817-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
감사 목적으로 기록되어야 함 = AWS KMS. 따라서 C,D 둘 중 하나가 정답. 
매년 키를 교체(rotate)해야하므로 운영 상 효율적인 방식은 수동이 아닌 자동 방식. 정답은 D. 
설명 2: 
https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html 
고객 관리형 키에 대해 자동 키 교체를 활성화하면 AWS KMS 는 매년 KMS 키에 대한 새로운 
암호화 자료를 생성합니다. 또한 AWS KMS 는 KMS 키가 암호화한 데이터를 해독하는 데 사용할 
수 있도록 KMS 키의 이전 암호화 자료를 영구적으로 저장합니다. AWS KMS 의 키 순환은 투명하고 
사용하기 쉽게 설계된 암호화 모범 사례입니다. AWS KMS 는 고객 관리형 CMK 에 대해서만 선택적 
자동 키 교체를 지원합니다. 키 순환을 활성화 및 비활성화합니다. 자동 키 교체는 고객 관리형 
CMK 에서 기본적으로 비활성화됩니다. 키 교체를 활성화(또는 재활성화)하면 AWS KMS 는 활성화 
날짜로부터 365 일 후 그리고 이후 365 일마다 CMK 를 자동으로 교체합니다. 
Q107 
자전거 공유 회사는 피크 운영 시간 동안 자전거의 위치를 추적하기 위해 다층 아키텍처를 
개발하고 있습니다. 회사는 기존 분석 플랫폼에서 이러한 데이터 포인트를 사용하려고 합니다. 
솔루션 설계자는 이 아키텍처를 지원하기 위해 가장 실행 가능한 다중 계층 옵션을 결정해야 
합니다. 데이터 포인트는 REST API 에서 액세스할 수 있어야 합니다. 
위치 데이터 저장 및 검색에 대한 이러한 요구 사항을 충족하는 작업은 무엇입니까? 
A. Amazon S3 와 함께 Amazon Athena 를 사용하십시오. 
B. AWS Lambda 와 함께 Amazon API Gateway 를 사용합니다. 
C. Amazon Redshift 와 함께 Amazon QuickSight 를 사용합니다. 
D. Amazon Kinesis Data Analytics 와 함께 Amazon API Gateway 를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85212-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
D?? 
설명 1: 
A(X) : 기존 분석 플랫폼을 사용하려고 한다고 했으므로 분석 기능이 있는 Athena 제외. 
Amazon Athena 는 표준 SQL 을 사용해 Amazon S3 에 저장된 데이터를 간편하게 분석할 수 있는 
대화식 쿼리 서비스입니다.  
https://aws.amazon.com/ko/athena/faqs/ 
B(O) : Lambda 는 512MB 의 임시 스토리지를 가지고 있기도 하고, S3 에 데이터를 저장할 수도 
있으며, 지문에서는 [이러한 데이터 포인트를 사용하려고 합니다.] 라고 언급함과 동시에 [다중 
계층 옵션]이라고 했으므로 Lambda + API Gateway 조합인 B 가 정답에 가깝다고 봄. 
・ 512MB 에서 10,240MB 사이에서 1MB 단위로 자체 임시 스토리지로 각 Lambda 함수를 구성할 
수 있습니다. 임시 스토리지는 각 함수의 /tmp 디렉터리에서 사용할 수 있습니다. 각 함수는 추가 
비용 없이 512MB 의 스토리지에 액세스할 수 있습니다.  
https://aws.amazon.com/ko/lambda/faqs/ 
・ Lambda 는 웹 애플리케이션 개발자의 요구 사항을 충족하는 포괄적인 스토리지 옵션을 
제공합니다. 여기에는 Amazon S3 및 Amazon EFS 와 같은 다른 AWS 서비스가 포함됩니다 . 임시 
저장소 또는 Lambda 계층과 같은 기본 저장소 옵션도 사용할 수 있습니다. 
https://aws.amazon.com/ko/blogs/compute/choosing-between-aws-lambda-data-storage-opti
ons-in-web-apps/ 
・ Lambda 계층은 Lambda 함수와 함께 사용할 수 있는 라이브러리 및 기타 종속성을 
패키징하는 편리한 방법을 제공합니다. 
https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/configuration-layers.html 
C(X) : RedShift 는 Athena 에 비해 가격보다 성능이 더 우선시 될 때 사용. 위치 정보 서비스는 
Athena 대신에 RedShift 를 사용해야할 정도의 서비스가 아님. 
Amazon Athena 와 Amazon Redshift 는 모두 서버리스 서비스이지만 그 필요와 사용 사례가 서로 
다릅니다. 어떤 규모에서든 높은 성능을 요하는 복잡한 BI 및 분석 워크로드를 위해 최고의 가격 
대비 성능이 필요하다면 Amazon Redshift 와 같은 데이터 웨어하우스가 최선의 
선택입니다.""(https://aws.amazon.com/ko/redshift/faqs/) 
D(X) : 기존 분석 플랫폼을 사용하려고 한다고 했으므로 분석 서비스인 Amazon Kinesis Data 
Analytics 는 제외. 
설명 2: 
https://aws.amazon.com/solutions/implementations/aws-streaming-data-solution-for-amazonki
nesis/ 
Q108 
한 회사에 Amazon RDS 의 데이터베이스에 목록을 저장하는 자동차 판매 웹사이트가 있습니다. 
자동차가 판매되면 웹사이트에서 목록을 제거해야 하고 데이터를 여러 대상 시스템으로 보내야 
합니다. 
솔루션 아키텍트는 어떤 디자인을 추천해야 할까요? 
A. Amazon RDS 의 데이터베이스가 업데이트되어 대상이 소비할 Amazon Simple Queue 
Service(Amazon SQS) 대기열로 정보를 보내도록 업데이트될 때 트리거되는 AWS Lambda 함수를 
생성합니다. 
B. Amazon RDS 의 데이터베이스가 대상이 사용할 Amazon Simple Queue Service(Amazon SQS) 
FIFO 대기열로 정보를 보내도록 업데이트될 때 트리거되는 AWS Lambda 함수를 생성합니다. 
C. RDS 이벤트 알림을 구독하고 여러 Amazon Simple Notification Service(Amazon SNS) 주제로 
팬아웃된 Amazon Simple Queue Service(Amazon SQS) 대기열을 보냅니다. AWS Lambda 함수를 
사용하여 대상을 업데이트합니다. 
D. RDS 이벤트 알림을 구독하고 Amazon Simple Notification Service(Amazon SNS) 주제를 여러 
Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. AWS Lambda 함수를 사용하여 
대상을 업데이트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85427-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q109 
회사는 Amazon S3 에 데이터를 저장해야 하며 데이터가 변경되지 않도록 해야 합니다. 회사는 
Amazon S3 에 업로드된 새 객체가 회사가 객체를 수정하기로 결정할 때까지 일정하지 않은 시간 
동안 변경할 수 없는 상태로 유지되기를 원합니다. 회사 AWS 계정의 특정 사용자만 객체를 
삭제할 수 있습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. S3 Glacier 볼트를 생성합니다. WORM(Write-Once, Read-Many) 볼트 잠금 정책을 개체에 
적용합니다. 
B. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다. 버전 관리를 활성화합니다. 보존 기간을 
100 년으로 설정합니다. 거버넌스 모드를 새 객체에 대한 S3 버킷의 기본 보존 모드로 사용합니다. 
C. S3 버킷을 생성합니다. AWS CloudTrail 을 사용하여 객체를 수정하는 모든 S3 API 이벤트를 
추적합니다. 통지 시 회사가 보유한 모든 백업 버전에서 수정된 개체를 복원합니다. 
D. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다. 버전 관리를 활성화합니다. 개체에 법적 
보존을 추가합니다. 객체를 삭제해야 하는 사용자의 IAM 정책에 s3:PutObjectLegalHold 권한을 
추가합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85634-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : S3 에 저장한다고 했지 S3 Glacier 같은 콜드 스토리지에 저장한다고 한 적 없음. 
B(X) : 일정하지 않은 시간 동안이라고 지문에서 언급했는데, 보존 기간을 설정해뒀으므로 오답. 
C(X) : 일단 일이 벌어지고 나서 수습하는 방식인데다가, 변경된 객체마다 일일히 CloudTrail 이 
작동하므로 운영 오버헤드와 비용이 증가할 우려가 있음. 
D(O) : 객체 잠금 법적 보존 작업을 사용하면 객체 버전에 법적 보전을 적용할 수 있습니다. 보관 
기간 설정과 마찬가지로 법적 보존을 사용하면 객체 버전을 덮어쓰거나 삭제할 수 없습니다. 
그러나 법적 보존에는 연결된 보관 기간이 없고, 제거될 때까지 유효합니다. S3 배치 작업은 
매니페스트의 키를 처리하기 전에 S3 버킷에서 객체 잠금이 활성화되어 있는지 확인합니다. 객체 
작업 및 버킷 수준 유효성(검증) 검사를 수행하려면 S3 배치 작업이 사용자를 대신하여 S3 객체 
잠금을 호출할 수 있도록 IAM 역할의 s3:PutObjectLegalHold 및 
s3:GetBucketObjectLockConfiguration 가 필요합니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/batch-ops-legal-hold.html 
설명 2: 
ALB 를 오리진으로 사용할 수 있음 
원본이 하나 이상의 Amazon EC2 인스턴스에서 호스트되는 하나 이상의 HTTP 서버(웹 서버)인 
경우 Application Load Balancer 를 사용하여 인스턴스에 트래픽을 분산할 수 있습니다. Application 
Load Balancer 를 CloudFront 의 원본으로 사용하는 방법에 대한 자세한 내용은 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/batch-ops-legal-hold.html 
Q110 
소셜 미디어 회사는 사용자가 웹사이트에 이미지를 업로드할 수 있도록 합니다. 웹 사이트는 
Amazon EC2 인스턴스에서 실행됩니다. 업로드 요청 중에 웹 사이트는 이미지의 크기를 표준 
크기로 조정하고 크기가 조정된 이미지를 Amazon S3 에 저장합니다. 사용자가 웹 사이트에 대한 
느린 업로드 요청을 경험하고 있습니다. 
회사는 애플리케이션 내 커플링을 줄이고 웹사이트 성능을 개선해야 합니다. 솔루션 설계자는 
이미지 업로드를 위한 운영상 가장 효율적인 프로세스를 설계해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자가 취해야 하는 조치의 조합은 무엇입니까? 
(2 개를 선택하세요.) 
A. S3 Glacier 에 이미지를 업로드하도록 애플리케이션을 구성합니다. 
B. 원본 이미지를 Amazon S3 에 업로드하도록 웹 서버를 구성합니다. 
C. 미리 서명된 URL 을 사용하여 각 사용자의 브라우저에서 Amazon S3 로 이미지를 직접 
업로드하도록 애플리케이션 구성 
D. 이미지가 업로드될 때 AWS Lambda 함수를 호출하도록 S3 이벤트 알림을 구성합니다. 기능을 
사용하여 이미지 크기를 조정합니다. 
E. 업로드된 이미지의 크기를 조정하기 위해 일정에 따라 AWS Lambda 함수를 호출하는 Amazon 
EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다. 
Answer: C, D 
https://www.examtopics.com/discussions/amazon/view/86471-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
B, D?? 
Q111 
한 회사는 최근에 메시지 처리 시스템을 AWS 로 마이그레이션했습니다. 시스템은 Amazon EC2 
인스턴스에서 실행되는 ActiveMQ 대기열로 메시지를 수신합니다. 메시지는 Amazon EC2 에서 
실행되는 소비자 애플리케이션에 의해 처리됩니다. 소비자 애플리케이션은 메시지를 처리하고 
결과를 Amazon EC2 에서 실행되는 MySQL 데이터베이스에 씁니다. 회사는 이 애플리케이션이 
낮은 운영 복잡성으로 고가용성을 갖기를 원합니다. 
가장 높은 가용성을 제공하는 아키텍처는 무엇입니까? 
A. 다른 가용 영역에 두 번째 ActiveMQ 서버를 추가합니다. 다른 가용 영역에 소비자 EC2 
인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다. 
B. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 다른 가용 영역에 
소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다. 
C. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 다른 가용 영역에 
소비자 EC2 인스턴스를 추가합니다. 다중 AZ 가 활성화된 MySQL 용 Amazon RDS 를 사용합니다. 
D. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 두 가용 영역에 
걸쳐 소비자 EC2 인스턴스에 대한 Auto Scaling 그룹을 추가합니다. 다중 AZ 가 활성화된 
MySQL 용 Amazon RDS 를 사용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85910-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 데이터베이스를 복제하는 것은 시간이 매우 걸리는 일임. 고가용성을 위해서라면 다중 AZ 를 
사용하는 것이 좋음. 
B(X) : A 와 마찬가지 이유로 오답. 
C(X) : D 가 더 좋음. 
D(O) : 평소에는 Standby 브로커 인스턴스에 낮은 트래픽 기준으로 AWS 리소스를 사용하여 
비용을 절감하다가 Active 브로커 인스턴스가 다운되어 Standby 브로커 인스턴스 쪽으로 트래픽이 
몰려오면 Auto Scaling 을 통해 대처. 
일반적으로 한 번에 하나의 브로커 인스턴스만 활성 상태이고, 다른 브로커 인스턴스는 대기 
상태입니다. 브로커 인스턴스 중 하나가 제대로 작동하지 않거나 유지 관리 중이면 Amazon MQ 가 
비활성 인스턴스를 서비스 중지하는 데 잠깐 시간이 걸립니다. 그런 다음 정상 대기 인스턴스가 
활성화되고 들어오는 통신을 수신하기 시작할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/amazon-mq/latest/developer-guide/active-standby-broker
-deployment.html 
설명 2: 
Amazon S3 는 확장성이 뛰어나고 내구성이 뛰어난 객체 스토리지 서비스로, 웹 어디에서나 원하는 
양의 데이터를 저장하고 검색할 수 있습니다. 사용자는 미리 서명된 URL 을 사용하여 각 사용자의 
브라우저에서 Amazon S3 로 직접 이미지를 업로드하도록 애플리케이션을 구성할 수 있습니다. 
미리 서명된 URL 은 제한된 시간 동안 특정 작업(예: 객체 업로드)으로 S3 버킷의 객체에 대한 
액세스 권한을 부여하는 URL 입니다. 사용자는 AWS SDK 또는 AWS CLI 를 사용하여 프로그래밍 
방식으로 미리 서명된 URL 을 생성할 수 있습니다. 미리 서명된 URL 을 사용하면 이미지를 웹 
서버에 먼저 보낼 필요가 없으므로 사용자는 애플리케이션 내에서 결합을 줄이고 웹 사이트 
성능을 향상시킬 수 있습니다. 
AWS Lambda 는 이벤트에 대한 응답으로 코드를 실행하고 기본 컴퓨팅 리소스를 자동으로 
관리하는 서버리스 컴퓨팅 서비스입니다. 사용자는 이미지가 업로드될 때 AWS Lambda 함수를 
호출하도록 S3 이벤트 알림을 구성할 수 있습니다. S3 이벤트 알림은 객체 생성 또는 삭제와 같은 
S3 버킷에서 특정 이벤트가 발생할 때 사용자가 알림을 받을 수 있도록 하는 기능입니다. 
사용자는 이미지 크기를 조정하고 동일한 S3 버킷 또는 다른 S3 버킷에 다시 저장하는 Lambda 
함수를 호출하도록 S3 이벤트 알림을 구성할 수 있습니다. 이러한 방식으로 사용자는 웹 서버에서 
Lambda 로 이미지 크기 조정 작업을 오프로드할 수 있습니다. 
Q112 
회사는 들어오는 요청을 처리하는 온프레미스 서버 집합에서 컨테이너화된 웹 애플리케이션을 
호스팅합니다. 요청 수가 빠르게 증가하고 있습니다. 온프레미스 서버는 증가된 요청 수를 처리할 
수 없습니다. 회사는 최소한의 코드 변경과 최소한의 개발 노력으로 애플리케이션을 AWS 로 
옮기기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Container Service(Amazon ECS)에서 AWS Fargate 를 사용하여 Service Auto 
Scaling 으로 컨테이너화된 웹 애플리케이션을 실행합니다. Application Load Balancer 를 사용하여 
수신 요청을 배포합니다. 
B. 두 개의 Amazon EC2 인스턴스를 사용하여 컨테이너화된 웹 애플리케이션을 호스팅합니다. 
Application Load Balancer 를 사용하여 수신 요청을 배포합니다. 
C. 지원되는 언어 중 하나를 사용하는 새 코드와 함께 AWS Lambda 를 사용합니다. 로드를 
지원하기 위해 여러 Lambda 함수를 생성합니다. Amazon API Gateway 를 Lambda 함수에 대한 
진입점으로 사용합니다. 
D. AWS ParallelCluster 와 같은 고성능 컴퓨팅(HPC) 솔루션을 사용하여 적절한 규모로 들어오는 
요청을 처리할 수 있는 HPC 클러스터를 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85913-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS Fargate 는 사용자가 Amazon EC2 인스턴스의 서버 또는 클러스터를 관리할 필요 없이 
컨테이너를 실행할 수 있게 해주는 서버리스 컴퓨팅 엔진입니다. 사용자는 Amazon Elastic 
Container Service(Amazon ECS)에서 AWS Fargate 를 사용하여 Service Auto Scaling 으로 
컨테이너화된 웹 애플리케이션을 실행할 수 있습니다. 
Amazon ECS 는 Docker 와 Kubernetes 를 모두 지원하는 완전관리형 컨테이너 오케스트레이션 
서비스입니다. Service Auto Scaling 은 사용자가 CPU 사용률 또는 요청 수와 같은 CloudWatch 
지표를 기반으로 ECS 서비스에서 원하는 작업 수를 조정할 수 있는 기능입니다. 사용자는 
Amazon ECS 에서 AWS Fargate 를 사용하여 애플리케이션을 컨테이너에 패키징하고 CPU 및 
메모리 요구 사항을 지정하기만 하면 되므로 최소한의 코드 변경과 최소한의 개발 노력으로 
애플리케이션을 AWS 로 마이그레이션할 수 있습니다. 
사용자는 Application Load Balancer 를 사용하여 수신 요청을 분산할 수도 있습니다. Application 
Load Balancer 는 애플리케이션 계층에서 작동하고 요청 내용에 따라 대상으로 트래픽을 
라우팅하는 로드 밸런서입니다. 사용자는 ECS 작업을 Application Load Balancer 의 대상으로 
등록하고 경로 또는 호스트 헤더를 기반으로 요청을 다른 대상 그룹으로 라우팅하도록 리스너 
규칙을 구성할 수 있습니다. 사용자는 Application Load Balancer 를 사용하여 웹 애플리케이션의 
가용성과 성능을 개선할 수 있습니다. 
컨테이너화된 웹 응용 프로그램이 핵심. Fargate + ECS 조합인 A 가 정답. 
Q113 
회사는 보고를 위해 50TB 의 데이터를 사용합니다. 회사는 이 데이터를 온프레미스에서 AWS 로 
이동하려고 합니다. 회사 데이터 센터의 사용자 지정 응용 프로그램은 매주 데이터 변환 작업을 
실행합니다. 회사는 데이터 이전이 완료되고 가능한 한 빨리 이전 프로세스를 시작해야 할 때까지 
응용 프로그램을 일시 중지할 계획입니다. 
데이터 센터에는 추가 워크로드에 사용할 수 있는 네트워크 대역폭이 없습니다. 솔루션 설계자는 
데이터를 전송하고 AWS 클라우드에서 계속 실행되도록 변환 작업을 구성해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS DataSync 를 사용하여 데이터를 이동합니다. AWS Glue 를 사용하여 사용자 지정 변환 
작업을 생성합니다. 
B. AWS Snowcone 디바이스에 데이터를 이동하도록 주문합니다. 장치에 변환 응용 프로그램을 
배포합니다. 
C. AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 데이터를 장치에 복사합니다. 
AWS Glue 를 사용하여 사용자 지정 변환 작업을 생성합니다. 
D. Amazon EC2 컴퓨팅이 포함된 AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 
데이터를 장치에 복사합니다. AWS 에서 새 EC2 인스턴스를 생성하여 변환 애플리케이션을 
실행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85912-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
추가 워크로드에 사용할 네트워크 대역폭이 없다는 게 핵심. 따라서 Snowball 디바이스가 필요. 
A(X) : 추가 워크로드에 사용할 네트워크 대역폭이 없다고 했으므로 DataSync 는 사용 불가. 
B(X) : Snowcone 으로 50TB 는 어림도 없음. 그리고 Snowcone 을 사용해서 업로드하는 방법은 
DataSync 를 사용하거나 AWS 로 다시 반송(?)하는 방법 뿐인데 DataSync 는 추가 워크로드에 
사용할 네트워크 대역폭이 없어서 불가능하다고 A 에서 이미 설명했고, AWS 로 다시 보내는 건 
시간이 너무 걸리고 번거로움. 
Snowcone 디바이스를 사용하여 디바이스를 AWS 로 배송하여 오프라인으로 또는 AWS 
DataSync 를 사용하여 온라인으로 데이터를 수집, 처리 및 AWS 클라우드로 이동할 수 있습니다. 
Snowcone 은 디바이스를 AWS 로 다시 배송하여 최대 8TB 또는 14TB 의 데이터를 AWS 
클라우드로 전송할 수 있는 빠르고 저렴한 방법을 제공합니다. 
https://docs.aws.amazon.com/snowball/latest/snowcone-guide/snowcone-what-is-snowcone.
html 
C(O) : Snowball Edge Storage Optimized 는 수십 테라바이트(TB)~페타바이트(PB)의 고용량 
데이터를 안전하고 신속하게 AWS 로 전송해야 할 때 선택할 수 있는 가장 적합한 옵션입니다. 이 
옵션은 대규모 데이터 전송 및 사전 처리 사용 사례를 위해 최대 80TB 의 가용 HDD 스토리지, 
40 개의 vCPU, 1TB 의 SATA SSD 스토리지 및 최대 40Gb 네트워크 연결을 제공합니다. 
https://aws.amazon.com/ko/snowball/faqs/ 
AWS Glue 를 사용하면 70 개 이상의 다양한 데이터 소스를 검색하여 연결하고 중앙 집중식 데이터 
카탈로그에서 데이터를 관리할 수 있습니다. 추출, 변환, 로드(ETL) 파이프라인을 시각적으로 생성, 
실행, 모니터링하여 데이터 레이크에 데이터를 로드할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html 
D(X) : 따로 변환 애플리케이션을 EC2 인스턴스에서 실행하므로 운영 오버헤드가 만만치 않음. 
Q114 
한 회사는 사용자가 사진을 업로드하고 이미지에 액자를 추가할 수 있는 이미지 분석 응용 
프로그램을 만들었습니다. 사용자는 이미지와 메타데이터를 업로드하여 이미지에 추가할 사진 
프레임을 나타냅니다. 애플리케이션은 단일 Amazon EC2 인스턴스와 Amazon DynamoDB 를 
사용하여 메타데이터를 저장합니다. 
응용 프로그램이 대중화되고 사용자 수가 증가하고 있습니다. 회사는 동시 접속자 수가 시간과 
요일에 따라 크게 달라질 것으로 예상하고 있습니다. 회사는 증가하는 사용자 기반의 요구 사항을 
충족하도록 애플리케이션을 확장할 수 있는지 확인해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Lambda 를 사용하여 사진을 처리합니다. 사진과 메타데이터를 DynamoDB 에 저장합니다. 
B. Amazon Kinesis Data Firehose 를 사용하여 사진을 처리하고 사진과 메타데이터를 저장합니다. 
C. AWS Lambda 를 사용하여 사진을 처리합니다. Amazon S3 에 사진을 저장합니다. DynamoDB 를 
유지하여 메타데이터를 저장합니다. 
D. EC2 인스턴스 수를 3 개로 늘립니다. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block 
Store(Amazon EBS) 볼륨을 사용하여 사진과 메타데이터를 저장합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85189-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : DynamoDB 는 데이터베이스 서비스이기 떄문에 이미지를 저장하기에는 적절치 않음. 
B(X) : Amazon Kinesis Data Firehose 는 저장 기능이 없고 전송 기능만 있음. 
Kinesis Data Firehose 는 스트리밍 ETL 솔루션입니다. 스트리밍 데이터를 캡처하고 변환한 후 
Amazon S3, Amazon Redshift, Amazon OpenSearch Service 및 Splunk 로 로드하여 이미 사용하고 
있는 기존 비즈니스 인텔리전스 도구 및 대시보드를 통해 거의 실시간으로 분석할 수 있습니다. 
https://aws.amazon.com/ko/kinesis/data-firehose/faqs/ 
C(O) : 정답. 
D(X) : 사용자 수가 증가하고 있으므로 프로비저닝은 적절치 않음. 
설명 2: 
이 솔루션은 확장성, 성능 및 가용성 요구 사항을 충족합니다. AWS Lambda 는 사진을 병렬로 
처리하고 수요에 따라 자동으로 확장 또는 축소할 수 있습니다. 
Amazon S3 는 사진과 메타데이터를 안정적이고 내구성 있게 저장할 수 있으며 고가용성과 짧은 
지연 시간을 제공합니다. DynamoDB 는 메타데이터를 효율적으로 저장하고 일관된 성능을 제공할 
수 있습니다. 또한 이 솔루션은 EC2 인스턴스 및 EBS 볼륨 관리의 비용과 복잡성을 줄입니다. 
DynamoDB 에 사진을 저장하는 것은 스토리지 비용을 증가시키고 처리량을 제한할 수 있으므로 A 
옵션은 올바르지 않습니다. 
옵션 B 는 Kinesis Data Firehose 가 사진 처리용이 아니라 S3 또는 Redshift 와 같은 대상으로 
데이터 스트리밍용으로 설계되었기 때문에 올바르지 않습니다. 
옵션 D 는 EC2 인스턴스 수를 늘리고 프로비저닝된 IOPS SSD 볼륨을 사용하는 것이 로드 밸런서 
및 애플리케이션 코드에 따라 확장성을 보장하지 않기 때문에 올바르지 않습니다. 또한 인프라 
관리 비용과 복잡성도 증가합니다. 
https://www.quora.com/How-can-I-use-DynamoDB-for-storing-metadata-for-Amazon-S3-obj
ects 
Q115 
의료 기록 회사는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 
애플리케이션은 Amazon S3 에 저장된 고객 데이터 파일을 처리합니다. EC2 인스턴스는 퍼블릭 
서브넷에서 호스팅됩니다. EC2 인스턴스는 인터넷을 통해 Amazon S3 에 액세스하지만 다른 
네트워크 액세스는 필요하지 않습니다. 
새로운 요구 사항은 파일 전송을 위한 네트워크 트래픽이 인터넷을 통해 전송되지 않고 개인 
경로를 사용하도록 규정하고 있습니다. 
솔루션 설계자가 이 요구 사항을 충족하기 위해 권장해야 하는 네트워크 아키텍처 변경 사항은 
무엇입니까? 
A. NAT 게이트웨이를 생성합니다. NAT 게이트웨이를 통해 Amazon S3 로 트래픽을 전송하도록 
퍼블릭 서브넷에 대한 라우팅 테이블을 구성합니다. 
B. S3 접두사 목록에 대한 트래픽만 허용되도록 아웃바운드 트래픽을 제한하도록 EC2 인스턴스에 
대한 보안 그룹을 구성합니다. 
C. EC2 인스턴스를 프라이빗 서브넷으로 이동합니다. Amazon S3 용 VPC 엔드포인트를 생성하고 
엔드포인트를 프라이빗 서브넷의 라우팅 테이블에 연결합니다. 
D. VPC 에서 인터넷 게이트웨이를 제거합니다. AWS Direct Connect 연결을 설정하고 Direct 
Connect 연결을 통해 Amazon S3 로 트래픽을 라우팅합니다. 
Answer: C  
https://www.examtopics.com/discussions/amazon/view/86031-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
S3 에 액세스하지만 다른 네트워크 액세스는 필요하지 않음 = S3 Gateway Endpoint. 
게이트웨이 엔드포인트는 인터넷 게이트웨이나 VPC 용 NAT 디바이스 없이 Amazon S3 및 
DynamoDB 에 안정적인 연결을 제공합니다. 게이트웨이 엔드포인트는 AWS PrivateLink 를 
활성화하지 않습니다. 
https://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html 
설명 2: 
프라이빗 경로를 통한 파일 전송의 새로운 요구 사항을 충족하려면 EC2 인스턴스를 인터넷에 직접 
액세스할 수 없는 프라이빗 서브넷으로 이동해야 합니다. 이렇게 하면 파일 전송을 위한 트래픽이 
인터넷을 통해 이동하지 않습니다. EC2 인스턴스가 Amazon S3 에 액세스할 수 있도록 Amazon 
S3 용 VPC 엔드포인트를 생성할 수 있습니다. VPC 엔드포인트를 사용하면 인터넷을 통해 트래픽을 
전송하지 않고도 VPC 내의 리소스가 다른 서비스의 리소스와 통신할 수 있습니다. VPC 
엔드포인트를 프라이빗 서브넷의 라우팅 테이블에 연결하면 EC2 인스턴스가 VPC 내의 프라이빗 
연결을 통해 Amazon S3 에 액세스할 수 있습니다. 
Q116 
회사는 회사 웹 사이트에 널리 사용되는 CMS(콘텐츠 관리 시스템)를 사용합니다. 그러나 필요한 
패치 및 유지 관리가 부담됩니다. 회사는 웹사이트를 재설계하고 있으며 새로운 솔루션을 원합니다. 
웹사이트는 1 년에 4 번 업데이트되며 사용 가능한 동적 콘텐츠가 필요하지 않습니다. 솔루션은 
높은 확장성과 향상된 보안을 제공해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 변경 조합은 무엇입니까? (2 개를 
선택하세요.) 
A. HTTPS 기능을 사용하도록 웹 사이트 앞에 Amazon CloudFront 를 구성합니다. 
B. 웹 사이트 앞에 AWS WAF 웹 ACL 을 배포하여 HTTPS 기능을 제공합니다. 
C. 웹 사이트 콘텐츠를 관리하고 제공하기 위해 AWS Lambda 함수를 생성 및 배포합니다. 
D. 새 웹 사이트와 Amazon S3 버킷을 생성합니다. 정적 웹 사이트 호스팅이 활성화된 S3 버킷에 
웹 사이트를 배포합니다. 
E. 새 웹사이트를 만듭니다. Application Load Balancer 뒤에서 Amazon EC2 인스턴스의 Auto 
Scaling 그룹을 사용하여 웹 사이트를 배포합니다. 
Answer: A, D  
https://www.examtopics.com/discussions/amazon/view/85996-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
지문은 정적 웹 사이트 호스팅에 대해서 설명하고 있음. 정적 웹사이트 호스팅에 관한 건 아래의 
링크를 참조할 것. 
https://aws.amazon.com/ko/getting-started/projects/build-serverless-web-app-lambda-apigat
eway-s3-dynamodb-cognito/module-1/ 
참고로 지문에서 높은 확장성을 요구하고 있는데, 높은 확장성이란 별 거 없고 정적 웹 사이트 
호스팅 환경을 구축하면 그게 높은 확장성을 갖춘 것. 
정적 웹 사이트 호스팅은 비용과 유지 관리 필요성이 가장 적은 옵션이고(예: 유지 관리해야 할 
서버가 없음), 높은 수준의 신뢰성과 [[[확장성]]]을 제공하기 때문입니다.  
https://aws.amazon.com/ko/getting-started/hands-on/host-static-website/faq/ 
A(O) : 뷰어가 HTTPS 를 사용할 것을 요청하도록 CloudFront 를 구성할 수 있습니다. 이렇게 하면 
CloudFront 가 뷰어와 통신할 때 연결이 암호화됩니다. 또한 CloudFront 가 오리진과 HTTPS 를 
사용하도록 구성할 수 있습니다. 이렇게 하면 CloudFront 가 오리진과 통신할 때 연결이 
암호화됩니다. 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/using-https.html 
B(X) : AWS Web ACL 은 HTTP(S) 웹 요청을 세부적으로 제어할 수 있게 해주는 것. 
웹 ACL (웹 ACL) 를 사용하면 보호된 리소스가 응답하는 모든 HTTP (S) 웹 요청을 세부적으로 
제어할 수 있게 해줍니다. 
https://docs.aws.amazon.com/ko_kr/waf/latest/developerguide/web-acl.html 
C(X) : 1 년에 4 번만 업데이트할 건데 그냥 Lambda 안 쓰고 수동으로 올려도 됨. 
D(O) : 동적 콘텐츠가 필요하지 않다고 했으므로 정적 웹사이트 호스팅. 따라서 S3 버킷 + 
CloudFront 조합. CloudFront 는 ▲위 선택지 A 번에서 이미 준비되었으므로 S3 버킷만 준비하면 
됨. 
E(X) : 정적 웹사이트 호스팅은 서버리스로서 EC2 를 사용할 필요가 없음. 
정적 웹 사이트 호스팅은 비용과 유지 관리 필요성이 가장 적은 옵션이고(예: 유지 관리해야 할 
서버가 없음) 
https://aws.amazon.com/ko/getting-started/hands-on/host-static-website/faq/ 
설명 2: 
A -> 클라이언트에서 HTTPS 를 요구하도록 CloudFront 를 구성할 수 있습니다(보안 강화). 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/using-https-view
ers-to-cloudfront.html 
D -> S3 에 정적 웹 사이트를 저장하면 확장성이 제공되고 운영 오버헤드가 줄어듭니다. 그런 다음 
애플리케이션 LB 및 EC2 인스턴스를 구성합니다(따라서 E 는 제외됨). 
Q117 
회사는 Amazon CloudWatch Logs 로그 그룹에 애플리케이션 로그를 저장합니다. 새로운 정책에 
따라 회사는 거의 실시간으로 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 모든 
애플리케이션 로그를 저장해야 합니다. 
최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)로 스트리밍하도록 
CloudWatch Logs 구독을 구성합니다. 
B. AWS Lambda 함수를 생성합니다. 로그 그룹을 사용하여 함수를 호출하여 Amazon OpenSearch 
Service(Amazon Elasticsearch Service)에 로그를 기록합니다. 
C. Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. 전송 스트림 소스로 로그 그룹을 
구성합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service)를 전송 스트림의 
대상으로 구성합니다. 
D. 각 애플리케이션 서버에 Amazon Kinesis Agent 를 설치하고 구성하여 Amazon Kinesis Data 
Streams 에 로그를 전달합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service)에 
로그를 전달하도록 Kinesis Data Streams 를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85802-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
CloudWatch Logs 구독을 통해 실시간에 가깝게 Amazon OpenSearch Service 클러스터로 수신한 
데이터를 스트리밍하도록 CloudWatch Logs 로그 그룹을 구성할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.h
tml 
정답은 A. 
최소한의 운영헤드, 기본으로 cloudwatch log - opensearch 간 연동을 제공함 
참고: 
https://computingforgeeks.com/stream-logs-in-aws-from-cloudwatch-to-elasticsearch/ 
Q118 
회사는 여러 가용 영역의 Amazon EC2 인스턴스에서 실행되는 웹 기반 애플리케이션을 구축하고 
있습니다. 웹 애플리케이션은 약 900TB 크기의 텍스트 문서 저장소에 대한 액세스를 제공합니다. 
회사는 웹 응용 프로그램이 수요가 많은 기간을 경험할 것으로 예상합니다. 솔루션 설계자는 
텍스트 문서의 스토리지 구성 요소가 애플리케이션의 요구 사항을 항상 충족할 수 있도록 확장할 
수 있는지 확인해야 합니다. 회사는 솔루션의 전체 비용에 대해 우려하고 있습니다. 
어떤 스토리지 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? 
A. Amazon Elastic Block Store(Amazon EBS) 
B. Amazon Elastic File System(Amazon EFS) 
C. Amazon OpenSearch Service(Amazon Elasticsearch Service) 
D. Amazon S3 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/86512-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
Amazon S3 는 가장 저렴하고 어디서나 액세스할 수 있습니다. 
Amazon S3 (Simple Storage Service)는 확장성이 뛰어나고 비용 효율적인 스토리지 서비스입니다. 
시나리오에서 언급한 900TB 의 텍스트 문서와 같은 대용량 데이터를 저장하는 데 적합합니다. 
S3 는 높은 내구성, 가용성 및 성능을 제공합니다. 
옵션 A (Amazon EBS)는 개별 EC2 인스턴스용으로 설계된 블록 스토리지이며 대용량 데이터의 
경우 S3 만큼 원활하고 비용 효율적으로 확장되지 않을 수 있습니다. 
옵션 B (Amazon EFS)는 확장 가능한 파일 스토리지 서비스이지만 특히 예상 스토리지 크기가 
900TB 인 경우 S3 에 비해 가장 비용 효율적인 옵션이 아닐 수 있습니다. 
옵션 C( Amazon OpenSearch 서비스)는 검색 및 분석 서비스이며 텍스트 문서의 기본 스토리지 
솔루션으로 적합하지 않을 수 있습니다. 
요약하면 Amazon S3 는 웹 애플리케이션에 필요한 대규모 텍스트 문서 리포지토리를 저장하기 
위한 높은 확장성, 비용 효율성 및 내구성을 제공하므로 권장되는 선택입니다. 
Q119 
글로벌 회사는 Amazon API Gateway 를 사용하여 us-east-1 리전 및 ap-southeast-2 리전의 
로열티 클럽 사용자를 위한 REST API 를 설계하고 있습니다. 솔루션 설계자는 SQL 주입 및 교차 
사이트 스크립팅 공격으로부터 여러 계정에서 이러한 API Gateway 관리 REST API 를 보호하는 
솔루션을 설계해야 합니다. 
최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 두 리전에 AWS WAF 를 설정합니다. 리전 웹 ACL 을 API 단계와 연결합니다. 
B. 두 리전에 AWS Firewall Manager 를 설정합니다. AWS WAF 규칙을 중앙에서 구성합니다. 
C. 목욕 리전에서 AWS Shield 를 설정합니다. 리전 웹 ACL 을 API 단계와 연결합니다. 
D. 한 리전에서 AWS Shield 를 설정합니다. 리전 웹 ACL 을 API 단계와 연결합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/86450-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
[여러 계정]에서 SQL 주입, XSS 공격, DDoS 등을 방어하려면 AWS Firewall Manager 가 적격. 
AWS Firewall Manager 는 AWS WAF 용 관리형 규칙과 통합되므로, 사전에 구성된 WAF 규칙을 
애플리케이션에 손쉽게 배포할 수 있습니다. 사용자는 콘솔에서 클릭 몇 번으로 AWS Marketplace 
판매자가 제공 및 업데이트하는 관리형 규칙을 선택하고 Application Load Balancer, API Gateway 
및 Amazon CloudFront 인프라에서 일관되게 해당 규칙을 배포할 수 있습니다. 
https://aws.amazon.com/ko/firewall-manager/ 
Q120 
한 회사는 us-west-2 리전의 NLB(Network Load Balancer) 뒤에 있는 3 개의 Amazon EC2 
인스턴스에 자체 관리형 DNS 솔루션을 구현했습니다. 회사 사용자의 대부분은 미국과 유럽에 
있습니다. 회사는 솔루션의 성능과 가용성을 개선하기를 원합니다. 회사는 eu-west-1 리전에서 
3 개의 EC2 인스턴스를 시작 및 구성하고 EC2 인스턴스를 새 NLB 의 대상으로 추가합니다. 
회사에서 트래픽을 모든 EC2 인스턴스로 라우팅하는 데 사용할 수 있는 솔루션은 무엇입니까? 
A. 두 NLB 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 
생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포의 오리진으로 
사용합니다. 
B. AWS Global Accelerator 에서 표준 액셀러레이터를 생성합니다. us-west-2 및 eu-west-1 에서 
엔드포인트 그룹을 생성합니다. 엔드포인트 그룹에 대한 엔드포인트로 두 개의 NLB 를 
추가하십시오. 
C. 탄력적 IP 주소를 6 개의 EC2 인스턴스에 연결합니다. 6 개의 EC2 인스턴스 중 하나로 요청을 
라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 
생성합니다. Route 53 레코드를 배포의 오리진으로 사용합니다. 
D. 2 개의 NLB 를 2 개의 ALB(Application Load Balancer)로 교체합니다. 두 ALB 중 하나로 요청을 
라우팅하는 Amazon Route 53 지연 시간 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 
생성합니다. Route 53 레코드를 배포의 오리진으로 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85807-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 자체 관리형 DNS 솔루션을 사용하고 있다고 이미 지문에서 언급했음. 자체적으로 해결할 
수 있는 걸 Route 53 을 사용해서 추가적인 지출을 할 이유가 없음. 게다가 CDN 서비스를 
사용해야한다는 단서가 없는데 굳이 CDN 서비스를 끼워넣을 이유가 없음. 
B(O) : AWS Global Accelerator 는 애플리케이션 상태, 사용자의 위치 및 고객이 구성하는 정책의 
변경에 즉각적으로 대응하여 항상 성능에 기반한 최적의 엔드포인트로 사용자 트래픽을 
라우팅합니다......온프레미스 엔드포인트를 처리하도록 각 AWS 리전에 Network Load 
Balancer(NLB)를 구성할 수 있습니다. 그러면 이러한 NLB 가 AWS Global Accelerator 구성에서 
엔드포인트가 될 수 있습니다. 
https://aws.amazon.com/ko/global-accelerator/faqs/ 
C(X) : 탄력적 IP 주소를 AWS Global Accelerator 에 연결하는 게 더 효과적. 앞으로 인스턴스가 
늘어날 때마다 EC2 인스턴스에 탄력적 IP 를 부여할 건지? 
D(X) : 가능은 한데 A 와 같은 이유로 out. 그리고 굳이 귀찮게 ALB 로 교체할 이유가 없음. 
설명 2: 
표준 액셀러레이터의 경우 Global Accelerator 는 AWS 글로벌 네트워크를 사용하여 사용자가 
구성한 상태, 클라이언트 위치 및 정책을 기반으로 트래픽을 최적의 지역 엔드포인트로 라우팅하여 
애플리케이션의 가용성을 높입니다. 표준 액셀러레이터의 엔드포인트는 Network Load Balancer, 
Application Load Balancer, Amazon EC2 인스턴스 또는 하나의 AWS 리전 또는 여러 리전에 
위치한 탄력적 IP 주소일 수 있습니다. 
https://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.html 
Q121 
회사는 AWS에서 OLTP(온라인 트랜잭션 처리) 워크로드를 실행하고 있습니다. 이 워크로드는 다중 
AZ 배포에서 암호화되지 않은 Amazon RDS DB 인스턴스를 사용합니다. 일일 데이터베이스 
스냅샷은 이 인스턴스에서 가져옵니다. 
데이터베이스와 스냅샷이 앞으로 항상 암호화되도록 하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 최신 DB 스냅샷 사본을 암호화합니다. 암호화된 스냅샷을 복원하여 기존 DB 인스턴스를 
교체합니다. 
B. 새 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하고 여기에 스냅샷을 
복사합니다. DB 인스턴스에서 암호화를 활성화합니다. 
C. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷을 복사하고 암호화를 
활성화합니다. 암호화된 스냅샷을 기존 DB 인스턴스로 복원합니다. 
D. AWS Key Management Service(AWS KMS) 관리형 키(SSE-KMS)로 서버 측 암호화를 사용하여 
암호화된 Amazon S3 버킷에 스냅샷을 복사합니다. 
Answer: A  
https://www.examtopics.com/discussions/amazon/view/85941-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Amazon RDS 암호화된 DB 인스턴스의 경우 모든 로그, 백업 및 스냅샷이 암호화됩니다.  Amazon 
RDS DB 인스턴스의 암호화는 인스턴스를 생성할 때에만 가능하며 DB 인스턴스가 생성된 후에는 
불가능합니다. 다만 암호화되지 않은 스냅샷의 사본을 암호화할 수 있기 때문에 암호화되지 않은 
DB 인스턴스에 실질적으로 암호화를 추가할 수 있습니다. 즉, DB 인스턴스의 스냅샷을 만든 다음 
해당 스냅샷의 암호화된 사본을 만들 수 있습니다. 그런 다음 암호화된 스냅샷에서 DB 인스턴스를 
복구할 수 있고, 원본 DB 인스턴스의 암호화된 사본이 생깁니다. 
https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Ov
erview.Encryption.Limitations 
설명 2: 
https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.
html#USE 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/EBSEncryption.html 
Q122 
회사는 응용 프로그램의 데이터를 암호화해야 하는 개발자를 지원하기 위해 확장 가능한 키 관리 
인프라를 구축하려고 합니다. 
솔루션 설계자는 운영 부담을 줄이기 위해 무엇을 해야 합니까? 
A. MFA(다단계 인증)를 사용하여 암호화 키를 보호합니다. 
B. AWS Key Management Service(AWS KMS)를 사용하여 암호화 키를 보호합니다. 
C. AWS Certificate Manager(ACM)를 사용하여 암호화 키를 생성, 저장 및 할당합니다. 
D. IAM 정책을 사용하여 암호화 키를 보호할 수 있는 액세스 권한이 있는 사용자의 범위를 
제한합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85942-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(X) : MFA 는 다중 인증으로, 운영 부담 감소와는 아무런 상관 없음. 
B(O) : ""AWS KMS 는 암호화 작업에 사용되는 키를 쉽게 생성하고 제어할 수 있도록 지원하는 
관리형 서비스입니다. https://aws.amazon.com/ko/kms/faqs/ 
C(X) : ACM 은 SSL/TLS 인증서 관련 서비스. 
AWS Certificate Manager 는 AWS 서비스 및 연결된 내부 리소스에 사용할 공인 및 사설 
SSL/TLS(Secure Sockets Layer/전송 계층 보안) 인증서를 손쉽게 프로비저닝, 관리 및 배포할 수 
있도록 지원하는 서비스입니다. 
https://aws.amazon.com/ko/certificate-manager/faqs/ 
D(X) : IAM 정책은 키 관리 서비스가 아니라 권한 관련 서비스. 
참고: 
https://aws.amazon.com/ko/kms/faqs/#:~:text=If%20you%20are%20a%20developer%20who%20
needs 
Q123 
회사에 두 개의 Amazon EC2 인스턴스에서 호스팅되는 동적 웹 애플리케이션이 있습니다. 
회사에는 SSL 종료를 수행하기 위해 각 인스턴스에 있는 자체 SSL 인증서가 있습니다. 
최근 트래픽이 증가하고 있으며 운영팀은 SSL 암호화 및 복호화로 인해 웹 서버의 컴퓨팅 용량이 
최대 한도에 도달했다고 판단했습니다. 
솔루션 설계자는 애플리케이션의 성능을 향상시키기 위해 무엇을 해야 합니까? 
A. AWS Certificate Manager(ACM)를 사용하여 새 SSL 인증서를 생성합니다. 각 인스턴스에 ACM 
인증서를 설치합니다. 
B. Amazon S3 버킷 생성 SSL 인증서를 S3 버킷으로 마이그레이션합니다. SSL 종료를 위해 버킷을 
참조하도록 EC2 인스턴스를 구성합니다. 
C. 다른 EC2 인스턴스를 프록시 서버로 생성합니다. SSL 인증서를 새 인스턴스로 
마이그레이션하고 기존 EC2 인스턴스에 직접 연결하도록 구성합니다. 
D. SSL 인증서를 AWS Certificate Manager(ACM)로 가져옵니다. ACM 의 SSL 인증서를 사용하는 
HTTPS 리스너로 Application Load Balancer 를 생성합니다. 
Answer: D  
https://www.examtopics.com/discussions/amazon/view/85943-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
AWS Certificate Manager 를 사용하면 인증서를 신속하게 요청하고 Elastic Load Balancer, Amazon 
CloudFront 배포, API Gateway 의 API 와 같은 ACM 통합 AWS 리소스에 배포하고 AWS Certificate 
Manager 가 인증서 갱신을 처리하도록 할 수 있습니다. 또한 내부 리소스에 대한 개인 인증서를 
만들고 중앙에서 인증서 수명 주기를 관리할 수 있습니다. 
설명 2: 
ACM(AWS Certificate Manager)이 필요한 상황. 
AWS Certificate Manager(ACM)는 AWS 서비스 및 연결된 내부 리소스에 사용할 공인 및 사설 
SSL/TLS(Secure Sockets Layer/전송 계층 보안) 인증서를 손쉽게 프로비저닝, 관리 및 배포할 수 
있도록 지원하는 서비스입니다.  
https://aws.amazon.com/ko/certificate-manager/ 
따라서 A,D 둘 중 하나가 정답. 
A(X) : 기존에 이미 사용하던 SSL 인증서가 있는데 하나 새로 만들 필요는 없음. 
D(O) : A 와 같은 이유로 정답. 
리스너는 연결 요청을 확인하는 프로세스입니다. 로드 밸런서를 생성할 때 리스너를 정의하면 
언제라도 로드 밸런서에 리스너를 추가할 수 있습니다. 암호화된 연결(SSL 오프로드라고도 함)을 
사용하는 HTTPS 리스너를 생성할 수 있습니다. 이 기능을 사용하면 로드 밸런서와 SSL 또는 TLS 
세션을 시작하는 클라이언트 간에 트래픽 암호화가 가능합니다. 
https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/create-https-listene
r.html 
Q124 
회사에 많은 Amazon EC2 인스턴스를 사용하여 완료하는 매우 동적인 배치 처리 작업이 있습니다. 
작업은 본질적으로 상태 비저장이며 부정적인 영향 없이 주어진 시간에 시작 및 중지할 수 있으며 
일반적으로 완료하는 데 총 60 분 이상이 걸립니다. 회사는 솔루션 설계자에게 작업 요구 사항을 
충족하는 확장 가능하고 비용 효율적인 솔루션을 설계하도록 요청했습니다. 
솔루션 설계자는 무엇을 권장해야 합니까? 
A. EC2 스팟 인스턴스를 구현합니다. 
B. EC2 예약 인스턴스 구매. 
C. EC2 온디맨드 인스턴스를 구현합니다. 
D. AWS Lambda 에서 처리를 구현합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/86038-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
EC2 스팟 인스턴스를 통해 사용자는 여분의 Amazon EC2 컴퓨팅 용량에 입찰할 수 있으며 
언제든지 시작 및 중지할 수 있는 상태 비저장 및 중단 가능한 워크로드를 위한 비용 효율적인 
솔루션이 될 수 있습니다. 
배치 처리 작업은 상태 비저장이고 언제든지 시작 및 중지할 수 있으며 일반적으로 완료하는 데 
60 분 이상 걸리므로 EC2 스팟 인스턴스는 이 워크로드에 적합합니다. 
설명 2: 
상태비저장, 시작 및 중지 가능이라는 단서를 볼 때 스팟 인스턴스가 적절함. 
Q125 
회사는 AWS 에서 2 계층 전자상거래 웹사이트를 운영합니다. 웹 계층은 트래픽을 Amazon EC2 
인스턴스로 보내는 로드 밸런서로 구성됩니다. 데이터베이스 계층은 Amazon RDS DB 인스턴스를 
사용합니다. EC2 인스턴스 및 RDS DB 인스턴스는 공용 인터넷에 노출되어서는 안 됩니다. EC2 
인스턴스는 타사 웹 서비스를 통한 주문 결제 처리를 완료하기 위해 인터넷 액세스가 필요합니다. 
애플리케이션은 고가용성이어야 합니다. 
이러한 요구 사항을 충족하는 구성 옵션의 조합은 무엇입니까? (2 개를 선택하세요.) 
A. Auto Scaling 그룹을 사용하여 프라이빗 서브넷에서 EC2 인스턴스를 시작합니다. 프라이빗 
서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다. 
B. 2 개의 가용 영역에 걸쳐 2 개의 프라이빗 서브넷과 2 개의 NAT 게이트웨이가 있는 VPC 를 
구성합니다. 프라이빗 서브넷에 Application Load Balancer 를 배포합니다. 
C. Auto Scaling 그룹을 사용하여 2 개의 가용 영역에 걸쳐 퍼블릭 서브넷에서 EC2 인스턴스를 
시작합니다. 프라이빗 서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다. 
D. 2 개의 가용 영역에 걸쳐 1 개의 퍼블릭 서브넷, 1 개의 프라이빗 서브넷 및 2 개의 NAT 
게이트웨이로 VPC 를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer 를 배포합니다. 
E. 2 개의 가용 영역에 걸쳐 2 개의 퍼블릭 서브넷, 2 개의 프라이빗 서브넷 및 2 개의 NAT 
게이트웨이로 VPC 를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer 를 배포합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/85221-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
시작하기 전에: EC2 인스턴스에 사용할 두 개의 가용 영역을 결정합니다. 이러한 각 가용 영역에서 
하나 이상의 퍼블릭 서브넷으로 Virtual Private Cloud(VPC)를 구성합니다. 
이러한 퍼블릭 서브넷은 로드 밸런서를 구성하는 데 사용됩니다. 대신 이러한 가용 영역의 다른 
서브넷에서 EC2 인스턴스를 시작할 수 있습니다. 
설명 2: 
・EC2 인스턴스와 RDS DB 인스턴스는 퍼블릭 인터넷에 노출되지 않아야 하므로 프라이빗 
서브넷에 위치해야 함. 
・그러면서도 EC2 인스턴스는 인터넷에 접속해야하니 NAT 서비스가 필요. NAT 
게이트웨이(기본적으로 퍼블릭 NAT 게이트웨이를 말함)는 퍼블릭 서브넷에 위치해야 함. 
퍼블릭 서브넷에서 퍼블릭 NAT 게이트웨이를 생성하고 생성 시 탄력적 IP 주소를 NAT 
게이트웨이와 연결해야 합니다. 트래픽을 NAT 게이트웨이에서 VPC 용 인터넷 게이트웨이로 
라우팅합니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-gateway.html 
・가용성 = Auto Scaling, Multi AZ 
A(O) : EC2 인스턴스와 RDS 인스턴스 모두 프라이빗 서브넷에 위치해야하며 고가용성을 
충족시켜야 하므로 다중 AZ 를 사용. 
B(X) : ALB 는 퍼블릭 서브넷에 위치해야 함. 
프라이빗 서브넷에 있는 Amazon EC2 인스턴스를 연결하려면 백엔드 인스턴스에서 사용하는 
프라이빗 서브넷과 동일한 가용 영역에 퍼블릭 서브넷을 생성합니다. 그런 다음 퍼블릭 서브넷을 
로드 밸런서와 연결합니다. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/public-load-balancer-private-e
c2/ 
C(X) : 퍼블릭 서브넷에서 EC2 인스턴스를 시작하기 때문에 오답. EC2 인스턴스는 퍼블릭 
인터넷에 노출되지 않아야 하므로 프라이빗 서브넷에 있어야 함. 
D(X) : 하나의 서브넷으로 두 개의 가용영역에 걸쳐 사용하는 것은 불가. 
각 서브넷은 완전히 하나의 가용 영역 내에 있어야 하며 여러 영역에 걸쳐 있을 수 없습니다. 
https://docs.aws.amazon.com/vpc/latest/userguide/configure-subnets.html#subnet-basics 
E(O) : 각 AZ 에 퍼블릭 서브넷은 1 개 있어야 하고(NAT 게이트웨이가 들어가야 하므로), 프라이빗 
서브넷은 1 개 이상 있어야 함(EC2 인스턴스와 RDS 가 들어갈 곳). 각 AZ 에 있는 퍼블릭 서브넷에 
NAT 게이트웨이가 하나씩 들어가야 각 가용영역에 있는 프라이빗 서브넷마다 인터넷에 액세스가 
가능한 상태가 되므로 NAT 게이트웨이는 총 2 개가 됨. 
따라서 2 개의 AZ 에 걸쳐 퍼블릭 서브넷 2, 프라이빗 서브넷 2, NAT 게이트웨이 2 개가 됨." 
Q126 
솔루션 설계자는 회사의 스토리지 비용을 줄이기 위한 솔루션을 구현해야 합니다. 회사의 모든 
데이터는 Amazon S3 Standard 스토리지 클래스에 있습니다. 회사는 모든 데이터를 최소 25 년 
동안 보관해야 합니다. 최근 2 년간의 데이터는 가용성이 높고 즉시 검색 가능해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 객체를 S3 Glacier Deep Archive 로 즉시 전환하도록 S3 수명 주기 정책을 설정하십시오. 
B. 2 년 후에 객체를 S3 Glacier Deep Archive 로 전환하도록 S3 수명 주기 정책을 설정합니다. 
C. S3 지능형 계층화를 사용합니다. 데이터가 S3 Glacier Deep Archive 에 보관되도록 보관 옵션을 
활성화합니다. 
D. 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 즉시 전환하고 2 년 후에 S3 
Glacier Deep Archive 로 전환하도록 S3 수명 주기 정책을 설정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/86731-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(X) : 가장 최근 2 년의 데이터는 즉시 검색할 수 있어야 하므로 콜드 스토리지는 부적절. 
B(O) : 정답 
C(X) : 가장 최근 2 년의 데이터는 모두 가용성이 높아야 하고 즉시 검색할 수 있어야하는 
데이터이므로 Intelligent-Tiering 이 따로 필요하진 않음. 
D(X) : One Zone-IA 는 고가용성 조건 불충족. 
https://aws.amazon.com/ko/about-aws/whats-new/2018/04/announcing-s3-one-zone-infrequ
ent-access-a-new-amazon-s3-storage-class/?nc1=h_ls 
Q127 
한 미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 비디오 
처리를 위한 가능한 최대 I/O 성능을 갖춘 최소 10TB 의 스토리지, 미디어 콘텐츠를 저장하기 위한 
300TB 의 매우 내구성 있는 스토리지, 더 이상 사용하지 않는 아카이브 미디어에 대한 요구 
사항을 충족하기 위해 900TB 의 스토리지가 필요합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 서비스 세트를 권장해야 합니까? 
A. 최고의 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 
스토리지를 위한 Amazon S3 Glacier 
B. 최고의 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon EFS, 
아카이브 스토리지를 위한 Amazon S3 Glacier 
C. 최고의 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 
Amazon EFS, 아카이브 스토리지를 위한 Amazon S3 
D. 최고의 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 
Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85432-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
고가용성이므로 Auto Scaling 이 들어간 C,D 둘 중 하나가 정답. EFS vs EBS 를 비교해보면 보통은 
EFS 가 정답인 경우가 많음. 일단 EBS 는 여러 EC2 인스턴스에서 동시 접속할 수 없다는 단점이 
치명적이기 때문. 
Amazon Elastic File System 은 전체 파일 시스템 액세스 의미 체계를 지원하는 표준 파일 시스템 
인터페이스를 제공합니다.  
https://docs.aws.amazon.com/efs/latest/ug/using-fs.html 
EBS 다중 연결 볼륨에서 표준 파일 시스템 작업은 지원되는 구성이 아닙니다. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/ebs-access-volumes-using-m
ulti-attach/ 
참조 
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html 
Q128 
회사에서 AWS 클라우드의 컨테이너에서 애플리케이션을 실행하려고 합니다. 이러한 
애플리케이션은 상태 비저장이며 기본 인프라 내에서 중단을 허용할 수 있습니다. 회사는 비용과 
운영 오버헤드를 최소화하는 솔루션이 필요합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon EC2 Auto Scaling 그룹의 스팟 인스턴스를 사용하여 애플리케이션 컨테이너를 
실행합니다. 
B. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 스팟 인스턴스를 
사용합니다. 
C. Amazon EC2 Auto Scaling 그룹의 온디맨드 인스턴스를 사용하여 애플리케이션 컨테이너를 
실행합니다. 
D. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 온디맨드 인스턴스를 
사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85404-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
중단을 허용할 수 있음 = 스팟 인스턴스. 컨테이너에서 애플리케이션 실행 = ECS, EKS 같은 
서비스. 답은 B. 
Q129 
회사에서 온프레미스에서 다중 계층 웹 애플리케이션을 실행하고 있습니다. 웹 애플리케이션은 
컨테이너화되어 있으며 사용자 레코드가 포함된 PostgreSQL 데이터베이스에 연결된 여러 Linux 
호스트에서 실행됩니다. 인프라 및 용량 계획을 유지 관리하는 운영 오버헤드가 회사의 성장을 
제한하고 있습니다. 솔루션 설계자는 애플리케이션의 인프라를 개선해야 합니다. 
솔루션 설계자는 이를 달성하기 위해 어떤 조합의 조치를 취해야 합니까? (2 개 선택) 
A. PostgreSQL 데이터베이스를 Amazon Aurora 로 마이그레이션합니다. 
B. Amazon EC2 인스턴스에서 호스팅할 웹 애플리케이션을 마이그레이션합니다. 
C. 웹 애플리케이션 콘텐츠에 대한 Amazon CloudFront 배포를 설정합니다. 
D. 웹 애플리케이션과 PostgreSQL 데이터베이스 간에 Amazon ElastiCache 를 설정합니다. 
E. Amazon Elastic Container Service(Amazon ECS)를 사용하여 AWS Fargate 에서 호스팅할 웹 
애플리케이션을 마이그레이션합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/86658-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
・컨테이너화 되어있음 = ECS(또는 EKS) + Fargate. 
A(O) : Amazon Aurora 는 PostgreSQL 과 호환되고 다중 리전 및 AZ 를 기본적으로 지원하므로 
인프라 및 용량 계획을 유지 관리 가능. 
Amazon Aurora 는 서버리스 및 기계 학습 기반 애플리케이션의 구축을 위한 규모에 따른 성능 및 
고가용성, 완전한 오픈 소스 MySQL 및 PostgreSQL 호환 버전과 광범위한 개발자 도구를 
제공….Amazon Aurora 는 데이터베이스 볼륨을 10GB 세그먼트로 자동으로 분리하여 여러 
디스크에 분산합니다. 데이터베이스 볼륨에서 각 10GB 청크가 3 개의 AZ 에 6 가지 방법으로 
복제됩니다. https://aws.amazon.com/ko/rds/aurora/faqs/ 
B(X) : 애플리케이션이 컨테이너화 되어있다고 했으므로 Fargate 사용이 더 적절. 
C(X) : CloudFront 는 CDN 서비스로 지문의 상황엔 적합치 않음. 
D(X) : ElastiCache 는 웹 애플리케이션과 DB 간 캐시 서비스로 지문의 상황엔 적합치 않음. 
E(O) : ECS + Fargate 로 컨테이너화된 애플리케이션 사용 가능. 
AWS Fargate Fargate 는 Amazon EC2 인스턴스의 서버나 클러스터를 관리할 필요 없이 컨테이너를 
실행하기 위해 Amazon ECS 에 사용할 수 있는 기술입니다. 
https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/userguide/what-is-fargate.html 
설명 2: 
Amazon Aurora 는 PostgreSQL 과 호환되는 완전히 관리되고 확장 가능하며 가용성이 높은 관계형 
데이터베이스 서비스입니다. 데이터베이스를 Amazon Aurora 로 마이그레이션하면 데이터베이스 
인프라를 유지 관리하는 운영 오버헤드가 줄어들고 회사는 애플리케이션 구축 및 확장에 집중할 
수 있습니다. AWS Fargate 는 사용자가 기본 EC2 인스턴스를 관리할 필요 없이 컨테이너를 실행할 
수 있도록 하는 완전 관리형 컨테이너 오케스트레이션 서비스입니다. 솔루션 설계자는 Amazon 
Elastic Container Service(Amazon ECS)와 함께 AWS Fargate 를 사용하여 웹 애플리케이션의 
확장성과 효율성을 개선하고 기본 인프라를 유지 관리하는 운영 오버헤드를 줄일 수 있습니다. 
Q130 
애플리케이션은 여러 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 Application 
Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 애플리케이션은 EC2 
인스턴스의 CPU 사용률이 40% 또는 거의 40%일 때 가장 잘 수행됩니다. 
솔루션 설계자는 그룹의 모든 인스턴스에서 원하는 성능을 유지하기 위해 무엇을 해야 합니까? 
A. Auto Scaling 그룹을 동적으로 확장하려면 간단한 확장 정책을 사용합니다. 
B. 대상 추적 정책을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다. 
C. AWS Lambda 함수를 사용하여 원하는 Auto Scaling 그룹 용량을 업데이트합니다. 
D. 예약된 조정 작업을 사용하여 Auto Scaling 그룹을 확장 및 축소합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/86659-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
CPU 사용률에 따라 Auto Scaling = Target Tracking Policy. 정답은 B. 
https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-targe
ttracking.html 
Q131 
한 회사에서 Amazon S3 버킷을 스토리지로 사용할 파일 공유 애플리케이션을 개발 중입니다. 
회사는 Amazon CloudFront 배포를 통해 모든 파일을 제공하려고 합니다. 회사는 S3 URL 에 대한 
직접 탐색을 통해 파일에 액세스하는 것을 원하지 않습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 각 S3 버킷에 대한 개별 정책을 작성하여 CloudFront 액세스에 대해서만 읽기 권한을 
부여합니다. 
B. IAM 사용자를 생성합니다. 사용자에게 S3 버킷의 객체에 대한 읽기 권한을 부여합니다. 
사용자를 CloudFront 에 할당합니다. 
C. CloudFront 배포 ID 를 보안 주체로 할당하고 대상 S3 버킷을 Amazon 리소스 이름(ARN)으로 
할당하는 S3 버킷 정책을 작성합니다. 
D. 원본 액세스 ID(OAI)를 생성합니다. CloudFront 배포에 OAI 를 할당합니다. OAI 만 읽기 권한을 
갖도록 S3 버킷 권한을 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85992-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-access-to-amazon-s3/ 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-content-
restricting-access-to-s3.html#private-content-restricting-access-to-s3-overview 
S3 + CloudFront 를 사용하는 상황에서 S3 에 직접 액세스하는 것을 막으려면 OAC 또는 OAI 를 
사용하면 됨. 
Amazon S3 버킷을 오리진으로 설정하여 CloudFront 를 사용하는 경우 다음과 같은 이점을 
제공하는 방식으로 CloudFront 및 Amazon S3 를 구성할 수 있습니다. ◎공개적으로 액세스할 수 
없도록 Amazon S3 버킷에 대한 액세스를 제한합니다. ◎뷰어(사용자)가 지정된 CloudFront 배포를 
통해서만 버킷의 콘텐츠에 액세스할 수 있도록 합니다. 즉, 뷰어가 버킷에서 직접 또는 의도하지 
않은 CloudFront 배포를 통해 콘텐츠에 액세스하는 것을 방지합니다. 이렇게 하려면 인증된 
요청을 Amazon S3 로 보내도록 CloudFront 를 구성하고 CloudFront 의 인증된 요청에 대한 
액세스만 허용하도록 Amazon S3를 구성합니다. CloudFront는 Amazon S3 오리진에 인증된 요청을 
전송하는 두 가지 방법으로 오리진 액세스 제어(OAC)와 오리진 액세스 ID(OAI)를 제공합니다. 
OAC 는 다음을 지원하므로 OAC 를 사용하는 것이 좋습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-content-
restricting-access-to-s3.html 
Q132 
회사 웹사이트는 사용자에게 다운로드 가능한 과거 실적 보고서를 제공합니다. 웹 사이트에는 전 
세계적으로 회사의 웹 사이트 요구 사항을 충족하도록 확장할 수 있는 솔루션이 필요합니다. 
솔루션은 비용 효율적이어야 하고 인프라 리소스 프로비저닝을 제한하며 가능한 가장 빠른 응답 
시간을 제공해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조합을 권장해야 합니까? 
A. Amazon CloudFront 및 Amazon S3 
B. AWS Lambda 및 Amazon DynamoDB 
C. Amazon EC2 Auto Scaling 이 있는 Application Load Balancer 
D. 내부 Application Load Balancer 가 있는 Amazon Route 53 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/86654-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
전 세계적으로 웹 사이트 요구 충족 = CloudFront.  
빠른 응답을 위한 Cloudfront 와 인프라를 최소화하기 위한 s3 
Q133 
회사는 온프레미스에서 Oracle 데이터베이스를 실행합니다. 회사는 AWS 로 마이그레이션하는 
과정에서 데이터베이스를 사용 가능한 최신 버전으로 업그레이드하려고 합니다. 회사는 또한 
데이터베이스에 대한 재해 복구(DR)를 설정하려고 합니다. 회사는 정상 운영 및 DR 설정을 위한 
운영 오버헤드를 최소화해야 합니다. 회사는 또한 데이터베이스의 기본 운영 체제에 대한 액세스를 
유지 관리해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션합니다. 다른 AWS 리전으로 
데이터베이스 복제를 설정합니다. 
B. Oracle 데이터베이스를 Oracle 용 Amazon RDS 로 마이그레이션합니다. 교차 리전 자동 백업을 
활성화하여 다른 AWS 리전에 스냅샷을 복제합니다. 
C. Oracle 데이터베이스를 Oracle 용 Amazon RDS Custom 으로 마이그레이션합니다. 다른 AWS 
리전의 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 
D. Oracle 데이터베이스를 Oracle 용 Amazon RDS 로 마이그레이션합니다. 다른 가용 영역에 대기 
데이터베이스를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85423-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
A?? 
설명: 
기본 운영 체제에 대한 액세스 유지 = Amazon RDS Custom. 
Amazon Relational Database Service(Amazon RDS) Custom 은 기본 OS 및 DB 환경에 액세스할 
필요가 있는 레거시, 사용자 지정, 패키지 애플리케이션을 위한 관리형 데이터베이스 
서비스입니다. 
https://aws.amazon.com/ko/about-aws/whats-new/2021/10/amazon-rds-custom-oracle/ 
참고: 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-custom.html 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/working-with-custom-oracle.html 
Q134 
한 회사에서 애플리케이션을 서버리스 솔루션으로 이동하려고 합니다. 서버리스 솔루션은 SL 을 
사용하여 기존 및 신규 데이터를 분석해야 합니다. 회사는 데이터를 Amazon S3 버킷에 
저장합니다. 데이터는 암호화가 필요하며 다른 AWS 리전에 복제해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 복제(CRR)를 
사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS 다중 리전 
kay(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다. 
B. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 복제(CRR)를 
사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS 다중 리전 
키(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon RDS 를 사용하여 데이터를 쿼리합니다. 
C. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 
다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 
사용합니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다. 
D. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 
다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 
사용합니다. Amazon RDS 를 사용하여 데이터를 쿼리합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/85993-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
A?? 
설명: 
A(X) : 최소한의 운영 오버헤드라고 했으므로 SSE-KMS 보다는 SSE-S3 가 AWS 에서 다 관리하기 
때문에 더 적합. 또한 회사는 데이터를 S3 버킷에 저장한다고 했으므로 기존 버킷이 있는 것이고, 
이는 현재 리전에서 새 S3 버킷을 생성할 필요가 없음을 의미. 그리고 지문에서 운영 오버헤드에 
대한 언급은 있어도 비용에 대한 언급은 없음. 
B(X) : S3 에 쿼리하는 건 RDS 가 아니라 Athena 가 더 적합. 
C(O) : KMS 필요없이 S3 측에서 암호화할 수 있음. 기존 버킷에 데이터를 로드하고 다른 리전으로 
복제하는 것이기 때문에 다른 리전에서도 기존 및 신규 데이터를 모두 사용할 수 있음. 
D(X) : B 와 같은 이유로 오답. 
Q135 
회사는 AWS 에서 워크로드를 실행합니다. 회사는 외부 공급자의 서비스에 연결해야 합니다. 
서비스는 공급자의 VPC 에서 호스팅됩니다. 회사 보안 팀에 따르면 연결은 비공개여야 하며 대상 
서비스로 제한되어야 합니다. 연결은 회사의 VPC 에서만 시작되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 회사의 VPC 와 공급자의 VPC 간에 VPC 피어링 연결을 생성합니다. 대상 서비스에 연결하도록 
라우팅 테이블을 업데이트합니다. 
B. 공급자에게 VPC 에 가상 프라이빗 게이트웨이를 생성하도록 요청합니다. AWS PrivateLink 를 
사용하여 대상 서비스에 연결합니다. 
C. 회사의 VPUpdate 라우팅 테이블의 퍼블릭 서브넷에 NAT 게이트웨이를 생성하여 대상 
서비스에 연결합니다. 
D. 공급자에게 대상 서비스에 대한 VPC 엔드포인트를 생성하도록 요청합니다. AWS PrivateLink 를 
사용하여 대상 서비스에 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85994-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(X) : 대상 서비스로 제한되어야 한다는 조건 불충족. VPC 내의 특정 애플리케이션이나 서비스에 
연결하려면 PrivateLInk 가 필요. 또한 연결은 회사의 VPC 에서만 시작되어야 한다는 점 불충족. 
설명 1: 
VPC 피어링을 사용하면 VPC 를 비공개로 연결할 수 있지만 AWS PrivateLink 를 사용하면 VPC 의 
애플리케이션이나 서비스를 VPC 피어링 연결에서 연결할 수 있는 엔드포인트로 구성할 수 
있습니다. (https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-peering.html) 
B(X) : Virtual Private Gateway 는 VPN 엔드포인트. 
가상 프라이빗 게이트웨이는 단일 VPC 에 연결할 수 있는 사이트 간 VPN 연결의 Amazon 측 VPN 
엔드포인트입니다. 
https://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/VPC_VPN.html 
C(X) : 대상 서비스로 제한되어야 한다는 조건 불충족. 퍼블릭 서브넷의 NAT 게이트웨이는 퍼블릭 
NAT 게이트웨이로서, IGW, VPC, 온프레미스 네트워크에 연결할 수 있지만 특정 서비스에만 
접속하도록 할 수 있다는 건 없음. 
""퍼블릭 서브넷에서 퍼블릭 NAT 게이트웨이를 생성하고 생성 시 탄력적 IP 주소를 NAT 
게이트웨이와 연결해야 합니다. 트래픽을 NAT 게이트웨이에서 VPC 용 인터넷 게이트웨이로 
라우팅합니다. 또는 퍼블릭 NAT 게이트웨이를 사용하여 다른 VPC 또는 온프레미스 네트워크에 
연결할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-gateway.html 
D(O) : A 번 참고. 
Q136 
회사는 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL 로 마이그레이션하고 
있습니다. 온-프레미스 데이터베이스는 온라인 상태를 유지하고 마이그레이션 중에 액세스할 수 
있어야 합니다. Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화된 상태를 유지해야 
합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자가 취해야 하는 조치의 조합은 무엇입니까? 
(2 개를 선택하세요.) 
A. 지속적인 복제 작업을 만듭니다. 
B. 온프레미스 데이터베이스의 데이터베이스 백업을 생성합니다. 
C. AWS Database Migration Service(AWS DMS) 복제 서버를 생성합니다. 
D. AWS Schema Conversion Tool(AWS SCT)을 사용하여 데이터베이스 스키마를 변환합니다. 
E. 데이터베이스 동기화를 모니터링하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 
생성합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/85438-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(O) : ongoing replication(진행중인 복제)은 CDC(변경 데이터 캡처)라고도 하며 소스 데이터 
스토어에서 진행 중인 변경 사항을 복제할 때 이 프로세스를 사용. 
(https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Task.CDC.html) 
이는 동기화된 상태를 만들어줌. "AWS DMS 를 사용하면 일회성 마이그레이션을 수행하고 지속적인 
변경 사항을 복제하여 소스와 대상을 동기화 상태로 유지할 수 있습니다. 
https://docs.aws.amazon.com/dms/latest/userguide/Welcome.html 
C(O) : DMS 는 대상이 소스와 동기화된 상태를 유지하도록 지속적 복제를 지원하지만, SCT 는 
그렇지 않습니다. AWS Database Migration Service(DMS)는 다양한 동종 및 이기종 데이터 복제를 
지원합니다. 
https://aws.amazon.com/ko/dms/faqs/?refid=bef7080f-573e-4a75-b22b-85f316173744 
설명 2: 
AWS Database Migration Service 는 Oracle 에서 Oracle 로의 동종 마이그레이션은 물론 Oracle 
또는 Microsoft SQL Server 에서 Amazon Aurora 로의 서로 다른 데이터베이스 플랫폼 간의 이기종 
마이그레이션을 지원합니다. AWS Database Migration Service 를 사용하면 지원되는 소스에서 
지원되는 대상으로 짧은 지연 시간으로 데이터를 지속적으로 복제할 수도 있습니다. 예를 들어 
여러 소스에서 Amazon Simple Storage Service(Amazon S3)로 복제하여 가용성과 확장성이 뛰어난 
데이터 레이크 솔루션을 구축할 수 있습니다. Amazon Redshift 로 데이터를 스트리밍하여 
데이터베이스를 페타바이트 규모의 데이터 웨어하우스로 통합할 수도 있습니다. 지원되는 소스 및 
대상 데이터베이스에 대해 자세히 알아보세요. 
https://aws.amazon.com/dms/ 
Q137 
회사는 AWS Organizations 를 사용하여 각 사업부에 대한 전용 AWS 계정을 생성하여 요청 시 각 
사업부의 계정을 독립적으로 관리합니다. 루트 이메일 수신자가 한 계정의 루트 사용자 이메일 
주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림을 놓치지 않기를 원합니다. 향후 알림은 
계정 관리자로 제한되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS 계정 루트 사용자 이메일 주소로 전송되는 알림 이메일 메시지를 조직의 모든 사용자에게 
전달하도록 회사 이메일 서버를 구성합니다. 
B. 모든 AWS 계정 루트 사용자 이메일 주소를 알림에 응답할 수 있는 소수의 관리자에게 
전달되는 배포 목록으로 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 
계정 대체 연락처를 구성합니다. 
C. 경보를 모니터링하고 해당 경보를 적절한 그룹에 전달할 책임이 있는 한 명의 관리자에게 모든 
AWS 계정 루트 사용자 이메일 메시지를 보내도록 구성합니다. 
D. 동일한 루트 사용자 이메일 주소를 사용하도록 기존의 모든 AWS 계정과 새로 생성된 모든 
계정을 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 계정 대체 
연락처를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/85997-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(X) : 향후 알림은 계정 관리자로 제한되어야 한다고 했으므로 오답. 
B(O) : AWS Organizations 콘솔에서 또는 AWS CLI 또는 AWS SDK 를 사용하여 프로그래밍 
방식으로 조직 내 계정의 대체 연락처를 업데이트할 수 있습니다. 조직의 관리 계정을 사용하여 
조직의 모든 계정에 대한 계정 설정을 보고 편집할 수 있습니다. 기본 계정 소유자는 루트 계정의 
이메일에 대한 모든 이메일 통신을 계속 수신합니다. 
https://docs.aws.amazon.com/accounts/latest/reference/manage-acct-update-contact-alternat
e.html 
C(X) : 루트 이메일 수신자가 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 놓쳤다고 
했는데, 선택지 C 의 방식은 기존의 방식과 동일함. 
D(X) : 향후 알림은 계정 관리자로 제한되어야 한다고 했으므로 오답. 
참고 
https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_best-practices_mgmt-
acct.html#best-practices_mgmt-acct_email-address 
Q138 
회사는 AWS 에서 전자 상거래 애플리케이션을 실행합니다. 모든 새 주문은 단일 가용 영역의 
Amazon EC2 인스턴스에서 실행되는 RabbitMQ 대기열에 마사지로 게시됩니다. 이러한 메시지는 
별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션에서 처리됩니다. 이 애플리케이션은 다른 
EC2 인스턴스의 PostgreSQL 데이터베이스에 세부 정보를 저장합니다. 모든 EC2 인스턴스는 
동일한 가용 영역에 있습니다. 
회사는 최소한의 운영 오버헤드로 최고의 가용성을 제공하도록 아키텍처를 재설계해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 대기열을 Amazon MQ 에서 RabbitMQ 인스턴스의 중복 쌍(활성/대기)으로 마이그레이션합니다. 
애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. 
PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling 그룹을 
생성합니다. 
B. 대기열을 Amazon MQ 에서 RabbitMQ 인스턴스의 중복 쌍(활성/대기)으로 마이그레이션합니다. 
애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. 
PostgreSQL용 Amazon RDS의 다중 AZ 배포에서 실행하도록 데이터베이스를 마이그레이션합니다. 
C. RabbitMQ 대기열을 호스팅하는 EC2 인스턴스용 다중 AZ Auto Scaling 그룹을 생성합니다. 
애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling 그룹을 생성합니다. 
PostgreSQL용 Amazon RDS의 다중 AZ 배포에서 실행하도록 데이터베이스를 마이그레이션합니다. 
D. RabbitMQ 대기열을 호스팅하는 EC2 인스턴스용 다중 AZ Auto Scaling 그룹을 생성합니다. 
애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling 그룹을 생성합니다. 
PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대한 세 번째 다중 AZ Auto Scaling 
그룹을 생성합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/85999-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
선택지는 활성/대기 인스턴스 쌍을 사용하는 A,B 와 대기열 호스팅 방식을 사용하는 C,D 로 
나눠짐. 
활성/대기 방식은 활성 인스턴스가 다운되어도 대기 인스턴스가 활성 인스턴스를 대체할 수 
있으므로 가용성이 높은 방식. 따라서 A,B 둘 중 하나가 답. 
PostgreSQL 데이터베이스를 사용하는 A 보다는 Amazon RDS for Postgre 를 사용하는 B 가 운영 
오버헤드 절감 효과가 큼. 
Amazon RDS 를 사용하면 클라우드에서 PostgreSQL 배포를 손쉽게 설정, 운영 및 확장할 수 
있습니다. Amazon RDS 에서는 비용 효율적이고 크기 조정 가능한 하드웨어 용량을 갖춘 확장 
가능한 PostgreSQL 을 몇 분 만에 배포할 수 있습니다. Amazon RDS 에서는 PostgreSQL 
소프트웨어 설치 및 업그레이드, 스토리지 관리, 고가용성 및 읽기 처리량을 위한 복제, 재해 
복구용 백업 등 복잡하고 시간 소모적인 관리 작업을 관리합니다. 
https://aws.amazon.com/ko/rds/postgresql/ 
설명 2: 
Amazon MQ 로 마이그레이션하면 대기열 관리의 오버헤드가 줄어듭니다. C 와 D 는 오답됩니다. 
A 와 B 사이에서 결정한다는 것은 EC2 용 AutoScaling 그룹 또는 Postgress 용 RDS(모두 다중 
AZ)로 이동하기로 결정하는 것을 의미합니다. RDS 옵션은 필요한 도구와 소프트웨어를 서비스로 
제공하므로 운영에 미치는 영향이 적습니다. 예를 들어 읽기 복제본과 같은 추가 노드를 DB 에 
추가하려는 노력을 고려하십시오. 
https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/activestandby-broker-deploy
ment.html 
Q139 
보고 팀은 Amazon S3 버킷에서 매일 파일을 수신합니다. 보고 팀은 이 초기 S3 버킷의 파일을 
수동으로 검토하고 Amazon QuickSight 와 함께 사용하기 위해 매일 같은 시간에 분석 S3 버킷으로 
복사합니다. 추가 팀이 초기 S3 버킷에 더 큰 크기의 더 많은 파일을 보내기 시작했습니다. 
보고 팀은 파일이 초기 S3 버킷에 들어갈 때 자동으로 분석 S3 버킷을 이동하려고 합니다. 또한 
보고 팀은 AWS Lambda 함수를 사용하여 복사된 데이터에서 패턴 일치 코드를 실행하려고 합니다. 
또한 보고 팀은 데이터 파일을 Amazon SageMaker Pipelines 의 파이프라인으로 보내려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 
합니까? 
A. 분석 S3 버킷에 파일을 복사하는 Lambda 함수를 생성합니다. 분석 S3 버킷에 대한 S3 이벤트 
알림을 생성합니다. 이벤트 알림의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다. 
s3:ObjectCreated:Put 을 이벤트 유형으로 구성합니다. 
B. 분석 S3 버킷에 파일을 복사하는 Lambda 함수를 생성합니다. Amazon EventBridge(Amazon 
CloudWatch Events)에 이벤트 알림을 보내도록 분석 S3 버킷을 구성합니다. 
EventBridge(CloudWatch 이벤트)에서 ObjectCreated 규칙을 구성합니다. 규칙의 대상으로 
Lambda 및 SageMaker 파이프라인을 구성합니다. 
C. S3 버킷 간에 S3 복제를 구성합니다. 분석 S3 버킷에 대한 S3 이벤트 알림을 생성합니다. 
이벤트 알림의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다. 
s3:ObjectCreated:Put 을 이벤트 유형으로 구성합니다. 
D. S3 버킷 간에 S3 복제를 구성합니다. Amazon EventBridge(Amazon CloudWatch Events)에 
이벤트 알림을 보내도록 분석 S3 버킷을 구성합니다. EventBridge(CloudWatch 이벤트)에서 
ObjectCreated 규칙을 구성합니다. 규칙의 대상으로 Lambda 및 SageMaker 파이프라인을 
구성합니다. 
Answer: D  
https://www.examtopics.com/discussions/amazon/view/85872-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
S3 복제를 사용하면 S3 버킷 간에 자동으로 복제됩니다. S3 이벤트를 CloudWatch Events 에서 
감지하여 특정 동작을 수행할 수 있습니다. Amazon S3 복제를 사용하면 S3 CRR(교차 리전 
복제)을 사용하여 서로 다른 AWS 리전에서, 또는 S3 SRR(동일 리전 복제)을 사용하여 같은 AWS 
리전 내의 버킷 간에 S3 객체를 자동으로 복제하도록 Amazon S3 를 구성할 수 있습니다.  
https://aws.amazon.com/ko/s3/features/replication/ 
Amazon S3 는 버킷에서 특정 이벤트가 발생할 때마다 Amazon EventBridge 에 이벤트를 보낼 수 
있습니다. 이벤트 유형 : Object Created 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/EventBridge.html) Amazon 
EventBridge 는 Amazon SageMaker 의 상태 변경 이벤트를 모니터링합니다. EventBridge 를 
사용하면 SageMaker 를 자동화하고 교육 작업 상태 변경 또는 끝점 상태 변경과 같은 이벤트에 
자동으로 응답할 수 있습니다. 자동으로 트리거될 수 있는 작업의 몇 가지 예는 다음과 같습니다. 
AWS Lambda 함수 호출 
https://docs.aws.amazon.com/sagemaker/latest/dg/automating-sagemaker-with-eventbridge.ht
ml 
설명 2: 
이 솔루션은 파일을 자동으로 이동하고, 복사된 데이터에서 Lambda 함수를 실행하고, 최소한의 
운영 오버헤드로 데이터 파일을 SageMaker Pipelines 로 보내는 요구 사항을 충족합니다. S3 
복제는 파일이 도착하면 초기 S3 버킷에서 분석 S3 버킷으로 파일을 복사할 수 있습니다. 분석 
S3 버킷은 객체가 생성될 때 Amazon EventBridge(Amazon CloudWatch Events)에 이벤트 알림을 
보낼 수 있습니다. EventBridge 는 Lambda 및 SageMaker 파이프라인을 ObjectCreated 규칙의 
대상으로 트리거할 수 있습니다. Lambda 는 복사된 데이터에서 패턴 일치 코드를 실행할 수 
있으며 SageMaker Pipelines 는 데이터 파일로 파이프라인을 실행할 수 있습니다. 
S3 복제가 자동으로 수행할 수 있는 경우 분석 S3 버킷에 파일을 복사하는 Lambda 함수를 
생성할 필요가 없기 때문에 옵션 A 는 올바르지 않습니다. 또한 Lambda 함수를 관리하기 위해 
운영 오버헤드를 추가합니다. 
S3 복제가 자동으로 수행할 수 있는 경우 분석 S3 버킷에 파일을 복사하는 Lambda 함수를 
생성할 필요가 없기 때문에 옵션 B 는 올바르지 않습니다. 또한 Lambda 함수를 관리하기 위해 
운영 오버헤드를 추가합니다. 
여러 대상과 함께 S3 이벤트 알림을 사용하면 이벤트가 너무 많은 경우 제한 또는 전달 실패가 
발생할 수 있으므로 옵션 C 는 올바르지 않습니다. 
참조: 
https://aws.amazon.com/ko/blogs/machine-learning/automate-feature-engineering-pipelines-w
ith-amazon-sagemaker/ 
https://docs.aws.amazon.com/sagemaker/latest/dg/automating-sagemaker-with-eventbridge.ht
ml 
https://aws.amazon.com/ko/about-aws/whats-new/2021/04/new-options-trigger-amazon-sag
emaker-pipeline-executions/ 
Q140 
솔루션 설계자는 회사가 AWS 에서 애플리케이션을 실행하는 비용을 최적화할 수 있도록 도와야 
합니다. 애플리케이션은 아키텍처 내 컴퓨팅을 위해 Amazon EC2 인스턴스, AWS Fargate 및 AWS 
Lambda 를 사용합니다. 
EC2 인스턴스는 애플리케이션의 데이터 수집 계층을 실행합니다. EC2 사용은 산발적이고 예측할 
수 없습니다. EC2 인스턴스에서 실행되는 워크로드는 언제든지 중단될 수 있습니다. 애플리케이션 
프런트 엔드는 Fargate 에서 실행되고 Lambda 는 API 계층을 제공합니다. 프론트엔드 활용도와 
API 계층 활용도는 내년에 예측할 수 있습니다. 
이 애플리케이션을 호스팅하는 데 가장 비용 효율적인 솔루션을 제공하는 구매 옵션 조합은 
무엇입니까? (2 개 선택) 
A. 데이터 수집 계층에 스팟 인스턴스 사용 
B. 데이터 수집 계층에 온디맨드 인스턴스 사용 
C. 프런트 엔드 및 API 계층에 대한 1 년 Compute Savings Plan 을 구매합니다. 
D. 데이터 수집 계층에 대한 1 년 전체 선결제 예약 인스턴스를 구매합니다. 
E. 프런트 엔드 및 API 계층을 위한 1 년 EC2 인스턴스 Savings Plan 을 구매합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/86083-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
・EC2 인스턴스에서 실행되는 워크로드는 언제든지 중단될 수 있습니다 = 스팟 인스턴스 
・프론트엔드 활용도와 API 계층 활용도는 내년에 예측할 수 있습니다 = Savings Plans 
Savings Plans 는 1 년 또는 3 년 기간의 일정 사용량 약정(시간당 USD 요금으로 측정)을 조건으로 
Amazon EC2, AWS Lambda 및 AWS Fargate 사용량에 대해 저렴한 요금을 제공하는 유연한 요금 
모델입니다. Savings Plans 에 가입하면 약정 사용량까지 할인된 Savings Plans 요금을 
적용받습니다. 
https://aws.amazon.com/ko/savingsplans/compute-pricing/ 
・그 중에서도 Compute Savings Plans 가 정답. 
Compute Savings Plans는 최대 66%까지 비용을 절감할 수 있는 가장 유연한 요금 모델입니다. 이 
플랜은 인스턴스 패밀리, 크기, AZ, 리전, OS 또는 테넌시와 관계없이 EC2 인스턴스 사용량에 
적용되며, Fargate 또는 Lambda 사용량에도 적용됩니다. 
https://aws.amazon.com/ko/savingsplans/compute-pricing/ 
정답은 A,C. 
설명 2: 
EC2 instance Savings Plan 은 72%, Compute Savings Plans 는 66%를 절약합니다. 그러나 링크에 
따르면 "Compute Savings Plans 는 최고의 유연성을 제공하고 비용을 최대 66%까지 줄이는 데 
도움이 됩니다. 
이러한 요금제는 인스턴스 패밀리, 크기, AZ, 리전, OS 또는 테넌시에 관계없이 EC2 인스턴스 
사용에 자동으로 적용되며 Fargate 및 Lambda 사용에도 적용됩니다." EC2 인스턴스 절약 계획은 
Fargate 또는 Lambda 에 적용되지 않습니다. 
Q141 
한 회사는 사용자에게 글로벌 속보, 지역 경보 및 날씨 업데이트를 제공하는 웹 기반 포털을 
운영합니다. 포털은 정적 콘텐츠와 동적 콘텐츠를 혼합하여 각 사용자에게 개인화된 보기를 
제공합니다. 콘텐츠는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 실행되는 
API 서버를 통해 HTTPS 를 통해 제공됩니다. 회사는 포털이 이 콘텐츠를 가능한 한 빨리 전 세계 
사용자에게 제공하기를 원합니다. 
솔루션 설계자는 모든 사용자의 대기 시간을 최소화하도록 애플리케이션을 어떻게 설계해야 
합니까? 
A. 단일 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon CloudFront 를 사용하여 ALB 를 
오리진으로 지정하여 모든 정적 및 동적 콘텐츠를 제공합니다. 
B. 두 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon Route 53 지연 시간 라우팅 정책을 
사용하여 가장 가까운 리전의 ALB 에서 모든 콘텐츠를 제공합니다. 
C. 단일 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon CloudFront 를 사용하여 정적 
콘텐츠를 제공합니다. ALB 에서 직접 동적 콘텐츠를 제공합니다. 
D. 두 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon Route 53 지리적 위치 라우팅 
정책을 사용하여 가장 가까운 리전에서 ALB 의 모든 콘텐츠를 제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/85439-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
ALB 를 오리진으로 사용할 수 있음 
원본이 하나 이상의 Amazon EC2 인스턴스에서 호스트되는 하나 이상의 HTTP 서버(웹 서버)인 
경우 Application Load Balancer 를 사용하여 인스턴스에 트래픽을 분산할 수 있습니다. Application 
Load Balancer 를 CloudFront 의 원본으로 사용하는 방법에 대한 자세한 내용은 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3
AndCustomOrigins.html#concept_elb_origin 
Q142 
게임 회사는 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux 커널에서 
실행되며 UDP 기반 트래픽만 지원합니다. 회사는 최상의 사용자 경험을 제공하기 위해 프런트 
엔드 계층이 필요합니다. 해당 계층은 대기 시간이 짧고 가장 가까운 엣지 로케이션으로 트래픽을 
라우팅하고 애플리케이션 엔드포인트에 진입하기 위한 고정 IP 주소를 제공해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 요청을 Application Load Balancer 로 전달하도록 Amazon Route 53 을 구성합니다. AWS 
Application Auto Scaling 의 애플리케이션에 AWS Lambda 를 사용합니다. 
B. 요청을 Network Load Balancer 로 전달하도록 Amazon CloudFront 를 구성합니다. AWS 
Application Auto Scaling 그룹의 애플리케이션에 AWS Lambda 를 사용합니다. 
C. 요청을 Network Load Balancer 로 전달하도록 AWS Global Accelerator 를 구성합니다. EC2 Auto 
Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다. 
D. 요청을 Application Load Balancer 로 전달하도록 Amazon API Gateway 를 구성합니다. EC2 Auto 
Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/86667-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
TCP/UDP+엔드포인트에 입력할 수 있는 고정 IP 주소를 가져야 한다는 대목에서 Global 
Accelerator 임을 유추할 수 있음.  
설명 2: 
AWS Global Accelerator 와 Amazon CloudFront 는 AWS 글로벌 네트워크와 전 세계 엣지 
로케이션을 사용하는 별도의 서비스입니다. CloudFront 는 캐시 가능한 콘텐츠(예: 이미지 및 
비디오)와 동적 콘텐츠(예: API 가속 및 동적 사이트 제공) 모두의 성능을 향상시킵니다. Global 
Accelerator 는 하나 이상의 AWS 리전에서 실행되는 애플리케이션에 대해 에지의 패킷을 
프록시하여 TCP 또는 UDP 를 통해 광범위한 애플리케이션의 성능을 개선합니다. Global 
Accelerator 는 게임(UDP), IoT(MQTT) 또는 VoIP 와 같은 비 HTTP 사용 사례와 특히 고정 IP 주소 
또는 결정론적이고 빠른 지역 장애 조치가 필요한 HTTP 사용 사례에 적합합니다. 두 서비스 모두 
DDoS 보호를 위해 AWS Shield 와 통합됩니다. 
Q143 
회사에서 기존 온프레미스 모놀리식 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 회사는 
프론트엔드 코드와 백엔드 코드를 최대한 많이 유지하려고 합니다. 그러나 회사는 응용 프로그램을 
더 작은 응용 프로그램으로 나누기를 원합니다. 다른 팀에서 각 애플리케이션을 관리합니다. 
회사는 운영 오버헤드를 최소화하는 확장성이 뛰어난 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Lambda 에서 애플리케이션을 호스팅합니다. 애플리케이션을 Amazon API Gateway 와 
통합합니다. 
B. AWS Amplify 를 사용하여 애플리케이션을 호스팅합니다. AWS Lambda 와 통합된 Amazon API 
Gateway API 에 애플리케이션을 연결합니다. 
C. Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Auto Scaling 그룹의 EC2 인스턴스를 
대상으로 하여 Application Load Balancer 를 설정합니다. 
D. Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon 
ECS 를 대상으로 하여 Application Load Balancer 를 설정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/86473-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
ECS 는 컨테이너화된 애플리케이션을 실행하기 위해 확장성이 뛰어난 관리형 환경을 제공하여 
운영 오버헤드를 줄입니다. ECS 를 대상으로 ALB 를 설정하면 확장성과 가용성을 위해 
애플리케이션의 여러 인스턴스에 트래픽을 분산할 수 있습니다. 이 솔루션을 사용하면 여러 팀이 
각 애플리케이션을 독립적으로 관리하여 팀 자율성과 효율적인 개발을 촉진할 수 있습니다. 
A 는 이벤트 기반 및 서버리스 워크로드에 더 적합합니다. 모놀리식 애플리케이션을 
마이그레이션하고 기존 코드베이스를 유지 관리하는 데 이상적인 선택이 아닐 수 있습니다. 
B 는 Lambda 및 API Gateway 와 통합되므로 애플리케이션을 더 작은 애플리케이션으로 분할하고 
독립적으로 관리하는 데 필요한 유연성을 제공하지 못할 수 있습니다. 
C 는 인프라 관리 및 수동 확장을 포함합니다. ECS 와 같은 컨테이너 서비스를 사용할 때보다 운영 
오버헤드가 높아질 수 있습니다. 
Q144 
한 회사는 최근 글로벌 전자 상거래 애플리케이션의 데이터 저장소로 Amazon Aurora 를 사용하기 
시작했습니다. 대규모 보고서가 실행되면 개발자는 전자상거래 애플리케이션의 성능이 좋지 않다고 
보고합니다. Amazon CloudWatch 의 지표를 검토한 후 솔루션 설계자는 월별 보고서가 실행될 때 
ReadIOPS 및 CPUUtilizalion 지표가 급증하고 있음을 발견했습니다. 
가장 비용 효율적인 솔루션은 무엇입니까? 
A. 월별 보고를 Amazon Redshift 로 마이그레이션합니다. 
B. 월별 보고를 Aurora 복제본으로 마이그레이션합니다. 
C. Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다. 
D. Aurora 인스턴스에서 프로비저닝된 IOPS 를 늘립니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/86781-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html 
#Aurora.Replication.Replicas Aurora 복제본에는 두 가지 주요 목적이 있습니다. 애플리케이션에 
대한 읽기 작업을 확장하기 위해 쿼리를 실행할 수 있습니다. 일반적으로 클러스터의 리더 
엔드포인트에 연결하여 이를 수행합니다. 이렇게 하면 Aurora 는 클러스터에 있는 만큼 많은 
Aurora 복제본에 읽기 전용 연결에 대한 로드를 분산시킬 수 있습니다. Aurora 복제본은 가용성을 
높이는 데도 도움이 됩니다. 클러스터의 라이터 인스턴스를 사용할 수 없게 되면 Aurora 는 리더 
인스턴스 중 하나를 자동으로 승격시켜 새 라이터로 대신합니다. 
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.html 
설명 2: 
ReadIOPS 가 증가하고 있다고 했으므로 Aurora replica 를 통한 읽기 부하 분산 가능 "Aurora 는 
클러스터에 있는 만큼의 Aurora 복제본에 읽기 전용 연결에 대한 로드를 분산할 수 있습니다.  
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html#Aur
ora.Replication.Replicas 
Q145 
회사는 단일 Amazon EC2 온디맨드 인스턴스에서 웹 사이트 분석 애플리케이션을 호스팅합니다. 
분석 소프트웨어는 PHP 로 작성되었으며 MySQL 데이터베이스를 사용합니다. 분석 소프트웨어, 
PHP 를 제공하는 웹 서버 및 데이터베이스 서버는 모두 EC2 인스턴스에서 호스팅됩니다. 응용 
프로그램은 바쁜 시간 동안 성능 저하 징후를 보이고 5xx 오류를 표시합니다. 회사는 
애플리케이션을 원활하게 확장해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? 
A. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 
애플리케이션의 AMI 를 생성합니다. AMI 를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. 
Application Load Balancer 를 사용하여 각 EC2 인스턴스에 로드를 분산합니다. 
B. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 
애플리케이션의 AMI 를 생성합니다. AMI 를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. 
Amazon Route 53 가중 라우팅을 사용하여 두 EC2 인스턴스에 로드를 분산합니다. 
C. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. AWS Lambda 
함수를 생성하여 EC2 인스턴스를 중지하고 인스턴스 유형을 변경합니다. CPU 사용률이 75%를 
초과할 때 Lambda 함수를 호출하는 Amazon CloudWatch 경보를 생성합니다. 
D. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 
AMI 를 생성합니다. 시작 템플릿에 AMI 를 적용합니다. 시작 템플릿으로 Auto Scaling 그룹 생성 
스팟 집합을 사용하도록 시작 템플릿을 구성합니다. Auto Scaling 그룹에 Application Load 
Balancer 를 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/86474-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 두 번째 온디맨드 인스턴스를 생성하기만 하고 Auto Scaling 설정을 안 하므로 확장성이 
D 에 비해 떨어짐. 
B(X) : Route 53 Weighted Routing 은 각 리소스로 라우팅되는 트래픽 양을 조절하는 기능 
가중 라우팅을 사용하면 여러 리소스를 단일 도메인 이름(example.com) 또는 하위 도메인 
이름(acme.example.com)과 연결하고 각 리소스로 라우팅되는 트래픽 양을 선택할 수 있습니다. 
https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-weighted.html 
C(X) : CloudWatch 경보는 임계값에 도달하면 자동으로 알림을 보내는 서비스. 
""인스턴스 중 하나에 대한 CloudWatch 지표를 모니터링하는 CloudWatch 경보를 생성할 수 
있습니다. 지표가 지정된 임계값에 도달하면 CloudWatch 에서 자동으로 알림을 보냅니다. 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/using-cloudwatch-createalarm.h
tml 
D(O) : 스팟인스턴스라는 점이 걸리긴 하지만 어차피 인스턴스를 중지해서는 안 된다는 말이 나온 
것도 아니고, Auto Scaling 이 명시되어있으므로 정답에 가장 가까움. 
설명 2: 
데이터베이스를 Amazon Aurora MySQL 로 마이그레이션합니다. 이렇게 하면 DB 가 자체적으로 
확장됩니다. 조정할 필요 없이 자동으로 크기가 조정됩니다. 시작 템플릿을 사용하여 웹 앱의 
AMI 를 생성합니다. 이렇게 하면 앱의 향후 인스턴스를 원활하게 생성할 수 있습니다. 그런 다음 
Auto Scaling 그룹에 추가하면 수요에 따라 확장 및 축소되므로 비용을 절약할 수 있습니다. 
스팟 집합을 사용하여 인스턴스를 시작합니다. 이것은 아마존이 적합하다고 판단하는 시점에 
종료되는 비용으로 스팟 인스턴스가 크게 할인되기 때문에 질문의 "가장 비용 효율적인" 부분을 
해결합니다. 이 부분에 대해서는 약간의 이견이 있기 때문이라고 생각합니다. 가장 비용 
효율적이지만 아마존이 사용량이 많은 기간에 해당 스팟 인스턴스를 종료한다면 끔찍한 선택이 될 
것입니다. 
Q146 
회사는 Application Load Balancer 뒤의 Amazon EC2 온디맨드 인스턴스 그룹에서 프로덕션 
환경에서 상태 비저장 웹 애플리케이션을 실행합니다. 매일 8 시간 동안 애플리케이션 사용량이 
많습니다. 응용 프로그램 사용량은 보통이고 밤새 안정적입니다. 주말에는 애플리케이션 사용량이 
적습니다. 
이 회사는 애플리케이션의 가용성에 영향을 주지 않으면서 EC2 비용을 최소화하려고 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 전체 워크로드에 대해 스팟 인스턴스를 사용합니다. 
B. 기본 사용량 수준에 대해 예약 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 용량에 
대해 스팟 인스턴스를 사용합니다. 
C. 기준 사용 수준에 대해 온디맨드 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 용량에 
대해 스팟 인스턴스를 사용합니다. 
D. 기본 사용량 수준에 대해 전용 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 용량에 
대해 온디맨드 인스턴스를 사용합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/86750-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(X) : 계속 사용량이 있고, 사용량이 적은 주말에도 꾸준히 사용량은 나오고 있는데 계속 작동 
중인 걸 스팟인스턴스로 둘 이유가 없음. 스팟 인스턴스는 중지해도 되는 인스턴스에 사용되는 
인스턴스 유형. 사용량이 많은 시간을 예상할 수 있는 상황에선 예약 인스턴스가 적절. 
B(O) : 상태 비저장 애플리케이션이라는 단서가 있으므로 추가 용량에 대해서는 스팟 인스턴스를 
사용하여 비용 절감 가능. 
C(X) : 기본 사용량 수준은 예상할 수 있으므로 예약 인스턴스가 적절. 
D(X) : Dedicated Instance 는 온디맨드에 비해서도 비용이 많이 들어가는 인스턴스 유형임. 해당 
부분에 대해서는 아래의 링크를 참고할 것. 
https://aws.amazon.com/ko/ec2/pricing/on-demand/ 
https://aws.amazon.com/ko/ec2/pricing/dedicated-instances/ 
Q147 
회사는 중요한 애플리케이션에 대한 애플리케이션 로그 파일을 10 년 동안 보관해야 합니다. 
애플리케이션 팀은 문제 해결을 위해 지난 달의 로그에 정기적으로 액세스하지만 1 개월 이상 된 
로그는 거의 액세스하지 않습니다. 애플리케이션은 매월 10TB 이상의 로그를 생성합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 옵션은 무엇입니까? 
A. Amazon S3 에 로그를 저장합니다. AWS Backup 을 사용하여 1 개월 이상 된 로그를 S3 Glacier 
Deep Archive 로 이동합니다. 
B. Amazon S3 에 로그를 저장합니다. S3 수명 주기 정책을 사용하여 1 개월 이상 된 로그를 S3 
Glacier Deep Archive 로 이동합니다. 
C. Amazon CloudWatch Logs 에 로그를 저장합니다. AWS Backup 을 사용하여 1 개월 이상 된 
로그를 S3 Glacier Deep Archive 로 이동합니다. 
D. Amazon CloudWatch Logs 에 로그를 저장합니다. Amazon S3 수명 주기 정책을 사용하여 1 개월 
이상 된 로그를 S3 Glacier Deep Archive 로 이동합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/86864-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(X) : Life Cycle Policy 를 사용하면 되는데 굳이 AWS Backup 까지 동원할 필요가 없음. 
B(O) : 정답. 한 달 후에 로그를 보관하려면 S3 가 필요합니다. CloudWatch Logs 로는 그렇게 할 수 
없습니다. 
C(X) : CloudWatch Logs 는 스토리지 서비스가 아님. 
D(X) : C 와 같은 이유로 오답. 
Q148 
회사에는 다음 구성 요소를 포함하는 데이터 수집 워크플로가 있습니다. 
* 새로운 데이터 전송에 대한 알림을 받는 Amazon Simple Notation Service(Amazon SNS) 
주제입니다. 
* 데이터를 처리하고 저장하는 AWS Lambda 함수입니다. 
네트워크 연결 문제로 인해 수집 워크플로가 때때로 실패합니다. 임기가 발생하면 회사에서 
수동으로 작업을 다시 실행하지 않는 한 해당 데이터가 수집되지 않습니다. 
모든 알림이 최종적으로 처리되도록 하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 여러 가용 영역에 걸쳐 배포할 Lambda 함수를 구성합니다. 
B. Lambda 함수의 구성을 수정하여 함수에 대한 CPU 및 메모리 할당을 늘립니다. 
C. 재시도 횟수와 재시도 간 대기 시간을 모두 늘리도록 SNS 주제의 재시도 전략을 구성합니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열을 장애 시 대상으로 구성합니다. 대기열의 
메시지를 처리하도록 Lambda 함수를 수정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/85424-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
실패한 메시지를 보관할 SQS 대기열이 필요. 정답은 D.  
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-d
ead-letter-queues.html 
C 같은 경우엔 재시도 전략인데, 'When tenure occurs the corresponding data is not ingested 
unless company manually reruns the job' (Tenure 가 발생하면 회사에서 수동으로 작업을 다시 
실행하지 않는 한 해당 데이터가 수집되지 않습니다.) 라는 대목이 있므로 C 는 오답. Amazon 
SNS 가 메시지 전송을 재시도하는 방식이 전송 정책에 따라 결정됩니다. 전송 정책이 소진되면 
Amazon SNS 는 전송 재시도를 중지하고 배달 못한 편지 대기열이 구독에 연결되어 있지 않는 한 
메시지를 삭제합니다. 
https://docs.aws.amazon.com/ko_kr/sns/latest/dg/sns-message-delivery-retries.html 
참고: 
https://docs.aws.amazon.com/ko_kr/sns/latest/dg/sns-dead-letter-queues.html 
Q149 
회사에 이벤트 데이터를 생성하는 서비스가 있습니다. 회사는 AWS 를 사용하여 이벤트 데이터를 
수신하는 대로 처리하려고 합니다. 데이터는 처리 전반에 걸쳐 유지되어야 하는 특정 순서로 
작성됩니다. 회사는 운영 오버헤드를 최소화하는 솔루션을 구현하려고 합니다. 
솔루션 설계자는 이를 어떻게 달성해야 합니까? 
A. 메시지를 보관할 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 생성합니다. 
대기열의 메시지를 처리하도록 AWS Lambda 함수를 설정합니다. 
B. 처리할 페이로드가 포함된 알림을 전달하기 위해 Amazon Simple Notification Service(Amazon 
SNS) 주제를 생성합니다. AWS Lambda 함수를 구독자로 구성합니다. 
C. 메시지를 보관할 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 생성합니다. 
대기열의 메시지를 독립적으로 처리하도록 AWS Lambda 함수를 설정합니다. 
D. 처리할 페이로드가 포함된 알림을 전달하기 위해 Amazon Simple Notification Service(Amazon 
SNS) 주제를 생성합니다. Amazon Simple Queue Service(Amazon SQS) 대기열을 구독자로 
구성합니다. 
Answer: A  
https://www.examtopics.com/discussions/amazon/view/86784-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:・ 
FIFO(First-In-First-Out) 대기열은 작업 및 이벤트 순서가 중요하거나 중복을 허용할 수 없는 경우 
애플리케이션 간의 메시징을 향상하도록 설계되었습니다. FIFO 대기열을 사용할 수 있는 상황의 
예는 다음과 같습니다. 사용자가 입력한 명령이 올바른 순서로 실행되도록 합니다. 올바른 순서로 
가격 수정을 전송하여 올바른 제품 가격을 표시합니다. 학생이 계정을 등록하기 전에 코스에 
등록하지 못하도록 합니다. 
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-
queues.html 
Q150 
회사는 온프레미스 서버에서 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션하고 있습니다. 
마이그레이션 설계 요구 사항의 일부로 솔루션 설계자는 인프라 메트릭 경보를 구현해야 합니다. 
CPU 사용률이 단기간에 50% 이상으로 증가하는 경우 회사는 조치를 취할 필요가 없습니다. 
하지만 CPU 사용률이 50% 이상으로 증가하고 디스크의 읽기 IOPS 가 동시에 높다면 회사에서 
최대한 빨리 조치를 취해야 합니다. 솔루션 설계자는 또한 오경보를 줄여야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 가능한 경우 Amazon CloudWatch 복합 경보를 생성합니다. 
B. Amazon CloudWatch 대시보드를 생성하여 지표를 시각화하고 문제에 신속하게 대응합니다. 
C. Amazon CloudWatch Synthetics 카나리아를 생성하여 애플리케이션을 모니터링하고 경보를 
발생시킵니다. 
D. 가능한 경우 여러 지표 임계값으로 단일 Amazon CloudWatch 지표 경보를 생성합니다. 
Answer: A  
https://www.examtopics.com/discussions/amazon/view/86034-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
자세한 내용은 아래 URL. 
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-
queues.html 
FIFO(First-In-First-Out) 대기열은 작업 및 이벤트 순서가 중요하거나 중복을 허용할 수 없는 경우 
애플리케이션 간의 메시징을 향상하도록 설계되었습니다. FIFO 대기열을 사용할 수 있는 상황의 
예는 다음과 같습니다. 사용자가 입력한 명령이 올바른 순서로 실행되도록 합니다. 올바른 순서로 
가격 수정을 전송하여 올바른 제품 가격을 표시합니다. 학생이 계정을 등록하기 전에 코스에 
등록하지 못하도록 합니다. 
Q151 
회사에서 온프레미스 데이터 센터를 AWS 로 마이그레이션하려고 합니다. 회사의 규정 준수 요구 
사항에 따라 회사는 ap-northeast-3 지역만 사용할 수 있습니다. 회사 관리자는 VPC 를 인터넷에 
연결할 수 없습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? (2 개를 선택하세요.) 
A. AWS Control Tower 를 사용하여 데이터 상주 가드레일을 구현하여 인터넷 액세스를 거부하고 
ap-northeast-3 을 제외한 모든 AWS 리전에 대한 액세스를 거부합니다. 
B. AWS WAF 의 규칙을 사용하여 인터넷 액세스를 방지합니다. AWS 계정 설정에서 
ap-northeast-3 을 제외한 모든 AWS 리전에 대한 액세스를 거부합니다. 
C. AWS Organizations 를 사용하여 VPC 가 인터넷에 액세스하지 못하도록 하는 서비스 제어 
정책(SCPS)을 구성합니다. ap-northeast-3 을 제외한 모든 AWS 리전에 대한 액세스를 
거부합니다. 
D. 각 VPC 의 네트워크 ACL 에 대한 아웃바운드 규칙을 생성하여 0.0.0.0/0 의 모든 트래픽을 
거부합니다. ap-northeast-3 이외의 AWS 리전을 사용하지 못하도록 각 사용자에 대한 IAM 정책을 
생성합니다. 
E. AWS Config 를 사용하여 관리형 규칙을 활성화하여 인터넷 게이트웨이를 감지 및 경고하고 
ap-northeast-3 외부에 배포된 새 리소스를 감지 및 경고합니다. 
Answer: A, C  
https://www.examtopics.com/discussions/amazon/view/86475-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(O) : AWS Control Tower Guardrail 을 사용해 SCP 를 통한 AWS API 액세스를 제한하여 특정 AWS 
리전에서의 특정 리소스 방지 가능. 
오늘부터 AWS Control Tower 를 사용하여 가드레일 이라고 하는 데이터 상주 예방 및 탐지 제어를 
배포할 수 있습니다 . 이러한 가드레일은 서비스 제어 정책(SCP) 을 통해 AWS API 에 대한 
액세스를 제한하여 원치 않는 AWS 리전에서 리소스 프로비저닝을 방지합니다. 예를 들어 독일의 
AWS 고객은 AWS Identity and Access Management(IAM) 및 AWS Organizations 와 같은 글로벌 
서비스를 제외하고 프랑크푸르트 이외의 지역에서 AWS 서비스에 대한 액세스를 거부할 수 
있습니다. 또한 AWS Control Tower 는 Amazon Simple Storage Service(Amazon S3) 교차 리전 
복제 차단 또는 인터넷 게이트웨이 생성 차단과 같은 기본 AWS 서비스 옵션의 데이터 상주를 
추가로 제어하기 위한 가드레일을 제공합니다. 
https://aws.amazon.com/blogs/aws/new-for-aws-control-tower-region-deny-and-guardrails-t
o-help-you-meet-data-residency-requirements/ 
B(X) : AWS WAF 는 Web ACL 을 통해 특정 국가나 지리적 위치, IP 의 요청을 차단할 수 있으나 
리전을 차단하는 옵션은 없음. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/waf-allow-block-country-geolo
cation/)(https://aws.amazon.com/ko/premiumsupport/knowledge-center/waf-allow-my-ip-bloc
k-other-ip/ 
C(O) : AWS Organizations 를 사용해 특정 리전에 대한 액세스 차단 가능. 
이 SCP 는 지정된 리전 외부의 모든 작업에 대한 액세스를 거부합니다. 이 정책은 Deny 효과를 
사용하여 승인된 두 리전(eu-central-1 및 eu-west-1) 중 하나를 대상으로 하지 않는 작업에 
대한 모든 요청에 대한 액세스를 거부합니다. 
https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_manage_policies_scps_
examples_general.html 
D(X) : NACL 0.0.0.0/0 의 아웃바운드 트래픽을 막아버리면 트래픽이 외부로 나갈 수 없어 아예 
통신 자체가 안 됨. IAM 정책으로 다른 AWS 리전의 다른 리소스에 대한 액세스를 막는 것은 가능. 
https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_deny-req
uested-region.html 
E(X) : AWS Config 는 리소스 구성 변경 사항을 감지하고 해당 구성 변경 기록 파일을 전송할 수 
있는 서비스로 지문의 요구사항에는 부합하지 않음. 
Q152 
회사에서 3 계층 웹 응용 프로그램을 사용하여 신입 직원에게 교육을 제공합니다. 애플리케이션은 
매일 12 시간 동안만 액세스됩니다. 회사는 Amazon RDS for MySQL DB 인스턴스를 사용하여 
정보를 저장하고 비용을 최소화하려고 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Systems Manager Session Manager 에 대한 IAM 정책을 구성합니다. 정책에 대한 IAM 
역할을 생성합니다. 역할의 신뢰 관계를 업데이트하십시오. DB 인스턴스에 대한 자동 시작 및 
중지를 설정합니다. 
B. DB 인스턴스가 중지될 때 사용자가 캐시의 데이터에 액세스할 수 있는 기능을 제공하는 
Redis 용 Amazon ElastiCache 캐시 클러스터를 생성합니다. DB 인스턴스가 시작된 후 캐시를 
무효화합니다. 
C. Amazon EC2 인스턴스를 시작합니다. Amazon RDS 에 대한 액세스 권한을 부여하는 IAM 역할을 
생성합니다. 역할을 EC2 인스턴스에 연결합니다. 원하는 일정에 따라 EC2 인스턴스를 시작 및 
중지하도록 크론 작업을 구성합니다. 
D. AWS Lambda 함수를 생성하여 DB 인스턴스를 시작 및 중지합니다. Amazon 
EventBridge(Amazon CloudWatch Events) 예약 규칙을 생성하여 Lambda 함수를 호출합니다. 
규칙에 대한 이벤트 대상으로 Lambda 함수를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/86046-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 권한에 대한 언급이 없는데 굳이 IAM 을 사용할 이유가 없음. 
B(X) : ElastiCache 는 웹 애플리케이션과 DB 간의 캐시 서비스. 
C(X) : A 와 같은 이유로 오답. 
D(O) : EC2 인스턴스를 자동으로 중지 및 시작하여 Amazon Elastic Compute Cloud(Amazon EC2) 
사용량을 줄이려고 합니다. 이를 위해 AWS Lambda 및 Amazon EventBridge 를 사용하려면 어떻게 
해야 하나요? 
이하의 항목 참고 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/start-stop-lambda-eventbridge
/ 
설명 2: 
일반적인 개발 환경에서 개발 및 테스트 데이터베이스는 대부분 하루 8 시간 동안 사용되며 
사용하지 않을 때는 유휴 상태입니다. 그러나 데이터베이스에는 이 유휴 시간 동안 컴퓨팅 및 
스토리지 비용이 청구됩니다. 전체 비용을 줄이기 위해 Amazon RDS 에서는 인스턴스를 
일시적으로 중지할 수 있습니다. 인스턴스가 중지된 동안에는 스토리지 및 백업에 대한 요금이 
부과되지만 DB 인스턴스 시간에 대한 요금은 부과되지 않습니다. 중지된 인스턴스는 7 일 후에 
자동으로 시작됩니다. 이 게시물은 컴퓨팅 비용을 절감하기 위해 특정 태그로 유휴 데이터베이스를 
중지 및 시작하도록 Lambda 함수를 예약할 수 있는 AWS Lambda 및 Amazon EventBridge 를 
사용하는 솔루션을 제시합니다. 두 번째 게시물은 AWS Systems Manager 를 사용하여 유휴 
Amazon RDS 데이터베이스의 중지 및 시작을 수행하는 솔루션을 제시합니다. 
Q153 
회사에서 인기 있는 노래 클립으로 만든 벨소리를 판매합니다. 벨소리가 포함된 파일은 Amazon 
S3 Standard 에 저장되며 크기는 최소 128KB 입니다. 이 회사에는 수백만 개의 파일이 있지만 
90 일보다 오래된 벨소리의 경우 다운로드가 드뭅니다. 회사는 가장 많이 액세스하는 파일을 
사용자가 쉽게 사용할 수 있도록 유지하면서 스토리지 비용을 절약해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 회사는 어떤 조치를 취해야 합니까? 
A. 객체의 초기 스토리지 계층에 대해 S3 Standard-Infrequent Access(S3 Standard-IA) 
스토리지를 구성합니다. 
B. 파일을 S3 Intelligent-Tiering 으로 이동하고 90 일 후에 객체를 더 저렴한 스토리지 계층으로 
이동하도록 구성합니다. 
C. 객체를 관리하도록 S3 인벤토리를 구성하고 90 일 후에 객체를 S3 Standard-Infrequent 
Access(S3 Standard-1A)로 이동합니다. 
D. 90 일 후에 객체를 S3 Standard 에서 S3 Standard-Infrequent Access(S3 Standard-1A)로 
이동하는 S3 수명 주기 정책을 구현합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/86933-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 초기에는 사용량이 많으므로 S3 Standard 가 적절. 
B(X) : 90 일 이상된 벨소리는 다운로드가 드물다고 했으므로 부적절. 
C(X) : Amazon S3 Inventory 는 Amazon S3 에서 스토리지 관리를 지원하기 위해 제공하는 도구 중 
하나로, 이 인벤토리를 사용하여 비즈니스, 규정 준수 및 규제 요건에 대한 객체의 복제 및 암호화 
상태를 감사하고 보고할 수 있습니다. 또한 Amazon S3 동기식 List API 작업의 대안으로 Amazon 
S3 인벤토리를 사용하면 비즈니스 워크플로 및 빅 데이터 업무를 단순화하고 속도를 높일 수 
있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-inventory.html 
D(O) : 90 일 이전에는 S3 Standard 로 빈번한 액세스 처리, 90 일 이후에는 다운로드가 드물지만 
가장 많이 액세스하는 일부 파일은 쉽게 사용, 즉 빠르게 액세스할 수 있어야 하므로 액세스 소요 
시간이 적은 S3 Standard-IA 사용이 적절. 
설명 2: 
이 솔루션은 사용자가 가장 많이 액세스하는 파일을 쉽게 사용할 수 있도록 유지하면서 스토리지 
비용을 절약해야 하는 요구 사항을 충족합니다. S3 수명 주기 정책은 사전 정의된 규칙에 따라 한 
스토리지 클래스에서 다른 스토리지 클래스로 객체를 자동으로 이동할 수 있습니다. S3 
Standard-IA 는 자주 액세스하지 않지만 필요할 때 신속하게 액세스해야 하는 데이터를 위한 
저비용 스토리지 클래스입니다. 드물게 다운로드되는 90 일 이상의 벨소리에 적합합니다. 
객체의 초기 스토리지 계층에 대해 S3 Standard-IA 를 구성하면 빈번한 액세스 및 검색 요금으로 
더 많은 비용이 발생할 수 있으므로 옵션 A 는 올바르지 않습니다. 
파일을 S3 Intelligent-Tiering 으로 이동하면 90 일보다 오래된 벨소리에는 필요하지 않을 수 있는 
추가 모니터링 및 자동화 요금이 발생할 수 있으므로 옵션 B 는 올바르지 않습니다. 
옵션 C 는 올바르지 않습니다. S3 인벤토리를 사용하여 객체를 관리하고 객체를 S3 Standard-IA 로 
이동하는 것은 복잡하고 시간이 많이 소요될 수 있으며 자동 비용 절감을 제공하지 않기 
때문입니다. 
참조: 
https://aws.amazon.com/s3/storage-classes/ 
https://aws.amazon.com/s3/cloud-storage-cost-optimization-ebook/ 
Q154 
회사는 의료 시험의 결과를 Amazon S3 리포지토리에 저장해야 합니다. 리포지토리는 일부 
과학자가 새 파일을 추가할 수 있도록 허용해야 하고 다른 모든 사용자는 읽기 전용 액세스로 
제한해야 합니다. 어떤 사용자도 저장소의 파일을 수정하거나 삭제할 수 없습니다. 회사는 모든 
파일을 생성일로부터 최소 1 년 동안 저장소에 보관해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 거버넌스 모드에서 1 년의 법적 보유 기간으로 S3 Object Lock 을 사용하십시오. 
B. 보존 기간이 365 일인 규정 준수 모드에서 S3 Object Lock 을 사용합니다. 
C. IAM 역할을 사용하여 모든 사용자가 S3 버킷의 객체를 삭제하거나 변경하지 못하도록 
제한합니다. S3 버킷 정책을 사용하여 IAM 역할만 허용합니다. 
D. 객체가 추가될 때마다 AWS Lambda 함수를 호출하도록 S3 버킷을 구성합니다. 수정된 개체가 
그에 따라 표시될 수 있도록 저장된 개체의 해시를 추적하는 기능을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/86359-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
S3 객체 수정 및 삭제 방지 = S3 Object Lock. 
S3 객체 잠금을 사용하면 write once, read many(WORM) 모델을 사용하여 객체를 저장할 수 
있습니다. 객체 잠금은 고정된 시간 동안 또는 무기한으로 객체의 삭제 또는 덮어쓰기를 방지하는 
데 도움이 될 수 있습니다. 보관 기간은 정해진 시간 동안 객체 버전을 보호합니다. 객체 버전에 
보관 기간을 설정하면 Amazon S3 는 객체 버전의 메타데이터에 타임스탬프를 저장하여 보관 
기간이 만료되는 시점을 표시합니다. 보관 기간이 만료된 후 객체 버전에 법적 보존을 설정하지 
않는 한 객체 버전을 덮어쓰거나 삭제할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lock-overview.html#obj
ect-lock-retention-periods 
설명 2: 
규정 준수 모드에서는 AWS 계정의 루트 사용자를 포함하여 어떤 사용자도 보호 객체 버전을 
덮어쓰거나 삭제할 수 없습니다. 객체가 규정 준수 모드에서 잠겨 있으면 보관 모드를 변경할 수 
없으며 보관 기간을 단축할 수 없습니다. 규정 준수 모드는 보존 기간 동안 개체 버전을 
덮어쓰거나 삭제할 수 없도록 합니다. 거버넌스 모드에서 사용자는 특별한 권한이 없는 한 개체 
버전을 덮어쓰거나 삭제할 수 없으며 잠금 설정을 변경할 수 없습니다. 거버넌스 모드를 사용하면 
대부분의 사용자가 개체를 삭제하지 못하도록 보호하지만 필요한 경우 일부 사용자에게 보존 
설정을 변경하거나 개체를 삭제할 수 있는 권한을 계속 부여할 수 있습니다. 거버넌스 모드에서는 
특수 권한이 있는 일부 사용자가 개체를 삭제할 수 있으며 이는 요구 사항에 위배됩니다. 
규정 준수: 
- 객체 버전은 루트 사용자를 포함한 모든 사용자가 덮어쓰거나 삭제할 수 없습니다. 
- 개체 보존 모드를 변경할 수 없으며 보존 기간을 단축할 수 없습니다. 거버넌스: 
- 대부분의 사용자는 개체 버전을 덮어쓰거나 삭제할 수 없으며 잠금 설정을 변경할 수 없습니다. 
- 일부 사용자는 보존을 변경하거나 개체를 삭제할 수 있는 특별한 권한이 있습니다. 
Q155 
대규모 미디어 회사는 AWS 에서 웹 애플리케이션을 호스팅합니다. 이 회사는 전 세계 사용자가 
파일에 안정적으로 액세스할 수 있도록 기밀 미디어 파일 캐싱을 시작하려고 합니다. 콘텐츠는 
Amazon S3 버킷에 저장됩니다. 회사는 요청의 지리적 위치에 관계없이 콘텐츠를 신속하게 
제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS DataSync 를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다. 
B. AWS Global Accelerator 를 배포하여 S3 버킷을 웹 애플리케이션에 연결합니다. 
C. Amazon CloudFront 를 배포하여 S3 버킷을 CloudFront 엣지 서버에 연결합니다. 
D. Amazon Simple Queue Service(Amazon SQS)를 사용하여 S3 버킷을 웹 애플리케이션에 
연결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/86795-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
S3 버킷에 저장 + 요청이 지리적으로 어디에서 발생했는지에 관계없이 콘텐츠를 신속하게 제공 = 
S3 + CloudFront. 답은 C. 
설명 2: 
CloudFront 는 로컬 캐시를 사용하여 응답을 제공하고, AWS Global Accelerator 는 요청을 
프록시하고 응답을 위해 항상 애플리케이션에 연결합니다. 
Q156 
회사는 다른 데이터베이스에서 가져온 배치 데이터를 생성합니다. 이 회사는 또한 네트워크 센서 
및 애플리케이션 API 에서 라이브 스트림 데이터를 생성합니다. 회사는 비즈니스 분석을 위해 모든 
데이터를 한 곳으로 통합해야 합니다. 회사는 수신 데이터를 처리한 다음 다른 Amazon S3 버킷에 
데이터를 준비해야 합니다. 팀은 나중에 일회성 쿼리를 실행하고 데이터를 비즈니스 인텔리전스 
도구로 가져와 핵심 성과 지표(KPI)를 표시합니다. 
가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개를 
선택하세요.) 
A. 일회성 쿼리에는 Amazon Athena 를 사용하십시오. Amazon QuickSight 를 사용하여 KPI 용 
대시보드를 생성합니다. 
B. 일회성 쿼리에 Amazon Kinesis Data Analytics 를 사용합니다. Amazon QuickSight 를 사용하여 
KPI 용 대시보드를 생성합니다. 
C. 개별 레코드를 데이터베이스에서 Amazon Redshift 클러스터로 이동하는 사용자 지정 AWS 
Lambda 함수를 생성합니다. 
D. AWS Glue 추출, 변환 및 로드(ETL) 작업을 사용하여 데이터를 JSON 형식으로 변환합니다. 
여러 Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 데이터를 
로드합니다. 
E. AWS Lake Formation 의 청사진을 사용하여 데이터 레이크에 수집할 수 있는 데이터를 
식별합니다. AWS Glue 를 사용하여 소스를 크롤링하고, 데이터를 추출하고, 데이터를 Apache 
Parquet 형식으로 Amazon S3 에 로드합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/85770-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
KPI 로 표시하기 위해선 Athena 가 필요하고, Athena 는 S3 에 쿼리함. 따라서 KPI 만 기억해도 
A,E 가 정답임을 쉽게 유추할 수 있음. 
・데이터베이스에서 가져온 배치 데이터와 네트워크 센서 및 애플리케이션 API 에서 생성한 라이브 
스트림 데이터를 한 곳에 모은다고 했으므로 형식이 다른 데이터를 한 곳에 모을 때 적절한 AWS 
LakeFormation 이 필요. 
・그리고 AWS Glue 는 Amazon S3 데이터 레이크의 필수 구성 요소이며 최신 데이터 분석을 위한 
데이터 카탈로그 및 변환 서비스 제공 
https://aws.amazon.com/ko/blogs/korea/build-a-data-lake-foundation-with-aws-glue-and-am
azon/ 
・AWS Glue 는 Athena 에서 쿼리 가능한 Parquet 파일을 쓸 수 있음. 
AWS Glue 를 사용하여 Amazon S3 와 스트리밍 소스에서 Parquet 파일을 읽을 수 있을 뿐만 
아니라 Amazon S3 에 Parquet 파일을 쓸 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/glue/latest/dg/aws-glue-programming-etl-format-parquet
-home.html 
Amazon Athena 에서 사용할 수 있는 Apache Parquet 
https://aws.amazon.com/ko/blogs/korea/build-a-data-lake-foundation-with-aws-glue-and-am
azon/ 
・S3 버킷에 있는 데이터를 Athena 로 쿼리 가능 
Amazon Athena 는 표준 SQL 을 사용하여 Amazon S3(Amazon Simple Storage Service)에 있는 
데이터를 직접 간편하게 분석할 수 있는 대화형 쿼리 서비스입니다. 
https://docs.aws.amazon.com/ko_kr/athena/latest/ug/what-is.html 
・QuickSight 로 KPI 표시 가능 
https://docs.aws.amazon.com/ko_kr/quicksight/latest/user/kpi.html 
설명 2: 
Amazon Athena 는 스트리밍 데이터에 대한 일회성 쿼리를 실행하기 위한 최상의 선택입니다. 
Amazon Kinesis Data Analytics 는 스트리밍 데이터를 실시간으로 분석할 수 있는 쉽고 친숙한 표준 
SQL 언어를 제공하지만 일회성 쿼리가 아닌 지속적인 쿼리를 위해 설계되었습니다. 반면 Amazon 
Athena 는 SQL 을 사용하여 Amazon S3 의 데이터를 쿼리할 수 있는 서버리스 대화형 쿼리 
서비스입니다. 임시 쿼리에 최적화되어 있으며 스트리밍 데이터에 대한 일회성 쿼리를 실행하는 데 
이상적입니다. 
AWS Lake Formation 은 분석 목적으로 모든 데이터를 보관하는 중앙 위치로 사용합니다. 
Athena 는 S3 와 완벽하게 통합되며 쿼리를 만들 수 있습니다. 
Q157 
회사는 Amazon Aurora PostgreSQL DB 클러스터에 데이터를 저장합니다. 회사는 모든 데이터를 
5 년간 보관하고 5 년이 지나면 모든 데이터를 삭제해야 합니다. 회사는 또한 데이터베이스 내에서 
수행되는 작업의 감사 로그를 무기한으로 유지해야 합니다. 현재 이 회사는 Aurora 용으로 자동 
백업을 구성했습니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (두 
가지를 선택하세요.) 
A. DB 클러스터의 수동 스냅샷을 생성합니다. 
B. 자동 백업에 대한 수명 주기 정책을 만듭니다. 
C. 5 년 동안 자동 백업 보존을 구성합니다. 
D. DB 클러스터에 대한 Amazon CloudWatch Logs 내보내기를 구성합니다. 
E. AWS Backup 을 사용하여 백업을 수행하고 5 년 동안 백업을 보관합니다. 
Answer: D, E 
https://www.examtopics.com/discussions/amazon/view/87629-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이전에는 특히 AWS 서비스 전체에서 백업을 조정할 때 수동 Aurora 클러스터 스냅샷에 대한 백업 
일정을 자동화하거나 보존 정책을 적용하거나 백업 활동을 통합하기 위해 사용자 지정 스크립트를 
생성해야 했습니다. AWS Backup 을 사용하면 스냅샷 예약 및 스냅샷 보존 관리 기능이 있는 완전 
관리형 정책 기반 백업 솔루션을 얻을 수 있습니다. 이제 PostgreSQL 호환 및 MySQL 호환 
Aurora 버전 모두에 대해 AWS Backup 콘솔에서 직접 Aurora 백업을 생성, 관리 및 복원할 수 
있습니다. 
시작하려면 AWS Backup 콘솔에서 Amazon Aurora 클러스터를 선택하고 온디맨드 백업을 
수행하거나 클러스터를 백업 계획에 할당하기만 하면 됩니다. 
Q158 
솔루션 아키텍트가 다가올 음악 행사를 위해 웹사이트를 최적화하고 있습니다. 공연 영상은 
실시간으로 스트리밍되며 주문형으로 제공된다. 이 행사는 전 세계 온라인 청중을 끌어들일 것으로 
예상됩니다. 
실시간 및 온디맨드 스트리밍의 성능을 모두 향상시키는 서비스는 무엇입니까? 
A. Amazon CloudFront 
B. AWS Global Accelerator 
C. Amazon Route 53 
D. Amazon S3 Transfer Acceleration  
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87514-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
CloudFront 를 사용하여 모든 HTTP 오리진을 사용하여 주문형 비디오(VOD) 또는 라이브 스트리밍 
비디오를 제공할 수 있습니다. 
클라우드에서 비디오 워크플로를 설정할 수 있는 한 가지 방법은 CloudFront 를 AWS Media 
Services 와 함께 사용하는 것입니다. 
https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/on-demand-streaming
video.html 
Q159 
회사에서 Amazon API Gateway 및 AWS Lambda 를 사용하는 공개적으로 액세스 가능한 서버리스 
애플리케이션을 실행하고 있습니다. 최근 봇넷의 사기성 요청으로 인해 애플리케이션의 트래픽이 
급증했습니다. 
승인되지 않은 사용자의 요청을 차단하기 위해 솔루션 설계자는 어떤 단계를 수행해야 합니까? (두 
가지를 선택하세요.) 
A. 정품 사용자에게만 공유되는 API 키로 사용량 계획을 생성합니다. 
B. 사기성 IP 주소의 요청을 무시하도록 Lambda 함수 내에 논리를 통합합니다. 
C. 악성 요청을 대상으로 하는 AWS WAF 규칙을 구현하고 이를 필터링하는 작업을 트리거합니다. 
D. 기존 공개 API 를 비공개 API 로 전환합니다. DNS 레코드를 업데이트하여 사용자를 새 API 
엔드포인트로 리디렉션합니다. 
E. API 에 액세스를 시도하는 각 사용자에 대해 IAM 역할을 생성합니다. 사용자는 API 호출 시 
역할을 맡게 됩니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/87516-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
API 사용 계획을 WAF 로 보완 가능. ""비용을 제어하거나 API 에 대한 액세스를 차단하기 위해 
사용량 계획 할당량 또는 조절에 의존하지 마십시오. AWS Budget 을 사용하여 비용을 
모니터링하고 AWS WAF  를 사용하여 API 요청을 관리하는 것을 고려하십시오. 
https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.
html 
A(O) : 애플리케이션 요청, 즉 API 요청을 함부로 하지 못하도록 하는 것이므로 A 는 정답. 
C(O) : 애플리케이션 계층 방어이고 봇넷 방어이므로 WAF 가 있는 C 는 정답 
(https://aws.amazon.com/ko/waf/getting-started/) 
E(X) : 공개적으로 사용가능한 서버리스 애플리케이션이라는 단서 때문에 제외됨. 
Q160 
전자상거래 회사는 AWS 클라우드에서 분석 애플리케이션을 호스팅합니다. 이 애플리케이션은 
매월 약 300MB 의 데이터를 생성합니다. 데이터는 JSON 형식으로 저장됩니다. 회사는 데이터 
백업을 위한 재해 복구 솔루션을 평가하고 있습니다. 데이터는 필요한 경우 밀리초 단위로 
액세스할 수 있어야 하며 데이터는 30 일 동안 보관되어야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon OpenSearch Service (Amazon Elasticsearch Service) 
B. Amazon S3 Glacier 
C. Amazon S3 Standard 
D. Amazon RDS for PostgreSQL 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/87632-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : Amazon OpenSerach Service 는 분석 및 모니터링 서비스인데 이미 회사에서 분석 
애플리케이션을 따로 사용 중이므로 데이터를 저장하는 서비스만 필요한 상황이라 필요가 없음. 
Amazon OpenSearch Service 는 AWS 클라우드에서 OpenSearch 클러스터를 손쉽게 배포, 운영 및 
확장할 수 있도록 해주는 관리형 서비스입니다. OpenSearch 는 로그 분석, 실시간 애플리케이션 
모니터링, 클릭 스트림 분석 같은 사용 사례를 위한 완전한 오픈 소스 검색 및 분석 엔진입니다. 
https://docs.aws.amazon.com/ko_kr/opensearch-service/latest/developerguide/what-is.html 
B(X) : 아무리 빨라봤자 액세스 타임이 1 분 정도 걸림. 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.ht
ml 
C(O) : S3 + Life Cycle Policy 조합으로 밀리초 단위 액세스와 30 일간 보관 조건 충족 가능 
https://aws.amazon.com/ko/s3/storage-classes/)(https://docs.aws.amazon.com/ko_kr/Amazon
S3/latest/userguide/object-lifecycle-mgmt.html 
D(X) : 데이터베이스는 데이터를 수집하여 다른 서비스에 이용할 목적으로 사용하는 것이지, 특정 
기간만 보관해두고자 하는 용도가 아님. 지문에서는 회사가 이미 분석 애플리케이션을 가지고 
있는데다가 원하는 건 분석 애플리케이션으로 생성한 데이터를 보관할 곳을 찾는 것임. 따라서 
C 가 더 적합. 
설명 2: 
이 솔루션은 분석 애플리케이션에서 생성되고 JSON 형식으로 저장되는 데이터를 백업하기 위한 
재해 복구 솔루션의 요구 사항을 충족하며 필요한 경우 밀리초 내에 액세스할 수 있어야 합니다. 
Amazon S3 Standard 는 자주 액세스하는 데이터를 위한 내구성 있고 확장 가능한 스토리지 
클래스입니다. 모든 양의 데이터를 저장할 수 있고 고가용성과 성능을 제공할 수 있습니다. 또한 
데이터 검색을 위한 밀리초 액세스 시간을 지원할 수 있습니다. 
Amazon OpenSearch Service(Amazon Elasticsearch Service)는 데이터를 인덱싱하고 쿼리할 수 
있는 검색 및 분석 서비스이지만 JSON 형식으로 저장된 데이터에 대한 백업 솔루션이 아니기 
때문에 옵션 A 는 올바르지 않습니다. 
옵션 B 는 Amazon S3 Glacier 가 데이터 보관 및 장기 백업을 위한 저비용 스토리지 클래스이지만 
데이터 검색을 위한 밀리초 액세스 시간을 지원하지 않기 때문에 정답이 아닙니다. 
PostgreSQL 용 Amazon RDS 는 구조화된 데이터를 저장하고 쿼리할 수 있는 관계형 데이터베이스 
서비스이지만 JSON 형식으로 저장된 데이터에 대한 백업 솔루션이 아니기 때문에 옵션 D 는 
올바르지 않습니다. 
참조: 
https://aws.amazon.com/s3/storage-classes/ 
https://aws.amazon.com/s3/faqs/#Durability_and_data_protection 
Q161 
회사에는 JSON 문서를 처리하고 그 결과를 온프레미스 SQL 데이터베이스에 출력하는 작은 
Python 애플리케이션이 있습니다. 이 애플리케이션은 매일 수천 번 실행됩니다. 회사는 
애플리케이션을 AWS 클라우드로 이동하려고 합니다. 이 회사는 확장성을 최대화하고 운영 
오버헤드를 최소화하는 고가용성 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. JSON 문서를 Amazon S3 버킷에 넣습니다. 여러 Amazon EC2 인스턴스에서 Python 코드를 
실행하여 문서를 처리합니다. 결과를 Amazon Aurora DB 클러스터에 저장합니다. 
B. JSON 문서를 Amazon S3 버킷에 넣습니다. 문서가 S3 버킷에 도착하면 이를 처리하기 위해 
Python 코드를 실행하는 AWS Lambda 함수를 생성합니다. 결과를 Amazon Aurora DB 클러스터에 
저장합니다. 
C. JSON 문서를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 넣습니다. EBS 다중 연결 
기능을 사용하여 볼륨을 여러 Amazon EC2 인스턴스에 연결합니다. EC2 인스턴스에서 Python 
코드를 실행하여 문서를 처리합니다. Amazon RDS DB 인스턴스에 결과를 저장합니다. 
D. JSON 문서를 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지로 배치합니다. 
Amazon EC2 시작 유형으로 구성된 Amazon Elastic Container Service(Amazon ECS) 클러스터에 
Python 코드를 컨테이너로 배포합니다. 컨테이너를 사용하여 SQS 메시지를 처리합니다. Amazon 
RDS DB 인스턴스에 결과를 저장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87633-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Lambda 를 사용하면 서버를 관리하고 프로비저닝할 필요가 없으므로 확장성이 보장되고 운영 
오버헤드가 최소화됩니다. S3 는 JSON 문서를 위한 내구성 있고 가용성이 높은 스토리지를 
제공합니다. Lambda 는 새 문서가 S3 버킷에 추가될 때마다 자동으로 트리거되어 실시간 처리가 
가능합니다. 결과를 Aurora DB 클러스터에 저장하면 처리된 데이터의 고가용성과 확장성이 
보장됩니다. 이 솔루션은 서버리스 아키텍처를 활용하여 인프라를 관리할 필요 없이 자동 확장 및 
고가용성을 허용하므로 가장 적합한 선택입니다. 
A. 이 옵션을 사용하려면 EC2 인스턴스를 수동으로 관리하고 확장해야 하므로 운영 오버헤드와 
복잡성이 높아집니다. 
C. 이 접근 방식에는 여전히 EC2 인스턴스의 수동 관리 및 확장이 포함되어 운영 복잡성과 
오버헤드가 증가합니다. 
D. 이 솔루션은 ECS 클러스터를 관리하고 확장해야 하므로 운영 오버헤드와 복잡성이 추가됩니다. 
SQS 를 활용하면 시스템에 복잡성이 추가되어 Python 코드에서 메시지 소비 및 처리를 사용자 
지정 처리해야 합니다. 
설명 2: 
JSON 문서를 S3 버킷에 넣으면 문서가 내구성과 확장성이 뛰어난 객체 스토리지 서비스에 
저장됩니다. AWS Lambda 를 사용하면 회사는 Python 코드를 실행하여 기본 인프라에 대해 걱정할 
필요 없이 S3 버킷에 도착하는 문서를 처리할 수 있습니다. 또한 AWS Lambda 가 들어오는 요청 
비율에 따라 함수의 인스턴스 수를 자동으로 조정하므로 수평적 확장성이 가능합니다. 결과는 
MySQL 및 PostgreSQL 과 호환되는 완전 관리형 고성능 데이터베이스 서비스인 Amazon Aurora 
DB 클러스터에 저장할 수 있습니다. 이는 처리 결과에 필요한 내구성과 확장성을 제공합니다. 
https://aws.amazon.com/rds/aurora/ 
Q162 
회사에서 재무 위험 모델링을 위해 AWS 에서 고성능 컴퓨팅(HPC) 인프라를 사용하려고 합니다. 
회사의 HPC 워크로드는 Linux 에서 실행됩니다. 각 HPC 워크플로는 수백 개의 Amazon EC2 스팟 
인스턴스에서 실행되고 수명이 짧으며 궁극적으로 분석 및 향후 장기적 사용을 위해 영구 
스토리지에 저장되는 수천 개의 출력 파일을 생성합니다. 
이 회사는 모든 EC2 인스턴스에서 데이터를 처리할 수 있도록 온프레미스 데이터를 장기 영구 
스토리지로 복사할 수 있는 클라우드 스토리지 솔루션을 찾고 있습니다. 솔루션은 또한 데이터 
세트와 출력 파일을 읽고 쓰기 위해 영구 스토리지와 통합된 고성능 파일 시스템이어야 합니다. 
이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까? 
A. Amazon S3 와 통합된 Amazon FSx for Lustre 
B. Amazon S3 와 통합된 Windows 파일 서버용 Amazon FSx 
C. Amazon Elastic Block Store(Amazon EBS)와 통합된 Amazon S3 Glacier 
D. Amazon Elastic Block Store(Amazon EBS) 범용 SSD(gp2) 볼륨과 통합된 VPC 엔드포인트가 
있는 Amazon S3 버킷 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87634-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
https://aws.amazon.com/fsx/lustre/ 
Amazon FSx for Lustre 는 컴퓨팅 워크로드를 위한 비용 효율적이고 확장 가능한 고성능 
스토리지를 제공하는 완전관리형 서비스입니다. 기계 학습, 고성능 컴퓨팅(HPC), 비디오 렌더링, 
재무 시뮬레이션과 같은 많은 워크로드는 고성능 공유 스토리지를 통해 동일한 데이터 세트에 
액세스하는 컴퓨팅 인스턴스에 의존합니다. 
HPC = Amazon FSx for Lustre. 정답은 A. 
Q163 
한 회사가 온프레미스에서 컨테이너화된 애플리케이션을 구축하고 애플리케이션을 AWS 로 
이전하기로 결정했습니다. 응용 프로그램은 배포된 직후 수천 명의 사용자를 보유하게 됩니다. 
회사는 규모에 맞게 컨테이너 배포를 관리하는 방법을 확신하지 못합니다. 회사는 운영 오버헤드를 
최소화하는 고가용성 아키텍처에 컨테이너화된 애플리케이션을 배포해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Container Registry(Amazon ECR) 리포지토리에 컨테이너 이미지를 저장합니다. 
AWS Fargate 시작 유형과 함께 Amazon Elastic Container Service(Amazon ECS) 클러스터를 
사용하여 컨테이너를 실행합니다. 대상 추적을 사용하여 수요에 따라 자동으로 확장합니다. 
B. 컨테이너 이미지를 Amazon Elastic Container Registry(Amazon ECR) 리포지토리에 저장합니다. 
Amazon EC2 시작 유형과 함께 Amazon Elastic Container Service(Amazon ECS) 클러스터를 
사용하여 컨테이너를 실행합니다. 대상 추적을 사용하여 수요에 따라 자동으로 확장합니다. 
C. Amazon EC2 인스턴스에서 실행되는 리포지토리에 컨테이너 이미지를 저장합니다. 여러 가용 
영역에 분산된 EC2 인스턴스에서 컨테이너를 실행합니다. Amazon CloudWatch 에서 평균 CPU 
사용률을 모니터링합니다. 필요에 따라 새 EC2 인스턴스를 시작합니다. 
D. 컨테이너 이미지가 포함된 Amazon EC2 Amazon 머신 이미지(AMI)를 생성합니다. 여러 가용 
영역의 Auto Scaling 그룹에서 EC2 인스턴스를 시작합니다. 평균 CPU 사용률 임계값을 초과하면 
Amazon CloudWatch 경보를 사용하여 EC2 인스턴스를 확장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87509-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS Fargate 는 사용자 애플리케이션을 위한 서버리스 환경으로, 사용자는 서버 구성 및 관리 
대신 애플리케이션 구축에 집중할 수 있습니다. 또한 Fargate 는 리소스 관리를 자동화하여 
사용자가 수요에 따라 애플리케이션을 쉽게 확장할 수 있도록 합니다. 
컨테이너화된 애플리케이션 배포 = Fargate + ECS. 정답은 A. 
Q164 
회사에는 처리할 페이로드가 포함된 메시지를 보내는 발신자 애플리케이션과 페이로드가 포함된 
메시지를 수신하기 위한 처리 애플리케이션의 두 가지 애플리케이션이 있습니다. 회사는 두 
애플리케이션 간의 메시지를 처리하기 위해 AWS 서비스를 구현하려고 합니다. 발신자 
애플리케이션은 매시간 약 1,000 개의 메시지를 보낼 수 있습니다. 메시지를 처리하는 데 최대 
2 일이 걸릴 수 있습니다. 메시지를 처리하지 못한 경우 나머지 메시지 처리에 영향을 주지 않도록 
보관해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? 
A. Redis 데이터베이스를 실행하는 Amazon EC2 인스턴스를 설정합니다. 인스턴스를 사용하도록 
두 애플리케이션을 모두 구성합니다. 메시지를 각각 저장, 처리 및 삭제합니다. 
B. Amazon Kinesis 데이터 스트림을 사용하여 발신자 애플리케이션에서 메시지를 수신합니다. 처리 
애플리케이션을 Kinesis Client Library(KCL)와 통합합니다. 
C. 발신자 및 프로세서 애플리케이션을 Amazon Simple Queue Service(Amazon SQS) 대기열과 
통합합니다. 처리에 실패한 메시지를 수집하도록 배달 못한 편지 대기열을 구성합니다. 
D. 처리할 알림을 수신하려면 처리 애플리케이션을 Amazon Simple Notification Service(Amazon 
SNS) 주제에 구독합니다. 발신자 애플리케이션을 통합하여 SNS 주제에 씁니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/87523-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
메시지 처리에 실패하면 = SQS Dead Letter Queue. 정답은 C. 
설명 2: 
발신자 및 프로세서 애플리케이션을 모두 SQS 와 통합하면 처리를 위해 발신자에서 프로세서 
애플리케이션으로 메시지를 안정적으로 보낼 수 있습니다. SQS 는 최소 1 회 전달을 제공하여 
메시지가 전송 중에 손실되지 않도록 합니다. 메시지 처리에 실패하면 다른 메시지 처리에 영향을 
주지 않고 대기열에 보관하고 다시 시도할 수 있습니다. DLQ 를 구성하면 반복적으로 처리에 
실패하는 메시지를 수집할 수 있으므로 문제 해결 및 분석을 위해 실패한 메시지를 볼 수 
있습니다. 
A 는 운영 오버헤드 및 유지 관리 요구 사항을 추가하는 Redis 를 실행하는 EC2 인스턴스의 관리 
및 구성과 관련되므로 최적의 선택이 아닙니다. 
B 는 Amazon Kinesis 데이터 스트림을 사용하고 메시지 처리를 위해 Kinesis Client Library 와 
통합함으로써 추가적인 복잡성을 도입하므로 운영상 가장 효율적인 솔루션은 아닙니다. 
SNS 를 사용하는 D 는 두 애플리케이션 간의 메시지 처리라는 특정 요구 사항보다 Pub/Sub 
메시징 및 방송 알림에 더 적합하므로 시나리오에 가장 적합하지 않습니다. 
참고: 
https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-le
tterqueues.html 
Q165 
솔루션 설계자는 정적 웹 사이트를 저장하기 위해 Amazon S3 오리진과 함께 Amazon 
CloudFront 를 사용하는 솔루션을 설계해야 합니다. 회사의 보안 정책에 따라 모든 웹 사이트 
트래픽은 AWS WAF 에서 검사해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 어떻게 준수해야 합니까? 
A. AWS WAF Amazon 리소스 이름(ARN)에서만 오는 요청을 수락하도록 S3 버킷 정책을 
구성합니다. 
B. S3 오리진에서 콘텐츠를 요청하기 전에 모든 수신 요청을 AWS WAF 로 전달하도록 Amazon 
CloudFront 를 구성합니다. 
C. Amazon CloudFront IP 주소가 Amazon S3 에만 액세스하도록 허용하는 보안 그룹을 구성합니다. 
AWS WAF 를 CloudFront 에 연결합니다. 
D. 원본 액세스 ID(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 Amazon CloudFront 및 
Amazon S3 를 구성합니다. 배포에서 AWS WAF 를 활성화합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/87524-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
B?? 
설명: 
CloudFront 로만 접속할 수 있도록 한 뒤에 WAF 로 검사해야 함. 
Amazon S3 버킷을 오리진으로 설정하여 CloudFront 를 사용하는 경우 다음과 같은 이점을 
제공하는 방식으로 CloudFront 및 Amazon S3 를 구성할 수 있습니다.  
◎공개적으로 액세스할 수 없도록 Amazon S3 버킷에 대한 액세스를 제한합니다.  
◎뷰어(사용자)가 지정된 CloudFront 배포를 통해서만 버킷의 콘텐츠에 액세스할 수 있도록 합니다. 
즉, 뷰어가 버킷에서 직접 또는 의도하지 않은 CloudFront 배포를 통해 콘텐츠에 액세스하는 것을 
방지합니다. 이렇게 하려면 인증된 요청을 Amazon S3 로 보내도록 CloudFront 를 구성하고 
CloudFront 의 인증된 요청에 대한 액세스만 허용하도록 Amazon S3 를 구성합니다. CloudFront 는 
Amazon S3 오리진에 인증된 요청을 전송하는 두 가지 방법으로 오리진 액세스 제어(OAC)와 
오리진 액세스 ID(OAI)를 제공합니다. 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-content-
restricting-access-to-s3.html 
AWS WAF 는 CloudFront 에 전달되는 HTTP 및 HTTPS 요청을 모니터링할 수 있게 해주고 
콘텐츠에 대한 액세스를 제어할 수 있게 해주는 웹 애플리케이션 방화벽입니다. 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/distribution-web
-awswaf.html 
참조 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-content-
restricting-access-to-s3.html 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/distribution-web
-awswaf.html 
Q166 
글로벌 이벤트의 주최자는 일일 보고서를 정적 HTML 페이지로 온라인에 게시하려고 합니다. 이 
페이지는 전 세계 사용자로부터 수백만 건의 조회수를 생성할 것으로 예상됩니다. 파일은 Amazon 
S3 버킷에 저장됩니다. 솔루션 설계자는 효율적이고 효과적인 솔루션을 설계하라는 요청을 
받았습니다. 
이를 달성하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까? 
A. 파일에 대해 미리 서명된 URL 을 생성합니다. 
B. 모든 리전에 교차 리전 복제를 사용합니다. 
C. Amazon Route 53 의 지리적 근접성 기능을 사용합니다. 
D. S3 버킷과 함께 Amazon CloudFront 를 원본으로 사용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/87522-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
정적 HTML 페이지 + 전 세계 사용자의 조회 + S3 버킷에 저장된 데이터 = S3 + CloudFront 조합. 
답은 D. 
설명 2: 
Amazon CloudFront 는 HTML 페이지, 이미지 및 비디오와 같은 정적 및 동적 웹 콘텐츠의 전송 
속도를 높이는 콘텐츠 전송 네트워크(CDN)입니다. CloudFront 를 사용하면 HTML 페이지가 가장 
가까운 엣지 로케이션에서 사용자에게 제공되므로 더 빠르게 전달되고 더 나은 사용자 경험을 
얻을 수 있습니다. 또한 CloudFront 는 글로벌 이벤트에 예상되는 높은 트래픽과 많은 수의 요청을 
처리하여 전 세계 사용자가 HTML 페이지를 사용할 수 있고 액세스할 수 있도록 합니다. 
Q167 
회사는 Amazon EC2 인스턴스 플릿에서 프로덕션 애플리케이션을 실행합니다. 애플리케이션은 
Amazon SQS 대기열에서 데이터를 읽고 병렬로 메시지를 처리합니다. 메시지 볼륨은 예측할 수 
없으며 종종 트래픽이 간헐적으로 발생합니다. 이 애플리케이션은 다운타임 없이 지속적으로 
메시지를 처리해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 스팟 인스턴스를 독점적으로 사용하여 필요한 최대 용량을 처리하십시오. 
B. 예약 인스턴스를 독점적으로 사용하여 필요한 최대 용량을 처리합니다. 
C. 기본 용량으로 예약 인스턴스를 사용하고 추가 용량을 처리하려면 스팟 인스턴스를 사용합니다. 
D. 기본 용량에는 예약 인스턴스를 사용하고 추가 용량을 처리하려면 온디맨드 인스턴스를 
사용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/87510-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
C?? 
설명 1: 
A(X) : 가동 중지 시간이 없어야 한다고 했으므로 중지될 위험이 잇는 스팟 인스턴스는 적절치 
않음. 
B(X) : 메시지 볼륨을 예측할 수 없고 간헐적인 트래픽이 발생하는 상황에서 예측할 수 있는 
트래픽이 발생하는 데에 적합한 예약 인스턴스는 맞지 않음. 
C(X) : A 와 같은 이유로 오답. 
D(O) : 최소 사용량을 기준 용량으로 삼아 예약 인스턴스를 사용함으로서 비용을 절감하고, 
추가적이고 유동적인 트래픽은 온디맨드 인스턴스로 유연하게 처리 가능. 
설명 2: 
중단할 수 없는 단기적이고 불규칙한 워크로드가 있는 애플리케이션에는 온디맨드 인스턴스를 
사용하는 것이 좋습니다. 
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-on-demand-instances.html 
Q168 
보안 팀은 팀의 모든 AWS 계정에서 특정 서비스 또는 작업에 대한 액세스를 제한하려고 합니다. 
모든 계정은 AWS Organizations 의 대규모 조직에 속합니다. 솔루션은 확장 가능해야 하며 권한을 
유지할 수 있는 단일 지점이 있어야 합니다. 
이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. ACL 을 생성하여 서비스 또는 작업에 대한 액세스를 제공합니다. 
B. 계정을 허용할 보안 그룹을 생성하고 사용자 그룹에 연결합니다. 
C. 각 계정에서 교차 계정 역할을 생성하여 서비스 또는 작업에 대한 액세스를 거부합니다. 
D. 루트 조직 단위에 서비스 제어 정책을 만들어 서비스 또는 작업에 대한 액세스를 거부합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/87512-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
권한을 유지할 수 있는 단일 지점이 핵심 키워드. 답은 D. 
서비스 제어 정책(SCP)은 조직에서 권한을 관리하는 데 사용할 수 있는 조직 정책 유형입니다. 
SCP 는 조직의 모든 계정에 대해 사용 가능한 최대 권한을 중앙에서 제어합니다. 
https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html 
설명 2: 
서비스 제어 정책(SCP)은 조직을 관리하는 데 사용할 수 있는 정책 유형 중 하나입니다. SCP 는 
조직의 모든 계정에 대해 사용 가능한 최대 권한에 대한 중앙 제어를 제공하므로 계정이 조직의 
액세스 제어 지침을 준수하도록 할 수 있습니다. 
https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html 
Q169 
회사는 최근 웹 공격으로 인해 공용 웹 애플리케이션의 보안에 대해 우려하고 있습니다. 
애플리케이션은 Application Load Balancer(ALB)를 사용합니다. 솔루션 설계자는 애플리케이션에 
대한 DDoS 공격의 위험을 줄여야 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. ALB 에 Amazon Inspector 에이전트를 추가합니다. 
B. 공격을 방지하도록 Amazon Macie 를 구성합니다. 
C. 공격을 방지하려면 AWS Shield Advanced 를 활성화하십시오. 
D. ALB 를 모니터링하도록 Amazon GuardDuty 를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/87526-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
AWS Shield Standard, AWS Shield Advanced 는 애플리케이션 계층에서 DDoS 공격을 방어. 
AWS Shield 는 AWS 에서 실행되는 애플리케이션을 보호하는 디도스(DDoS) 보호 서비스입니다. 
AWS Shield 에는 두 계층 – Standard 및 Advanced 가 있습니다. 
https://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.postDateTi
me&whats-new-cards.sort-order=desc 
설명 2: 
AWS Shield Advanced 는 Amazon EC2 인스턴스, Elastic Load Balancing 로드 밸런서, CloudFront 
배포, Route 53 호스팅 영역 및 AWS Global Accelerator 표준 가속기에 대해 확장된 DDoS 공격 
보호 기능을 제공합니다. 
https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html 
Q170 
회사의 웹 애플리케이션이 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행되고 
있습니다. 이 회사는 최근 정책을 변경하여 이제 특정 국가에서만 애플리케이션에 액세스하도록 
요구합니다. 
이 요구 사항을 충족하는 구성은 무엇입니까? 
A. EC2 인스턴스에 대한 보안 그룹을 구성합니다. 
B. Application Load Balancer 에서 보안 그룹을 구성합니다. 
C. VPC 의 Application Load Balancer 에서 AWS WAF 를 구성합니다. 
D. EC2 인스턴스를 포함하는 서브넷에 대한 네트워크 ACL 을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/87528-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS WAF 를 사용하여 특정 국가 또는 지리적 위치로부터의 요청을 허용하거나 차단하려면 어떻게 
해야 합니까?  
특정 국가의 사이트 액세스를 차단하거나 특정 국가에서만 액세스하도록 허용하려면 지리적 일치 
규칙 문을 사용합니다. 기원 국가를 기준으로 일부 웹 요청을 허용하려면 허용하려는 국가에 대한 
지리적 일치 규칙 문을 추가합니다. 그런 다음 차단하려는 국가에 대한 두 번째 지리적 일치 규칙 
문을 추가합니다. 
https://aws.amazon.com/ko/premiumsupport/knowledge-center/waf-allow-block-country-geolo
cation/ 
Q171 
회사는 사용자에게 항목 가격을 기반으로 세금 계산을 위한 조회를 자동화하는 API 를 제공합니다. 
회사는 연휴 기간에만 더 많은 수의 문의가 발생하여 응답 시간이 느려집니다. 솔루션 설계자는 
확장 가능하고 탄력적인 솔루션을 설계해야 합니다. 
이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. Amazon EC2 인스턴스에서 호스팅되는 API 를 제공합니다. EC2 인스턴스는 API 요청이 있을 때 
필요한 계산을 수행합니다. 
B. 항목 이름을 허용하는 Amazon API Gateway 를 사용하여 REST API 를 설계합니다. API 
Gateway 는 세금 계산을 위해 항목 이름을 AWS Lambda 에 전달합니다. 
C. 두 개의 Amazon EC2 인스턴스가 있는 Application Load Balancer 를 생성합니다. EC2 
인스턴스는 받은 항목 이름에 대한 세금을 계산합니다. 
D. Amazon EC2 인스턴스에서 호스팅되는 API와 연결되는 Amazon API Gateway 를 사용하여 REST 
API 를 설계합니다. API Gateway 는 세금 계산을 위해 항목 이름을 수락하고 EC2 인스턴스에 
전달합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87529-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
API 제공 + 탄력적인 = API Gateway + Lambda. 답은 B. 
설명 2: 
Lambda 서버리스는 EC2 api 게이트웨이 솔루션보다 확장 가능하고 탄력적입니다. 
Q172 
솔루션 설계자가 애플리케이션을 위한 새로운 Amazon CloudFront 배포를 생성하고 있습니다. 
사용자가 제출한 정보 중 일부는 민감한 정보입니다. 애플리케이션은 HTTPS 를 사용하지만 다른 
보안 계층이 필요합니다. 민감한 정보는 전체 애플리케이션 스택에서 보호되어야 하며 정보에 대한 
액세스는 특정 애플리케이션으로 제한되어야 합니다. 
솔루션 설계자는 어떤 조치를 취해야 합니까? 
A. CloudFront 서명 URL 을 구성합니다. 
B. CloudFront 서명 쿠키를 구성합니다. 
C. CloudFront 필드 수준 암호화 프로필을 구성합니다. 
D. CloudFront 를 구성하고 뷰어 프로토콜 정책에 대해 오리진 프로토콜 정책 설정을 HTTPS 
전용으로 설정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/87517-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Amazon CloudFront 를 사용하면 HTTPS 를 통해 오리진 서버에 대한 종단 간 보안 연결을 적용할 
수 있습니다. 필드 레벨 암호화는 추가 보안 레이어를 추가하여 시스템 처리 전체에서 특정 
데이터를 보호하고 특정 애플리케이션만 이를 볼 수 있도록 합니다. 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/field-level-encry
ption.html 
설명 2: 
https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/field-levelencryption.ht
ml 
"Amazon CloudFront 를 사용하면 HTTPS 를 사용하여 오리진 서버에 대한 엔드 투 엔드 보안 
연결을 적용할 수 있습니다. 
필드 수준 암호화는 특정 애플리케이션만 볼 수 있도록 시스템 처리 전반에 걸쳐 특정 데이터를 
보호할 수 있는 추가 보안 계층을 추가합니다." 
Q173 
게임 회사는 AWS 에서 브라우저 기반 애플리케이션을 호스팅합니다. 애플리케이션 사용자는 
Amazon S3 에 저장된 많은 수의 비디오 및 이미지를 소비합니다. 이 내용은 모든 사용자에게 
동일합니다. 
이 응용 프로그램은 인기가 높아졌으며 전 세계적으로 수백만 명의 사용자가 이러한 미디어 
파일에 액세스합니다. 회사는 원본에 대한 부하를 줄이면서 사용자에게 파일을 제공하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 웹 서버 앞에 AWS Global Accelerator 액셀러레이터를 배포합니다. 
B. S3 버킷 앞에 Amazon CloudFront 웹 배포를 배포합니다. 
C. 웹 서버 앞에 Redis 인스턴스용 Amazon ElastiCache 를 배포합니다. 
D. 웹 서버 앞에 Amazon ElastiCache for Memcached 인스턴스를 배포합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87530-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
S3 + 많은 수의 비디오와 이미지 + 수백만명 액세스가 핵심. S3 + CloudFront 로 CDN 서비스 
사용해야 부하를 줄일 수 있음. 
설명 2: 
ElastiCache 는 완전 관리형 인 메모리 데이터 저장소에서 정보를 신속하게 검색하여 웹 
애플리케이션의 성능을 향상시킵니다. Memcached 및 Redis 를 활용하고 애플리케이션이 디스크 
기반 데이터베이스에서 데이터를 읽는 데 걸리는 시간을 상당히 단축합니다. Amazon CloudFront 는 
TCP(전송 제어 프로토콜) 프로토콜을 기반으로 하는 HTTP 및 WebSocket 프로토콜의 동적 
콘텐츠를 지원합니다. 일반적인 사용 사례에는 동적 API 호출, 웹 페이지 및 웹 애플리케이션뿐만 
아니라 오디오 및 이미지와 같은 애플리케이션의 정적 파일이 포함됩니다. 또한 HTTP 를 통한 
주문형 미디어 스트리밍을 지원합니다. AWS Global Accelerator 는 UDP(사용자 데이터그램 
프로토콜)와 TCP 기반 프로토콜을 모두 지원합니다. 일반적으로 게임, IoT 및 VoIP(Voice over 
IP)와 같은 비 HTTP 사용 사례에 사용됩니다. 고정 IP 주소 또는 빠른 지역 장애 조치가 필요한 
HTTP 사용 사례에도 적합합니다. 
Q174 
회사에는 ALB(Application Load Balancer) 뒤의 단일 가용 영역에 있는 Amazon EC2 Auto Scaling 
그룹에서 6 개의 프런트 엔드 웹 서버를 실행하는 다중 계층 애플리케이션이 있습니다. 솔루션 
설계자는 애플리케이션을 수정하지 않고 인프라를 고가용성으로 수정해야 합니다. 
고가용성을 제공하는 솔루션 설계자는 어떤 아키텍처를 선택해야 합니까? 
A. 두 리전 각각에서 세 개의 인스턴스를 사용하는 Auto Scaling 그룹을 만듭니다. 
B. 2 개의 가용 영역 각각에서 3 개의 인스턴스를 사용하도록 Auto Scaling 그룹을 수정합니다. 
C. 다른 리전에서 더 많은 인스턴스를 빠르게 생성하는 데 사용할 수 있는 Auto Scaling 템플릿을 
생성합니다. 
D. 라운드 로빈 구성에서 Amazon EC2 인스턴스 앞의 ALB 를 변경하여 웹 계층에 대한 트래픽의 
균형을 맞춥니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87533-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
다중 AZ 를 사용해야 하는 상황. 
A(X) : 리전 간 Auto Scaling 은 불가. 
지리적 이중화의 안전성과 안정성을 활용하려면 Auto Scaling 그룹을 리전 내의 여러 가용 영역에 
걸쳐 확장하고 로드 밸런서를 연결하여 해당 가용 영역에 들어오는 트래픽을 분산하십시오. 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html 
설명 2: 
여러 가용 영역을 사용하도록 기존 Auto Scaling 그룹을 수정하여 이 아키텍처에 대해 매우 
간단하게 고가용성을 활성화할 수 있습니다. ASG 는 부하를 자동으로 분산하므로 실제로 AZ 당 
인스턴스를 지정할 필요가 없습니다. 
참조: 
https://aws.amazon.com/ec2/autoscaling/ 
Q175 
전자 상거래 회사에는 Amazon API Gateway 및 AWS Lambda 함수를 사용하는 주문 처리 
애플리케이션이 있습니다. 애플리케이션은 Amazon Aurora PostgreSQL 데이터베이스에 데이터를 
저장합니다. 최근 판매 행사 중에 고객 주문이 갑자기 급증했습니다. 일부 고객은 시간 초과를 
경험했고 애플리케이션은 해당 고객의 주문을 처리하지 않았습니다. 
솔루션 설계자는 많은 수의 열린 연결로 인해 데이터베이스에서 CPU 사용률과 메모리 사용률이 
높다고 판단했습니다. 솔루션 설계자는 응용 프로그램을 최소한으로 변경하면서 시간 초과 오류를 
방지해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. 여러 AWS 리전에서 글로벌 
데이터베이스가 되도록 데이터베이스를 수정합니다. 
B. Amazon RDS 프록시를 사용하여 데이터베이스에 대한 프록시를 생성합니다. 데이터베이스 
엔드포인트 대신 RDS 프록시 엔드포인트를 사용하도록 Lambda 함수를 수정합니다. 
C. 다른 AWS 리전에서 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. API Gateway 에서 
쿼리 문자열 파라미터를 사용하여 트래픽을 읽기 전용 복제본으로 라우팅합니다. 
D. AWS Database Migration Service(AWS DMS)를 사용하여 Aurora PostgreSQL 에서 Amazon 
DynamoDB 로 데이터를 마이그레이션합니다. DynamoDB 테이블을 사용하도록 Lambda 함수를 
수정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87533-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
연결 수가 많음 = RDS Proxy. 정답은 B. 
RDS 프록시를 사용하여 예기치 않은 데이터베이스 트래픽 급증을 처리할 수 있습니다. 급증을 
처리하지 않으면 연결 초과 구독 또는 빠른 속도의 새 연결 생성으로 인한 문제가 발생할 수 
있습니다. RDS 프록시는 데이터베이스 연결 풀을 설정하고 이 풀에서 연결을 재사용합니다. 이 
접근 방식은 매번 새 데이터베이스 연결을 여는 데서 오는 메모리 및 CPU 오버헤드 를 
방지합니다. 과다 구독으로부터 데이터베이스를 보호하기 위해 생성되는 데이터베이스 연결 수를 
제어할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/rds-proxy.html 
설명 2: 
최신 서버리스 아키텍처에 구축된 애플리케이션을 포함하여 많은 애플리케이션은 데이터베이스 
서버에 대해 많은 수의 열린 연결을 가질 수 있으며 빠른 속도로 데이터베이스 연결을 열고 닫을 
수 있으므로 데이터베이스 메모리와 컴퓨팅 리소스가 고갈될 수 있습니다. Amazon RDS Proxy 를 
사용하면 애플리케이션이 데이터베이스와 설정된 연결을 풀링하고 공유하여 데이터베이스 
효율성과 애플리케이션 확장성을 개선할 수 있습니다. 
https://aws.amazon.com/id/rds/proxy/ 
Q176 
애플리케이션은 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 
Amazon DynamoDB 테이블에 액세스해야 합니다. 
트래픽이 AWS 네트워크를 벗어나지 않도록 하면서 테이블에 액세스하는 가장 안전한 방법은 
무엇입니까? 
A. DynamoDB 용 VPC 엔드포인트를 사용합니다. 
B. 퍼블릭 서브넷에서 NAT 게이트웨이를 사용합니다. 
C. 프라이빗 서브넷에서 NAT 인스턴스를 사용합니다. 
D. VPC 에 연결된 인터넷 게이트웨이를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87532-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
VPC 내에 있는 프라이빗 서브넷의 EC2 인스턴스와 DynamoDB 간 가장 안전한 AWS 네트워크 
통신 = VPC Gateway Endpoint. 
게이트웨이 엔드포인트는 VPC 용 인터넷 게이트웨이 또는 NAT 디바이스가 없어도 Amazon S3 및 
DynamoDB 에 대한 안정적인 연결을 제공합니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpce-gateway.html#vpc-endpoints-li
mitations 
설명 2: 
DynamoDB 용 VPC 엔드포인트를 사용하면 VPC 의 Amazon EC2 인스턴스가 프라이빗 IP 주소를 
사용하여 퍼블릭 인터넷에 노출되지 않고 DynamoDB 에 액세스할 수 있습니다. EC2 인스턴스에는 
퍼블릭 IP 주소가 필요하지 않으며 VPC 에 인터넷 게이트웨이, NAT 디바이스 또는 가상 프라이빗 
게이트웨이가 필요하지 않습니다. 엔드포인트 정책을 사용하여 DynamoDB 에 대한 액세스를 
제어합니다. VPC 와 AWS 서비스 간의 트래픽은 Amazon 네트워크를 벗어나지 않습니다. 
Q177 
엔터테인먼트 회사는 Amazon DynamoDB 를 사용하여 미디어 메타데이터를 저장하고 있습니다. 
애플리케이션이 읽기 집약적이며 지연이 발생합니다. 회사에는 추가 운영 오버헤드를 처리할 
직원이 없으며 애플리케이션을 재구성하지 않고 DynamoDB 의 성능 효율성을 개선해야 합니다. 
이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. Redis 용 Amazon ElastiCache 를 사용합니다. 
B. Amazon DynamoDB Accelerator(DAX)를 사용합니다. 
C. DynamoDB 전역 테이블을 사용하여 데이터를 복제합니다. 
D. 자동 검색이 활성화된 Memcached 용 Amazon ElastiCache 를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87572-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
DynamoDB 와 DAX 가 결합되면 성능을 한 단계 업그레이드하여 읽기 중심의 워크로드에서 초당 
수백만 개의 요청에도 마이크로초의 응답 시간을 지원합니다. DynamoDB 와 마찬가지로 DAX 는 
완전관리형입니다. 따라서 하드웨어나 소프트웨어 프로비저닝, 설정 및 구성, 소프트웨어 패치, 
분산 캐시 클러스터 운영 또는 확장 시 여러 인스턴스에 데이터 복제 등과 같은 관리 작업에 대해 
더 이상 걱정할 필요가 없습니다. DAX 는 장애 탐지, 장애 복구, 소프트웨어 패치와 같은 일반적인 
관리 작업 상당 부분을 자동화합니다. DAX는 DynamoDB API와 호환되므로 작동하는 애플리케이션 
코드를 변경할 필요가 없습니다.  
참고: 
https://aws.amazon.com/dynamodb/dax/ 
Q178 
회사의 인프라는 단일 AWS 리전에 있는 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 
구성됩니다. 회사는 별도의 리전에 데이터를 백업하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Backup 을 사용하여 EC2 백업과 RDS 백업을 별도의 리전에 복사합니다. 
B. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 EC2 백업 및 RDS 백업을 별도의 
리전에 복사합니다. 
C. EC2 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 별도의 리전에 복사합니다. 
별도의 리전에서 RDS DB 인스턴스에 대한 읽기 전용 복제본을 생성합니다. 
D. Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. EBS 스냅샷을 별도의 리전에 
복사합니다. RDS 스냅샷을 생성합니다. RDS 스냅샷을 Amazon S3 로 내보냅니다. S3 
CRR(Cross-Region Replication)을 별도의 리전에 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87639-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS Backup 을 사용하여 EC2 및 RDS 백업을 별도의 리전에 복사하는 것은 최소한의 운영 
오버헤드로 요구 사항을 충족하는 솔루션입니다. AWS Backup 은 백업 프로세스를 간소화하고 
백업을 다른 리전으로 자동 복사하여 EC2 인스턴스 및 RDS 데이터베이스에 대한 별도의 백업 
프로세스 관리와 관련된 수동 작업 및 운영 복잡성을 줄입니다. 
B: Amazon Data Lifecycle Manager(Amazon DLM)가 RDS 백업을 별도의 리전에 직접 복사하도록 
설계되지 않았기 때문에 올바르지 않습니다. 
C: Amazon 머신 이미지(AMI) 및 읽기 전용 복제본을 생성하면 전용 백업 솔루션에 비해 복잡성과 
운영 오버헤드가 추가되기 때문에 올바르지 않습니다. 
D: Amazon EBS 스냅샷, RDS 스냅샷 및 S3 CRR(Cross-Region Replication)을 사용하려면 여러 
수동 단계와 추가 구성이 수반되어 복잡성이 증가하기 때문에 올바르지 않습니다. 
Q179 
솔루션 설계자는 애플리케이션이 Amazon RDS DB 인스턴스에 액세스하는 데 사용하는 
데이터베이스 사용자 이름과 암호를 안전하게 저장해야 합니다. 데이터베이스에 액세스하는 
애플리케이션은 Amazon EC2 인스턴스에서 실행됩니다. 솔루션 설계자는 AWS Systems Manager 
Parameter Store 에서 보안 매개변수를 생성하려고 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Parameter Store 파라미터에 대한 읽기 액세스 권한이 있는 IAM 역할을 생성합니다. 파라미터를 
암호화하는 데 사용되는 AWS Key Management Service(AWS KMS) 키에 대한 Decrypt 액세스를 
허용합니다. 이 IAM 역할을 EC2 인스턴스에 할당합니다. 
B. Parameter Store 파라미터에 대한 읽기 액세스를 허용하는 IAM 정책을 생성합니다. 파라미터를 
암호화하는 데 사용되는 AWS Key Management Service(AWS KMS) 키에 대한 Decrypt 액세스를 
허용합니다. 이 IAM 정책을 EC2 인스턴스에 할당합니다. 
C. Parameter Store 파라미터와 EC2 인스턴스 간에 IAM 신뢰 관계를 생성합니다. 신뢰 정책에서 
Amazon RDS 를 보안 주체로 지정합니다. 
D. DB 인스턴스와 EC2 인스턴스 간에 IAM 신뢰 관계를 생성합니다. 신뢰 정책에서 Systems 
Manager 를 보안 주체로 지정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87582-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
데이터베이스 사용자 이름과 암호를 AWS 시스템 관리자 파라미터 스토어에 안전하게 저장하고 
EC2 인스턴스에서 실행 중인 애플리케이션이 액세스할 수 있도록 하려면 솔루션스 아키텍트는 
파라미터 스토어 파라미터에 대한 읽기 액세스 권한이 있는 IAM 역할을 생성하고 파라미터를 
암호화하는 데 사용되는 AWS KMS 키에 대한 암호 해독 액세스를 허용해야 합니다. 그런 다음 
솔루션스 아키텍트는 이 IAM 역할을 EC2 인스턴스에 할당해야 합니다. 
이 접근 방식을 사용하면 EC2 인스턴스가 파라미터 스토어의 파라미터에 액세스하고 지정된 KMS 
키를 사용하여 해독하는 동시에 필요한 보안 제어를 적용하여 승인된 당사자만 파라미터에 
액세스할 수 있도록 할 수 있습니다. 
Q180 
회사에서 API 로 구동되는 클라우드 통신 플랫폼을 설계하고 있습니다. 애플리케이션은 
NLB(Network Load Balancer) 뒤의 Amazon EC2 인스턴스에서 호스팅됩니다. 이 회사는 Amazon 
API Gateway 를 사용하여 외부 사용자에게 API 를 통해 애플리케이션에 대한 액세스 권한을 
제공합니다. 이 회사는 SQL 인젝션과 같은 웹 익스플로잇으로부터 플랫폼을 보호하고 대규모의 
정교한 DDoS 공격을 감지하고 완화하기를 원합니다. 
어떤 솔루션 조합이 MOST 보호를 제공합니까? (두 가지를 선택하세요.) 
A. AWS WAF 를 사용하여 NLB 를 보호하십시오. 
B. NLB 와 함께 AWS Shield Advanced 를 사용합니다. 
C. AWS WAF 를 사용하여 Amazon API Gateway 를 보호합니다. 
D. AWS Shield Standard 와 함께 Amazon GuardDuty 사용 
E. Amazon API Gateway 와 함께 AWS Shield Standard 를 사용합니다. 
Answer: B, C 
https://www.examtopics.com/discussions/amazon/view/87640-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
AWS Shield Advanced 는 Amazon EC2 인스턴스, Elastic Load Balancing 로드 밸런서, CloudFront 
배포, Route 53 호스팅 영역 및 AWS Global Accelerator 표준 가속기에 대해 확장된 DDoS 공격 
보호 기능을 제공합니다. AWS WAF 는 보호된 웹 애플리케이션 리소스로 전달되는 HTTP 및 
HTTPS 요청을 모니터링할 수 있는 웹 애플리케이션 방화벽입니다. 다음 리소스 유형을 보호할 수 
있습니다. 
Amazon CloudFront 배포 
아마존 API 게이트웨이 REST API 
애플리케이션 로드 밸런서 
AWS AppSync GraphQL API 
Amazon Cognito 사용자 풀 
https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html 
설명 2: 
지문에서 등장한 수단은 AWS WAF, AWS Shield Standard, AWS Shield Advanced 로 3 개. 
◈Shield Advanced = WAF + Shield Standard. 
・Shield Advanced = Amazon Elastic Compute Cloud(EC2), Elastic Load Balancing(ELB), Amazon 
CloudFront, AWS Global Accelerator 및 Amazon Route 53 리소스에서 실행되는 애플리케이션을 
목표로 하는 공격에 대해 더 높은 수준의 보호를 구현. 정교한 대규모 DDoS 공격에 대한 추가 
보호 및 완화, 실시간에 가까운 공격에 대한 가시성, 웹 애플리케이션 방화벽 [AWS WAF 와의 
통합]을 제공. 
https://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.postDateTi
me&whats-new-cards.sort-order=desc 
AWS Shield Advanced 구독에는 다음 기능과 옵션이 포함됩니다. 이는 AWS 에서 이미 받은 DDoS 
탐지 및 완화 기능을 보완합니다. ◎AWS WAF 통합. ◎보호 그룹. ◎AWS Firewall Manager 를 통한 
Shield Advanced 보호의 중앙 집중식 관리.◎AWS Shield 대응 팀(SRT) 
https://docs.aws.amazon.com/waf/latest/developerguide/ddos-advanced-summary-capabilities
.html 
・Shield Standard = ""네트워크 및 전송 계층 DDoS 공격으로부터 보호 
https://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.postDateTi
me&whats-new-cards.sort-order=desc 
・WAF = 일반적인 웹 공격으로부터 웹 애플리케이션이나 API 를 보호하는 데 도움이 되는 웹 
애플리케이션 방화벽입니다. SQL 주입 또는 사이트 간 스크립팅과 같은 일반적인 공격 패턴을 
차단하는 보안 규칙 및 사용자가 정의한 특정 트래픽 패턴을 필터링하는 규칙을 생성하도록 지원 
https://aws.amazon.com/ko/waf/ 
AWS WAF 로 보호할 수 있는 리소스. ◎Amazon CloudFront 배포. ◎Amazon API 게이트웨이 REST 
API ◎애플리케이션 로드 밸런서 ◎AWS AppSync GraphQL API ◎Amazon Cognito 사용자 풀 
https://docs.aws.amazon.com/waf/latest/developerguide/how-aws-waf-works.html 
A(X) : WAF 는 웹 애플리케이션 방화벽으로, 네트워크 계층이 아니라 애플리케이션 계층을 방어. 
B(O) : AWS Shield Advanced 는 DDoS EC2, ELB, CloudFront, AGA, Route 53 리소스 방어하며 
WAF 와 통합. 
C(O) : AWS WAF 는 웹 애플리케이션 및 API 를 공격으로부터 보호하는 데 도움이 되는 웹 
애플리케이션 방화벽입니다. 
https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/apigateway-control-acce
ss-aws-waf.html 
D(X) : GuardDuty 는 AWS 계정 보호 시스템. https://aws.amazon.com/ko/guardduty/ 
E(X) : AWS Shield Standard 는 DDoS 보호만을 제공. 
Q181 
회사에는 Amazon EC2 인스턴스에서 실행되는 레거시 데이터 처리 애플리케이션이 있습니다. 
데이터는 순차적으로 처리되지만 결과의 순서는 중요하지 않습니다. 응용 프로그램은 모놀리식 
아키텍처를 사용합니다. 회사에서 수요 증가에 맞춰 애플리케이션을 확장할 수 있는 유일한 방법은 
인스턴스 크기를 늘리는 것입니다. 
이 회사의 개발자는 Amazon Elastic Container Service(Amazon ECS)에서 마이크로서비스 
아키텍처를 사용하도록 애플리케이션을 다시 작성하기로 결정했습니다. 
솔루션 설계자는 마이크로서비스 간의 통신을 위해 무엇을 권장해야 합니까? 
A. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 데이터 생산자에 코드를 
추가하고 데이터를 대기열로 보냅니다. 데이터 소비자에 코드를 추가하여 대기열의 데이터를 
처리합니다. 
B. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. 데이터 생산자에 코드를 
추가하고 주제에 알림을 게시합니다. 데이터 소비자에 코드를 추가하여 주제를 구독합니다. 
C. 메시지를 전달할 AWS Lambda 함수를 생성합니다. 데이터 생산자에 코드를 추가하여 데이터 
객체로 Lambda 함수를 호출합니다. 데이터 소비자에 코드를 추가하여 Lambda 함수에서 전달되는 
데이터 객체를 수신합니다. 
D. Amazon DynamoDB 테이블을 생성합니다. DynamoDB 스트림을 활성화합니다. 데이터 생산자에 
코드를 추가하여 테이블에 데이터를 삽입합니다. 데이터 소비자에 코드를 추가하여 DynamoDB 
Streams API 를 사용하여 새 테이블 항목을 감지하고 데이터를 검색합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87647-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
분리와 함께 처리할 응용 프로그램에 대한 메시지를 보관할 큐를 수용하도록 아키텍처를 
변경하기만 하면 됨 A(O) – SQS 
설명 2: 
대기열의 처리량이 제한됨(일괄 처리 없이 300msg/s, 일괄 처리 시 3000msg/s, 일괄 작업당 
최대 10msg, 대기열에서 메시지 복제가 허용되지 않음(정확히 한 번 전달), 메시지 순서가 
보존됨(FIFO), 대기열 이름 .fifo 로 끝나야 합니다. 
Q182 
회사에서 MySQL 데이터베이스를 온프레미스에서 AWS 로 마이그레이션하려고 합니다. 이 회사는 
최근 비즈니스에 상당한 영향을 미치는 데이터베이스 중단을 경험했습니다. 이러한 일이 다시 
발생하지 않도록 회사는 데이터 손실을 최소화하고 모든 트랜잭션을 최소 두 개의 노드에 
저장하는 안정적인 AWS 데이터베이스 솔루션을 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 3 개의 가용 영역에 있는 3 개의 노드에 대한 동기식 복제로 Amazon RDS DB 인스턴스를 
생성합니다. 
B. 다중 AZ 기능이 활성화된 Amazon RDS MySQL DB 인스턴스를 생성하여 데이터를 동기식으로 
복제합니다. 
C. Amazon RDS MySQL DB 인스턴스를 생성한 다음 데이터를 동기식으로 복제하는 별도의 AWS 
리전에서 읽기 전용 복제본을 생성합니다. 
D. Amazon RDS MySQL DB 인스턴스에 데이터를 동기식으로 복제하기 위해 AWS Lambda 함수를 
트리거하는 MySQL 엔진이 설치된 Amazon EC2 인스턴스를 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87641-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
데이터베이스의 고가용성이 필요한 상황이므로 Multi AZ 가 필수인 상황. 
A(X) : AWS 로 MySQL 데이터베이스를 마이그레이션하려고 한다 했으므로 Amazon RDS for 
MySQL 이 맞음. 
B(O) : Amazon RDS 다중 AZ 동기 복제 기술을 사용하여 대기 데이터베이스 인스턴스의 데이터를 
프라이머리와 함께 최신 상태로 유지합니다. 장애를 감지하면 Amazon RDS 는 수동 개입 없이 
자동으로 대기 인스턴스로 장애 조치합니다. 
https://aws.amazon.com/ko/rds/features/multi-az/ 
C(X) : RDS read replica 는 동기식이 아닌 비동기식 방식임. 
기본 DB 인스턴스에 적용된 업데이트는 읽기 전용 복제본에 비동기식으로 복사됩니다. 
https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html 
D(X) : 다른 AZ 나 리전에 복제하는지에 대한 여부가 안 나와 있음. 그리고 굳이 Lambda 를 
사용해야 하는지도 의문. 
설명 2: 
Q: Amazon RDS 는 나를 대신하여 무엇을 관리합니까? 
Amazon RDS 는 요청한 인프라 용량 프로비저닝에서 데이터베이스 소프트웨어 설치에 이르기까지 
관계형 데이터베이스 설정과 관련된 작업을 관리합니다. 데이터베이스가 가동되고 실행되면 
Amazon RDS 는 백업 수행 및 데이터베이스를 강화하는 소프트웨어 패치와 같은 일반적인 관리 
작업을 자동화합니다. 선택적 다중 AZ 배포를 통해 Amazon RDS 는 자동 장애 조치를 통해 가용 
영역 전체에서 동기식 데이터 복제도 관리합니다. 
https://aws.amazon.com/rds/faqs/ 
Q183 
회사에서 새로운 동적 주문 웹사이트를 구축하고 있습니다. 회사는 서버 유지 관리 및 패치를 
최소화하려고 합니다. 웹 사이트는 가용성이 높아야 하며 사용자 요구의 변화를 충족하기 위해 
가능한 한 빨리 읽기 및 쓰기 용량을 확장해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon S3 에서 정적 콘텐츠를 호스팅합니다. Amazon API Gateway 및 AWS Lambda 를 
사용하여 동적 콘텐츠를 호스팅합니다. 데이터베이스에 대한 온디맨드 용량과 함께 Amazon 
DynamoDB 를 사용합니다. 웹 사이트 콘텐츠를 제공하도록 Amazon CloudFront 를 구성합니다. 
B. Amazon S3 에서 정적 콘텐츠를 호스팅합니다. Amazon API Gateway 및 AWS Lambda 를 
사용하여 동적 콘텐츠를 호스팅합니다. 데이터베이스에는 Aurora Auto Scaling 과 함께 Amazon 
Aurora 를 사용하십시오. 웹 사이트 콘텐츠를 제공하도록 Amazon CloudFront 를 구성합니다. 
C. Amazon EC2 인스턴스에서 모든 웹 사이트 콘텐츠를 호스팅합니다. Auto Scaling 그룹을 
생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer 를 사용하여 트래픽을 분산합니다. 
데이터베이스에 대해 프로비저닝된 쓰기 용량과 함께 Amazon DynamoDB 를 사용합니다. 
D. Amazon EC2 인스턴스에서 모든 웹 사이트 콘텐츠를 호스팅합니다. Auto Scaling 그룹을 
생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer 를 사용하여 트래픽을 분산합니다. 
데이터베이스에는 Aurora Auto Scaling 과 함께 Amazon Aurora 를 사용하십시오. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87570-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
질문의 핵심 문구는 읽기 및 쓰기 용량을 확장해야 한다는 것입니다. Aurora 는 읽기 전용입니다. 
Amazon DynamoDB 에는 테이블에 대한 읽기 및 쓰기를 처리하기 위한 두 가지 읽기/쓰기 용량 
모드가 있습니다. 온디맨드 프로비저닝(기본, 프리 티어 가능) 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteC
apacityMode.html 
DynamoDB 는 주문 데이터(키값)을 저장하는데 적합하고 온디맨드 방식으로 쓰기 및 읽기 용량을 
확장합니다. 
Q184 
회사에 소프트웨어 엔지니어링에 사용되는 AWS 계정이 있습니다. AWS 계정은 한 쌍의 AWS 
Direct Connect 연결을 통해 회사의 온프레미스 데이터 센터에 액세스할 수 있습니다. 모든 비 
VPC 트래픽은 가상 프라이빗 게이트웨이로 라우팅됩니다. 
개발팀은 최근 콘솔을 통해 AWS Lambda 함수를 생성했습니다. 개발 팀은 함수가 회사 데이터 
센터의 프라이빗 서브넷에서 실행되는 데이터베이스에 액세스할 수 있도록 허용해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 적절한 보안 그룹을 사용하여 VPC 에서 실행되도록 Lambda 함수를 구성합니다. 
B. AWS 에서 데이터 센터로 VPN 연결을 설정합니다. VPN 을 통해 Lambda 함수의 트래픽을 
라우팅합니다. 
C. Lambda 함수가 Direct Connect 를 통해 온프레미스 데이터 센터에 액세스할 수 있도록 VPC 의 
라우팅 테이블을 업데이트합니다. 
D. 탄력적 IP 주소를 생성합니다. 탄력적 네트워크 인터페이스 없이 탄력적 IP 주소를 통해 
트래픽을 보내도록 Lambda 함수를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87534-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설: 
A(O) : 보안 그룹을 정의하여 VPC 에 Lambda 연결 가능. 
AWS 계정의 가상 사설 클라우드(VPC)에 있는 사설 서브넷에 연결하도록 Lambda 함수를 구성할 
수 있습니다. Amazon Virtual Private Cloud(Amazon VPC)를 사용하여 데이터베이스, 캐시 인스턴스 
또는 내부 서비스와 같은 리소스에 대한 사설 네트워크를 생성합니다. 함수가 실행되는 동안 
프라이빗 리소스에 액세스하려면 함수를 VPC 에 연결합니다. 함수를 VPC 에 연결하면 Lambda 는 
함수의 VPC 구성에 있는 각 서브넷의 Hyperplane ENI(탄력적 네트워크 인터페이스)에 함수를 
할당합니다. Lambda 는 계정의 VPC 지원 기능에 대해 고유한 서브넷 및 보안 그룹 조합이 
처음으로 정의될 때 Hyperplane ENI 를 생성합니다. 
https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-managing-eni 
B(X) : ・선택지에서 말하는 VPN 연결이란 VPC-온프레미스 간 연결을 말함. 
VPN 연결 이라는 용어 는 일반적인 용어이지만 이 설명서에서 VPN 연결은 VPC 와 자체 
온프레미스 네트워크 간의 연결을 나타냅니다. 
https://docs.aws.amazon.com/vpn/latest/s2svpn/VPC_VPN.html 
・먼저 Virtual Private Gateway 를 사용하여 VPC-온프레미스 간 Site to Site VPN 연결을 수립.  
◎AWS Site-to-Site VPN : VPC 와 원격 네트워크 사이에 IPsec VPN 연결을 생성할 수 있습니다. 
AWS 측 Site-to-Site VPN 연결에서 가상 프라이빗 게이트웨이 또는 Transit Gateway 는 자동 장애 
조치를 위한 2 개의 VPN 엔드포인트(터널)를 제공합니다. Site-to-Site VPN 원격 연결 측에서 고객 
게이트웨이 디바이스를 구성합니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpn-connections.html 
・Virtual Private Gateway + Direct Connect + VPN 조합을 사용하는 이유는 Virtual Private Gateway 
+ VPN 조합은 IPv4 밖에 전송이 안 되는데, Virtual Private Gateway + Direct Connect 조합은 
IPv6 를 지원하므로 3 가지를 조합하면 IPv4, IPv6 를 모두 사용할 수 있기 때문. 
가상 프라이빗 게이트웨이로 라우팅 : AWS Site-to-Site VPN 연결을 사용하여 VPC 의 인스턴스를 
사용자의 네트워크와 통신하도록 할 수 있습니다. 이렇게 하려면 가상 프라이빗 게이트웨이를 
생성하여 VPC 에 연결합니다.그런 다음 네트워크 대상 및 가상 프라이빗 
게이트웨이(vgw-xxxxxxxxxxxxxxxxx)의 대상이 있는 서브넷 라우팅 테이블에 라우팅을 
추가합니다....가상 프라이빗 게이트웨이의 Site-to-Site VPN 연결은 IPv6 트래픽을 지원하지 
않습니다. 그러나 가상 프라이빗 게이트웨이를 통해 AWS Direct Connect 연결로 라우팅되는 IPv6 
트래픽은 지원합니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/route-table-options.html#route-table
s-vgw 
・VPC 과 Lambda 함수 연결 
AWS 계정에서 VPC(Virtual Private Cloud)의 프라이빗 서브넷에 연결하도록 Lambda 함수를 구성할 
수 있습니다. 
https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/configuration-vpc.html 
But, 여기까지는 가능하지만 정작 Lambda 함수가 VPN 을 통해 트래픽을 라우팅할 수 있는지는 
불명확. 
그리고 어차피 A 의 내용이 충족되어야만 가능하기 때문에 정답이 아닐 가능성이 큼. 
C(X) : A 의 내용이 충족되지 않으면 수립 불가. 즉, VPC 에 Lambda 가 연결이 되어야 가능하던 
말던 함. 
Lambda 함수는 항상 Lambda 서비스가 소유한 VPC 내에서 실행됩니다. 기본적으로 Lambda 
함수는 사용자 계정의 VPC 에 연결되지 않습니다. 
https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/foundation-networking.html 
D(X) : 탄력적 IP 주소는 퍼블릭 IP 주소로, Direct Connect 가 있는 상황에서 굳이 사용할 필요가 
없음. 게다가 온프레미스 데이터베이스가 있는 곳은 프라이빗 서브넷이라 퍼블릭 IP 주소로는 
무리임. 
참조 
https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-managing-eni 
Q185 
회사에서 Amazon ECS 를 사용하여 애플리케이션을 실행합니다. 애플리케이션은 원본 이미지의 
크기가 조정된 버전을 생성한 다음 Amazon S3 API 를 호출하여 크기가 조정된 이미지를 Amazon 
S3 에 저장합니다. 
솔루션 설계자는 애플리케이션이 Amazon S3 에 액세스할 권한이 있는지 어떻게 확인할 수 
있습니까? 
A. Amazon ECS 에서 읽기/쓰기 액세스를 허용하도록 AWS IAM 에서 S3 역할을 업데이트한 다음 
컨테이너를 다시 시작합니다. 
B. S3 권한이 있는 IAM 역할을 생성한 다음 작업 정의에서 해당 역할을 taskRoleArn 으로 
지정합니다. 
C. Amazon ECS 에서 Amazon S3 로의 액세스를 허용하는 보안 그룹을 생성하고 ECS 클러스터에서 
사용하는 시작 구성을 업데이트합니다. 
D. S3 권한이 있는 IAM 사용자를 만든 다음 이 계정으로 로그인한 상태에서 ECS 클러스터에 대한 
Amazon EC2 인스턴스를 다시 시작합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87648-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A(X) : S3 에 관한 권한을 물어본 거지 ECS 에 대한 권한을 물어본 게 아님. 
B(O) : 태스크 정의를 등록할 때 태스크 권한의 컨테이너가 사용자 대신 연결된 정책에 지정된 
AWS API 를 호출하도록 허용하는 IAM 역할에 태스크 역할을 제공할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/task_definition_paramete
rs.html 
C(X) : 보안 그룹 아웃바운드는 별 설정 안 해놔도 모두 허용이 기본값임. 굳이 설정할 필요가 
없음. 
D(X) : 액세스 권한이 있는지 확인하겠다고 다른 걸로 로그인해서 굳이 EC2 인스턴스를 다시 
시작하는 것은 비효율적. 
Q186 
회사에 AWS 로 마이그레이션해야 하는 Windows 기반 애플리케이션이 있습니다. 이 
애플리케이션은 여러 가용 영역에 배포된 여러 Amazon EC2 Windows 인스턴스에 연결된 공유 
Windows 파일 시스템을 사용해야 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 볼륨 게이트웨이 모드에서 AWS Storage Gateway 를 구성합니다. 각 Windows 인스턴스에 
볼륨을 마운트합니다. 
B. Windows 파일 서버용 Amazon FSx 를 구성합니다. Amazon FSx 파일 시스템을 각 Windows 
인스턴스에 탑재합니다. 
C. Amazon Elastic File System(Amazon EFS)을 사용하여 파일 시스템을 구성합니다. EFS 파일 
시스템을 각 Windows 인스턴스에 마운트합니다. 
D. 필요한 크기로 Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성합니다. 각 EC2 
인스턴스를 볼륨에 연결합니다. 볼륨 내의 파일 시스템을 각 Windows 인스턴스에 마운트합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/87650-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 솔루션은 여러 가용 영역에 배포된 여러 Amazon EC2 Windows 인스턴스에 연결된 공유 
Windows 파일 시스템을 사용해야 하는 Windows 기반 애플리케이션 마이그레이션 요구 사항을 
충족합니다. Amazon FSx for Windows File Server 는 Windows Server 에 구축된 완전 관리형 공유 
스토리지를 제공하며 광범위한 데이터 액세스, 데이터 관리 및 관리 기능을 제공합니다. SMB(서버 
메시지 블록) 프로토콜을 지원하며 여러 가용 영역에서 EC2 Windows 인스턴스에 탑재할 수 
있습니다. 
Windows 기반 애플리케이션이 핵심 키워드. 답은 B. 
옵션 A 의 볼륨 게이트웨이 모드의 AWS Storage Gateway 는 온프레미스 애플리케이션 서버에서 
iSCSI 디바이스로 마운트할 수 있는 클라우드 지원 스토리지 볼륨을 제공하지만 SMB 프로토콜 
또는 EC2 Windows 인스턴스를 지원하지 않기 때문에 올바르지 않습니다. 
옵션 C 는 Amazon Elastic File System(Amazon EFS)이 Linux 기반 워크로드를 위한 확장 가능하고 
탄력적인 NFS 파일 시스템을 제공하지만 SMB 프로토콜 또는 EC2 Windows 인스턴스를 지원하지 
않기 때문에 올바르지 않습니다. 
옵션 D 는 Amazon Elastic Block Store(Amazon EBS)가 EC2 인스턴스와 함께 사용할 영구 블록 
스토리지 볼륨을 제공하지만 SMB 프로토콜을 지원하지 않거나 동일한 볼륨에 여러 인스턴스를 
연결하기 때문에 올바르지 않습니다. 
참조: 
https://aws.amazon.com/fsx/windows/ 
https://docs.aws.amazon.com/fsx/latest/WindowsGuide/using-file-shares.html 
Q187 
한 회사에서 로드 밸런싱된 프런트 엔드, 컨테이너 기반 애플리케이션 및 관계형 데이터베이스로 
구성될 전자상거래 애플리케이션을 개발하고 있습니다. 솔루션 설계자는 가능한 한 적은 수동 
개입으로 작동하는 고가용성 솔루션을 만들어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) 
A. 다중 AZ 모드에서 Amazon RDS DB 인스턴스를 생성합니다. 
B. 다른 가용 영역에서 Amazon RDS DB 인스턴스와 하나 이상의 복제본을 생성합니다. 
C. 동적 애플리케이션 로드를 처리하기 위해 Amazon EC2 인스턴스 기반 Docker 클러스터를 
생성합니다. 
D. 동적 애플리케이션 로드를 처리하기 위해 Fargate 시작 유형으로 Amazon Elastic Container 
Service(Amazon ECS) 클러스터를 생성합니다. 
E. 동적 애플리케이션 로드를 처리하기 위해 Amazon EC2 시작 유형으로 Amazon Elastic 
Container Service(Amazon ECS) 클러스터를 생성합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/87695-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(O) : 다중 AZ 모드로 고가용성 충족. 관계형 데이터베이스로 구성된 프로그램이어야 하므로 RDS 
사용. 
다중 AZ 배포로 실행되도록 DB 인스턴스를 생성 또는 수정하면 Amazon RDS 가 다른 가용 영역에 
동기식 ‘예비’ 복제본을 자동으로 프로비저닝하고 유지합니다. 특정 유형의 계획된 유지 관리를 
수행하는 도중에, 또는 예기치 않은 DB 인스턴스 장애나 가용 영역 장애가 발생할 경우 Amazon 
RDS 가 자동으로 예비 복제본으로 장애 조치하므로 예비 복제본이 승격되자마자 데이터베이스 
쓰기 및 읽기를 재개할 수 있습니다. 
https://aws.amazon.com/ko/rds/faqs/ 
B(X) : 장애 발생 시 복구를 위한 것이면 Multi AZ 가 더 유리하므로 고가용성 면에선 Multi AZ 가 
추천됨. 읽기 복제본을 사용해 데이터베이스 쓰기 가용성을 개선하거나 내 소스 DB 인스턴스의 
데이터를 장애로부터 보호할 수 있습니까? 복제를 사용해 데이터베이스 쓰기 가용성을 높이고 
최근 데이터베이스 업데이트를 다양한 장애 조건으로부터 보호하려면 DB 인스턴스를 다중 AZ 
배포로 실행하는 것이 좋습니다. Amazon RDS 읽기 전용 복제본과 지원되는 엔진의 기본 비동기식 
복제를 사용하면 데이터베이스 쓰기가 소스 DB 인스턴스에서 발생한 후, 읽기 전용 복제본에서 
발생합니다. 이 복제 ‘지연 시간’은 상당히 다를 수 있습니다. 
https://aws.amazon.com/ko/rds/faqs/ 
C(X) : EC2 로 굳이 돌릴 거 없이 ECS 를 사용해서 서버리스로 돌릴 수 있음 
D(O) : Fargate + ECS 조합으로 컨테이너 애플리케이션을 서버리스로 돌릴 수 있음. 
AWS Fargate Fargate 는 Amazon EC2 인스턴스의 서버나 클러스터를 관리할 필요 없이 컨테이너를 
실행하기 위해 Amazon ECS 에 사용할 수 있는 기술입니다. 
https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/AWS_Fargate.html 
E(X) : C 와 같은 이유로 오답. 
설명 2: 
https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html 
1. 관계형 데이터베이스: RDS 
2. 컨테이너 기반 애플리케이션: ECS 
"Amazon ECS 를 사용하면 간단한 API 호출을 사용하여 컨테이너 기반 애플리케이션을 시작 및 
중지할 수 있습니다. 또한 중앙 집중식 서비스에서 클러스터 상태를 검색하고 많은 익숙한 
Amazon EC2 기능에 액세스할 수 있습니다." 
3. 약간의 수동 개입: Fargate AWS Fargate 에서 관리하는 서버리스 인프라에서 작업과 서비스를 
실행할 수 있습니다. 또는 인프라를 더 잘 제어하기 위해 관리하는 Amazon EC2 인스턴스의 
클러스터에서 작업과 서비스를 실행할 수 있습니다. 
Q188 
회사는 Amazon S3 를 데이터 레이크로 사용합니다. 회사에는 SFTP 를 사용하여 데이터 파일을 
업로드해야 하는 새로운 파트너가 있습니다. 솔루션 설계자는 운영 오버헤드를 최소화하는 
고가용성 SFTP 솔루션을 구현해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Transfer Family 를 사용하여 공개적으로 액세스할 수 있는 엔드포인트가 있는 SFTP 지원 
서버를 구성합니다. S3 데이터 레이크를 대상으로 선택합니다. 
B. Amazon S3 파일 게이트웨이를 SFTP 서버로 사용합니다. S3 파일 게이트웨이 엔드포인트 
URL 을 새 파트너에게 노출합니다. S3 파일 게이트웨이 엔드포인트를 새 파트너와 공유합니다. 
C. VP 의 프라이빗 서브넷에서 Amazon EC2 인스턴스를 시작합니다. 새 파트너에게 VPN 을 
사용하여 EC2 인스턴스에 파일을 업로드하도록 지시합니다. EC2 인스턴스에서 cron 작업 
스크립트를 실행하여 S3 데이터 레이크에 파일을 업로드합니다. 
D. VPC 의 프라이빗 서브넷에서 Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스 앞에 
NLB(Network Load Balancer)를 배치합니다. NLB 에 대한 SFTP 수신기 포트를 만듭니다. NLB 
호스트 이름을 새 파트너와 공유합니다. EC2 인스턴스에서 cron 작업 스크립트를 실행하여 S3 
데이터 레이크에 파일을 업로드합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/87566-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 솔루션은 수동 관리 또는 운영 오버헤드 없이 고가용성 SFTP 솔루션을 제공합니다. AWS 
Transfer Family 를 사용하면 인증, 권한 부여 및 스토리지 백엔드로 S3 와의 통합을 통해 SFTP 
서버를 쉽게 설정할 수 있습니다. 
옵션 B 는 SFTP 액세스가 아닌 NFS 또는 SMB 프로토콜을 통한 S3 스토리지에 대한 파일 기반 
액세스에 주로 사용되는 Amazon S3 파일 게이트웨이 사용을 제안하므로 최선의 선택이 아닙니다. 
옵션 C 는 파일 업로드를 위한 EC2 인스턴스, VPN 설정 및 cron 작업 스크립트의 수동 관리가 
필요하여 운영 오버헤드와 잠재적인 복잡성을 유발하므로 최선의 선택이 아닙니다. 
옵션 D 는 파일 업로드를 위한 EC2 인스턴스, Network Load Balancer 및 cron 작업 스크립트의 
수동 관리도 필요하므로 최선의 선택이 아닙니다. 옵션 A 에서 AWS Transfer Family 가 제공하는 더 
단순하고 완벽하게 관리되는 솔루션에 비해 더 복잡하고 추가 구성 요소가 필요합니다. 
Q189 
회사는 계약 문서를 보관해야 합니다. 계약은 5 년 동안 지속됩니다. 회사는 5 년 동안 문서를 
덮어쓰거나 삭제할 수 없도록 해야 합니다. 회사는 미사용 문서를 암호화하고 매년 암호화 키를 
자동으로 교체해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 솔루션 설계자가 수행해야 하는 
단계 조합은 무엇입니까? (두 가지를 선택하세요.) 
A. Amazon S3 에 문서를 저장합니다. 거버넌스 모드에서 S3 객체 잠금을 사용합니다. 
B. Amazon S3 에 문서를 저장합니다. 규정 준수 모드에서 S3 객체 잠금을 사용합니다. 
C. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용합니다. 키 순환을 구성합니다. 
D. AWS Key Management Service(AWS KMS) 고객 관리형 키로 서버 측 암호화를 사용합니다. 키 
순환을 구성합니다. 
E. AWS Key Management Service(AWS KMS) 고객 제공(가져온) 키로 서버 측 암호화를 사용합니다. 
키 순환을 구성합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/87535-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
B. 규정 준수 모드에서 S3 객체 잠금을 사용하면 객체에 엄격한 보존 정책을 적용하여 수정이나 
삭제를 방지합니다. 
D. AWS KMS 고객 관리형 키와 함께 서버 측 암호화를 사용하면 문서가 고객 제어형 키로 
암호화됩니다. 키 순환을 활성화하면 정의된 순환 간격으로 새 암호화 키가 자동으로 생성되어 
보안이 강화됩니다. 
옵션 A: 거버넌스 모드의 S3 객체 잠금은 문서에 필요한 불변성을 제공하지 않으므로 잠재적인 
수정 또는 삭제가 허용됩니다. 
옵션 C: SSE-S3 만으로는 서버 측 암호화가 명시적으로 지정된 암호화 키 순환 요구 사항을 
충족하지 않습니다. 
옵션 E: AWS KMS 고객 관리 키(옵션 D)를 사용할 수 있는 경우 고객 제공(가져온) 키(SSE-C)를 
사용한 서버 측 암호화는 필요하지 않으며, 이는 보다 통합되고 관리 가능한 솔루션을 제공합니다. 
Q190 
회사에 Java 및 PHP 기반 웹 애플리케이션이 있습니다. 회사는 애플리케이션을 온프레미스에서 
AWS 로 옮길 계획입니다. 회사는 새로운 사이트 기능을 자주 테스트할 수 있는 능력이 필요합니다. 
회사는 또한 최소한의 운영 오버헤드를 필요로 하는 가용성이 높고 관리되는 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon S3 버킷을 생성합니다. S3 버킷에서 정적 웹 호스팅을 활성화합니다. 정적 콘텐츠를 S3 
버킷에 업로드합니다. AWS Lambda 를 사용하여 모든 동적 콘텐츠를 처리합니다. 
B. 웹 애플리케이션을 AWS Elastic Beanstalk 환경에 배포합니다. 기능 테스트를 위해 URL 
스와핑을 사용하여 여러 Elastic Beanstalk 환경 간에 전환합니다. 
C. Java 및 PHP 로 구성된 Amazon EC2 인스턴스에 웹 애플리케이션을 배포합니다. Auto Scaling 
그룹과 Application Load Balancer 를 사용하여 웹 사이트의 가용성을 관리하십시오. 
D. 웹 애플리케이션을 컨테이너화합니다. 웹 애플리케이션을 Amazon EC2 인스턴스에 배포합니다. 
AWS 로드 밸런서 컨트롤러를 사용하여 테스트용 새 사이트 기능이 포함된 컨테이너 간에 
트래픽을 동적으로 라우팅합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/87536-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Elastic Beanstalk 를 사용하면 애플리케이션을 실행하는 인프라에 대해 자세히 알지 못해도 AWS 
클라우드에서 애플리케이션을 신속하게 배포하고 관리할 수 있습니다. 
Elastic Beanstalk 는 Go, Java, .NET, Node.js, PHP, Python 및 Ruby 에서 개발된 애플리케이션을 
지원합니다....애플리케이션을 생성 및 배포한 후에는 지표, 이벤트, 환경 상태 등의 애플리케이션 
정보를 Elastic Beanstalk 콘솔, API 또는 통합된 AWS CLI 를 비롯한 명령줄 인터페이스를 통해 
확인할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/Welcome.html 
설명 2: 
빈번한 기능 테스트 - 
- 개발, 테스트 및 프로덕션 사용 사례를 위해 여러 Elastic Beanstalk 환경을 쉽게 생성할 수 
있습니다. 
- 간단한 URL 스와핑 기술을 사용하여 A/B 테스트 및 기능 반복을 위한 환경 간에 트래픽을 
라우팅할 수 있습니다. 복잡한 라우팅 규칙이나 인프라 변경이 필요하지 않습니다. 
Q191 
회사에는 MySQL 용 Amazon RDS 에 고객 정보를 저장하는 주문 애플리케이션이 있습니다. 정규 
업무 시간 동안 직원은 보고 목적으로 일회성 쿼리를 실행합니다. 보고 쿼리를 실행하는 데 시간이 
오래 걸리기 때문에 주문 처리 중에 시간 초과가 발생합니다. 회사는 직원이 쿼리를 수행하는 것을 
막지 않으면서 시간 초과를 제거해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 읽기 전용 복제본을 생성합니다. 보고 쿼리를 읽기 전용 복제본으로 이동합니다. 
B. 읽기 전용 복제본을 생성합니다. 주문 애플리케이션을 기본 DB 인스턴스와 읽기 전용 복제본에 
배포합니다. 
C. 주문형 용량이 있는 Amazon DynamoDB 로 주문 애플리케이션을 마이그레이션합니다. 
D. 사용량이 적은 시간에 보고 쿼리를 예약합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/89077-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. 보고 쿼리를 읽기 전용 복제본으로 이동하면 주문 처리에 사용되는 기본 DB 인스턴스가 장기 
실행 보고 쿼리의 영향을 받지 않습니다. 이렇게 하면 주문 처리 중 시간 초과를 제거하는 동시에 
직원이 애플리케이션 성능에 영향을 주지 않고 쿼리를 수행할 수 있습니다. 
B. 이것은 일정 수준의 부하 분산을 제공할 수 있지만 주문 처리 중 쿼리 보고로 인해 발생하는 
시간 초과 문제를 구체적으로 다루지는 않습니다. 
C. DynamoDB 는 확장성과 성능상의 이점을 제공하지만 애플리케이션의 데이터 모델 및 쿼리 접근 
방식을 크게 변경해야 할 수 있습니다. 
D. 이 접근 방식은 주문 처리에 미치는 영향을 완화하는 데 도움이 될 수 있지만 직원이 쿼리를 
수행하는 것을 막지 않고 시간 초과를 제거해야 하는 요구 사항을 해결하지는 못합니다. 
Q192 
한 병원에서 대규모 기록 기록 수집을 위한 디지털 사본을 만들고자 합니다. 병원은 매일 수백 
개의 새로운 문서를 계속 추가할 것입니다. 병원의 데이터 팀이 문서를 스캔하고 문서를 AWS 
클라우드에 업로드합니다. 
솔루션 설계자는 애플리케이션이 데이터에 대해 SQL 쿼리를 실행할 수 있도록 문서를 분석하고, 
의료 정보를 추출하고, 문서를 저장하는 솔루션을 구현해야 합니다. 솔루션은 확장성과 운영 
효율성을 극대화해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? (2 개 
선택) 
A. MySQL 데이터베이스를 실행하는 Amazon EC2 인스턴스에 문서 정보를 씁니다. 
B. 문서 정보를 Amazon S3 버킷에 씁니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다. 
C. Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하여 스캔한 파일을 처리하고 의료 정보를 
추출하는 사용자 지정 애플리케이션을 실행합니다. 
D. 새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 생성합니다. Amazon Rekognition 을 
사용하여 문서를 원시 텍스트로 변환합니다. Amazon Transcribe Medical 을 사용하여 텍스트에서 
관련 의료 정보를 감지하고 추출합니다. 
E. 새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 생성합니다. Amazon Textract 를 
사용하여 문서를 원시 텍스트로 변환합니다. Amazon Comprehend Medical 을 사용하여 텍스트에서 
관련 의료 정보를 감지하고 추출합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/89133-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : AWS 클라우드에 문서를 업로드할 거라고 했으니 적절치 않음. MySQL 이 아니라 Amazon 
RDS for MySQL 이 됐던지 했어야 함. 
B(O) : S3 는 자료를 저장하는데 많이 사용되고, Athena 는 S3 에 쿼리하는 대화형 서비스임. 
Amazon Athena 는 표준 SQL 을 사용하여 Amazon S3(Amazon Simple Storage Service)에 있는 
데이터를 직접 간편하게 분석할 수 있는 대화형 쿼리 서비스입니다. 
https://docs.aws.amazon.com/ko_kr/athena/latest/ug/what-is.html 
C(?) : 프로그램을 AWS 에서 돌려야한다는 말이 없어서 불명확. 
D(X) : Amazon Rekognition 은 이미지나 비디오 분석 서비스인데, 문서라면 텍스트 위주라서 탈락. 
그리고 Transcribe Medical 은 음성->텍스트 변환이지 텍스트->의료 정보 추출이 아님. 
Amazon Transcribe Medical 은 사용자가 의료 관련 음성 데이터를 텍스트로 변환하는 기능을 
사용자의 음성 지원 애플리케이션에 쉽게 추가할 수 있도록 하는 자동 음성 인식(ASR) 
서비스입니다. 
https://aws.amazon.com/ko/transcribe/medical/ 
E(O) : Lambda로 Scalabilty 확보 가능. Amazon Textract는 이미지 등에서 텍스트를 추출하는 OCR 
서비스로 문서화에 적합. Amazon Comprehend Medical 은 미리 학습된 기계 학습을 사용하여 
처방전, 처치, 진단과 같은 의료 텍스트에서 의료 데이터를 파악하고 추출하는 서비스로 병원에서 
사용하기 적합. 
확장성 : Lambda 는 코드를 실행하는 인프라를 관리하고 수신 요청에 대한 응답으로 자동 
확장됩니다. 
https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/gettingstarted-features.html#gettingstarte
d-features-scaling 
Amazon Textract 는 스캔한 문서에서 텍스트, 필기 및 데이터를 자동으로 추출하는 기계 학습(ML) 
서비스입니다. 단순한 광학 문자 인식(OCR) 이상으로 양식 및 표의 데이터를 식별하고 이해하며 
추출합니다.  
https://aws.amazon.com/ko/textract/ 
Amazon Comprehend Medical 은 HIPAA 적격 자연어 처리(NLP) 서비스로, 미리 학습된 기계 
학습을 사용하여 처방전, 처치, 진단과 같은 의료 텍스트에서 의료 데이터를 파악하고 추출합니다. 
https://aws.amazon.com/ko/comprehend/medical/ 
설명 2: 
이 솔루션은 애플리케이션이 데이터에 대해 SQL 쿼리를 실행할 수 있도록 문서를 분석하고 의료 
정보를 추출하고 문서를 저장하는 대량의 과거 서면 기록 컬렉션을 위한 디지털 사본 생성 요구 
사항을 충족합니다. 문서 정보를 Amazon S3 버킷에 쓰면 스캔한 파일을 위한 확장 가능하고 
내구성 있는 스토리지를 제공할 수 있습니다. Amazon Athena 를 사용하여 데이터를 쿼리하면 S3 에 
저장된 데이터에 대한 서버리스 및 대화형 SQL 분석을 제공할 수 있습니다. 새 문서가 업로드될 
때 실행되는 AWS Lambda 함수를 생성하면 스캔한 파일의 이벤트 기반 및 서버리스 처리를 
제공할 수 있습니다. Amazon Textract 를 사용하여 문서를 원시 텍스트로 변환하면 정확한 광학 
문자 인식(OCR)을 제공하고 인공 지능(AI)을 사용하여 문서에서 테이블 및 양식과 같은 구조화된 
데이터를 추출할 수 있습니다. Amazon Comprehend Medical 을 사용하여 텍스트에서 관련 의료 
정보를 감지하고 추출하면 의료 텍스트에서 건강 데이터를 이해하고 추출하도록 사전 훈련된 기계 
학습을 사용하는 자연어 처리(NLP) 서비스를 제공할 수 있습니다. 
실행되는 Amazon EC2 인스턴스에 문서 정보를 쓰기 때문에 옵션 A 가 올바르지 않습니다. 
MySQL 데이터베이스는 인프라 오버헤드와 복잡성을 증가시킬 수 있으며 대량의 데이터를 
처리하지 못할 수 있습니다. 
스캔한 파일을 처리하고 의료 정보를 추출하는 사용자 지정 애플리케이션을 실행하기 위해 
Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하면 인프라 오버헤드와 복잡성이 증가할 수 
있고 기존 AI 및 NLP 서비스를 활용하지 못할 수 있으므로 옵션 C 는 올바르지 않습니다. Textract 
및 Comprehend Medical 과 같은 
Amazon Rekognition 을 사용하여 문서를 원시 텍스트로 변환하면 이미지 및 비디오 분석을 제공할 
수 있지만 OCR 또는 문서에서 구조화된 데이터 추출을 지원하지 않기 때문에 옵션 D 는 올바르지 
않습니다. Amazon Transcribe Medical 을 사용하여 텍스트에서 관련 의료 정보를 감지하고 
추출하면 의료 대화를 위한 음성-텍스트 변환 서비스를 제공할 수 있지만 텍스트 분석이나 의료 
텍스트에서 건강 데이터 추출은 지원하지 않습니다. 
참조: 
https://aws.amazon.com/s3/ 
https://aws.amazon.com/athena/ 
https://aws.amazon.com/lambda/ 
https://aws.amazon.com/texttract/ 
https://aws.amazon.com/comprehend/medical/ 
Q193 
회사는 Amazon EC2 인스턴스에서 배치 애플리케이션을 실행하고 있습니다. 애플리케이션은 여러 
Amazon RDS 데이터베이스가 있는 백엔드로 구성됩니다. 응용 프로그램으로 인해 
데이터베이스에서 많은 수의 읽기가 발생하고 있습니다. 솔루션 설계자는 고가용성을 보장하면서 
데이터베이스 읽기 수를 줄여야 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon RDS 읽기 전용 복제본을 추가합니다. 
B. Redis 용 Amazon ElastiCache 를 사용합니다. 
C. Amazon Route 53 DNS 캐싱 사용 
D. Memcached 용 Amazon ElastiCache 를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/89134-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
B?? 
설명 1: 
이 솔루션은 여러 Amazon RDS 데이터베이스가 있는 백엔드로 구성된 배치 애플리케이션의 
고가용성을 보장하면서 데이터베이스 읽기 수를 줄이는 요구 사항을 충족합니다. 
Amazon RDS 읽기 전용 복제본은 읽기 전용 트래픽을 처리할 수 있는 기본 데이터베이스 
인스턴스의 복사본입니다. 기본 데이터베이스 인스턴스에 대해 하나 이상의 읽기 전용 복제본을 
만들고 특수 엔드포인트를 사용하여 연결할 수 있습니다. 읽기 전용 복제본은 기본 데이터베이스 
인스턴스에서 읽기 쿼리를 오프로드하여 애플리케이션의 성능과 가용성을 향상시킬 수 있습니다. 
Redis 용 Amazon ElastiCache 를 사용하면 자주 액세스하는 데이터를 캐시할 수 있는 빠른 인 
메모리 데이터 스토어를 제공할 수 있지만 Amazon RDS 데이터베이스에서 복제를 지원하지 않기 
때문에 옵션 B 는 올바르지 않습니다. 
Amazon Route 53 DNS 캐싱을 사용하면 DNS 쿼리의 성능과 가용성을 개선할 수 있지만 
데이터베이스 읽기 수는 줄어들지 않기 때문에 옵션 C 는 올바르지 않습니다. 
Memcached 용 Amazon ElastiCache 를 사용하면 자주 액세스하는 데이터를 캐시할 수 있는 빠른 
메모리 데이터 스토어를 제공할 수 있지만 Amazon RDS 데이터베이스에서 복제를 지원하지 않기 
때문에 옵션 D 는 올바르지 않습니다. 
설명 2: 
Amazon RDS 데이터베이스에 읽기 전용 복제본을 추가하면 읽기 워크로드를 복제본으로 
오프로드하여 데이터베이스 읽기 수를 줄이고 성능을 향상할 수 있습니다. 읽기 전용 복제본은 
고가용성을 제공하고 읽기 트래픽을 독립적으로 처리하여 로드를 분산하고 기본 데이터베이스의 
부담을 줄일 수 있습니다. 
B. Redis 용 Amazon ElastiCache 는 주로 캐싱에 사용되는 인 메모리 데이터 스토어로, 읽기 
성능을 향상시킬 수 있지만 데이터베이스 읽기 수를 직접적으로 줄이지는 않습니다. 
C. Amazon Route 53 DNS 캐싱은 DNS 응답을 캐시하는 서비스로, 전체 네트워크 성능을 향상시킬 
수 있지만 데이터베이스 읽기 감소를 구체적으로 다루지는 않습니다. 
D. Memcached 용 Amazon ElastiCache 는 Redis 와 유사한 또 다른 캐싱 서비스이지만 
데이터베이스 읽기 감소 문제를 직접적으로 해결하지는 않습니다. 
참조: 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html 
Q194 
회사는 AWS 에서 중요한 애플리케이션을 실행해야 합니다. 회사는 애플리케이션의 데이터베이스에 
Amazon EC2 를 사용해야 합니다. 데이터베이스는 가용성이 높아야 하며 중단 이벤트가 발생할 
경우 자동으로 장애 조치되어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 동일한 AWS 지역의 다른 가용 영역에서 각각 두 개의 EC2 인스턴스를 시작합니다. 두 EC2 
인스턴스 모두에 데이터베이스를 설치합니다. EC2 인스턴스를 클러스터로 구성합니다. 
데이터베이스 복제를 설정합니다. 
B. 가용 영역에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에 데이터베이스를 설치합니다. 
Amazon 머신 이미지(AMI)를 사용하여 데이터를 백업하십시오. 중단 이벤트가 발생할 경우 AWS 
CloudFormation 을 사용하여 EC2 인스턴스의 프로비저닝을 자동화하십시오. 
C. 각각 다른 AWS 지역에서 두 개의 EC2 인스턴스를 시작합니다. 두 EC2 인스턴스 모두에 
데이터베이스를 설치합니다. 데이터베이스 복제를 설정합니다. 데이터베이스를 두 번째 리전으로 
장애 조치합니다. 
D. 가용 영역에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에 데이터베이스를 설치합니다. 
Amazon 머신 이미지(AMI)를 사용하여 데이터를 백업하십시오. 중단 이벤트가 발생하면 EC2 자동 
복구를 사용하여 인스턴스를 복구하십시오. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/89136-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
C?? 
설명: 
서로 다른 가용 영역에서 두 개의 EC2 인스턴스를 시작하고 데이터베이스 복제가 있는 클러스터로 
구성하면 데이터베이스에서 고가용성과 자동 장애 조치를 달성할 수 있습니다. 한 인스턴스 또는 
가용 영역을 사용할 수 없게 되더라도 다른 인스턴스는 중단 없이 애플리케이션을 계속 제공할 수 
있습니다. 
B. 단일 EC2 인스턴스를 시작하고 백업 및 프로비저닝 자동화를 위해 AMI 를 사용하면 자동 장애 
조치 또는 고가용성이 제공되지 않습니다. 
C. 다른 AWS 리전에서 EC2 인스턴스를 시작하고 데이터베이스 복제를 설정하는 것은 재해 복구 
기능을 제공할 수 있지만 단일 리전 내에서 자동 장애 조치를 제공하지 않는 다중 리전 
설정입니다. 
D. EC2 자동 복구를 사용하면 하드웨어 문제로 인해 인스턴스가 실패하는 경우 인스턴스를 복구할 
수 있지만 여러 인스턴스 또는 가용 영역에서 자동 장애 조치 또는 고가용성을 제공하지는 
않습니다. 
Q195 
회사의 주문 시스템은 클라이언트의 요청을 Amazon EC2 인스턴스로 보냅니다. EC2 인스턴스는 
주문을 처리한 다음 Amazon RDS 의 데이터베이스에 주문을 저장합니다. 사용자는 시스템이 
실패하면 주문을 다시 처리해야 한다고 보고합니다. 회사는 시스템 중단이 발생할 경우 주문을 
자동으로 처리할 수 있는 탄력적인 솔루션을 원합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. EC2 인스턴스를 Auto Scaling 그룹으로 이동합니다. Amazon Elastic Container Service(Amazon 
ECS) 작업을 대상으로 하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 
생성합니다. 
B. Application Load Balancer(ALB) 뒤에 있는 Auto Scaling 그룹으로 EC2 인스턴스를 이동합니다. 
ALB 엔드포인트에 메시지를 보내도록 주문 시스템을 업데이트합니다. 
C. EC2 인스턴스를 Auto Scaling 그룹으로 이동합니다. Amazon Simple Queue Service(Amazon 
SQS) 대기열로 메시지를 보내도록 주문 시스템을 구성합니다. 대기열의 메시지를 사용하도록 EC2 
인스턴스를 구성합니다. 
D. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. AWS Lambda 함수를 
생성하고 함수를 SNS 주제에 구독합니다. SNS 주제에 메시지를 보내도록 주문 시스템을 
구성합니다. AWS Systems Manager Run Command 를 사용하여 메시지를 처리하도록 EC2 
인스턴스에 명령을 보냅니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/89138-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
SQS 는 Dead Letter Queue 등 다양한 옵션으로 메시지 처리가 실패했을 경우 해당 메시지를 
보관했다가 다시 처리할 수 있게끔 하는 기능을 제공하고 있음. 
설명 2: 
시스템 중단 시 자동으로 주문을 처리할 수 있는 탄력적인 솔루션을 보유해야 한다는 회사의 요구 
사항을 충족하려면 솔루션 설계자가 내결함성 아키텍처를 구현해야 합니다. 주어진 시나리오에 
따라 가능한 솔루션은 EC2 인스턴스를 Auto Scaling 그룹으로 이동하고 메시지를 Amazon Simple 
Queue Service(Amazon SQS) 대기열로 보내도록 주문 시스템을 구성하는 것입니다. 그런 다음 
EC2 인스턴스는 대기열의 메시지를 사용할 수 있습니다. 
Q196 
회사는 대규모 Amazon EC2 인스턴스 플릿에서 애플리케이션을 실행합니다. 애플리케이션은 
항목을 읽고 Amazon DynamoDB 테이블에 씁니다. DynamoDB 테이블의 크기는 지속적으로 
증가하지만 애플리케이션에는 지난 30 일 동안의 데이터만 필요합니다. 회사는 비용과 개발 노력을 
최소화하는 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS CloudFormation 템플릿을 사용하여 전체 솔루션을 배포합니다. 30 일마다 CloudFormation 
스택을 재배포하고 원래 스택을 삭제합니다. 
B. AWS Marketplace 에서 모니터링 애플리케이션을 실행하는 EC2 인스턴스를 사용합니다. Amazon 
DynamoDB Streams를 사용하여 테이블에 새 항목이 생성될 때 타임스탬프를 저장하도록 모니터링 
애플리케이션을 구성합니다. EC2 인스턴스에서 실행되는 스크립트를 사용하여 30 일보다 오래된 
타임스탬프가 있는 항목을 삭제합니다. 
C. 테이블에 새 항목이 생성될 때 AWS Lambda 함수를 호출하도록 Amazon DynamoDB 
Streams 를 구성합니다. 테이블에서 30 일보다 오래된 항목을 삭제하도록 Lambda 함수를 
구성합니다. 
D. 애플리케이션을 확장하여 현재 타임스탬프에 30 일을 더한 값을 테이블에 생성된 각 새 항목에 
추가하는 속성을 추가합니다. 속성을 TTL 속성으로 사용하도록 DynamoDB 를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/89140-exam-aws-certified-solut 
ions-architect-associate-saa-c03/ 
해설 1: 
30 일 동안의 데이터만 필요하다고 했으니 30 일이 지나면 자동 삭제되도록 하는 기능이 필요. 
A(X) : 30 일마다 재배포하는 것은 번거로움. 
B(X) : 스크립트를 사용하는 것은 스크립트를 짜야하므로 번거로움. 
C(X) : Lambda 함수를 매번 쓰는 것은 비용 효율성 면에서 좋지 않고 Lambda 코드 짜는 것도 
번거로움. 
D(O) : TTL 속성을 사용하면 별다른 코딩이나 노력 없이 설정만 해두면 자동으로 삭제되므로 
간편함. 
Amazon DynamoDB TTL(Time to Live)을 사용하면 항목별 타임스탬프를 정의하여 항목이 더 이상 
필요하지 않은 시기를 결정할 수 있습니다. 지정된 타임스탬프의 날짜 및 시간 직후 DynamoDB 는 
쓰기 처리량을 소모하지 않고 테이블에서 항목을 삭제합니다. 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html 
설명 2: 
Amazon DynamoDB TTL(Time to Live)을 사용하면 항목별 타임스탬프를 정의하여 항목이 더 이상 
필요하지 않은 시기를 결정할 수 있습니다. 지정된 타임스탬프의 날짜 및 시간 직후 DynamoDB 는 
쓰기 처리량을 소비하지 않고 테이블에서 항목을 삭제합니다. TTL 은 워크로드 요구 사항에 따라 
최신 상태로 유지되는 항목만 유지하여 저장된 데이터 볼륨을 줄이는 수단으로 추가 비용 없이 
제공됩니다. TTL 은 특정 시간이 지나면 관련성을 잃는 항목을 저장할 때 유용합니다. 
다음은 TTL 사용 사례의 예입니다. 
애플리케이션에서 1 년 동안 활동이 없으면 사용자 또는 센서 데이터를 제거합니다. 만료된 항목을 
Amazon DynamoDB Streams 및 AWS Lambda 를 통해 Amazon S3 데이터 레이크에 보관합니다. 
계약 또는 규제 의무에 따라 일정 기간 동안 민감한 데이터를 보관합니다. 
https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html 
Q197 
회사에는 온프레미스 Windows Server 에서 실행되는 Microsoft .NET 애플리케이션이 있습니다. 
애플리케이션은 Oracle Database Standard 를 사용하여 데이터를 저장합니다. 
에디션 서버. 이 회사는 AWS 로의 마이그레이션을 계획하고 있으며 애플리케이션을 이동하는 동안 
개발 변경을 최소화하려고 합니다. AWS 애플리케이션 환경은 가용성이 높아야 합니다. 
이러한 요구 사항을 충족하기 위해 회사는 어떤 조합의 조치를 취해야 합니까? (두 가지를 
선택하세요.) 
A. .NET Core 를 실행하는 AWS Lambda 함수를 사용하여 애플리케이션을 서버리스로 
리팩터링합니다. 
B. 다중 AZ 배포에서 .NET 플랫폼을 사용하여 AWS Elastic Beanstalk 에서 애플리케이션을 다시 
호스팅합니다. 
C. Amazon Linux Amazon 머신 이미지(AMI)를 사용하여 Amazon EC2 에서 실행되도록 
애플리케이션 플랫폼을 변경합니다. 
D. 다중 AZ 배포에서 AWS DMS(AWS Database Migration Service)를 사용하여 Oracle 
데이터베이스에서 Amazon DynamoDB 로 마이그레이션합니다. 
E. 다중 AZ 배포에서 AWS Database Migration Service(AWS DMS)를 사용하여 Oracle 
데이터베이스에서 Amazon RDS 의 Oracle 로 마이그레이션합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/89068-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 리팩터링은 코드 변경을 수반하므로 개발 변경 사항 최소화 조건 불충족. 
B(O) : AWS Elastic Beanstalk.NET 용 에서 Amazon Web Services 를 사용하는 ASP.NET 웹 
애플리케이션을 보다 쉽게 배포, 관리 및 조정할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/create_deploy_NET.html 
C(X) : 재플랫폼화는 개발 변경 사항 최소화 조건 불충족. 
D(X) : Oracle 데이터베이스는 관계형 데이터베이스이고, DynamoDB 는 비관계형 데이터베이스로 
유형이 다름. 개발 변경 최소화 조건 불충족. 
E(O) : 다중 AZ 배포로 고가용성 조건 충족. DMS 서비스로 데이터베이스 마이그레이션 가능. RDS 
for Oracle 로 개발 변경 최소화 가능. 
설명 2: 
애플리케이션을 AWS 로 이동하는 동안 개발 변경을 최소화하고 높은 수준의 가용성을 보장하기 
위해 회사는 다중 AZ 배포에서 .NET 플랫폼을 사용하여 AWS Elastic Beanstalk 에서 
애플리케이션을 다시 호스팅할 수 있습니다. 이렇게 하면 애플리케이션 코드를 변경할 필요 없이 
고가용성 환경에서 애플리케이션을 실행할 수 있습니다. 
또한 회사는 AWS Database Migration Service(AWS DMS)를 사용하여 다중 AZ 배포에서 Oracle 
데이터베이스를 Amazon RDS 의 Oracle 로 마이그레이션할 수 있습니다. 이를 통해 회사는 여전히 
높은 수준의 가용성을 달성하면서 기존 데이터베이스 플랫폼을 유지할 수 있습니다. 
Q198 
회사는 온프레미스 데이터 센터의 Kubernetes 클러스터에서 컨테이너화된 애플리케이션을 
실행합니다. 회사는 데이터 저장을 위해 MongoDB 데이터베이스를 사용하고 있습니다. 
회사는 이러한 환경 중 일부를 AWS 로 마이그레이션하려고 하지만 현재로서는 코드 변경이나 배포 
방법 변경이 불가능합니다. 회사는 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 컴퓨팅을 위해 Amazon EC2 작업자 노드와 함께 Amazon Elastic Container Service(Amazon 
ECS)를 사용하고 데이터 저장을 위해 EC2 의 MongoDB 를 사용합니다. 
B. 컴퓨팅용 AWS Fargate 및 데이터 저장용 Amazon DynamoDB 와 함께 Amazon Elastic 
Container Service(Amazon ECS)를 사용합니다. 
C. Amazon Elastic Kubernetes Service(Amazon EKS)를 Amazon EC2 작업자 노드와 함께 
컴퓨팅용으로 사용하고 Amazon DynamoDB 를 데이터 저장용으로 사용합니다. 
D. 컴퓨팅용 AWS Fargate 및 데이터 스토리지용 Amazon DocumentDB(MongoDB 호환)와 함께 
Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/89078-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Kubernetes 클러스터 = EKS 
MongoDB 호환 = DocumentDB 
설명 2: 
Amazon DocumentDB(MongoDB 와 호환)는 빠르고 안정적이며 완벽하게 관리되는 데이터베이스 
서비스입니다. 
Amazon DocumentDB 를 사용하면 클라우드에서 MongoDB 호환 데이터베이스를 쉽게 설정, 운영 
및 확장할 수 있습니다. Amazon DocumentDB 를 사용하면 동일한 애플리케이션 코드를 실행하고 
MongoDB 에서 사용하는 것과 동일한 드라이버 및 도구를 사용할 수 있습니다. 
https://docs.aws.amazon.com/documentdb/latest/developerguide/what-is.html 
Q199 
텔레마케팅 회사는 AWS 에서 고객 콜 센터 기능을 설계하고 있습니다. 이 회사는 여러 화자 
인식을 제공하고 대본 파일을 생성하는 솔루션이 필요합니다. 회사는 비즈니스 패턴을 분석하기 
위해 트랜스크립트 파일을 쿼리하려고 합니다. 기록 파일은 감사 목적으로 7 년 동안 저장되어야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 여러 화자 인식을 위해 Amazon Rekognition 을 사용하십시오. 성적표 파일을 Amazon S3 에 
저장합니다. 성적표 파일 분석을 위해 기계 학습 모델을 사용합니다. 
B. 여러 화자 인식을 위해 Amazon Transcribe 를 사용합니다. 성적표 파일 분석에 Amazon 
Athena 를 사용합니다. 
C. 여러 화자 인식을 위해 Amazon Translate 를 사용합니다. Amazon Redshift 에 기록 파일을 
저장합니다. 성적표 파일 분석에 SQL 쿼리를 사용합니다. 
D. 여러 화자 인식을 위해 Amazon Rekognition 을 사용합니다. 성적표 파일을 Amazon S3 에 
저장합니다. 성적표 파일 분석에 Amazon Textract 를 사용하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/89141-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : Amazon Rekognition 은 이미지/비디오 분석 서비스. 콜센터라고 했으므로 오디오를 다른 
걸로 변환시켜주는 서비스가 필요하므로 오답. 
Amazon Rekognition 은 애플리케이션에 강력한 시각 분석 기능을 쉽게 추가할 수 있게 해 주는 
서비스입니다. Rekognition Image 를 통해 수백만 개의 이미지를 검색, 확인 및 구성할 수 있는 
강력한 애플리케이션을 쉽게 구축할 수 있습니다. Rekognition Video 를 통해 저장된 동영상 또는 
실시간 스트림 동영상에서 동작 기반 컨텍스트를 추출하고 이를 분석할 수 있습니다. 
https://aws.amazon.com/ko/rekognition/faqs/ 
B(O) : Amazon Transcribe 로 다중 Speaker 인식 가능. 7 년 동안 저장해야한다고 했으므로 S3 같은 
스토리지 서비스가 필요한데, 해당 선택지에서는 S3 가 언급은 되지 않았으나 S3 에 쿼리하는 
Athena 가 있으므로 S3 를 사용하고 있다고 추측할 수 있음. 
Amazon Transcribe 는 고객이 손쉽게 음성을 텍스트로 변환할 수 있게 해주는 AWS 서비스입니다. 
https://aws.amazon.com/ko/transcribe/faqs/ 
C(X) : Amazon Translate 는 기계 번역 서비스. 
Amazon Translate 는 합리적인 가격으로 고품질의 사용자 지정 가능한 언어 번역을 빠르게 
제공하는 신경망 기계 번역 서비스입니다.  https://aws.amazon.com/ko/translate/ 
D(X) : A 와 동일한 이유로 오답. 
설명 2: 
Amazon Transcribe 는 이제 스트리밍 트랜스크립션을 위한 화자 레이블 지정을 지원합니다. 
Amazon Transcribe 는 음성을 텍스트로 쉽게 변환할 수 있는 자동 음성 인식(ASR) 서비스입니다. 
라이브 오디오 전사에서 각 오디오 스트림에는 여러 명의 화자가 포함될 수 있습니다. 이제 
화자에게 레이블을 지정하는 기능을 편리하게 켤 수 있으므로 출력 기록에서 누가 무엇을 
말하는지 식별하는 데 도움이 됩니다. 
https://aws.amazon.com/ko/about-aws/whats-new/2020/08/amazon-transcribe-supports-spea
ker-labeling-streaming-transcription/ 
Q200 
회사는 AWS 에서 애플리케이션을 호스팅합니다. 이 회사는 Amazon Cognito 를 사용하여 사용자를 
관리합니다. 사용자가 애플리케이션에 로그인하면 애플리케이션은 Amazon API Gateway 에서 
호스팅되는 REST API 를 사용하여 Amazon DynamoDB 에서 필요한 데이터를 가져옵니다. 이 
회사는 개발 노력을 줄이기 위해 REST API 에 대한 액세스를 제어하는 AWS 관리형 솔루션을 
원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 어떤 사용자가 요청했는지 확인하기 위해 API Gateway 에서 권한 부여자가 되도록 AWS 
Lambda 함수를 구성합니다. 
B. 각 사용자에 대해 각 요청과 함께 전송되어야 하는 API 키를 생성하고 할당합니다. AWS 
Lambda 함수를 사용하여 키를 검증합니다. 
C. 모든 요청과 함께 헤더에 사용자의 이메일 주소를 보냅니다. 해당 이메일 주소를 가진 
사용자에게 적절한 액세스 권한이 있는지 확인하려면 AWS Lambda 함수를 호출하십시오. 
D. Amazon Cognito 가 각 요청을 검증할 수 있도록 API Gateway 에서 Amazon Cognito 사용자 풀 
권한 부여자를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/89142-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Amazon Cognito 콘솔, CLI/SDK 또는 API 를 사용하여 사용자 풀을 만들거나 다른 AWS 계정이 
소유한 풀을 사용합니다. 
설명 2: 
https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-integrate-withcogn
ito.html 
REST API 에 대한 액세스를 제어하고 개발 노력을 줄이기 위해 회사는 API Gateway 에서 Amazon 
Cognito 사용자 풀 권한 부여자를 사용할 수 있습니다. 이를 통해 Amazon Cognito 는 각 요청을 
검증하고 인증된 사용자만 API 에 액세스할 수 있도록 합니다. 이 솔루션은 회사가 추가 인프라나 
코드를 개발하고 유지 관리할 필요가 없으므로 운영 오버헤드가 가장 적습니다. 
Q201 
회사에서 모바일 앱 사용자를 대상으로 하는 마케팅 커뮤니케이션 서비스를 개발하고 있습니다. 
회사는 SMS(Short Message Service)를 통해 사용자에게 확인 메시지를 보내야 합니다. 사용자는 
SMS 메시지에 회신할 수 있어야 합니다. 회사는 분석을 위해 응답을 1 년 동안 저장해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon Connect 통화 흐름을 생성하여 SMS 메시지를 보냅니다. AWS Lambda 를 사용하여 
응답을 처리합니다. 
B. Amazon Pinpoint 여정을 구축하십시오. 분석 및 보관을 위해 이벤트를 Amazon Kinesis 데이터 
스트림으로 보내도록 Amazon Pinpoint 를 구성합니다. 
C. Amazon Simple Queue Service(Amazon SQS)를 사용하여 SMS 메시지를 배포합니다. AWS 
Lambda 를 사용하여 응답을 처리합니다. 
D. Amazon Simple Notification Service(Amazon SNS) FIFO 주제를 생성합니다. 분석 및 보관을 
위해 Amazon Kinesis 데이터 스트림을 SNS 주제에 구독합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/89080-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
https://aws.amazon.com/pinpoint/product-details/sms/ 
양방향 메시징: 고객으로부터 SMS 메시지를 받고 채팅과 같은 대화형 환경에서 회신합니다. 
Amazon Pinpoint 를 사용하면 고객이 특정 키워드가 포함된 메시지를 보낼 때 자동 응답을 생성할 
수 있습니다. Amazon Lex 를 사용하여 대화형 봇을 만들 수도 있습니다. 대부분의 휴대폰 사용자는 
들어오는 SMS 메시지를 받은 직후에 읽습니다. 고객에게 긴급하거나 중요한 정보를 제공해야 하는 
경우 SMS 메시징이 적합한 솔루션일 수 있습니다. Amazon Pinpoint 를 사용하여 대상 고객 그룹을 
생성한 다음 캠페인 기반 메시지를 보낼 수 있습니다. Amazon Pinpoint 를 사용하여 약속 확인, 
주문 업데이트, 일회용 암호와 같은 다이렉트 메시지를 보낼 수도 있습니다. 
Q202 
회사에서 데이터를 Amazon S3 버킷으로 이동할 계획입니다. 데이터는 S3 버킷에 저장될 때 
암호화되어야 합니다. 또한 암호화 키는 매년 자동으로 순환되어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 데이터를 S3 버킷으로 이동합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 
사용합니다. SSE-S3 암호화 키의 기본 제공 키 회전 동작을 사용합니다. 
B. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. 자동 키 순환을 
활성화합니다. 고객 관리형 KMS 키를 사용하도록 S3 버킷의 기본 암호화 동작을 설정합니다. 
데이터를 S3 버킷으로 이동합니다. 
C. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. 고객 관리형 KMS 
키를 사용하도록 S3 버킷의 기본 암호화 동작을 설정합니다. 데이터를 S3 버킷으로 이동합니다. 
매년 KMS 키를 수동으로 교체합니다. 
D. 데이터를 S3 버킷으로 이동하기 전에 고객 키 자료로 데이터를 암호화합니다. 키 자료 없이 
AWS Key Management Service(AWS KMS) 키를 생성합니다. 고객 키 자료를 KMS 키로 가져옵니다. 
자동 키 순환을 활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/89081-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
A?? 
설명 1: 
・S3 버킷에 저장될 때 암호화되므로 SSE(서버 측 암호화). 만약 S3 버킷으로 보내기 전에 
암호화하면 CSE(클라이언트 측 암호화)임. 
・Amazon S3 버킷에 저장되는 모든 객체를 암호화하는 기본 암호화 동작을 버킷에 설정할 수 
있습니다. 객체는 Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3) 또는 AWS Key 
Management Service(AWS KMS) 키를 사용한 서버 측 암호화를 사용하여 암호화됩니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/default-bucket-encryption.html 
A(X) : 먼저 S3 버킷을 암호화한 게 아니라 데이터를 S3 버킷에 담아놓고 암호화를 했기 때문에 
불필요한 배치 작업이 발생. 
Amazon S3 기본 암호화를 사용하면 S3 버킷에 대한 기본 암호화 동작을 설정하여 모든 새 객체가 
버킷에 저장될 때 암호화되도록 할 수 있습니다. Amazon S3 관리형 키를 사용한 서버 측 
암호화(SSE-S3) 또는 AWS Key Management Service(AWS KMS)에 저장된 AWS KMS keys 를 
사용한 서버 측 암호화(SSE-KMS)로 객체를 암호화합니다. 서버 측 암호화를 사용하는 경우 
Amazon S3 에서는 객체를 디스크에 저장하기 전에 암호화하고 기존 Amazon S3 객체를 
암호화하기 위해 Amazon S3 배치 작업을 사용할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/bucket-encryption.html 
B(O) : AWS KMS CMK(고객 관리 키)는 원래 키 자동 교체(rotate)을 하진 않지만 이를 활성화할 수 
있음. 
https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/concepts.html#customer-cmk 
C(X) : 암호화 키는 매년 자동 순환되어야 한다고 했는데 수동 순환이라 오답. 
D(X) : S3 버킷으로 이동하기 전에 기본 암호화 동작을 설정하므로 SSE 가 아닌 CSE(클라이언트 
측 암호화)임. 
설명 2: 
SSE-S3 - 무료이며 AWS 소유 CMK(CMK = 고객 마스터 키)를 사용합니다. 암호화 키는 AWS 에서 
소유하고 관리하며 여러 계정 간에 공유됩니다. 회전은 여기 표에 표시된 대로 시간에 따라 
자동으로 바뀝니다. 시간은 명시적으로 정의되지 않습니다. 
SSE-KMS - 두 가지 특징이 있습니다. 
AWS 관리형 CMK. 귀하의 계정에 대해서만 생성된 무료 CMK 입니다. 정책을 보고 사용량을 
감사할 수만 있고 관리할 수는 없습니다. 교체는 자동입니다. 1095일(3년)당 한 번, 고객이 CMK를 
관리합니다. 이것은 사용자가 생성하고 관리할 수 있는 사용자 고유의 키를 사용합니다. 회전은 
기본적으로 활성화되어 있지 않습니다. 그러나 활성화하면 1 년마다 자동으로 순환됩니다. 이 
변형은 사용자가 가져온 키 자료를 사용할 수도 있습니다. 가져온 자료로 이러한 키를 생성하면 
자동 회전이 없습니다. 수동 회전만 가능합니다. 
SSE-C - 고객 제공 키. 암호화 키는 AWS 외부에서 사용자가 완전히 관리합니다. AWS 는 이를 
교체하지 않습니다. 
이 솔루션은 데이터를 Amazon S3 버킷으로 이동하고, 데이터가 S3 버킷에 저장될 때 데이터를 
암호화하고, 최소한의 운영 오버헤드로 매년 암호화 키를 자동으로 교체하는 요구 사항을 
충족합니다. AWS Key Management Service(AWS KMS)는 데이터의 암호화 키를 생성하고 관리할 수 
있는 서비스입니다. 고객 관리형 키는 AWS KMS 에서 생성하고 관리하는 대칭 암호화 키입니다. 
고객 관리형 키에 대해 자동 키 교체를 활성화할 수 있습니다. 즉, AWS KMS 는 매년 키에 대한 
새로운 암호화 자료를 생성합니다. 고객 관리형 KMS 키를 사용하도록 S3 버킷의 기본 암호화 
동작을 설정할 수 있습니다. 즉, 암호화 방법을 지정하지 않고 버킷에 업로드된 모든 객체는 해당 
키로 암호화됩니다. 
Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하면 암호화 키를 제어하거나 
관리할 수 없으므로 옵션 A 는 올바르지 않습니다. SSE-S3 는 각 객체에 대해 고유한 키를 
사용하고 S3에서 정기적으로 순환하는 마스터 키로 해당 키를 암호화합니다. 그러나 SSE-S3 키에 
대한 키 교체를 활성화 또는 비활성화하거나 교체 간격을 지정할 수 없습니다. 
옵션 C 는 올바르지 않습니다. 매년 KMS 키를 수동으로 교체하면 운영 오버헤드와 복잡성이 
증가할 수 있고 교체 프로세스를 잊어버리거나 지연하는 경우 매년 키 교체 요구 사항을 충족하지 
못할 수 있기 때문입니다. 
데이터를 S3 버킷으로 이동하기 전에 고객 키 자료로 데이터를 암호화하면 운영 오버헤드와 
복잡성이 증가할 수 있고 버킷의 모든 객체에 대해 일관된 암호화를 제공하지 못할 수 있으므로 
옵션 D 는 올바르지 않습니다. 키 자료 없이 KMS 키를 생성하고 고객 키 자료를 KMS 키로 
가져오면 고유한 임의 비트 소스를 사용하여 KMS 키를 생성할 수 있지만 자동 키 순환은 
지원하지 않습니다. 
참조: 
https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html 
https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-encryption.html 
Q203 
금융 회사의 고객은 문자 메시지를 보내 재정 고문과의 약속을 요청합니다. Amazon EC2 
인스턴스에서 실행되는 웹 애플리케이션은 약속 요청을 수락합니다. 텍스트 메시지는 웹 
애플리케이션을 통해 Amazon Simple Queue Service(Amazon SQS) 대기열에 게시됩니다. EC2 
인스턴스에서 실행되는 또 다른 애플리케이션은 회의 초대장과 회의 확인 이메일 메시지를 
고객에게 보냅니다. 예약에 성공한 후 이 애플리케이션은 회의 정보를 Amazon DynamoDB 
데이터베이스에 저장합니다. 
회사가 확장됨에 따라 고객은 회의 초대장이 도착하는 데 시간이 더 오래 걸린다고 보고합니다. 
솔루션 설계자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까? 
A. DynamoDB 데이터베이스 앞에 DynamoDB Accelerator(DAX) 클러스터를 추가합니다. 
B. 약속 요청을 수락하는 웹 애플리케이션 앞에 Amazon API Gateway API 를 추가합니다. 
C. Amazon CloudFront 배포를 추가합니다. 오리진을 약속 요청을 수락하는 웹 애플리케이션으로 
설정합니다. 
D. 회의 초대를 보내는 애플리케이션에 대한 Auto Scaling 그룹을 추가합니다. SQS 대기열의 
깊이에 따라 확장되도록 Auto Scaling 그룹을 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/89082-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
회의 초대 전달 시간이 길어지는 문제를 해결하기 위해 솔루션 설계자는 회의 초대를 보내는 
애플리케이션에 대해 Auto Scaling 그룹을 추가하고 SQS 대기열의 깊이에 따라 확장되도록 Auto 
Scaling 그룹을 구성하도록 권장할 수 있습니다. 이렇게 하면 약속 요청 수가 증가함에 따라 
애플리케이션이 확장되어 회의 초대의 성능 및 배달 시간이 향상됩니다. 
Q204 
한 온라인 소매 회사는 5 천만 명 이상의 활성 고객을 보유하고 있으며 매일 25,000 건 이상의 
주문을 받습니다. 회사는 고객의 구매 데이터를 수집하고 이 데이터를 Amazon S3 에 저장합니다. 
추가 고객 데이터는 Amazon RDS 에 저장됩니다. 
회사는 팀이 분석을 수행할 수 있도록 다양한 팀에서 모든 데이터를 사용할 수 있도록 하려고 
합니다. 솔루션은 데이터에 대한 세분화된 권한을 관리하는 기능을 제공하고 운영 오버헤드를 
최소화해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 구매 데이터를 마이그레이션하여 Amazon RDS 에 직접 씁니다. RDS 액세스 제어를 사용하여 
액세스를 제한하십시오. 
B. Amazon RDS 에서 Amazon S3 로 데이터를 주기적으로 복사하도록 AWS Lambda 함수를 
예약합니다. AWS Glue 크롤러를 생성합니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다. S3 
정책을 사용하여 액세스를 제한하십시오. 
C. AWS Lake Formation 을 사용하여 데이터 레이크를 생성합니다. Amazon RDS 에 대한 AWS Glue 
JDBC 연결을 생성합니다. Lake Formation 에 S3 버킷을 등록합니다. Lake Formation 액세스 제어를 
사용하여 액세스를 제한하십시오. 
D. Amazon Redshift 클러스터를 생성합니다. Amazon S3 및 Amazon RDS 에서 Amazon Redshift 로 
데이터를 주기적으로 복사하도록 AWS Lambda 함수를 예약합니다. Amazon Redshift 액세스 
제어를 사용하여 액세스를 제한하십시오. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/89083-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A(X) : 액세스 제어하는 것까지만 나왔고 어떻게 쿼리할 것인지는 언급 안 함. 
B(X) : 처음부터 S3 에 다 저장할 것이지 결국 S3 에 저장할 거면서 왜 RDS 에 저장했다가 다시 
S3 에 저장하는지? 
C(O) : S3 버킷을 데이터레이크로 만들고 Glue 를 통해서 ETL 함으로서 S3 에 저장된 데이터를 
RedShift 같은 서비스에서 사용할 수 있게끔 함. RDS 에 저장된 고객 데이터는 Glue JDBC 를 통해 
변환 
・S3 버킷을 AWS Lake Formation 을 사용해 데이터레이크로 만들고 Glue 기능 사용해 ETL. 
AWS Lake Formation 콘솔, Lake Formation API 또는 AWS 명령줄 인터페이스(AWS CLI)를 
사용하여 Amazon S3 위치를 등록할 수 있습니다. 
https://docs.aws.amazon.com/lake-formation/latest/dg/register-location.html 
Lake Formation 은 콘솔 제어, ETL 코드 생성, 작업 모니터링, 공통 데이터 카탈로그, 서버리스 
아키텍처를 포함하여 AWS Glue 에서 공유 인프라를 활용합니다. AWS Glue 는 아직 이러한 유형의 
기능에 초점을 맞추고 있는 반면, Lake Formation 은 AWS Glue 기능을 포함하면서, 동시에 데이터 
레이크를 구축하고 보안하고 관리하는 데 유용한 추가 기능을 제공합니다. 
https://aws.amazon.com/ko/glue/faqs/ 
・AWS RDS 에 저장된 데이터를 Glue 에서 사용 
AWS Glue 는 기본적으로 Amazon Aurora, Amazon RDS for MySQL, Amazon RDS for Oracle, 
Amazon RDS for PostgreSQL, Amazon RDS for SQL Server, Amazon Redshift, DynamoDB 및 
Amazon S3 뿐만 아니라 Amazon EC2 에서 실행되는 Virtual Private Cloud(Amazon VPC)에 있는 
MySQL, Oracle, Microsoft SQL Server 및 PostgreSQL 데이터베이스에 저장된 데이터를 
지원합니다. 
https://aws.amazon.com/ko/glue/faqs/ 
AWS Glue 는 JDBC 연결을 통해 다음 데이터 스토어에 연결할 수 있습니다. ◎Amazon Redshift. 
◎Amazon RDS for MariaDB 
https://docs.aws.amazon.com/ko_kr/glue/latest/dg/connection-properties.html#connection-pro
perties-jdbc 
・데이터에 대한 세분화된 권한 관리 
AWS Lake Formation은 간단한 권한 부여/취소 메커니즘을 기반으로 하는 권한 모델을 제공합니다. 
Lake Formation 권한은 AWS Identity and Access Management(IAM) 권한과 결합되어 데이터 
레이크에 저장된 데이터 및 해당 데이터를 설명하는 메타데이터에 대한 액세스를 제어합니다. 
https://docs.aws.amazon.com/lake-formation/latest/dg/security-data-access.html 
D(X) : 주기적으로 처리하라는 요구 사항이 있지 않는 이상 바로바로 처리하는 게 보통인데, 
주기적으로 처리하고 있음. 
설명 2: 
다양한 팀에서 모든 데이터를 사용할 수 있도록 하고 운영 오버헤드를 최소화하기 위해 회사는 
AWS Lake Formation 을 사용하여 데이터 레이크를 생성할 수 있습니다. 이를 통해 회사는 모든 
데이터를 한 곳에서 중앙 집중화하고 세분화된 액세스 제어를 사용하여 데이터에 대한 액세스를 
관리할 수 있습니다. 회사의 요구 사항을 충족하기 위해 솔루션 설계자는 AWS Lake Formation 을 
사용하여 데이터 레이크를 만들고, Amazon RDS 에 대한 AWS Glue JDBC 연결을 만들고, Lake 
Formation 에 S3 버킷을 등록할 수 있습니다. 그런 다음 솔루션 설계자는 Lake Formation 액세스 
제어를 사용하여 데이터에 대한 액세스를 제한할 수 있습니다. 이 솔루션은 데이터에 대한 
세분화된 권한을 관리하고 운영 오버헤드를 최소화하는 기능을 제공합니다. 
Q205 
회사는 온프레미스 데이터 센터에서 마케팅 웹 사이트를 호스팅합니다. 웹 사이트는 정적 문서로 
구성되며 단일 서버에서 실행됩니다. 관리자는 웹 사이트 콘텐츠를 자주 업데이트하지 않고 SFTP 
클라이언트를 사용하여 새 문서를 업로드합니다. 
회사는 AWS에서 웹 사이트를 호스팅하고 Amazon CloudFront를 사용하기로 결정했습니다. 회사의 
솔루션 아키텍트가 CloudFront 배포를 생성합니다. 솔루션 설계자는 웹 사이트 호스팅이 
CloudFront 오리진 역할을 할 수 있도록 가장 비용 효율적이고 탄력적인 아키텍처를 설계해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Lightsail 을 사용하여 가상 서버를 생성합니다. Lightsail 인스턴스에서 웹 서버를 
구성합니다. SFTP 클라이언트를 사용하여 웹 사이트 콘텐츠를 업로드합니다. 
B. Amazon EC2 인스턴스에 대한 AWS Auto Scaling 그룹을 생성합니다. Application Load 
Balancer 를 사용하십시오. SFTP 클라이언트를 사용하여 웹 사이트 콘텐츠를 업로드합니다. 
C. 프라이빗 Amazon S3 버킷을 생성합니다. S3 버킷 정책을 사용하여 CloudFront 원본 액세스 
ID(OAI)에서 액세스를 허용합니다. AWS CLI 를 사용하여 웹사이트 콘텐츠를 업로드합니다. 
D. 퍼블릭 Amazon S3 버킷을 생성합니다. SFTP 용 AWS 전송을 구성합니다. 웹 사이트 호스팅을 
위해 S3 버킷을 구성합니다. SFTP 클라이언트를 사용하여 웹 사이트 콘텐츠를 업로드합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/89085-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
프라이빗 S3 에서 웹사이트를 호스팅하면 정적 웹사이트 콘텐츠를 위한 비용 효율적이고 가용성이 
높은 스토리지를 제공합니다. CloudFront OAI 의 액세스를 허용하도록 버킷 정책을 구성하면 
CloudFront 를 통해서만 S3 에 안전하게 액세스할 수 있습니다. 이렇게 하면 웹 사이트 콘텐츠가 
S3 를 비공개로 유지하면서 CloudFront 를 통해 제공됩니다. AWS CLI 를 사용하여 웹 사이트 
콘텐츠를 업로드하면 콘텐츠를 쉽고 효율적으로 관리할 수 있습니다. 
A. Lightsail 가상 서버에서 웹 사이트를 호스팅하면 정적 콘텐츠 호스팅에 S3 를 직접 사용하는 
것과 비교하여 추가 관리 오버헤드와 비용이 발생합니다. 
B. 정적 웹 사이트 콘텐츠를 제공하기 위해 EC2 인스턴스 및 ALB 와 함께 AWS ASG 를 사용할 
필요가 없습니다. 불필요한 복잡성과 비용이 추가됩니다. 
D. AWS Transfer for SFTP 를 사용하면 SFTP 업로드가 가능하지만 AWS CLI 를 사용하여 콘텐츠를 
S3 에 직접 업로드하는 것과 비교하여 추가 비용과 복잡성이 발생합니다. 또한 공용 S3 에서 웹 
사이트 콘텐츠를 호스팅하는 것은 보안 관점에서 바람직하지 않을 수 있습니다. 
참고: 
https://docs.aws.amazon.com/cli/latest/reference/transfer/describe-server.html 
Q206 
회사에서 Amazon 머신 이미지(AMI)를 관리하려고 합니다. 회사는 현재 AMI 가 생성된 동일한 
AWS 리전에 AMI 를 복사합니다. 회사는 AWS API 호출을 캡처하고 회사 계정 내에서 Amazon EC2 
CreateImage API 작업이 호출될 때마다 알림을 보내는 애플리케이션을 설계해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS CloudTrail 로그를 쿼리하고 CreateImage API 호출이 감지되면 알림을 보내는 AWS 
Lambda 함수를 생성합니다. 
B. 업데이트된 로그가 Amazon S3 로 전송될 때 발생하는 Amazon Simple Notification 
Service(Amazon SNS) 알림으로 AWS CloudTrail 을 구성합니다. Amazon Athena 를 사용하여 새 
테이블을 생성하고 API 호출이 감지되면 CreateImage 에서 쿼리합니다. 
C. CreateImage API 호출에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 
생성합니다. CreateImage API 호출이 감지되면 알림을 보내도록 대상을 Amazon Simple 
Notification Service(Amazon SNS) 주제로 구성합니다. 
D. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 AWS CloudTrail 로그의 대상으로 
구성합니다. CreateImage API 호출이 감지되면 Amazon Simple Notification Service(Amazon SNS) 
주제에 알림을 보내는 AWS Lambda 함수를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/89086-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/WindowsGuide/monitor-ami-events.html 
CreateImage API 호출에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하고 
CreateImage API 호출이 감지될 때 알림을 보내도록 대상을 Amazon Simple Notification 
Service(Amazon SNS) 주제로 구성하면 운영 오버헤드가 최소인 요구 사항을 충족합니다. . 
Amazon EventBridge 는 자체 애플리케이션, 통합 SaaS(Software as a Service) 애플리케이션 및 
AWS 서비스의 데이터를 사용하여 애플리케이션을 쉽게 함께 연결할 수 있게 해주는 서버리스 
이벤트 버스입니다. CreateImage API 호출에 대한 EventBridge 규칙을 생성하여 회사는 계정 
내에서 이 작업이 호출될 때마다 경고를 설정할 수 있습니다. 경고는 SNS 주제로 보낼 수 있으며, 
그런 다음 회사의 이메일 또는 기타 원하는 대상으로 알림을 보내도록 구성할 수 있습니다. 
참고 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/WindowsGuide/monitor-ami-events.html 
Q207 
회사는 사용자 요청을 수집하고 요청 유형에 따라 처리를 위해 적절한 마이크로 서비스에 요청을 
발송하는 데 사용되는 비동기 API 를 소유하고 있습니다. 이 회사는 Amazon API Gateway 를 
사용하여 API 프런트 엔드를 배포하고 Amazon DynamoDB 를 호출하여 사용자 요청을 처리 
마이크로서비스로 보내기 전에 저장하는 AWS Lambda 함수를 사용하고 있습니다. 
회사는 예산이 허용하는 한 많은 DynamoDB 처리량을 프로비저닝했지만 회사는 여전히 가용성 
문제를 겪고 있으며 사용자 요청이 손실되고 있습니다. 
솔루션 설계자는 기존 사용자에게 영향을 주지 않고 이 문제를 해결하기 위해 무엇을 해야 
합니까? 
A. API 게이트웨이에서 서버 측 조절 제한을 사용하여 조절을 추가합니다. 
B. DynamoDB Accelerator(DAX) 및 Lambda 를 사용하여 DynamoDB 에 대한 쓰기를 버퍼링합니다. 
C. 사용자 요청이 있는 테이블에 대해 DynamoDB 에서 보조 인덱스를 생성합니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열과 Lambda 를 사용하여 DynamoDB 에 
대한 쓰기를 버퍼링합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/89087-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
솔루션 설계자는 SQS 대기열과 Lambda 를 사용하여 처리 마이크로서비스에서 API 프런트 엔드를 
분리하고 시스템의 전반적인 확장성과 가용성을 개선할 수 있습니다. SQS 대기열은 버퍼 역할을 
하여 API 프런트 엔드가 마이크로서비스 처리에 높은 작업 부하가 발생하거나 일시적으로 사용할 
수 없는 경우에도 사용자 요청을 계속 수락할 수 있도록 합니다. 그런 다음 Lambda 함수는 SQS 
대기열에서 요청을 검색하고 DynamoDB 에 기록하여 모든 사용자 요청이 저장 및 처리되도록 할 
수 있습니다. 이 접근 방식을 통해 회사는 API 프런트 엔드와 독립적으로 처리 마이크로서비스를 
확장할 수 있으므로 수요가 많은 기간에도 사용자가 API 를 계속 사용할 수 있습니다. 
즉 사용자 요청을 잃고 있음 = SQS 로 해결. 정답은 D. 
Q208 
회사는 Amazon EC2 인스턴스에서 Amazon S3 버킷으로 데이터를 이동해야 합니다. 회사는 API 
호출 및 데이터가 공용 인터넷 경로를 통해 라우팅되지 않도록 해야 합니다. EC2 인스턴스만 S3 
버킷에 데이터를 업로드할 수 있는 액세스 권한을 가질 수 있습니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EC2 인스턴스가 있는 서브넷에서 Amazon S3 에 대한 인터페이스 VPC 엔드포인트를 
생성합니다. EC2 인스턴스의 IAM 역할만 액세스할 수 있도록 리소스 정책을 S3 버킷에 
연결합니다. 
B. EC2 인스턴스가 있는 가용 영역에서 Amazon S3 에 대한 게이트웨이 VPC 엔드포인트를 
생성합니다. 엔드포인트에 적절한 보안 그룹을 연결합니다. EC2 인스턴스의 IAM 역할만 액세스할 
수 있도록 리소스 정책을 S3 버킷에 연결합니다. 
C. EC2 인스턴스 내부에서 nslookup 도구를 실행하여 S3 버킷 서비스 API 엔드포인트의 프라이빗 
IP 주소를 얻습니다. S3 버킷에 대한 액세스 권한을 EC2 인스턴스에 제공하기 위해 VPC 경로 
테이블에 경로를 생성합니다. EC2 인스턴스의 IAM 역할만 액세스할 수 있도록 리소스 정책을 S3 
버킷에 연결합니다. 
D. AWS 에서 제공하고 공개적으로 사용 가능한 ip-ranges.json 파일을 사용하여 S3 버킷 서비스 
API 엔드포인트의 프라이빗 IP 주소를 얻습니다. S3 버킷에 대한 액세스 권한을 EC2 인스턴스에 
제공하기 위해 VPC 경로 테이블에 경로를 생성합니다. EC2 인스턴스의 IAM 역할만 액세스할 수 
있도록 리소스 정책을 S3 버킷에 연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/89088-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
B?? 
설명 1: 
EC2 인스턴스-S3 버킷 간 통신이 인터넷에 노출되지 않음 = S3 Gateway Endpoint. 
설명 2: 
EC2 인스턴스와 동일한 서브넷에 Amazon S3 용 인터페이스 VPC 종단점을 생성하면 EC2 
인스턴스와 S3 간의 데이터 전송이 공용 인터넷을 거치지 않고 Amazon 네트워크 내에서 
비공개로 발생할 수 있습니다. 이렇게 하면 EC2 인스턴스와 S3 간의 안전하고 직접적인 통신이 
보장됩니다. EC2 인스턴스와 연결된 IAM 역할의 액세스만 허용하는 리소스 정책을 S3 버킷에 
연결하면 권한이 부여된 인스턴스에 대한 액세스만 추가로 제한됩니다. 
B. Amazon S3 용 게이트웨이 VPC 종단점을 생성하려면 공용 인터넷을 통한 라우팅이 여전히 
필요하므로 이 경우에는 바람직하지 않습니다. 
C. nslookup 을 실행하거나 VPC 경로 테이블에서 특정 경로를 생성하면 트래픽이 여전히 공용 
인터넷 경로를 통과할 수 있으므로 원하는 수준의 보안 및 개인 정보 보호를 제공하지 않습니다. 
D. 공개적으로 사용 가능한 ip-ranges.json 파일을 사용하여 S3 버킷의 서비스 API 엔드포인트의 
프라이빗 IP 주소를 얻는 것은 권장되는 접근 방식이 아닙니다. IP 주소는 시간이 지남에 따라 
변경될 수 있고 동일한 수준의 보안을 제공하지 않기 때문입니다. VPC 엔드포인트를 사용합니다. 
참고 
https://aws.amazon.com/blogs/security/how-to-restrict-amazon-s3-bucket-access-to-a-spec
ific-iamrole/ 
Q209 
솔루션 아키텍트는 AWS 클라우드에 배포되는 새 애플리케이션의 아키텍처를 설계하고 있습니다. 
애플리케이션은 Amazon EC2 온디맨드 인스턴스에서 실행되며 여러 가용 영역에서 자동으로 
확장됩니다. EC2 인스턴스는 하루 종일 자주 확장 및 축소됩니다. Application Load 
Balancer(ALB)는 부하 분산을 처리합니다. 아키텍처는 분산 세션 데이터 관리를 지원해야 합니다. 
회사는 필요한 경우 기꺼이 코드를 변경할 수 있습니다. 
아키텍처가 분산 세션 데이터 관리를 지원하도록 하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. Amazon ElastiCache 를 사용하여 세션 데이터를 관리하고 저장합니다. 
B. ALB 의 세션 선호도(스티키 세션)를 사용하여 세션 데이터를 관리합니다. 
C. AWS Systems Manager 의 Session Manager 를 사용하여 세션을 관리합니다. 
D. AWS Security Token Service(AWS STS)에서 GetSessionToken API 작업을 사용하여 세션을 
관리합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/89089-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
https://aws.amazon.com/vi/caching/session-management/ 
확장성을 해결하고 개별 웹 서버에서 액세스할 수 있는 세션에 대한 공유 데이터 저장소를 
제공하기 위해 웹 서버 자체에서 HTTP 세션을 추상화할 수 있습니다. 
이에 대한 일반적인 솔루션은 Redis 및 Memcached 와 같은 메모리 내 키/값 저장소를 활용하는 
것입니다. 메모리 내 키/값 저장소용 ElastiCache 제품에는 복제를 지원할 수 있는 Redis 용 
ElastiCache 와 복제를 지원하지 않는 Memcached 용 ElastiCache 가 포함됩니다. 
설명 2: 
A(O) : 분산 세션 관리 : 확장성을 해결하고 개별 웹 서버에서 액세스할 수 있는 세션에 대한 공유 
데이터 저장소를 제공하기 위해 웹 서버 자체에서 HTTP 세션을 추상화할 수 있습니다. 이에 대한 
일반적인 솔루션은 Redis 및 Memcached 와 같은 메모리 내 키/값 저장소 를 활용하는 것 
입니다. 
https://aws.amazon.com/ko/caching/session-management/ 
Redis 용 Amazon ElastiCache 는 사용자 인증 토큰, 세션 상태 등 세션 정보를 관리하는 세션 
스토어로 사용하기에 매우 적합합니다. Redis 용 Amazon ElastiCache 를 세션 키에 대한 적절한 
TTL 과 함께 빠른 키-값 스토어로 사용하면 세션 정보를 관리할 수 있습니다. 
https://aws.amazon.com/ko/elasticache/redis/?nc=sn&loc=2&dn=1#Session_Store 
B(X) : EC2 인스턴스는 하루 종일 자주 확장 및 축소된다고 했는데 Session Affinity(=Sticky 
Session)은 이에 맞지 않음. ""개별 노드에 세션 저장을 사용할 때의 단점은 장애가 발생할 경우 
장애가 발생한 노드에 있던 세션이 손실될 가능성이 있다는 것입니다. 또한 웹 서버 수가 변경되는 
경우(예: 확장 시나리오) 활성 세션이 특정 서버에 존재할 수 있으므로 트래픽이 웹 서버 전체에 
불균등하게 분산될 수 있습니다.  
https://aws.amazon.com/ko/caching/session-management/ 
C(X) : Session Manager 는 접속 서비스이지 데이터 관리 서비스가 아님. Session Manager 는 
인바운드 포트를 열거나, 배스천 호스트를 유지하거나, SSH 키를 관리할 필요 없이 안전하고 감사 
가능한 노드 관리를 제공 
https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html 
D(X) : STS 는 임시 보안 자격 증명 서비스. ""AWS Security Token Service(AWS STS)를 사용하면 
AWS 리소스에 대한 액세스를 제어할 수 있는 임시 보안 자격 증명을 생성하여 신뢰받는 
사용자에게 제공할 수 있습니다. 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_credentials_temp.html 
Q210 
빠르게 성장하고 있는 음식 배달 서비스를 제공하는 회사가 있습니다. 성장으로 인해 회사의 주문 
처리 시스템은 피크 트래픽 시간 동안 확장 문제를 겪고 있습니다. 현재 아키텍처에는 다음이 
포함됩니다. 
• 애플리케이션에서 주문을 수집하기 위해 Amazon EC2 Auto Scaling 그룹에서 실행되는 Amazon 
EC2 인스턴스 그룹입니다. 
• 주문을 이행하기 위해 Amazon EC2 Auto Scaling 그룹에서 실행되는 또 다른 EC2 인스턴스 
그룹. 
주문 수집 프로세스는 빠르게 진행되지만 주문 이행 프로세스는 더 오래 걸릴 수 있습니다. 
스케일링 이벤트로 인해 데이터가 손실되어서는 안 됩니다. 
솔루션 설계자는 주문 수집 프로세스와 주문 이행 프로세스가 트래픽이 가장 많은 시간에 
적절하게 확장될 수 있는지 확인해야 합니다. 솔루션은 회사의 AWS 리소스 활용을 최적화해야 
합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon CloudWatch 지표를 사용하여 Auto Scaling 그룹에 있는 각 인스턴스의 CPU 를 
모니터링합니다. 최대 워크로드 값에 따라 각 Auto Scaling 그룹의 최소 용량을 구성합니다. 
B. Amazon CloudWatch 지표를 사용하여 Auto Scaling 그룹에 있는 각 인스턴스의 CPU 를 
모니터링합니다. 요청 시 추가 Auto Scaling 그룹을 생성하는 Amazon Simple Notification 
Service(Amazon SNS) 주제를 호출하도록 CloudWatch 경보를 구성합니다. 
C. 두 개의 Amazon Simple Queue Service(Amazon SQS) 대기열을 프로비저닝합니다. 하나는 주문 
수집용이고 다른 하나는 주문 이행용입니다. 각 대기열을 폴링하도록 EC2 인스턴스를 구성합니다. 
대기열이 보내는 알림을 기반으로 Auto Scaling 그룹을 조정합니다. 
D. 2 개의 Amazon Simple Queue Service(Amazon SQS) 대기열을 프로비저닝합니다. 하나는 주문 
수집용이고 다른 하나는 주문 이행용입니다. 각 대기열을 폴링하도록 EC2 인스턴스를 구성합니다. 
인스턴스 계산당 백로그를 기반으로 지표를 만듭니다. 이 지표를 기반으로 Auto Scaling 그룹을 
조정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/94992-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Auto Scaling 그룹의 인스턴스 수는 메시지를 처리하는 데 걸리는 시간과 허용 가능한 지연 
시간(대기열 지연)에 따라 결정될 수 있습니다. 해결책은 유지 관리할 인스턴스당 허용 가능한 
백로그인 대상 값과 함께 인스턴스 메트릭당 백로그를 사용하는 것입니다. 
설명 2: 
A. 이 접근 방식은 CPU 사용률에만 초점을 맞추므로 주문 수집 및 이행 프로세스의 확장 요구 
사항을 정확하게 반영하지 못할 수 있습니다. 분리 및 신뢰할 수 있는 메시지 처리에 대한 요구 
사항은 다루지 않습니다. 
B. 이 접근 방식은 경보를 통합하여 추가 Auto Scaling 그룹을 트리거하지만 SQS 대기열을 
사용하여 제공되는 분리 및 안정적인 메시지 처리가 부족합니다. 비효율적인 확장 및 잠재적인 
데이터 손실이 발생할 수 있습니다. 
C. SQS 대기열을 사용하는 것이 올바른 방향으로 나아가는 단계이지만 대기열 알림만을 기준으로 
확장하는 것은 최적의 리소스 활용을 제공하지 못할 수 있습니다. 인스턴스당 백로그를 고려하지 
않으며 조정에 대한 세밀한 제어를 허용하지 않습니다. 
전반적으로 주문 수집 및 이행을 위해 SQS 대기열을 사용하고, 인스턴스 계산당 백로그를 
기반으로 메트릭을 생성하고, 이에 따라 Auto Scaling 그룹을 확장하는 옵션 D 는 리소스 활용을 
최적화하고 보장하면서 확장 문제를 해결하는 가장 적합한 솔루션입니다. 신뢰할 수 있는 메시지 
처리 
Q211 
한 회사에서 여러 프로덕션 애플리케이션을 호스팅합니다. 애플리케이션 중 하나는 여러 AWS 
리전에서 Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service(Amazon 
SNS) 및 Amazon Simple Queue Service(Amazon SQS)의 리소스로 구성됩니다. 모든 회사 
리소스에는 "응용 프로그램"이라는 태그 이름과 각 응용 프로그램에 해당하는 값이 태그로 
지정됩니다. 솔루션 설계자는 태그가 지정된 모든 구성 요소를 식별하기 위한 가장 빠른 솔루션을 
제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS CloudTrail 을 사용하여 애플리케이션 태그가 있는 리소스 목록을 생성합니다. 
B. AWS CLI 를 사용하여 모든 리전에서 각 서비스를 쿼리하여 태그가 지정된 구성 요소를 
보고합니다. 
C. Amazon CloudWatch Logs Insights 에서 쿼리를 실행하여 애플리케이션 태그가 있는 구성 
요소에 대해 보고합니다. 
D. AWS Resource Groups Tag Editor 로 쿼리를 실행하여 애플리케이션 태그를 사용하여 전역적으로 
리소스에 대해 보고합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95145-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
CloudTrail 은 주로 API 활동 캡처 및 로깅에 중점을 두기 때문에 A 는 가장 빠른 솔루션이 
아닙니다. 리소스 변경에 대한 정보를 제공할 수 있지만 여러 서비스 및 리전에서 태그가 지정된 
모든 구성 요소를 식별하는 포괄적이고 빠른 방법을 제공하지 않을 수 있습니다. 
B 에는 AWS CLI 를 사용하여 각 서비스를 수동으로 쿼리하는 작업이 포함되며, 이는 특히 여러 
서비스 및 리전을 처리할 때 시간이 많이 걸리고 번거로울 수 있습니다. 태그가 지정된 구성 
요소를 빠르게 식별하기 위한 가장 효율적인 솔루션은 아닙니다. 
C 는 태그가 지정된 구성 요소를 직접 식별하기보다는 로그 분석에 중점을 둡니다. CloudWatch 
Logs Insights 는 로그에서 정보를 추출하는 데 도움이 될 수 있지만 여러 서비스 및 리전에서 
태그가 지정된 모든 구성 요소의 통합 목록을 수집하는 간단하고 빠른 방법을 제공하지 않을 수 
있습니다. 
D 는 태그를 기반으로 리소스를 관리하고 구성하도록 특별히 설계된 Resource Groups Tag 
Editor 를 활용하므로 가장 빠른 솔루션입니다. 여러 서비스 및 리전에서 태그가 지정된 구성 
요소에 대한 보고서를 생성하는 중앙 집중식의 효율적인 접근 방식을 제공합니다. 
참고: 
https://docs.aws.amazon.com/tag-editor/latest/userguide/tagging.html 
Q212 
회사는 다른 팀이 액세스할 수 있도록 데이터베이스를 하루에 한 번 Amazon S3 로 내보내야 
합니다. 내보낸 개체 크기는 2GB 에서 5GB 사이입니다. 데이터에 대한 S3 액세스 패턴은 
가변적이며 빠르게 변경됩니다. 데이터는 즉시 사용할 수 있어야 하며 최대 3 개월 동안 액세스할 
수 있어야 합니다. 회사는 검색 시간을 늘리지 않는 가장 비용 효율적인 솔루션이 필요합니다. 
회사는 이러한 요구 사항을 충족하기 위해 어떤 S3 스토리지 클래스를 사용해야 합니까? 
A. S3 지능형 계층화(S3 Intelligent-Tiering) 
B. S3 Glacier 즉시 검색(S3 Glacier Instant Retrieval) 
C. S3 표준(S3 Standard) 
D. S3 Standard-Infrequent Access(S3 Standard-IA) 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95300-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
옵션 A 는 액세스 패턴이 변화하는 개체를 위해 설계되었지만 특히 액세스 패턴이 가변적이고 
빠르게 변경되는 경우 데이터의 장기 저장을 위한 가장 비용 효율적인 솔루션이 아닐 수 있습니다. 
옵션 B 는 장기 아카이브 저장에 최적화되어 있으며 회사에서 요구하는 즉각적인 액세스를 
제공하지 않을 수 있습니다. Glacier 스토리지에서 데이터를 검색하면 일반적으로 다른 스토리지 
클래스에 비해 검색 시간이 더 오래 걸립니다. 
옵션 C 는 즉각적인 가용성과 데이터에 대한 빠른 액세스를 위한 적절한 선택입니다. 높은 내구성, 
가용성 및 낮은 대기 시간 액세스를 제공하므로 회사의 요구 사항에 적합합니다. 그러나 장기 
보관을 위한 가장 비용 효율적인 옵션은 아닙니다. 
옵션 D 는 특히 자주 액세스하지 않는 데이터의 경우 S3 Standard 에 비해 비용 효율적인 스토리지 
클래스입니다. 그러나 데이터에 대한 액세스 패턴이 가변적이고 빠르게 변경되기 때문에 S3 
Standard-IA 는 빈번한 액세스에 대한 추가 검색 비용이 발생하므로 가장 비용 효율적인 솔루션이 
아닐 수 있습니다. 
Q213 
회사에서 새로운 모바일 앱을 개발하고 있습니다. 회사는 교차 사이트 스크립팅 또는 SQL 주입과 
같은 일반적인 애플리케이션 수준 공격으로부터 ALB(Application Load Balancer)를 보호하기 위해 
적절한 트래픽 필터링을 구현해야 합니다. 이 회사는 최소한의 인프라와 운영 인력을 보유하고 
있습니다. 회사는 AWS 환경의 서버를 관리, 업데이트 및 보호하는 책임을 줄여야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. AWS WAF 규칙을 구성하고 이를 ALB 와 연결합니다. 
B. 퍼블릭 호스팅이 활성화된 Amazon S3 를 사용하여 애플리케이션을 배포합니다. 
C. AWS Shield Advanced 를 배포하고 ALB 를 보호된 리소스로 추가합니다. 
D. 타사 방화벽을 실행하는 Amazon EC2 인스턴스로 트래픽을 보낸 다음 트래픽을 현재 ALB 로 
전달하는 새 ALB 를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95301-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
솔루션 설계자는 AWS WAF 규칙을 구성하고 이를 ALB 와 연결하는 옵션 A 를 권장해야 합니다. 
이를 통해 회사는 교차 사이트 스크립팅 또는 SQL 주입과 같은 일반적인 애플리케이션 수준 
공격으로부터 ALB 를 보호하는 데 필요한 애플리케이션 계층에서 트래픽 필터링을 적용할 수 
있습니다. AWS WAF 는 애플리케이션 가용성에 영향을 미치거나 보안을 손상시키거나 과도한 
리소스를 소비할 수 있는 일반적인 웹 익스플로잇으로부터 웹 애플리케이션을 쉽게 보호할 수 
있게 해주는 관리형 서비스입니다. 회사는 애플리케이션의 보안을 보장하기 위해 규칙을 쉽게 
관리하고 업데이트할 수 있습니다. 
설명 2: 
AWS WAF 규칙을 구성하고 이를 ALB 와 연결함으로써 회사는 악성 트래픽이 애플리케이션에 
도달하기 전에 필터링하고 차단할 수 있습니다. AWS WAF 는 사전 구성된 규칙 세트를 제공하고 
사용자 지정 규칙 생성을 허용하여 XSS 및 SQL 주입과 같은 일반적인 취약성으로부터 
보호합니다. 
옵션 B 는 애플리케이션 수준 공격으로부터 보호하는 데 필요한 보안 및 트래픽 필터링 기능을 
제공하지 않습니다. 보안 조치를 구현하는 것보다 정적 콘텐츠를 호스팅하는 데 더 적합합니다. 
옵션 C 는 XSS 또는 SQL 주입과 같은 애플리케이션 수준 공격이 아닌 DDoS 보호에 중점을 
둡니다. AWS Shield Advanced 는 시나리오에 언급된 특정 요구 사항을 다루지 않습니다. 
옵션 D 는 추가 인프라를 유지하고 보호하는 것과 관련되며, 이는 책임을 줄이고 최소한의 운영 
직원에 의존해야 한다는 요구 사항에 위배됩니다. 
Q214 
회사의 보고 시스템은 매일 수백 개의 .csv 파일을 Amazon S3 버킷에 전달합니다. 회사는 이러한 
파일을 Apache Parquet 형식으로 변환하고 변환된 데이터 버킷에 파일을 저장해야 합니다. 
최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Apache Spark 가 설치된 Amazon EMR 클러스터를 생성합니다. 데이터를 변환하는 Spark 
애플리케이션을 작성합니다. EMRFS(EMR 파일 시스템)를 사용하여 변환된 데이터 버킷에 파일을 
씁니다. 
B. AWS Glue 크롤러를 생성하여 데이터를 검색합니다. AWS Glue 추출, 변환 및 로드(ETL) 작업을 
생성하여 데이터를 변환합니다. 출력 단계에서 변환된 데이터 버킷을 지정합니다. 
C. AWS Batch 를 사용하여 Bash 구문으로 작업 정의를 생성하여 데이터를 변환하고 데이터를 
변환된 데이터 버킷으로 출력합니다. 작업 정의를 사용하여 작업을 제출합니다. 어레이 작업을 
작업 유형으로 지정합니다. 
D. 데이터를 변환하고 변환된 데이터 버킷으로 데이터를 출력하는 AWS Lambda 함수를 
생성합니다. S3 버킷에 대한 이벤트 알림을 구성합니다. 이벤트 알림의 대상으로 Lambda 함수를 
지정합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/95154-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS Glue 는 분석을 위해 데이터를 준비하고 변환하는 프로세스를 간소화하는 완전 관리형 ETL 
서비스입니다. AWS Glue 를 사용하려면 다른 옵션에 비해 최소한의 개발 노력이 필요합니다. 
옵션 A 는 데이터 변환을 위한 Spark 애플리케이션 작성과 관련되므로 더 많은 개발 노력이 
필요합니다. 또한 EMR 클러스터로 추가 인프라 관리를 소개합니다. 
옵션 C 는 데이터 변환을 위한 사용자 지정 Bash 스크립트를 작성하고 관리해야 합니다. 수동 
작업이 더 많이 필요하며 데이터 변환을 위한 AWS Glue 의 내장 기능을 제공하지 않습니다. 
옵션 D 는 데이터 변환을 위해 사용자 지정 Lambda 를 개발하고 관리해야 합니다. Lambda 는 
변환을 처리할 수 있지만 ETL 작업을 위해 특별히 설계된 AWS Glue 에 비해 더 많은 노력이 
필요합니다. 
따라서 옵션 B 는 AWS Glue 의 데이터 검색, 변환 및 변환된 데이터 버킷으로의 출력 기능을 
활용하여 가장 쉽고 최소한의 개발 노력을 제공합니다. 
참고: 
https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/patterns/three-aws-glue-etl-j
ob-types-for-converting-data-to-apache-parquet.html 
Q215 
회사는 데이터 센터의 NAS(Network Attached Storage)에 700TB 의 백업 데이터를 저장하고 
있습니다. 이 백업 데이터는 드문 규제 요청을 위해 액세스할 수 있어야 하며 7 년 동안 보관해야 
합니다. 회사는 이 백업 데이터를 데이터 센터에서 AWS 로 마이그레이션하기로 결정했습니다. 
마이그레이션은 1 개월 이내에 완료되어야 합니다. 회사는 데이터 전송에 사용할 수 있는 공용 
인터넷 연결에 500Mbps 의 전용 대역폭을 가지고 있습니다. 
최저 비용으로 데이터를 마이그레이션하고 저장하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 데이터를 전송할 AWS Snowball 디바이스를 주문합니다. 수명 주기 정책을 사용하여 파일을 
Amazon S3 Glacier Deep Archive 로 전환합니다. 
B. 데이터 센터와 Amazon VPC 간에 VPN 연결을 배포합니다. AWS CLI 를 사용하여 
온프레미스에서 Amazon S3 Glacier 로 데이터를 복사합니다. 
C. 500Mbps AWS Direct Connect 연결을 프로비저닝하고 데이터를 Amazon S3 로 전송합니다. 수명 
주기 정책을 사용하여 파일을 Amazon S3 Glacier Deep Archive 로 전환합니다. 
D. AWS DataSync 를 사용하여 데이터를 전송하고 온프레미스에 DataSync 에이전트를 배포합니다. 
DataSync 작업을 사용하여 온프레미스 NAS 스토리지에서 Amazon S3 Glacier 로 파일을 
복사합니다. 
Answer: A  
https://www.examtopics.com/discussions/amazon/view/94983-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
해설: 
700TB 나 되는 대용량을 Snowball Edge Device 를 사용하지 않고 네트워크 상으로 옮기는 것은 
굉장히 많은 시간이 소요됨. 
https://kindloveit.tistory.com/68 
https://www.omnicalculator.com/other/data-transfer 
Q216 
회사에는 Amazon S3 버킷에 수백만 개의 객체가 있는 서버리스 웹 사이트가 있습니다. 회사는 S3 
버킷을 Amazon CloudFront 배포의 오리진으로 사용합니다. 회사는 개체가 로드되기 전에 S3 
버킷에 암호화를 설정하지 않았습니다. 솔루션 설계자는 모든 기존 객체와 향후 S3 버킷에 
추가되는 모든 객체에 대해 암호화를 활성화해야 합니다. 
최소한의 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 새 S3 버킷을 생성합니다. 새 S3 버킷에 대한 기본 암호화 설정을 켭니다. 모든 기존 개체를 
임시 로컬 저장소에 다운로드합니다. 새 S3 버킷에 객체를 업로드합니다. 
B. S3 버킷의 기본 암호화 설정을 켭니다. S3 Inventory 기능을 사용하여 암호화되지 않은 객체를 
나열하는 .csv 파일을 생성합니다. 복사 명령을 사용하여 해당 객체를 암호화하는 S3 배치 작업 
작업을 실행합니다. 
C. AWS Key Management Service(AWS KMS)를 사용하여 새 암호화 키를 생성합니다. AWS KMS 
관리형 암호화 키(SSE-KMS)로 서버 측 암호화를 사용하도록 S3 버킷의 설정을 변경합니다. S3 
버킷에 대한 버전 관리를 켭니다. 
D. AWS Management Console 에서 Amazon S3 로 이동합니다. S3 버킷의 객체를 찾습니다. 암호화 
필드를 기준으로 정렬합니다. 암호화되지 않은 각 개체를 선택합니다. 수정 버튼을 사용하여 S3 
버킷의 모든 암호화되지 않은 객체에 기본 암호화 설정을 적용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/95040-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
S3 에서 기본 암호화 설정을 활성화하면 새로 추가된 모든 객체가 자동으로 암호화됩니다. 기존 
객체를 암호화하기 위해 S3 Inventory 기능을 사용하여 암호화되지 않은 객체 목록을 생성할 수 
있습니다. 그런 다음 암호화를 적용하는 동안 해당 객체를 복사하기 위해 S3 배치 작업 작업을 
실행할 수 있습니다. 
A. 이 솔루션에는 새 S3 를 생성하고 모든 기존 개체를 수동으로 다운로드 및 업로드하는 작업이 
포함됩니다. 수백만 개의 개체를 전송하는 데 상당한 노력과 시간이 필요하므로 효율성이 떨어지는 
솔루션입니다. 
C. AWS KMS 로 SSE 를 활성화하는 것은 S3 에서 객체를 암호화하는 유효한 접근 방식이지만 기존 
객체를 암호화해야 하는 요구 사항을 해결하지는 않습니다. 버킷에 추가된 새 객체에만 암호화를 
적용합니다. 
D. 기본 암호화 설정을 적용하기 위해 S3 의 각 개체를 수동으로 수정하는 것은 노동 집약적이고 
오류가 발생하기 쉬운 프로세스입니다. 암호화되지 않은 각 개체를 개별적으로 선택하고 수정해야 
하므로 많은 수의 개체에 비실용적입니다. 
참고: 
https://spin.atomicobject.com/2020/09/15/aws-s3-encrypt-existing-objects/ 
Q217 
회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 글로벌 웹 애플리케이션을 
실행합니다. 애플리케이션은 Amazon Aurora 에 데이터를 저장합니다. 회사는 재해 복구 솔루션을 
만들어야 하며 최대 30 분의 다운타임과 잠재적인 데이터 손실을 허용할 수 있습니다. 솔루션은 
기본 인프라가 정상일 때 부하를 처리할 필요가 없습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 필요한 인프라 요소가 있는 애플리케이션을 배치합니다. Amazon Route 53 을 사용하여 
활성-수동 장애 조치를 구성합니다. 두 번째 AWS 리전에서 Aurora 복제본을 생성합니다. 
B. 두 번째 AWS 리전에서 애플리케이션의 축소된 배포를 호스팅합니다. Amazon Route 53 을 
사용하여 활성-활성 장애 조치를 구성합니다. 두 번째 리전에서 Aurora 복제본을 생성합니다. 
C. 두 번째 AWS 리전에서 기본 인프라를 복제합니다. Amazon Route 53 을 사용하여 활성-활성 
장애 조치를 구성합니다. 최신 스냅샷에서 복원된 Aurora 데이터베이스를 생성합니다. 
D. AWS Backup 으로 데이터를 백업합니다. 백업을 사용하여 두 번째 AWS 리전에 필요한 인프라를 
생성합니다. Amazon Route 53 을 사용하여 활성-수동 장애 조치를 구성합니다. 두 번째 리전에서 
Aurora 두 번째 기본 인스턴스를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95015-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
솔루션은 기본 인프라가 정상일 때 부하를 처리할 필요가 없다고 했으므로 Active/Passive 
Failover 를 사용하면 됨. 따라서 A,D 둘 중 하나가 답. 
A(O) : Q: Amazon Aurora 는 교차 리전 복제를 지원하나요? 예. 물리적 또는 논리적 복제를 
사용하여 교차 리전 Aurora 복제본을 설정할 수 있습니다. Amazon RDS 콘솔에서 교차 리전 
복제본을 새로운 기본 복제본으로 승격할 수 있습니다. 논리적(binlog) 복제의 경우, 승격 
프로세스는 워크로드에 따라 다르지만 보통 몇 분 정도 걸립니다. 승격 프로세스를 시작하면 교차 
리전 복제가 중단됩니다. https://aws.amazon.com/ko/rds/aurora/faqs/ 
D(X) : 굳이 AWS Backup 을 사용하지 않아도 오로라 교차 리전 복제본 (Aurora Cross Region 
Replica)를 사용하면 됨. 그리고 글로벌 웹 애플리케이션을 사용한다고 했는데 이런 경우엔 
데이터를 복제해 인스턴스를 다른 리전에 생성하는 것보단 복제본을 사용해서 각 지역에서 읽기 
쿼리를 할 때 지연시간을 줄이는 것이 더 좋음. 
참고: 
https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html 
Q218 
회사에는 탄력적 IP 주소가 있는 퍼블릭 서브넷의 Amazon EC2 인스턴스에서 실행되는 웹 서버가 
있습니다. 기본 보안 그룹은 EC2 인스턴스에 할당됩니다. 모든 트래픽을 차단하도록 기본 
네트워크 ACL 이 수정되었습니다. 솔루션 설계자는 포트 443 을 통해 어디에서나 웹 서버에 
액세스할 수 있도록 해야 합니다. 
이 작업을 수행할 단계 조합은 무엇입니까? (2 개 선택) 
A. 소스 0.0.0.0/0 에서 TCP 포트 443 을 허용하는 규칙으로 보안 그룹을 생성합니다. 
B. 대상 0.0.0.0/0 에 대한 TCP 포트 443 을 허용하는 규칙으로 보안 그룹을 생성합니다. 
C. 소스 0.0.0.0/0 에서 TCP 포트 443 을 허용하도록 네트워크 ACL 을 업데이트합니다. 
D. 소스 0.0.0.0/0 에서 대상 0.0.0.0/0 으로 인바운드/아웃바운드 TCP 포트 443 을 허용하도록 
네트워크 ACL 을 업데이트합니다. 
E. 소스 0.0.0.0/0 에서 인바운드 TCP 포트 443 을 허용하고 대상 0.0.0.0/0 으로 아웃바운드 TCP 
포트 32768-65535 를 허용하도록 네트워크 ACL 을 업데이트합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/95056-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
포트 443 의 모든 위치에서 웹 서버에 액세스할 수 있도록 하는 작업을 수행하는 단계 조합은 소스 
0.0.0.0/0(A)에서 TCP 포트 443 을 허용하고 네트워크 ACL 을 업데이트하는 규칙으로 보안 그룹을 
생성하는 것입니다. 소스 0.0.0.0/0(C)에서 인바운드 TCP 포트 443 을 허용합니다. 
이렇게 하면 포트 443 에 대한 트래픽이 보안 그룹 수준과 네트워크 ACL 수준 모두에서 허용되어 
포트 443 의 모든 위치에서 웹 서버에 액세스할 수 있습니다. 
Q219 
회사의 애플리케이션에 성능 문제가 있습니다. 애플리케이션은 상태 저장이며 Amazon EC2 
인스턴스에서 인 메모리 작업을 완료해야 합니다. 이 회사는 AWS CloudFormation 을 사용하여 
인프라를 배포하고 M5 EC2 인스턴스 제품군을 사용했습니다. 트래픽이 증가함에 따라 
애플리케이션 성능이 저하되었습니다. 사용자는 사용자가 애플리케이션에 액세스하려고 할 때 
지연을 보고합니다. 
운영상 가장 효율적인 방식으로 이러한 문제를 해결하는 솔루션은 무엇입니까? 
A. Auto Scaling 그룹에서 실행되는 T3 EC2 인스턴스로 EC2 인스턴스를 교체합니다. AWS 
Management Console 을 사용하여 변경합니다. 
B. Auto Scaling 그룹에서 EC2 인스턴스를 실행하도록 CloudFormation 템플릿을 수정합니다. 
증가가 필요한 경우 Auto Scaling 그룹의 원하는 용량과 최대 용량을 수동으로 늘립니다. 
C. CloudFormation 템플릿을 수정합니다. EC2 인스턴스를 R5 EC2 인스턴스로 교체합니다. 
Amazon CloudWatch 내장 EC2 메모리 메트릭을 사용하여 향후 용량 계획을 위해 애플리케이션 
성능을 추적합니다. 
D. CloudFormation 템플릿을 수정합니다. EC2 인스턴스를 R5 EC2 인스턴스로 교체합니다. EC2 
인스턴스에 Amazon CloudWatch 에이전트를 배포하여 향후 용량 계획을 위한 사용자 지정 
애플리케이션 지연 시간 메트릭을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95162-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
M5 인스턴스를 메모리 집약적인 워크로드에 최적화된 R5 인스턴스로 교체하면 애플리케이션에서 
메모리 용량과 성능을 높일 수 있습니다. 
또한 EC2 인스턴스에 CloudWatch 에이전트를 배포하면 애플리케이션 성능에 대한 중요한 
통찰력을 제공할 수 있는 사용자 지정 애플리케이션 대기 시간 메트릭을 생성할 수 있습니다. 
이 솔루션은 적절한 인스턴스 유형을 활용하고 더 나은 모니터링 및 향후 용량 계획을 위해 
사용자 지정 애플리케이션 메트릭을 수집하여 성능 문제를 효율적으로 해결합니다. 
A. T3 인스턴스로 교체하면 인 메모리 작업에 충분한 메모리 용량을 제공하지 못할 수 있습니다. 
B. ASG 의 용량을 수동으로 늘리면 성능 문제가 직접적으로 해결되지 않습니다. 
C. 내장된 EC2 메모리 메트릭에만 의존하면 메모리 내 작업을 최적화하는 데 충분한 세분성을 
제공하지 못할 수 있습니다. 
가장 효율적인 솔루션은 CloudFormation 템플릿을 수정하고, R5 인스턴스로 교체하고, 사용자 
지정 메트릭을 위해 CloudWatch 에이전트를 배포하는 것입니다. 
Q220 
솔루션 설계자는 Amazon API Gateway 를 사용하여 사용자의 요청을 수신할 새 API 를 설계하고 
있습니다. 요청량은 매우 다양합니다. 단일 요청을 받지 않고 몇 시간이 지날 수 있습니다. 데이터 
처리는 비동기식으로 이루어지지만 요청이 이루어진 후 몇 초 이내에 완료되어야 합니다. 
최저 비용으로 요구 사항을 제공하기 위해 솔루션 설계자가 API 를 호출하도록 해야 하는 컴퓨팅 
서비스는 무엇입니까? 
A. AWS Glue 작업 
B. AWS Lambda 함수 
C. Amazon Elastic Kubernetes Service(Amazon EKS)에서 호스팅되는 컨테이너화된 서비스 
D. Amazon EC2 와 함께 Amazon ECS 에서 호스팅되는 컨테이너화된 서비스 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/95306-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
API Gateway + Lambda 는 서버리스 아키텍처를 사용하는 최신 애플리케이션을 위한 완벽한 
솔루션입니다. 
설명 2: 
Lambda 는 요청을 비동기식으로 처리하기 위해 API Gateway 에서 트리거할 수 있는 서버리스 
컴퓨팅 서비스입니다. 들어오는 요청 볼륨에 따라 자동으로 확장되며 요청을 처리하는 데 사용된 
실제 컴퓨팅 시간에 대해서만 요금을 부과하여 비용 최적화를 허용합니다. 
A. Glue 는 완전히 관리되는 ETL 서비스입니다. API 요청을 제공하는 대신 데이터 처리 및 변환 
작업을 위해 설계되었습니다. 가변적인 요청량을 처리하고 몇 초 내에 응답을 전달하는 데 
적합하지 않을 수 있습니다. 
C. EKS 는 확장성과 유연성을 제공하지만 가변적인 API 요청 볼륨을 처리하기 위해 인프라를 
관리하고 확장하는 데 추가적인 복잡성과 오버헤드가 발생할 수 있습니다. 
D. 이전 옵션과 마찬가지로 EC2 와 함께 ECS 를 사용하려면 인프라 관리 및 확장을 위한 추가 
노력이 필요하며, 이는 간헐적이고 가변적인 API 요청 볼륨을 처리하는 데 필요하지 않을 수 
있습니다. 
Q221 
회사는 Amazon Linux EC2 인스턴스 그룹에서 애플리케이션을 실행합니다. 규정 준수를 위해 
회사는 모든 애플리케이션 로그 파일을 7 년 동안 보관해야 합니다. 로그 파일은 모든 파일에 
동시에 액세스할 수 있어야 하는 보고 도구로 분석됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까? 
A. Amazon Elastic Block Store(Amazon EBS) 
B. Amazon Elastic File System(Amazon EFS) 
C. Amazon EC2 인스턴스 스토어 
D. Amazon S3 
Answer: D  
https://www.examtopics.com/discussions/amazon/view/95307-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. EBS 는 EC2 인스턴스와 함께 사용할 블록 수준 스토리지 볼륨을 제공합니다. 내구성과 
지속성을 제공하지만 로그 파일의 장기 보존을 위한 가장 비용 효율적인 솔루션은 아닙니다. 또한 
이 시나리오의 요구 사항인 파일에 대한 동시 액세스를 제공하지 않습니다. 
B. EFS 는 여러 EC2 인스턴스에 동시에 탑재할 수 있는 확장 가능한 파일 스토리지 서비스입니다. 
파일에 대한 동시 액세스를 제공하지만 S3 에 비해 가격이 높기 때문에 장기 보존을 위한 가장 
비용 효율적인 옵션이 아닐 수 있습니다. 
C. 인스턴스 스토어는 EC2 인스턴스에 물리적으로 연결된 임시 스토리지 옵션입니다. 규정 준수 
목적에 필요한 내구성 및 장기 보존을 제공하지 않습니다. 또한 인스턴스 스토어는 연결된 특정 
EC2 인스턴스 외부에서 액세스할 수 없으므로 보고 도구를 통한 동시 액세스가 불가능합니다. 
따라서 장기보존, 동시접속, 가성비 등의 요구사항을 고려할 때 S3 가 가장 적합하고 가성비 좋은 
스토리지 솔루션입니다. 
참고: 
https://docs.aws.amazon.com/efs/latest/ug/transfer-data-to-efs.html 
Q222 
회사는 회사의 AWS 계정에서 작업을 수행하기 위해 외부 공급업체를 고용했습니다. 벤더는 
벤더가 소유한 AWS 계정에서 호스팅되는 자동화 도구를 사용합니다. 벤더는 회사의 AWS 계정에 
대한 IAM 액세스 권한이 없습니다. 
솔루션 설계자는 공급업체에 이 액세스 권한을 어떻게 부여해야 합니까? 
A. 공급업체의 IAM 역할에 대한 액세스 권한을 위임하려면 회사 계정에서 IAM 역할을 생성합니다. 
벤더가 요구하는 권한에 대한 역할에 적절한 IAM 정책을 연결합니다. 
B. 암호 복잡성 요구 사항을 충족하는 암호를 사용하여 회사 계정에 IAM 사용자를 만듭니다. 
벤더가 요구하는 권한에 대해 적절한 IAM 정책을 사용자에게 연결합니다. 
C. 회사 계정에 IAM 그룹을 생성합니다. 공급업체 계정의 도구 IAM 사용자를 그룹에 추가합니다. 
공급업체에 필요한 권한에 대해 적절한 IAM 정책을 그룹에 연결합니다. 
D. IAM 콘솔에서 공급자 유형으로 "AWS 계정"을 선택하여 새 자격 증명 공급자를 만듭니다. 
공급업체의 AWS 계정 ID 와 사용자 이름을 제공합니다. 벤더가 요구하는 권한에 대해 적절한 IAM 
정책을 새 제공자에 연결하십시오. 
Answer: A  
https://www.examtopics.com/discussions/amazon/view/95160-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명:  
IAM 역할을 생성하고 공급업체의 IAM 역할에 대한 액세스 권한을 위임함으로써 계정 간에 신뢰 
관계를 설정합니다. 이렇게 하면 공급업체의 자동화 도구가 회사 계정의 역할을 맡고 필요한 
리소스에 액세스할 수 있습니다. 
적절한 IAM 정책을 역할에 연결하면 해당 도구가 작업을 수행하는 데 벤더가 요구하는 정확한 
권한을 정의할 수 있습니다. 이렇게 하면 공급업체가 회사 계정에 대한 직접적인 IAM 액세스 
권한을 부여하지 않고도 필요한 액세스 권한을 가질 수 있습니다. 
B 는 암호가 있는 IAM 사용자를 생성하려면 벤더와 자격 증명을 공유해야 하므로 보안상의 이유로 
권장되지 않습니다. 
공급업체의 IAM 사용자를 회사 계정의 IAM 그룹에 추가하면 공급업체 도구에 대한 액세스를 
위임하는 직접적이고 통제된 방법을 제공하지 않기 때문에 C 는 올바르지 않습니다. 
공급업체의 AWS 계정에 대한 새 자격 증명 공급자를 생성하면 공급업체 도구에 대한 액세스 
권한을 위임하는 간단한 방법이 제공되지 않기 때문에 D 는 틀렸습니다. ID 공급자는 일반적으로 
외부 ID 시스템을 사용하는 연합 액세스에 사용됩니다. 
참고: 
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_third-party.ht
ml 
Q223 
한 회사에서 Java Spring Boot 애플리케이션을 프라이빗 서브넷의 Amazon Elastic Kubernetes 
Service(Amazon EKS)에서 실행되는 포드로 배포했습니다. 애플리케이션은 Amazon DynamoDB 
테이블에 데이터를 써야 합니다. 솔루션 설계자는 애플리케이션이 인터넷에 트래픽을 노출하지 
않고 DynamoDB 테이블과 상호 작용할 수 있는지 확인해야 합니다. 
이 목표를 달성하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (2 개 선택) 
A. EKS 포드에 충분한 권한이 있는 IAM 역할을 연결합니다. 
B. EKS 포드에 충분한 권한이 있는 IAM 사용자를 연결합니다. 
C. 프라이빗 서브넷의 네트워크 ACL 을 통해 DynamoDB 테이블에 대한 아웃바운드 연결을 
허용합니다. 
D. DynamoDB 용 VPC 엔드포인트를 생성합니다. 
E. Java Spring Boot 코드에 액세스 키를 삽입합니다. 
Answer: A, D  
https://www.examtopics.com/discussions/amazon/view/95310-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. IAM 역할을 EKS 포드에 연결하면 포드가 DynamoDB 에 액세스하는 데 필요한 권한을 부여할 
수 있습니다. IAM 역할에는 DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책이 있어야 
합니다. 
D. DynamoDB 용 VPC 엔드포인트를 생성하면 EKS 포드가 인터넷 연결 없이도 VPC 내에서 
비공개로 DynamoDB 에 액세스할 수 있습니다. VPC 엔드포인트는 DynamoDB 에 대한 직접적이고 
안전한 연결을 제공하므로 트래픽이 인터넷을 통해 흐를 필요가 없습니다. 
B 는 IAM 사용자를 포드에 연결하는 것이 권장되는 접근 방식이 아니기 때문에 올바르지 않습니다. 
IAM 사용자는 AWS Management Console 또는 AP 를 통해 AWS 서비스에 액세스하기 위한 
것입니다. 
네트워크 ACL 을 통한 아웃바운드 연결 구성은 DynamoDB 에 대한 안전하고 직접적인 연결을 
제공하지 않기 때문에 C 는 올바르지 않습니다. 
코드에 액세스 키를 포함하는 것은 권장되는 보안 방법이 아니기 때문에 E 는 올바르지 않습니다. 
잠재적인 보안 취약성이 발생할 수 있습니다. AWS 서비스에 대한 액세스를 제공하기 위해 IAM 
역할 또는 기타 보안 메커니즘을 사용하는 것이 좋습니다. 
참고 
https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/vpc-endpoints-dy
namodb.html 
https://aws.amazon.com/ko/about-aws/whats-new/2019/09/amazon-eks-adds-support-to-ass
ign-iam-permissions-to-kubernetes-service-accounts/ 
Q224 
한 회사가 최근 단일 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 다시 호스팅하여 웹 
애플리케이션을 AWS 로 마이그레이션했습니다. 이 회사는 응용 프로그램 아키텍처를 고가용성 및 
내결함성을 갖도록 재설계하려고 합니다. 트래픽은 실행 중인 모든 EC2 인스턴스에 무작위로 
도달해야 합니다. 
회사는 이러한 요구 사항을 충족하기 위해 어떤 조합의 단계를 수행해야 합니까? (2 개 선택) 
A. Amazon Route 53 장애 조치 라우팅 정책을 만듭니다. 
B. Amazon Route 53 가중 라우팅 정책을 생성합니다. 
C. Amazon Route 53 다중값 응답 라우팅 정책을 생성합니다. 
D. 3 개의 EC2 인스턴스를 시작합니다. 하나의 가용 영역에 있는 2 개의 인스턴스와 다른 가용 
영역에 있는 하나의 인스턴스입니다. 
E. 4 개의 EC2 인스턴스를 시작합니다. 하나의 가용 영역에 2 개의 인스턴스와 다른 가용 영역에 
2 개의 인스턴스가 있습니다. 
Answer: C, E 
https://www.examtopics.com/discussions/amazon/view/95311-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
C. Route 53 의 다중 응답 라우팅 정책을 사용하면 DNS 레코드에 대한 다중 값을 구성할 수 
있으며 Route 53 은 다중 임의 값으로 DNS 쿼리에 응답합니다. 이를 통해 사용 가능한 EC2 
인스턴스 간에 트래픽을 무작위로 분산할 수 있습니다. 
E. 다른 AZ 에서 EC2 인스턴스를 시작하면 고가용성과 내결함성을 얻을 수 있습니다. 4 개의 
인스턴스(각 AZ 에 2 개)를 시작하면 트래픽 로드를 처리하고 원하는 수준의 가용성을 유지하기에 
충분한 리소스가 있습니다. 
A. 장애 조치 라우팅은 기본 리소스 또는 위치를 사용할 수 없는 경우에만 트래픽을 백업 리소스 
또는 보조 위치로 보내도록 설계되었습니다. 
B. 가중 라우팅 정책을 사용하면 여러 EC2 인스턴스에 트래픽을 분산할 수 있지만 무작위 분산이 
보장되지는 않습니다. 
D. 여러 AZ 에서 인스턴스를 시작하는 것은 내결함성을 위해 중요하지만 세 개의 인스턴스만 
있으면 트래픽이 고르게 분산되지 않습니다. 인스턴스가 3 개뿐이면 트래픽이 고르게 분산되지 
않아 리소스 활용이 불균형해질 수 있습니다. 
참고 
https://aws.amazon.com/premiumsupport/knowledge-center/multivalue-versus-simple-policies/ 
Q225 
미디어 회사는 온프레미스에서 사용자 활동 데이터를 수집하고 분석합니다. 회사는 이 기능을 
AWS 로 마이그레이션하려고 합니다. 사용자 활동 데이터 저장소는 계속해서 성장하여 크기가 
페타바이트가 될 것입니다. 회사는 SQL 을 사용하여 기존 데이터 및 새 데이터의 온디맨드 분석을 
용이하게 하는 고가용성 데이터 수집 솔루션을 구축해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 활동 데이터를 Amazon Kinesis 데이터 스트림으로 보냅니다. 데이터를 Amazon S3 버킷으로 
전달하도록 스트림을 구성합니다. 
B. 활동 데이터를 Amazon Kinesis Data Firehose 전송 스트림으로 보냅니다. 데이터를 Amazon 
Redshift 클러스터로 전달하도록 스트림을 구성합니다. 
C. 활동 데이터를 Amazon S3 버킷에 배치합니다. 데이터가 S3 버킷에 도착하면 데이터에서 AWS 
Lambda 함수를 실행하도록 Amazon S3 를 구성합니다. 
D. 여러 가용 영역에 분산된 Amazon EC2 인스턴스에서 수집 서비스를 생성합니다. 데이터를 
Amazon RDS 다중 AZ 데이터베이스로 전달하도록 서비스를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/94985-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Amazon Redshift 는 클라우드에서 완벽하게 관리되는 페타바이트 규모의 데이터 웨어하우스 
서비스입니다. 수백 기가바이트의 데이터로 시작하여 페타바이트 이상으로 확장할 수 있습니다. 
이를 통해 데이터를 사용하여 비즈니스와 고객에 대한 새로운 통찰력을 얻을 수 있습니다. 데이터 
웨어하우스를 생성하는 첫 번째 단계는 Amazon Redshift 클러스터라는 노드 집합을 시작하는 
것입니다. 클러스터를 프로비저닝한 후 데이터 세트를 업로드한 다음 데이터 분석 쿼리를 수행할 
수 있습니다. 데이터 세트의 크기에 관계없이 Amazon Redshift 는 오늘날 사용하는 것과 동일한 
SQL 기반 도구 및 비즈니스 인텔리전스 애플리케이션을 사용하여 빠른 쿼리 성능을 제공합니다. 
설명 2: 
B 는 데이터 수집 및 분석을 위한 완전히 관리되고 확장 가능한 솔루션을 제공합니다. KDF 는 
대량의 스트리밍 데이터를 처리하도록 자동으로 확장하여 데이터 수집 프로세스를 간소화합니다. 
강력하고 완전히 관리되는 데이터 웨어하우징 솔루션인 Redshift 클러스터에 데이터를 직접 로드할 
수 있습니다. 
A. Kinesis 는 스트리밍 데이터를 처리할 수 있지만 분석 솔루션에 데이터를 로드하려면 추가 
처리가 필요합니다. 
C. S3 및 Lambda 가 데이터 저장 및 처리를 처리할 수 있지만 KDF 및 Redshift 가 제공하는 
완전관리형 솔루션에 비해 수동 구성 및 관리가 더 많이 필요합니다. 
D. 이 옵션은 EC2 인스턴스 및 RDS 데이터베이스 인프라를 수동으로 관리하고 확장해야 하므로 
더 많은 운영 오버헤드가 필요합니다. 
따라서 Redshift 클러스터에 데이터를 제공하는 KDF 가 포함된 옵션 B 는 주어진 시나리오에서 
사용자 활동 데이터를 수집하고 분석하기 위한 가장 간소화되고 운영상 효율적인 솔루션을 
제공합니다. 
Q226 
회사는 Amazon EC2 인스턴스에서 실행되는 RESTful 웹 서비스 애플리케이션을 사용하여 수천 
개의 원격 장치에서 데이터를 수집합니다. EC2 인스턴스는 원시 데이터를 수신하고 원시 데이터를 
변환하며 모든 데이터를 Amazon S3 버킷에 저장합니다. 원격 장치의 수는 곧 수백만 개로 증가할 
것입니다. 이 회사는 운영 오버헤드를 최소화하는 확장성이 뛰어난 솔루션이 필요합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (2 개 
선택) 
A. AWS Glue 를 사용하여 Amazon S3 에서 원시 데이터를 처리합니다. 
B. Amazon Route 53 을 사용하여 트래픽을 다른 EC2 인스턴스로 라우팅합니다. 
C. 들어오는 데이터의 양을 수용하기 위해 더 많은 EC2 인스턴스를 추가합니다. 
D. 원시 데이터를 Amazon Simple Queue Service(Amazon SQS)로 보냅니다. EC2 인스턴스를 
사용하여 데이터를 처리합니다. 
E. Amazon API Gateway 를 사용하여 원시 데이터를 Amazon Kinesis 데이터 스트림으로 보냅니다. 
데이터 스트림을 소스로 사용하여 데이터를 Amazon S3 에 전달하도록 Amazon Kinesis Data 
Firehose 를 구성합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/95312-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
"RESTful 웹 서비스" => API 게이트웨이. 
"EC2 인스턴스는 원시 데이터를 수신하고, 원시 데이터를 변환하고, 모든 데이터를 Amazon S3 
버킷에 저장합니다." 
=> (Extract - Transform - Load)가 있는 GLUE 
설명 2: 
A. 데이터의 스키마를 자동으로 발견하고 ETL 코드를 생성하여 변환합니다. 
E. API Gateway 는 RESTful 웹 서비스를 통해 원격 장치에서 원시 데이터를 수신하는 데 사용할 수 
있습니다. 들어오는 요청을 처리하기 위해 확장 가능하고 관리되는 인프라를 제공합니다. 그런 
다음 데이터를 확장성과 내구성이 뛰어난 실시간 데이터 스트리밍 서비스인 Amazon Kinesis 
데이터 스트림으로 보낼 수 있습니다. 여기에서 데이터 스트림을 소스로 사용하고 변환된 데이터를 
Amazon S3 에 전달하도록 Amazon Kinesis Data Firehose 를 구성할 수 있습니다. 이러한 서비스 
조합을 통해 운영 오버헤드를 최소화하면서 원활한 데이터 수집 및 처리가 가능합니다. 
B. 확장 가능한 데이터 처리 및 저장의 필요성을 직접적으로 다루지는 않습니다. DNS 관리 및 
트래픽을 다른 끝점으로 라우팅하는 데 중점을 둡니다. 
C. 더 많은 EC2 를 추가하면 인스턴스 관리 및 확장 측면에서 운영 오버헤드가 증가할 수 
있습니다. 
D. 데이터 처리에 SQS 및 EC2 를 사용하면 더 복잡해지고 운영 오버헤드가 발생합니다. 
Q227 
회사는 AWS CloudTrail 로그를 3 년 동안 보관해야 합니다. 회사는 상위 계정의 AWS 
Organizations 를 사용하여 AWS 계정 집합에 CloudTrail 을 적용하고 있습니다. CloudTrail 대상 S3 
버킷은 S3 버전 관리가 활성화된 상태로 구성됩니다. 3 년 후 현재 객체를 삭제하는 S3 수명 주기 
정책이 있습니다. 
S3 버킷 사용 4 년차 이후 S3 버킷 지표는 개체 수가 계속 증가했음을 보여줍니다. 그러나 S3 
버킷에 전달되는 새 CloudTrail 로그의 수는 일관되게 유지되었습니다. 
가장 비용 효율적인 방식으로 3 년 이상 된 개체를 삭제하는 솔루션은 무엇입니까? 
A. 3 년 후에 개체가 만료되도록 조직의 중앙 집중식 CloudTrail 추적을 구성합니다. 
B. 현재 버전뿐만 아니라 이전 버전도 삭제하도록 S3 수명 주기 정책을 구성합니다. 
C. Amazon S3 에서 3 년 이상 된 객체를 열거하고 삭제하는 AWS Lambda 함수를 생성합니다. 
D. 상위 계정을 S3 버킷으로 전달되는 모든 객체의 소유자로 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/95314-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이전 버전과 현재 버전을 삭제하도록 S3 수명 주기 정책을 구성하면 이전 버전의 CloudTrail 
로그가 삭제됩니다. 이렇게 하면 3 년 이상 된 객체가 S3 버킷에서 제거되어 객체 수를 줄이고 
스토리지 비용을 제어할 수 있습니다. 
A. 이 옵션은 S3 의 개체 관리와 직접적인 관련이 없습니다. S3 버킷에서 객체를 삭제해야 하는 
필요성을 해결하지 못할 수 있는 CloudTrail 추적 만료 구성에 중점을 둡니다. 
C. Lambda를 생성하여 3년 이상 된 객체를 삭제하는 것은 기술적으로 가능하지만 이 접근 방식은 
복잡성과 운영 오버헤드를 추가로 도입합니다. 
D. S3 버킷에 있는 객체의 소유권을 변경해도 3 년 이상 된 객체를 삭제해야 하는 필요성이 
직접적으로 해결되지는 않습니다. 소유권은 개체의 삭제 동작에 영향을 주지 않습니다. 
참고: 
https://docs.aws.amazon.com/ko_kr/awscloudtrail/latest/userguide/best-practices-security.html 
Q228 
회사에는 여러 모니터링 장치에서 실시간 데이터를 수신하는 API 가 있습니다. API 는 나중에 
분석할 수 있도록 이 데이터를 Amazon RDS DB 인스턴스에 저장합니다. 모니터링 장치가 API 로 
보내는 데이터의 양은 변동합니다. 트래픽이 많은 기간 동안 API 는 종종 시간 초과 오류를 
반환합니다. 
로그를 검사한 후 회사는 데이터베이스가 API 에서 오는 쓰기 트래픽 볼륨을 처리할 수 없음을 
확인합니다. 솔루션 설계자는 데이터베이스에 대한 연결 수를 최소화하고 트래픽이 많은 기간 동안 
데이터가 손실되지 않도록 해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 사용 가능한 메모리가 더 많은 인스턴스 유형으로 DB 인스턴스의 크기를 늘리십시오. 
B. DB 인스턴스를 다중 AZ DB 인스턴스로 수정합니다. 모든 활성 RDS DB 인스턴스에 쓰도록 
애플리케이션을 구성합니다. 
C. 수신 데이터를 Amazon Simple Queue Service(Amazon SQS) 대기열에 쓰도록 API 를 
수정합니다. Amazon SQS 가 호출하는 AWS Lambda 함수를 사용하여 대기열에서 데이터베이스로 
데이터를 씁니다. 
D. 수신 데이터를 Amazon Simple Notification Service(Amazon SNS) 주제에 쓰도록 API 를 
수정합니다. Amazon SNS 가 호출하는 AWS Lambda 함수를 사용하여 주제에서 데이터베이스로 
데이터를 씁니다. 
Answer: C  
https://www.examtopics.com/discussions/amazon/view/95318-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
Amazon SQS 를 사용하면 API 가 데이터를 데이터베이스에 직접 쓰지 않고 대기열에 쓰기 때문에 
데이터베이스에 대한 연결 수를 최소화하는 데 도움이 됩니다. 또한 대기열에서 데이터베이스로 
데이터를 쓰기 위해 Amazon SQS 가 호출하는 AWS Lambda 함수를 사용하면 대기열이 API 와 
데이터베이스 사이에서 버퍼 역할을 하므로 트래픽이 많은 기간 동안 데이터가 손실되지 않도록 
하는 데 도움이 됩니다. 
설명 2: 
SQS 를 버퍼로 활용하고 Lambda 를 사용하여 큐에서 데이터베이스로 데이터를 처리하고 
기록함으로써 이 솔루션은 데이터베이스에 대한 연결 수를 최소화하면서 확장성, 분리 및 안정성을 
제공합니다. 이 접근 방식은 트래픽 변동을 처리하고 트래픽이 많은 기간 동안 데이터 무결성을 
보장합니다. 
A. DB 인스턴스의 크기를 늘리면 더 많은 메모리를 제공할 수 있지만 높은 쓰기 트래픽을 
효율적으로 처리하고 데이터베이스에 대한 연결을 최소화하는 문제는 해결되지 않습니다. 
B. DB 인스턴스를 다중 AZ 인스턴스로 수정하고 모든 활성 인스턴스에 쓰면 가용성이 향상될 수 
있지만 높은 쓰기 트래픽을 효율적으로 처리하고 데이터베이스에 대한 연결을 최소화하는 문제는 
해결되지 않습니다. 
D. SNS 와 Lambda 를 사용하면 디커플링과 확장성을 제공할 수 있지만 많은 쓰기 트래픽을 
효율적으로 처리하고 데이터베이스에 대한 연결을 최소화하는 데 적합하지 않습니다. 
Q229 
회사는 MySQL 데이터베이스를 실행하는 자체 Amazon EC2 인스턴스를 관리합니다. 회사는 
수요가 증가하거나 감소함에 따라 복제 및 확장을 수동으로 관리하고 있습니다. 회사는 필요에 
따라 데이터베이스 계층에서 컴퓨팅 용량을 추가하거나 제거하는 프로세스를 간소화하는 새로운 
솔루션이 필요합니다. 또한 솔루션은 최소한의 운영 노력으로 향상된 성능, 확장성 및 내구성을 
제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터베이스를 Aurora MySQL 용 Amazon Aurora Serverless 로 마이그레이션합니다. 
B. 데이터베이스를 Aurora PostgreSQL 용 Amazon Aurora Serverless 로 마이그레이션합니다. 
C. 데이터베이스를 하나의 더 큰 MySQL 데이터베이스로 결합합니다. 더 큰 EC2 인스턴스에서 더 
큰 데이터베이스를 실행합니다. 
D. 데이터베이스 계층에 대한 EC2 Auto Scaling 그룹을 생성합니다. 기존 데이터베이스를 새 
환경으로 마이그레이션합니다. 
Answer: A  
https://www.examtopics.com/discussions/amazon/view/95319-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
데이터베이스를 Aurora Serverless 로 마이그레이션하면 자동 조정 및 복제 기능이 제공됩니다. 
Aurora Serverless 는 워크로드에 따라 자동으로 용량을 조정하므로 필요에 따라 컴퓨팅 용량을 
원활하게 추가하거나 제거할 수 있습니다. 또한 복제 및 확장을 수동으로 관리할 필요 없이 향상된 
성능, 내구성 및 고가용성을 제공합니다. 
B. 호환성 문제가 발생할 수 있고 중요한 코드 수정이 필요할 수 있는 다른 데이터베이스 
엔진으로의 마이그레이션을 제안하기 때문에 올바르지 않습니다. 
C. 더 큰 EC2 인스턴스에서 더 큰 MySQL 데이터베이스로 통합하면 원하는 확장성과 자동화가 
제공되지 않기 때문에 올바르지 않습니다. 
D. 데이터베이스 계층에 대해 EC2 Auto Scaling 그룹을 사용하려면 여전히 복제 및 조정을 
수동으로 관리해야 하기 때문에 올바르지 않습니다. 
참고: 
https://aws.amazon.com/rds/aurora/serverless/ 
Q230 
회사는 사용 중인 두 개의 NAT 인스턴스가 더 이상 회사 애플리케이션에 필요한 트래픽을 지원할 
수 없을 것이라고 우려합니다. 솔루션 설계자는 가용성이 높고 내결함성이 있으며 자동으로 확장 
가능한 솔루션을 구현하려고 합니다. 
솔루션 설계자는 무엇을 추천해야 합니까? 
A. 2 개의 NAT 인스턴스를 제거하고 동일한 가용 영역에 있는 2 개의 NAT 게이트웨이로 
교체합니다. 
B. 다른 가용 영역의 NAT 인스턴스에 대해 Network Load Balancer 와 함께 Auto Scaling 그룹을 
사용합니다. 
C. 2 개의 NAT 인스턴스를 제거하고 서로 다른 가용 영역에 있는 2 개의 NAT 게이트웨이로 
교체합니다. 
D. 두 개의 NAT 인스턴스를 서로 다른 가용 영역의 스팟 인스턴스로 교체하고 Network Load 
Balancer 를 배포합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95322-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
여러 가용 영역에 리소스가 있고 하나의 NAT 게이트웨이를 공유하는 경우 NAT 게이트웨이의 가용 
영역이 다운되면 다른 가용 영역의 리소스가 인터넷에 액세스할 수 없게 됩니다. 가용 영역 독립적 
아키텍처를 생성하려면 각 가용 영역에 NAT 게이트웨이를 생성하고 리소스가 동일한 가용 
영역에서 NAT 게이트웨이를 사용하도록 라우팅을 구성합니다. 
https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html#nat-gateway-basics 
설명 2: 
이 권장 사항은 NAT 게이트웨이를 여러 AZ 에 분산하여 고가용성과 내결함성을 보장합니다. NAT 
게이트웨이는 확장 가능하고 가용성이 높은 아웃바운드 NAT 기능을 제공하는 관리형 AWS 
서비스입니다. 서로 다른 AZ 에 NAT 게이트웨이를 배포함으로써 회사는 중복성을 확보하고 단일 
장애 지점을 방지할 수 있습니다. 또한 이 솔루션은 수동 개입 없이 증가하는 트래픽을 처리할 수 
있는 자동 크기 조정을 제공합니다. 
두 NAT 게이트웨이를 동일한 가용 영역에 배치하면 내결함성이 제공되지 않으므로 옵션 A 는 
올바르지 않습니다. 
옵션 B 는 Network Load Balancer 와 함께 Auto Scaling 그룹을 사용하는 것이 NAT 인스턴스에 
권장되는 접근 방식이 아니기 때문에 올바르지 않습니다. 
옵션 D 는 스팟 인스턴스가 NAT 인스턴스와 같은 중요한 인프라 구성 요소에 적합하지 않기 
때문에 올바르지 않습니다. 
Q231 
애플리케이션은 VPC A 에 탄력적 IP 주소가 있는 Amazon EC2 인스턴스에서 실행됩니다. 
애플리케이션은 VPC B 의 데이터베이스에 액세스해야 합니다. 두 VPC 모두 동일한 AWS 계정에 
있습니다. 
필요한 액세스를 가장 안전하게 제공하는 솔루션은 무엇입니까? 
A. VPC A 에 있는 애플리케이션 서버의 퍼블릭 IP 주소에서 오는 모든 트래픽을 허용하는 DB 
인스턴스 보안 그룹을 생성합니다. 
B. VPC A 와 VPC B 사이에 VPC 피어링 연결을 구성합니다. 
C. DB 인스턴스를 공개적으로 액세스할 수 있도록 합니다. 퍼블릭 IP 주소를 DB 인스턴스에 
할당합니다. 
D. 탄력적 IP 주소가 있는 EC2 인스턴스를 VPC B 로 시작합니다. 새 EC2 인스턴스를 통해 모든 
요청을 프록시합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/95323-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
VPC 피어링 연결은 사용자가 프라이빗 IP 주소를 사용하여 트래픽을 라우팅할 수 있도록 하는 두 
VPC 간의 네트워킹 연결입니다. 각 VPC 의 인스턴스는 마치 동일한 네트워크 내에 있는 것처럼 
서로 통신할 수 있습니다. VPC 피어링 연결은 같거나 다른 AWS 계정과 Regions1 의 VPC 간에 
생성할 수 있습니다. 솔루션은 VPC A 와 VPC B 간에 VPC 피어링 연결을 구성하여 필요한 
액세스를 가장 안전하게 제공할 수 있습니다. 
1. VPC A 에 있는 애플리케이션 서버의 퍼블릭 IP 주소에서 오는 모든 트래픽을 허용하는 DB 
인스턴스 보안 그룹을 생성합니다. 이 솔루션은 DB 인스턴스를 퍼블릭 인터넷에 노출하고 액세스 
제어를 위한 단일 IP 주소. 
2. DB 인스턴스를 공개적으로 액세스할 수 있도록 합니다. 퍼블릭 IP 주소를 DB 인스턴스에 
할당합니다. 이 솔루션은 DB 인스턴스를 퍼블릭 인터넷에 노출하고 모든 소스에 연결할 수 있도록 
허용하므로 필요한 액세스를 가장 안전하게 제공하지 않습니다. 
3. 탄력적 IP 주소가 있는 EC2 인스턴스를 VPC B 로 시작합니다. 새 EC2 인스턴스를 통해 모든 
요청을 프록시합니다. 이 솔루션은 대기 시간과 복잡성을 유발할 수 있는 추가 리소스 생성 및 
프록시 서버 구성과 관련되므로 필요한 액세스를 가장 안전하게 제공하지 않습니다. 
참조 URL: https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html 
설명 2: 
VPC A 와 VPC B 간에 VPC 피어링 연결을 구성하면 VPC A 의 EC2 인스턴스와 VPC B 의 
데이터베이스 간에 비공개 보안 통신을 설정할 수 있습니다. 공용 IP 주소가 필요하거나 
데이터베이스를 인터넷에 노출해야 합니다. 
옵션 A 는 덜 안전할 수 있는 응용 프로그램 서버의 공용 IP 주소에서 오는 모든 트래픽을 
허용해야 하므로 최상의 솔루션이 아닙니다. 
옵션 C 는 DB 인스턴스를 공개적으로 액세스 가능하게 만드는 것과 관련이 있으며, 이는 
데이터베이스를 인터넷에 직접 노출함으로써 보안 위험을 초래합니다. 
옵션 D 는 VPC B 에서 추가 EC2 인스턴스를 시작하고 이를 통해 모든 요청을 프록시하여 불필요한 
복잡성을 추가합니다. 이는 이 시나리오에서 가장 효율적이고 안전한 접근 방식이 아닙니다. 
Q232 
회사는 Amazon EC2 인스턴스에서 고객을 위한 데모 환경을 실행합니다. 각 환경은 자체 VPC 에서 
격리됩니다. 환경에 대한 RDP 또는 SSH 액세스가 설정되면 회사의 운영 팀에 알려야 합니다. 
A. RDP 또는 SSH 액세스가 감지되면 AWS Systems Manager OpsItems 를 생성하도록 Amazon 
CloudWatch Application Insights 를 구성합니다. 
B. AmazonSSMManagedInstanceCore 정책이 연결된 IAM 역할이 있는 IAM 인스턴스 프로필로 
EC2 인스턴스를 구성합니다. 
C. Amazon CloudWatch Logs 에 VPC 흐름 로그를 게시합니다. 필요한 메트릭 필터를 만듭니다. 
경보가 ALARM 상태일 때 알림 작업이 포함된 Amazon CloudWatch 지표 경보를 생성합니다. 
D. EC2 인스턴스 상태 변경 알림 유형의 이벤트를 수신하도록 Amazon EventBridge 규칙을 
구성합니다. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 구성합니다. 
주제에 대한 운영 팀을 구독하십시오. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95324-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
CloudWatch Logs 에 VPC 흐름 로그를 게시하고 RDP 또는 SSH 액세스를 감지하는 지표 필터를 
생성함으로써 운영 팀은 경보가 트리거될 때 이를 알리도록 CloudWatch 지표 경보를 구성할 수 
있습니다. 이렇게 하면 환경에 대한 RDP 또는 SSH 액세스가 설정될 때 원하는 알림이 
제공됩니다. 
CloudWatch Application Insights 는 RDP 또는 SSH 액세스를 감지하도록 설계되지 않았기 때문에 
옵션 A 는 올바르지 않습니다. 
옵션 B 도 올바르지 않습니다. AmazonSSMManagedInstanceCore 정책으로 IAM 인스턴스 
프로필을 구성하면 RDP 또는 SSH 액세스가 발생할 때 운영 팀에 알려야 하는 요구 사항이 직접 
해결되지 않기 때문입니다. 
EC2 인스턴스 상태 변경 알림 이벤트를 수신하도록 EventBridge 규칙을 구성하고 SNS 주제를 
대상으로 사용하면 운영 팀에 인스턴스 시작 또는 중지와 같은 인스턴스 상태 변경 사항을 알릴 
수 있으므로 옵션 D 는 잘못된 것입니다. 그러나 질문에 명시된 요구 사항인 RDP 또는 SSH 
액세스가 설정된 시기를 구체적으로 감지하거나 알리지는 않습니다. 
참고: 
https://aws.amazon.com/blogs/security/how-to-monitor-and-visualize-failed-ssh-access-atte
mptsto-amazon-ec2-linux-instances/ 
Q233 
솔루션 설계자가 새 AWS 계정을 생성했으며 AWS 계정 루트 사용자 액세스를 보호해야 합니다. 
어떤 작업 조합이 이를 달성합니까? (2 개 선택) 
A. 루트 사용자가 강력한 암호를 사용하는지 확인하십시오. 
B. 루트 사용자에 대한 다단계 인증을 활성화합니다. 
C. 암호화된 Amazon S3 버킷에 루트 사용자 액세스 키를 저장합니다. 
D. 관리 권한이 포함된 그룹에 루트 사용자를 추가합니다. 
E. 인라인 정책 문서를 사용하여 루트 사용자에게 필요한 권한을 적용합니다. 
Answer: A, B  
https://www.examtopics.com/discussions/amazon/view/95084-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. 루트 사용자에 대해 강력한 암호를 설정하는 것은 무단 액세스를 방지하기 위한 필수 보안 
조치입니다. 
B. MFA 를 활성화하면 암호 외에 모바일 앱의 코드 또는 하드웨어 토큰과 같은 추가 인증 요소를 
요구하여 추가 보안 계층을 추가합니다. 
C. 루트 사용자 액세스 키는 가능하면 피해야 하며 대신 권한이 제한된 IAM 사용자를 사용하는 
것이 가장 좋습니다. 
D. 루트 사용자는 이미 계정의 모든 리소스 및 서비스에 대한 무제한 액세스 권한을 가지고 
있으므로 추가 관리 권한을 부여하면 무단 작업의 위험이 높아질 수 있습니다. 
E. 대신 적절한 권한을 가진 IAM 사용자를 생성하고 해당 사용자를 일상적인 작업에 사용하는 
동시에 루트 사용자를 보호하고 필요한 관리 작업에만 사용하는 것이 좋습니다. 
설명 2: 
https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html 
https://docs.aws.amazon.com/accounts/latest/reference/best-practices-root-user.html 
* AWS 계정 루트 사용자에서 AWS Multi-Factor Authentication(MFA)을 활성화합니다. 자세한 
내용은 IAM 사용 설명서의 AWS 에서 멀티 팩터 인증(MFA) 사용을 참조하십시오. 
* AWS 계정 루트 사용자 암호 또는 액세스 키를 누구와도 공유하지 마십시오. 
* 강력한 암호를 사용하여 AWS Management Console 에 대한 액세스를 보호하십시오. AWS 계정 
루트 사용자 암호 관리에 대한 자세한 내용은 루트 사용자 암호 변경 단원을 참조하십시오. 
Q234 
회사에서 새로운 웹 기반 고객 관계 관리 애플리케이션을 구축하고 있습니다. 애플리케이션은 
Application Load Balancer(ALB) 뒤에 있는 Amazon Elastic Block Store(Amazon EBS) 볼륨이 
지원하는 여러 Amazon EC2 인스턴스를 사용합니다. 이 애플리케이션은 Amazon Aurora 
데이터베이스도 사용합니다. 애플리케이션의 모든 데이터는 유휴 및 전송 중에 암호화되어야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. ALB 에서 AWS Key Management Service(AWS KMS) 인증서를 사용하여 전송 중인 데이터를 
암호화합니다. AWS Certificate Manager(ACM)를 사용하여 유휴 상태의 EBS 볼륨 및 Aurora 
데이터베이스 스토리지를 암호화합니다. 
B. AWS 루트 계정을 사용하여 AWS Management Console 에 로그인합니다. 회사의 암호화 
인증서를 업로드합니다. 루트 계정에 있는 동안 계정의 저장 및 전송 중인 모든 데이터에 대해 
암호화를 켜는 옵션을 선택합니다. 
C. AWS Key Management Service(AWS KMS)를 사용하여 유휴 상태의 EBS 볼륨 및 Aurora 
데이터베이스 스토리지를 암호화합니다. ALB 에 AWS Certificate Manager(ACM) 인증서를 연결하여 
전송 중인 데이터를 암호화합니다. 
D. BitLocker 를 사용하여 유휴 상태의 모든 데이터를 암호화합니다. 회사의 TLS 인증서 키를 AWS 
Key Management Service(AWS KMS)로 가져옵니다. KMS 키를 ALB 에 연결하여 전송 중인 
데이터를 암호화합니다. 
Answer: C  
https://www.examtopics.com/discussions/amazon/view/95325-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 AWS Key Management Service(AWS KMS)를 사용하기 때문에 가장 효율적입니다. 이 
서비스는 암호화 키를 쉽게 생성 및 관리하고 다양한 AWS 서비스와 실행 중인 애플리케이션에서 
키 사용을 제어할 수 있게 해줍니다. AWS 에서. 또한 AWS KMS 를 사용하여 EBS 볼륨과 유휴 
Aurora 데이터베이스 스토리지를 암호화하여 관리하는 암호화 키로 데이터를 암호화하여 데이터 
보호를 제공합니다. 또한 AWS 서비스 및 내부 연결 리소스와 함께 사용할 공용 및 개인 
SSL/TLS(Secure Sockets Layer/Transport Layer Security) 인증서를 쉽게 프로비저닝, 관리 및 
배포할 수 있는 서비스인 AWS Certificate Manager(ACM)를 사용합니다. . 또한 ACM 인증서를 
ALB 에 연결하여 전송 중인 데이터를 암호화합니다. 이는 클라이언트와 로드 밸런서 간의 연결에 
SSL/TLS 암호화를 활성화하여 데이터 보호를 제공합니다. 이 솔루션은 미사용 및 전송 중인 
애플리케이션의 모든 데이터를 암호화해야 한다는 요구 사항을 충족합니다. 
옵션 A 는 ALB 에서 AWS KMS 인증서를 사용하여 전송 중인 데이터를 암호화하기 때문에 효율성이 
떨어집니다. 이는 AWS KMS 가 인증서를 제공하지 않고 키만 제공하기 때문에 불가능합니다. 또한 
AWS Certificate Manager(ACM)를 사용하여 유휴 EBS 볼륨 및 Aurora 데이터베이스 스토리지를 
암호화합니다. 이는 ACM 이 암호화를 제공하지 않고 인증서만 제공하기 때문에 불가능합니다. 
옵션 B 는 AWS 루트 계정을 사용하여 AWS Management Console 에 로그인하기 때문에 효율성이 
떨어집니다. 이 방법은 계정의 모든 리소스에 대한 무제한 액세스 권한이 있으므로 권장되지 
않습니다. 또한 회사의 암호화 인증서를 업로드하는데 ACM 은 인증서를 무료로 제공할 수 
있으므로 필요하지 않습니다. 또한 계정에 대해 저장 및 전송 중인 모든 데이터에 대해 암호화를 
켜는 옵션을 선택합니다. 이는 암호화 설정이 각 서비스 및 리소스에 따라 다르기 때문에 
불가능합니다. 
옵션 D 는 Windows 서버의 볼륨에 대한 암호화를 제공하는 Windows 기능인 BitLocker 를 
사용하여 미사용 데이터를 모두 암호화하기 때문에 효율성이 떨어집니다. 그러나 이것은 Aurora 가 
Linux 서버에서 실행되기 때문에 미사용 Aurora 데이터베이스 스토리지에 대한 암호화를 제공하지 
않습니다. 또한 회사의 TLS 인증서 키를 AWS KMS 로 가져오는데, 이는 ACM 이 인증서를 무료로 
제공할 수 있으므로 필요하지 않습니다. 또한 KMS 키를 ALB 에 연결하여 전송 중인 데이터를 
암호화합니다. ALB 에는 키가 아닌 인증서가 필요하기 때문에 불가능합니다. 
설명 2: 
AWS KMS 를 사용하여 유휴 상태의 EBS 및 Aurora 데이터베이스 스토리지를 암호화할 수 
있습니다. 
ACM 을 사용하여 SSL/TLS 인증서를 가져와 ALB 에 연결할 수 있습니다. 이는 클라이언트와 ALB 
간에 전송 중인 데이터를 암호화합니다. 
A 는 EBS 를 암호화하기 위한 올바른 서비스가 아닌 EBS 를 암호화하기 위해 ACM 을 사용하도록 
제안하기 때문에 올바르지 않습니다. 
B 는 정답이 아닙니다. AWS 루트 계정에 의존하고 AWS Management Console 에서 유휴 및 전송 
중인 모든 데이터에 대한 암호화를 활성화하는 옵션을 선택하는 것은 유효한 접근 방식이 아니기 
때문입니다. 
BitLocker 는 AWS 서비스에서 데이터를 암호화하는 데 적합한 솔루션이 아니기 때문에 D 는 
틀렸습니다. 주로 Windows 기반 운영 체제에서 데이터를 암호화하는 데 사용됩니다. 또한 TLS 
인증서 키를 AWS KMS 로 가져와 ALB 에 연결하는 것은 전송 중인 데이터를 암호화하는 데 
권장되는 접근 방식이 아닙니다. 
Q235 
회사에서 온프레미스 Oracle 데이터베이스를 Amazon Aurora PostgreSQL 로 이전하고 있습니다. 
데이터베이스에는 동일한 테이블에 쓰는 여러 응용 프로그램이 있습니다. 응용 프로그램은 각 
마이그레이션 사이에 한 달씩 하나씩 마이그레이션해야 합니다. 경영진은 데이터베이스에 많은 
수의 읽기 및 쓰기가 있다는 우려를 표명했습니다. 데이터는 마이그레이션하는 동안 두 
데이터베이스에서 동기화 상태를 유지해야 합니다. 
솔루션 설계자는 무엇을 추천해야 합니까? 
A. 초기 마이그레이션에는 AWS DataSync 를 사용하십시오. AWS Database Migration Service(AWS 
DMS)를 사용하여 변경 데이터 캡처(CDC) 복제 작업 및 테이블 매핑을 생성하여 모든 테이블을 
선택합니다. 
B. 초기 마이그레이션에 AWS DataSync 를 사용합니다. AWS Database Migration Service(AWS 
DMS)를 사용하여 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 테이블 매핑을 생성하여 
모든 테이블을 선택합니다. 
C. 메모리 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 함께 
AWS Schema Conversion Tool 을 사용합니다. 전체 로드 및 CDC(변경 데이터 캡처) 복제 작업과 
테이블 매핑을 생성하여 모든 테이블을 선택합니다. 
D. 컴퓨팅 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 함께 
AWS Schema Conversion Tool 을 사용합니다. 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 
테이블 매핑을 생성하여 가장 큰 테이블을 선택합니다. 
Answer: C  
https://www.examtopics.com/discussions/amazon/view/95326-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS SCT 는 Oracle 데이터베이스의 스키마와 코드를 Aurora PostgreSQL 과 호환되도록 변환하는 
데 사용됩니다. AWS DMS 는 Oracle 데이터베이스에서 Aurora PostgreSQL 로 데이터를 
마이그레이션하는 데 활용됩니다. 마이그레이션 프로세스 중에 많은 수의 읽기 및 쓰기를 
처리하려면 메모리 최적화 복제 인스턴스를 사용하는 것이 좋습니다. 
전체 로드 및 CDC 복제 작업을 생성하면 초기 데이터 마이그레이션이 수행되고 Oracle 
데이터베이스의 진행 중인 변경 사항이 지속적으로 캡처되어 Aurora PostgreSQL 데이터베이스에 
적용됩니다. 테이블 매핑을 위해 모든 테이블을 선택하면 동일한 테이블에 쓰는 모든 응용 
프로그램이 마이그레이션됩니다. 
AWS DataSync 를 단독으로 사용하는 것은 데이터베이스 마이그레이션 및 데이터 동기화에 
충분하지 않기 때문에 옵션 A 및 B 는 올바르지 않습니다. 
계산에 최적화된 복제 인스턴스를 사용하는 것이 많은 수의 읽기 및 쓰기를 처리하는 데 가장 
적합한 선택이 아니기 때문에 옵션 D 는 올바르지 않습니다. 
참고 
https://repost.aws/ko/knowledge-center/dms-memory-optimization 
Q236 
회사에 이미지 공유를 위한 3 계층 애플리케이션이 있습니다. 이 애플리케이션은 프런트 엔드 
계층에 Amazon EC2 인스턴스를 사용하고, 애플리케이션 계층에 또 다른 EC2 인스턴스를 
사용하고, MySQL 데이터베이스에 세 번째 EC2 인스턴스를 사용합니다. 솔루션 설계자는 응용 
프로그램에 최소한의 변경만 필요한 확장 가능하고 가용성이 높은 솔루션을 설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon S3 를 사용하여 프런트 엔드 계층을 호스팅하십시오. 애플리케이션 계층에 AWS 
Lambda 함수를 사용합니다. 데이터베이스를 Amazon DynamoDB 테이블로 이동합니다. Amazon 
S3 를 사용하여 사용자 이미지를 저장하고 제공합니다. 
B. 프런트엔드 계층과 애플리케이션 계층에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경을 
사용합니다. 데이터베이스를 여러 읽기 전용 복제본이 있는 Amazon RDS DB 인스턴스로 이동하여 
사용자 이미지를 제공합니다. 
C. Amazon S3 를 사용하여 프런트 엔드 계층을 호스팅합니다. 애플리케이션 계층에 대한 Auto 
Scaling 그룹의 EC2 인스턴스 플릿을 사용합니다. 데이터베이스를 메모리 최적화 인스턴스 
유형으로 이동하여 사용자 이미지를 저장하고 제공합니다. 
D. 프런트엔드 계층과 애플리케이션 계층에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경을 
사용합니다. 데이터베이스를 Amazon RDS 다중 AZ DB 인스턴스로 이동합니다. Amazon S3 를 
사용하여 사용자 이미지를 저장하고 제공합니다. 
Answer: D  
https://www.examtopics.com/discussions/amazon/view/94990-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
로드 밸런싱된 다중 AZ AWS EBS 를 사용하면 애플리케이션을 크게 변경하지 않고도 두 계층 
모두에 대한 확장성과 고가용성을 얻을 수 있습니다. DB 를 RDS 다중 AZ DB 로 이동하면 
고가용성과 자동 장애 조치가 보장됩니다. S3 를 통해 사용자 이미지를 저장하고 제공하면 확장 
가능하고 가용성이 높은 솔루션을 제공합니다. 
프런트 엔드 계층에 S3 를 사용하고 애플리케이션 계층에 Lambda 를 사용하려면 애플리케이션 
아키텍처를 크게 변경해야 하므로 A 는 정답이 아닙니다. DB 를 DynamoDB 로 이동하려면 DB 관련 
코드를 다시 작성해야 합니다. 
이미지를 제공하기 위해 로드 밸런싱된 다중 AZ AWS EBS 환경과 읽기 전용 복제본이 있는 RDS 
DB 를 사용하는 것이 더 적합한 솔루션이기 때문에 B 는 틀렸습니다. 읽기 전용 복제본이 있는 
RDS 는 이러한 용도로 S3 를 사용하는 것보다 이미지 제공 워크로드를 더 효율적으로 처리할 수 
있습니다. 
프런트 엔드 계층에 S3 를 사용하고 애플리케이션 계층에 EC2 의 ASG 를 사용하려면 애플리케이션 
아키텍처를 수정해야 하므로 C 는 올바르지 않습니다. 메모리 최적화 EC2 유형의 이미지를 
저장하고 제공하는 것은 S3 를 사용할 때보다 가장 효율적이고 확장 가능한 접근 방식이 아닐 수 
있습니다. 
설명 2: 
AWS Fargate 는 Amazon EC2 인스턴스의 서버 또는 클러스터를 관리할 필요 없이 컨테이너를 
실행하기 위해 Amazon ECS 와 함께 사용할 수 있는 기술입니다. Fargate 를 사용하면 더 이상 
컨테이너를 실행하기 위해 가상 머신의 클러스터를 프로비저닝, 구성 또는 확장할 필요가 
없습니다. 
https://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html 
"고가용성"의 경우: 다중 AZ 및 "애플리케이션에 대한 최소 변경 사항"의 경우: Elastic Beanstalk 는 
용량 프로비저닝, 로드 밸런싱, 자동 확장에서 애플리케이션 상태 모니터링에 이르기까지 배포를 
자동으로 처리합니다. 
Q237 
VPC-A 의 Amazon EC2 인스턴스에서 실행 중인 애플리케이션은 VPC-B 의 다른 EC2 인스턴스에 
있는 파일에 액세스해야 합니다. 두 VPC 모두 별도의 AWS 계정에 있습니다. 네트워크 관리자는 
VPC-A 에서 VPC-B 의 EC2 인스턴스에 대한 보안 액세스를 구성하는 솔루션을 설계해야 합니다. 
연결에는 단일 장애 지점이나 대역폭 문제가 없어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. VPC-A 와 VPC-B 간에 VPC 피어링 연결을 설정합니다. 
B. VPC-B 에서 실행되는 EC2 인스턴스에 대한 VPC 게이트웨이 엔드포인트를 설정합니다. 
C. 가상 프라이빗 게이트웨이를 VPC-B 에 연결하고 VPC-A 에서 라우팅을 설정합니다. 
D. VPC-B 에서 실행 중인 EC2 인스턴스에 대한 프라이빗 가상 인터페이스(VIF)를 생성하고 
VPC-A 에서 적절한 경로를 추가합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95144-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
VPC 피어링 연결을 사용하면 인터넷 게이트웨이, VPN 연결 또는 NAT 장치 없이 프라이빗 IP 
주소를 사용하여 서로 다른 VPC 의 인스턴스 간에 안전한 통신이 가능합니다. 이를 설정하면 
VPC-A 에서 실행 중인 애플리케이션이 공용 인터넷이나 단일 장애 지점을 거치지 않고 VPC-B 의 
EC2 에 직접 액세스할 수 있습니다. 
B 는 VPC 게이트웨이 엔드포인트가 인터넷을 통하지 않고 VPC 에서 S3 또는 DynamoDB 에 
액세스하는 데 사용되기 때문에 올바르지 않습니다. 서로 다른 VPC 에 있는 EC2 인스턴스 간에 
연결을 설정하도록 설계되지 않았습니다. 
C 는 VPC 간에 VPN 연결을 구성해야 하므로 올바르지 않습니다. 이로 인해 추가적인 복잡성과 
잠재적인 단일 실패 지점이 발생합니다. 
D 는 프라이빗 VIF 를 생성하고 경로를 추가하면 Direct Connect 를 사용하여 온프레미스 인프라와 
VPC-B 간에 직접 연결을 설정하는 데 적용할 수 있기 때문에 올바르지 않지만 서로 다른 VPC 
내의 별도 VPC 에 있는 EC2 인스턴스 간의 통신 시나리오에는 적합하지 않습니다. AWS 계정. 
설명 2: 
AWS 는 VPC 의 기존 인프라를 사용하여 VPC 피어링 연결을 생성합니다. 게이트웨이나 VPN 
연결이 아니며 별도의 물리적 하드웨어에 의존하지 않습니다. 통신 또는 대역폭 병목 현상에 대한 
단일 장애 지점이 없습니다. 
https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html 
Q238 
회사에서 엔지니어 팀을 위해 개별 AWS 계정을 실험하려고 합니다. 회사는 지정된 달의 Amazon 
EC2 인스턴스 사용량이 각 계정의 특정 임계값을 초과하는 즉시 알림을 받기를 원합니다. 
이 요구 사항을 가장 비용 효율적으로 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. Cost Explorer 를 사용하여 서비스별 비용에 대한 일일 보고서를 생성합니다. EC2 인스턴스별로 
보고서를 필터링합니다. 임계값을 초과하면 Amazon Simple Email Service(Amazon SES) 알림을 
보내도록 Cost Explorer 를 구성합니다. 
B. Cost Explorer 를 사용하여 서비스별 월별 비용 보고서를 생성합니다. EC2 인스턴스별로 
보고서를 필터링합니다. 임계값을 초과하면 Amazon Simple Email Service(Amazon SES) 알림을 
보내도록 Cost Explorer 를 구성합니다. 
C. AWS 예산을 사용하여 각 계정에 대한 비용 예산을 생성합니다. 기간을 매월로 설정합니다. 
범위를 EC2 인스턴스로 설정합니다. 예산에 대한 경고 임계값을 설정합니다. 임계값 초과 시 
알림을 받도록 Amazon Simple Notification Service(Amazon SNS) 주제를 구성합니다. 
D. AWS 비용 및 사용 보고서를 사용하여 시간 단위로 보고서를 생성합니다. 보고서 데이터를 
Amazon Athena 와 통합합니다. Amazon EventBridge 를 사용하여 Athena 쿼리를 예약합니다. 
임계값 초과 시 알림을 받도록 Amazon Simple Notification Service(Amazon SNS) 주제를 
구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/94996-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
각 계정에 대한 비용 예산을 생성하고 기간을 월 단위로 지정하고 범위를 EC2 로 지정하면 EC2 와 
관련된 비용을 구체적으로 추적하고 모니터링할 수 있습니다. 예산에 경고 임계값을 설정하면 
지정된 임계값이 초과될 때 알림이 트리거됩니다. 알림을 받도록 SNS 를 구성합니다. 회사에서 
구독하면 즉시 알림을 받을 수 있습니다. 
A 와 B 는 Cost Explorer 를 사용하여 임계값을 초과할 때 실시간 알림을 제공하지 않을 수 있는 
보고서를 생성하기 때문에 가장 비용 효율적인 솔루션이 아닙니다. 또한 A.는 일일 보고서 사용을 
제안하고 B.는 월별 보고서 사용을 제안합니다. 이는 즉각적인 알림에 대해 원하는 수준의 
세분성을 제공하지 않을 수 있습니다. 
D 는 Athena 및 EventBridge 와 함께 비용 및 사용 보고서를 사용하는 것과 관련됩니다. 이 
솔루션은 더 많은 유연성과 데이터 분석 기능을 제공하며 더 복잡하고 Athena 를 사용하고 시간별 
보고서를 생성하는 데 추가 비용이 발생할 수 있습니다. 
설명 2: 
AWS 예산을 사용하면 AWS 계정에 대한 예산을 생성하고 사용량이 특정 임계값을 초과할 때 
알림을 설정할 수 있습니다. 각 계정에 대한 예산을 생성하고 기간을 월 단위로 지정하고 범위를 
EC2 인스턴스로 지정하면 각 계정의 EC2 사용량을 효과적으로 추적하고 임계값을 초과할 때 
알림을 받을 수 있습니다. 이 솔루션은 Amazon Athena 또는 Amazon EventBridge 와 같은 추가 
리소스가 필요하지 않기 때문에 가장 비용 효율적인 옵션입니다. 
Q239 
솔루션 설계자는 회사의 애플리케이션을 위한 새로운 마이크로서비스를 설계해야 합니다. 
클라이언트는 마이크로 서비스에 도달하기 위해 HTTPS 끝점을 호출할 수 있어야 합니다. 또한 
마이크로서비스는 AWS Identity and Access Management(IAM)를 사용하여 호출을 인증해야 합니다. 
솔루션 설계자는 Go 1.x 로 작성된 단일 AWS Lambda 함수를 사용하여 이 마이크로서비스에 대한 
논리를 작성합니다. 
어떤 솔루션이 운영상 가장 효율적인 방식으로 기능을 배포합니까? 
A. Amazon API Gateway REST API를 생성합니다. Lambda 함수를 사용하도록 메서드를 구성합니다. 
API 에서 IAM 인증을 활성화합니다. 
B. 함수에 대한 Lambda 함수 URL 을 생성합니다. 인증 유형으로 AWS_IAM 을 지정합니다. 
C. Amazon CloudFront 배포를 생성합니다. 함수를 Lambda@Edge 에 배포합니다. IAM 인증 로직을 
Lambda@Edge 함수에 통합합니다. 
D. Amazon CloudFront 배포를 생성합니다. CloudFront Functions 에 함수를 배포합니다. 인증 
유형으로 AWS_IAM 을 지정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95365-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
API Gateway REST API 를 생성하면 클라이언트가 마이크로서비스에 도달하기 위해 호출할 수 있는 
HTTPS 엔드포인트를 정의할 수 있습니다. API 에서 IAM 인증을 활성화하여 API 호출에 대한 
인증을 적용합니다. 이렇게 하면 인증된 요청만 마이크로서비스에 도달할 수 있습니다. 이 
솔루션은 API 게이트웨이의 기본 제공 기능을 활용하여 HTTP 엔드포인트, 요청 라우팅 및 IAM 
인증을 처리하므로 운영상 효율적입니다. 추가 인프라 구성 요소 없이 확장 가능하고 관리되는 
솔루션을 제공합니다. 
B 는 Lambda URL 을 생성하고 인증 유형으로 AWS IAM 을 지정할 것을 제안합니다. 이것은 IAM 
인증을 제공할 수 있지만 요청 유효성(검증) 검사, 속도 제한 및 API 구성의 손쉬운 관리와 같은 
API Gateway 의 이점이 없습니다. 
C 와 D 에는 CloudFront, Lambda@Edge 및 CloudFront 함수 사용이 포함됩니다. 이러한 서비스는 
유연성과 에지 위치에서 논리를 실행할 수 있는 기능을 제공하지만 추가적인 복잡성을 야기하며 
지정된 요구 사항에 필요하지 않을 수 있습니다. 
Q240 
한 회사가 이전에 데이터 웨어하우스 솔루션을 AWS 로 마이그레이션했습니다. 회사에는 AWS 
Direct Connect 연결도 있습니다. 본사 사용자는 시각화 도구를 사용하여 데이터 웨어하우스를 
쿼리합니다. 데이터 웨어하우스에서 반환한 쿼리의 평균 크기는 50MB 이고 시각화 도구에서 보낸 
각 웹 페이지는 약 500KB 입니다. 데이터 웨어하우스에서 반환된 결과 집합은 캐시되지 않습니다. 
회사에 가장 낮은 데이터 전송 송신 비용을 제공하는 솔루션은 무엇입니까? 
A. 온프레미스에서 시각화 도구를 호스팅하고 인터넷을 통해 직접 데이터 웨어하우스를 
쿼리합니다. 
B. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅합니다. 인터넷을 통해 
액세스하십시오. 
C. 온프레미스에서 시각화 도구를 호스팅하고 동일한 AWS 리전의 위치에서 Direct Connect 
연결을 통해 직접 데이터 웨어하우스를 쿼리합니다. 
D. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하고 동일한 리전의 위치에서 
Direct Connect 연결을 통해 액세스합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/94998-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하고 동일한 리전 내에서 Direct 
Connect 연결을 통해 액세스하면 데이터 전송 비용이 없어지고 지연 시간이 짧은 고대역폭 
연결이 보장됩니다. 
A. 온프레미스에서 시각화 도구를 호스팅하고 인터넷을 통해 데이터 웨어하우스를 쿼리하면 모든 
쿼리 결과에 대한 데이터 전송 비용과 잠재적 대기 시간 및 대역폭 제한이 발생합니다. 
B. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하지만 인터넷을 통해 
액세스하면 여전히 각 쿼리 결과에 대한 데이터 전송 비용이 발생합니다. 
C. 온프레미스에서 시각화 도구를 호스팅하고 동일한 AWS 리전 내에서 Direct Connect 연결을 
통해 데이터 웨어하우스를 쿼리하면 모든 쿼리 결과에 대한 데이터 전송 비용이 발생하고 
온프레미스 인프라가 필요하여 복잡성이 추가됩니다. 
참고: 
https://aws.amazon.com/directconnect/pricing/ 
https://aws.amazon.com/blogs/aws/aws-data-transfer-prices-reduced/ 
Q241 
온라인 학습 회사가 AWS 클라우드로 마이그레이션하고 있습니다. 회사는 PostgreSQL 
데이터베이스에 학생 기록을 유지합니다. 회사는 여러 AWS 리전에서 데이터를 항상 온라인으로 
사용할 수 있는 솔루션이 필요합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. PostgreSQL 데이터베이스를 Amazon EC2 인스턴스의 PostgreSQL 클러스터로 
마이그레이션합니다. 
B. PostgreSQL 데이터베이스를 다중 AZ 기능이 켜진 PostgreSQL DB 인스턴스용 Amazon RDS 로 
마이그레이션합니다. 
C. PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스로 마이그레이션합니다. 
다른 리전에서 읽기 전용 복제본을 생성합니다. 
D. PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스로 마이그레이션합니다. 
다른 리전에 복사할 DB 스냅샷을 설정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95000-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
PostgreSQL 데이터베이스를 PostgreSQL DB 유지용 RDS 로 늘리고 다른 AWS 리전에 읽기 전용 
복제본을 생성하면 여러 리전에서 데이터 가용성과 온라인 액세스를 충분히 할 수 있습니다. 이 
솔루션은 EC2 폐쇄에서 PostgreSQL 클러스터를 관리하거나(옵션 A) 스냅샷을 사용하여 수동 
복제를 설정하는 것(옵션 D)에 비해 연산된 헤드가 적입니다. 또한 Amazon RDS 는 기본 복원 및 
복제 설정을 처리하여 회사의 운영 문제를 줄입니다. 
B 는 단일 AWS 리전 내에서 고가용성을 누릴 수 있습니다. 그러나 질문에 여러 개의 AWS 
리전에서 항상 데이터를 온라인으로 사용할 수 있어야만 요구 사항을 충족할 수 없습니다. RDS 의 
다중 AZ 기능은 동일한 리전 내에서 자동으로 조치를 취하지만 데이터를 여러 리전으로 복제하지 
않습니다. 
설명 2: 
"항상 여러 AWS 리전에서 온라인으로". 현재 읽기 전용 복제본만 지역 간 지원, 다중 AZ 는 지역 
간 지원하지 않음(동일한 지역에서만 작동) 
https://aws.amazon.com/ko/about-aws/whats-new/2018/01/amazon-rds-read-replicas-now-s
upport-multi-az-deployments/ 
Q242 
회사는 7 개의 Amazon EC2 인스턴스를 사용하여 AWS 에서 웹 애플리케이션을 호스팅합니다. 
회사는 DNS 쿼리에 대한 응답으로 모든 정상적인 EC2 인스턴스의 IP 주소가 반환되도록 
요구합니다. 
이 요구 사항을 충족하려면 어떤 정책을 사용해야 합니까? 
A. 단순 라우팅 정책(Simple routing policy) 
B. 레이턴시 라우팅 정책(Latency routing policy) 
C. 다중값 라우팅 정책(Multivalue routing policy) 
D. 지리적 위치 라우팅 정책(Geolocation routing policy) 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95001-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
다중 응답 라우팅 정책을 사용하여 여러 리소스에 DNS 응답을 배포할 수 있습니다. 
예를 들어 라우팅 레코드를 Route 53 상태 확인과 연결하려는 경우 다중값 응답 라우팅을 
사용합니다. 예를 들어 DNS 쿼리에 대해 여러 값을 반환하고 트래픽을 여러 IP 주소로 라우팅해야 
하는 경우 다중 값 응답 라우팅을 사용합니다. 
https://aws.amazon.com/premiumsupport/knowledge-center/multivalue-versus-simple-policies/ 
설명 2: 
다중값 라우팅 정책은 Route 53 이 동일한 리소스에 대한 여러 정상 IP 주소로 DNS 쿼리에 
응답하도록 허용합니다. 이는 여러 인스턴스가 동일한 용도로 사용되며 부하 분산 또는 장애 
조치가 가능한 시나리오에서 특히 유용합니다. 다중 값 라우팅 정책을 사용하면 Route 53 은 여러 
IP 주소를 무작위 순서로 반환하여 모든 정상 인스턴스에 트래픽을 분산합니다. 
옵션 A(단순 라우팅 정책)는 DNS 쿼리에 대한 응답으로 단일 IP 주소만 반환하며 여러 주소 
반환을 지원하지 않습니다. 
옵션 B(대기 시간 라우팅 정책)는 리소스에 대한 최저 대기 시간을 기반으로 트래픽을 라우팅하는 
데 사용되며 모든 정상 IP 주소를 반환해야 하는 요구 사항을 충족하지 않습니다. 
옵션 D(Geolocation 라우팅 정책)는 사용자의 지리적 위치를 기반으로 트래픽을 라우팅하는 데 
사용되며 정상 IP 주소를 모두 반환해야 하는 요구 사항을 충족하지 않습니다. 
따라서 다중 값 라우팅 정책은 DNS 쿼리에 대한 응답으로 모든 정상 EC2 인스턴스의 IP 주소를 
반환하는 데 가장 적합한 옵션입니다. 
Q243 
의학 연구실에서 새로운 연구와 관련된 데이터를 생성합니다. 연구소는 온프레미스 파일 기반 
애플리케이션을 위해 전국의 클리닉에 최소한의 대기 시간으로 데이터를 제공하고자 합니다. 
데이터 파일은 각 클리닉에 대한 읽기 전용 권한이 있는 Amazon S3 버킷에 저장됩니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. 각 클리닉에서 온프레미스로 AWS Storage Gateway 파일 게이트웨이를 가상 머신(VM)으로 
배포합니다. 
B. 처리를 위해 AWS DataSync 를 사용하여 각 클리닉의 온프레미스 애플리케이션으로 파일을 
마이그레이션합니다. 
C. 각 클리닉에서 온프레미스로 AWS Storage Gateway 볼륨 게이트웨이를 가상 머신(VM)으로 
배포합니다. 
D. Amazon Elastic File System(Amazon EFS) 파일 시스템을 각 클리닉의 온프레미스 서버에 
연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95002-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
AWS Storage Gateway 는 온프레미스 소프트웨어 어플라이언스와 클라우드 기반 스토리지를 
연결하여 조직의 온프레미스 IT 환경과 AWS 스토리지 인프라 간의 원활하고 안전한 통합을 
제공하는 서비스입니다. 각 진료소 구내에 파일 게이트웨이를 가상 머신으로 배포함으로써 의료 
연구실은 각 진료소에 대한 읽기 전용 권한을 유지하면서 S3 버킷에 저장된 데이터에 대한 짧은 
대기 시간 액세스를 제공할 수 있습니다. 이 솔루션을 통해 클리닉은 데이터 전송이나 
마이그레이션 없이 온프레미스 파일 기반 애플리케이션에서 직접 데이터 파일에 액세스할 수 
있습니다. 
설명 2: 
A. 클리닉에서 파일 인터페이스를 통해 S3 버킷에 저장된 데이터 파일에 액세스할 수 있습니다. 
파일 게이트웨이는 자주 액세스하는 데이터를 로컬로 캐시하여 대기 시간을 줄이고 데이터에 대한 
빠른 액세스를 제공합니다. 
B. AWS DataSync 를 사용하여 Amazon S3 버킷에서 각 클리닉의 온프레미스 애플리케이션으로 
데이터 파일을 전송하는 작업이 포함됩니다. 이렇게 하면 데이터 마이그레이션이 가능하지만 
실시간 액세스를 제공하지 않을 수 있으며 추가 대기 시간이 발생할 수 있습니다. 
C. 파일 수준의 접근보다는 데이터에 대한 블록 수준의 접근에 적합하다. 파일 기반 
애플리케이션을 위한 가장 효율적인 솔루션이 아닐 수도 있습니다. 
D. 확장 가능한 파일 스토리지 서비스인 Amazon EFS 를 사용하여 데이터에 대한 파일 수준 
액세스를 제공합니다. 그러나 파일 게이트웨이 솔루션을 사용할 때보다 복잡성과 대기 시간이 
추가로 발생할 수 있습니다. 
Q244 
회사에서 단일 Amazon EC2 인스턴스에서 실행되는 콘텐츠 관리 시스템을 사용하고 있습니다. 
EC2 인스턴스에는 웹 서버와 데이터베이스 소프트웨어가 모두 포함되어 있습니다. 회사는 웹 
사이트 플랫폼을 고가용성으로 만들고 사용자 요구에 맞게 웹 사이트를 확장할 수 있어야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. 데이터베이스를 Amazon RDS 로 이동하고 자동 백업을 활성화합니다. 동일한 가용 영역에서 
다른 EC2 인스턴스를 수동으로 시작합니다. 가용 영역에서 Application Load Balancer 를 구성하고 
두 인스턴스를 대상으로 설정합니다. 
B. 기존 EC2 인스턴스와 동일한 가용 영역에 있는 읽기 전용 복제본이 있는 Amazon Aurora 
인스턴스로 데이터베이스를 마이그레이션합니다. 동일한 가용 영역에서 다른 EC2 인스턴스를 
수동으로 시작합니다. Application Load Balancer 를 구성하고 두 개의 EC2 인스턴스를 대상으로 
설정합니다. 
C. 다른 가용 영역에 읽기 전용 복제본이 있는 Amazon Aurora 로 데이터베이스를 이동합니다. EC2 
인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 두 가용 영역에서 Application Load 
Balancer 를 구성합니다. 두 가용 영역에서 AMI 를 사용하는 Auto Scaling 그룹을 연결합니다. 
D. 데이터베이스를 별도의 EC2 인스턴스로 이동하고 Amazon S3 로 백업을 예약합니다. 원래 EC2 
인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 두 가용 영역에서 Application Load 
Balancer 를 구성합니다. 두 가용 영역에서 AMI 를 사용하는 Auto Scaling 그룹을 연결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95336-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
이 접근 방식은 웹 사이트 플랫폼에 고가용성과 확장성을 모두 제공합니다. 데이터베이스를 다른 
가용 영역에 있는 읽기 전용 복제본이 있는 Amazon Aurora 로 이동하면 데이터베이스에 대한 장애 
조치 옵션이 제공됩니다. 두 가용 영역에서 Application Load Balancer 및 Auto Scaling 그룹을 
사용하면 증가하는 사용자 수요를 충족하기 위해 웹 사이트를 자동으로 확장할 수 있습니다. 또한 
원래 EC2 인스턴스에서 AMI 를 생성하면 장애 발생 시 인스턴스를 쉽게 복제할 수 있습니다. 
설명 2: 
옵션 A 는 고가용성 또는 확장성을 위한 솔루션을 제공하지 않습니다. 동일한 AZ 에서 다른 EC2 
인스턴스를 수동으로 시작하면 해당 AZ 에 장애가 발생하면 다운타임이 발생하므로 고가용성이 
보장되지 않을 수 있습니다. 
옵션 B 는 데이터베이스 성능을 개선하고 내결함성 수준을 제공하지만 웹 사이트 플랫폼의 확장성 
측면을 다루지는 않습니다. 
옵션 C 는 고가용성과 내결함성을 모두 제공합니다. AMI 를 생성하면 AZ 간에 EC2 인스턴스를 
쉽게 복제할 수 있습니다. 두 AZ 에서 ALB 를 구성하고 ASG 를 연결하면 여러 인스턴스에 걸쳐 
확장성과 부하 분산이 보장됩니다. 
옵션 D 는 회사에서 요구하는 고가용성 및 확장성을 제공하지 않습니다. S3 에 예약된 백업은 
데이터 보호를 다루지만 웹사이트 가용성이나 확장성에 기여하지는 않습니다. 
Q245 
회사가 AWS 에서 애플리케이션을 시작하고 있습니다. 애플리케이션은 Application Load 
Balancer(ALB)를 사용하여 단일 대상 그룹에 있는 최소 2 개의 Amazon EC2 인스턴스로 트래픽을 
보냅니다. 인스턴스는 각 환경의 Auto Scaling 그룹에 있습니다. 회사는 개발 환경과 생산 환경이 
필요합니다. 프로덕션 환경에는 트래픽이 많은 기간이 있습니다. 
개발 환경을 가장 비용 효율적으로 구성하는 솔루션은 무엇입니까? 
A. 하나의 EC2 인스턴스만 대상으로 하도록 개발 환경에서 대상 그룹을 재구성합니다. 
B. ALB 밸런싱 알고리즘을 최소 미해결 요청으로 변경합니다. 
C. 두 환경 모두에서 EC2 인스턴스의 크기를 줄입니다. 
D. 개발 환경의 Auto Scaling 그룹에서 최대 EC2 인스턴스 수를 줄입니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95337-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
A?? 
Q246 
한 회사가 여러 가용 영역의 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. EC2 
인스턴스는 프라이빗 서브넷에 있습니다. 솔루션 설계자는 인터넷 연결 ALB(Application Load 
Balancer)를 구현하고 EC2 인스턴스를 대상 그룹으로 지정합니다. 그러나 인터넷 트래픽이 EC2 
인스턴스에 도달하지 않습니다. 
솔루션 설계자는 이 문제를 해결하기 위해 아키텍처를 어떻게 재구성해야 합니까? 
A. ALB를 Network Load Balancer 로 교체하십시오. 인터넷 트래픽을 허용하도록 퍼블릭 서브넷에서 
NAT 게이트웨이를 구성합니다. 
B. EC2 인스턴스를 퍼블릭 서브넷으로 이동합니다. EC2 인스턴스의 보안 그룹에 규칙을 추가하여 
0.0.0.0/0 으로의 아웃바운드 트래픽을 허용합니다. 
C. 인터넷 게이트웨이 경로를 통해 0.0.0.0/0 트래픽을 보내도록 EC2 인스턴스의 서브넷에 대한 
경로 테이블을 업데이트합니다. EC2 인스턴스의 보안 그룹에 규칙을 추가하여 0.0.0.0/0 으로의 
아웃바운드 트래픽을 허용합니다. 
D. 각 가용 영역에서 퍼블릭 서브넷을 생성합니다. 퍼블릭 서브넷을 ALB 와 연결합니다. 프라이빗 
서브넷에 대한 경로로 퍼블릭 서브넷에 대한 경로 테이블을 업데이트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95003-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. 다른 유형의 로드 밸런서를 사용하고 NAT 게이트웨이를 구성할 것을 제안하지만 EC2 
인스턴스에 도달하는 인터넷 트래픽 문제는 다루지 않습니다. 
B.는 EC2 인스턴스를 퍼블릭 인터넷에 노출할 것을 제안합니다. 이는 보안 위험을 초래할 수 
있으며 인스턴스에 도달하는 인바운드 인터넷 트래픽 문제를 해결하지 않습니다. 
C.는 아웃바운드 인터넷 액세스를 갖도록 EC2 인스턴스를 구성할 것을 제안하지만 인스턴스에 
도달하는 인바운드 인터넷 트래픽 문제를 해결하지는 않습니다. 
D.가 정답입니다. 퍼블릭 서브넷을 생성하고 이를 ALB 와 연결하면 인바운드 인터넷 트래픽이 
ALB 에 도달할 수 있습니다. 프라이빗 서브넷에 대한 경로를 포함하도록 퍼블릭 서브넷의 라우팅 
테이블이 업데이트되어 트래픽이 프라이빗 서브넷의 EC2 인스턴스에 도달할 수 있습니다. 이 
설정을 사용하면 인터넷 트래픽이 ALB 를 통해 EC2 인스턴스에 도달하도록 허용하면서 
애플리케이션에 대한 보안 액세스가 가능합니다. 
참고: 
https://repost.aws/ko/knowledge-center/public-load-balancer-private-ec2 
Q247 
한 회사에서 MySQL 용 Amazon RDS 에 데이터베이스를 배포했습니다. 트랜잭션 증가로 인해 
데이터베이스 지원 팀은 DB 인스턴스에 대한 느린 읽기를 보고하고 있으며 읽기 전용 복제본을 
추가할 것을 권장합니다. 
이 변경 사항을 구현하기 전에 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까? (2 개 
선택) 
A. RDS 기본 노드에서 binlog 복제를 활성화합니다. 
B. 원본 DB 인스턴스의 장애 조치 우선 순위를 선택합니다. 
C. 원본 DB 인스턴스에서 장기 실행 트랜잭션이 완료되도록 허용합니다. 
D. 글로벌 테이블을 생성하고 테이블을 사용할 수 있는 AWS 리전을 지정합니다. 
E. 백업 보존 기간을 0 이외의 값으로 설정하여 원본 인스턴스에서 자동 백업을 활성화합니다. 
Answer: C, E 
https://www.examtopics.com/discussions/amazon/view/95004-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. 읽기 복제본 설정에 필요한 RDS 기본 노드에서 이진 로그 복제 기능을 활성화합니다. 
B. 장애 조치 시나리오 중에 DB 인스턴스가 기본 역할로 승격되는 순서를 결정합니다. 느린 읽기 
문제를 해결하기 위해 읽기 전용 복제본을 추가하는 것과 직접적인 관련이 없습니다. 
C. 원본 DB 인스턴스에서 진행 중인 모든 트랜잭션이 변경 사항을 구현하기 전에 완료되도록 
합니다. 읽기 전용 복제본으로 전환하는 동안 데이터 무결성과 일관성을 유지하는 데 도움이 
됩니다. 
D.는 DynamoDB 전용 기능입니다. DynamoDB 에서 다중 리전 복제 및 고가용성을 허용하지만 이 
시나리오에는 적용할 수 없습니다. 
E. 원본 DB 인스턴스에 대해 정기적인 백업이 수행되는지 확인합니다. 이는 읽기 전용 복제본을 
추가하는 동안 또는 이후에 문제가 발생할 경우 특정 시점 복원을 허용하므로 데이터 보호 및 
복구 목적에 중요합니다. 
설명 2: 
"오래 실행되는 활성 트랜잭션은 읽기 전용 복제본 생성 프로세스를 느리게 할 수 있습니다. 읽기 
전용 복제본을 생성하기 전에 장기 실행 트랜잭션이 완료될 때까지 기다리는 것이 좋습니다. 
동일한 원본 DB 인스턴스에서 여러 읽기 전용 복제본을 병렬로 생성하는 경우 , Amazon RDS 는 
첫 번째 생성 작업 시작 시 하나의 스냅샷만 찍습니다. 읽기 전용 복제본을 생성할 때 고려해야 할 
몇 가지 사항이 있습니다. 먼저 백업 보존 기간을 0 이외의 값. 
이 요구 사항은 다른 읽기 전용 복제본의 원본 DB 인스턴스인 읽기 전용 복제본에도 적용됩니다." 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html 
Q248 
회사는 Amazon EC2 인스턴스에서 분석 소프트웨어를 실행합니다. 소프트웨어는 Amazon S3 에 
업로드된 데이터를 처리하기 위해 사용자의 작업 요청을 수락합니다. 일부 제출된 데이터가 
처리되지 않고 있다고 사용자가 보고합니다. Amazon CloudWatch 는 EC2 인스턴스의 일관된 CPU 
사용률이 100% 또는 거의 100%에 가깝다고 밝혔습니다. 회사는 시스템 성능을 개선하고 사용자 
부하에 따라 시스템을 확장하려고 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 인스턴스의 복사본을 만듭니다. Application Load Balancer 뒤에 모든 인스턴스를 배치합니다. 
B. Amazon S3 용 S3 VPC 엔드포인트를 생성합니다. 엔드포인트를 참조하도록 소프트웨어를 
업데이트합니다. 
C. EC2 인스턴스를 중지합니다. CPU 와 메모리가 더 강력한 인스턴스 유형으로 인스턴스 유형을 
수정합니다. 인스턴스를 다시 시작하십시오. 
D. 들어오는 요청을 Amazon Simple Queue Service(Amazon SQS)로 라우팅합니다. 대기열 크기에 
따라 EC2 Auto Scaling 그룹을 구성합니다. 대기열에서 읽을 수 있도록 소프트웨어를 
업데이트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95329-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. 인스턴스 사본을 생성하고 모든 인스턴스를 ALB 뒤에 배치하는 것은 높은 CPU 사용률 문제를 
해결하거나 사용자 부하에 따라 확장성을 제공하지 않습니다. 
B. S3 용 S3 VPC 엔드포인트를 생성하고 엔드포인트를 참조하도록 소프트웨어를 업데이트하면 
네트워크 성능이 향상되지만 높은 CPU 사용률 문제를 해결하거나 사용자 부하에 따라 확장성을 
제공하지 않습니다. 
C. EC2 인스턴스를 중지하고 인스턴스 유형을 더 강력한 CPU 와 더 많은 메모리를 가진 인스턴스 
유형으로 수정하면 성능이 향상될 수 있지만 사용자 부하에 따른 확장성은 해결되지 않습니다. 
D. 들어오는 요청을 SQS 로 라우팅하고, 대기열 크기에 따라 EC2 ASG 를 구성하고, 대기열에서 
읽을 수 있도록 소프트웨어를 업데이트하면 시스템 성능이 향상되고 사용자 로드에 따라 확장성이 
제공됩니다. 
따라서 옵션 D 는 높은 CPU 사용률을 해결하고 시스템 성능을 개선하며 사용자 부하에 따라 
확장성을 활성화하므로 올바른 선택입니다. 
Q249 
회사는 AWS 클라우드에서 호스팅되는 미디어 애플리케이션을 위한 공유 스토리지 솔루션을 
구현하고 있습니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 
필요합니다. 솔루션은 완전히 관리되어야 합니다. 
어떤 AWS 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Storage Gateway 볼륨 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하는 
파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다. 
B. AWS Storage Gateway 테이프 게이트웨이를 생성합니다. Amazon S3 를 사용하도록 테이프를 
구성합니다. 애플리케이션 서버를 테이프 게이트웨이에 연결합니다. 
C. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 
설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다. 
D. Windows 파일 서버 파일 시스템용 Amazon FSx 를 생성합니다. 원본 서버에 파일 시스템을 
연결합니다. 애플리케이션 서버를 파일 시스템에 연결하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95006-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. Storage Gateway 사용과 관련이 있지만 SMB 클라이언트에 대한 지원을 구체적으로 언급하지는 
않습니다. SMB 클라이언트를 사용하여 데이터에 액세스해야 하는 요구 사항을 충족하지 못할 수 
있습니다. 
B. S3 에 데이터를 보관하는 데 주로 사용되는 테이프 게이트웨이 구성과 함께 Storage Gateway 를 
사용하는 것과 관련됩니다. SMB 클라이언트가 데이터에 액세스할 수 있도록 기본 지원을 제공하지 
않습니다. 
C. EC2 Windows 인스턴스에서 Windows 파일 공유를 수동으로 설정하고 구성하는 작업이 
포함됩니다. SMB 클라이언트가 데이터에 액세스할 수 있지만 수동 설정 및 유지 관리가 
필요하므로 완전히 관리되는 솔루션은 아닙니다. 
D. SMB 클라이언트를 지원하는 완전히 관리되는 Windows 파일 시스템인 FSx for Windows 파일 
서버 파일 시스템 생성이 포함됩니다. 기본 SMB 를 지원하는 사용하기 쉬운 공유 스토리지 
솔루션을 제공합니다. 
SMB 클라이언트를 사용하고 완전히 관리되는 솔루션이 필요한 요구 사항을 기반으로 옵션 D 가 
가장 적합한 선택입니다. 
설명 2: 
https://aws.amazon.com/fsx/lustre/ 
Amazon FSx 는 Windows 파일 시스템 기능과 업계 표준 서버를 기본적으로 지원합니다. 
네트워크를 통해 파일 저장소에 액세스하기 위한 메시지 블록(SMB) 프로토콜. 
https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html 
온프레미스-AWS 간 스토리지 서비스 중 SMB 지원하는 건 Storage Gateway File Gateway 나 
Amazon FSx for Windows 라고 보면 됨.  
Q250 
회사의 보안 팀이 VPC 흐름 로그에서 네트워크 트래픽을 캡처하도록 요청합니다. 로그는 90 일 
동안 자주 액세스한 후 간헐적으로 액세스합니다. 
솔루션 설계자는 로그를 구성할 때 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon CloudWatch 를 대상으로 사용하십시오. 90 일 만료로 CloudWatch 로그 그룹 설정 
B. Amazon Kinesis 를 대상으로 사용합니다. 항상 90 일 동안 로그를 유지하도록 Kinesis 스트림을 
구성합니다. 
C. AWS CloudTrail 을 대상으로 사용합니다. Amazon S3 버킷에 저장하도록 CloudTrail 을 구성하고 
S3 Intelligent-Tiering 을 활성화합니다. 
D. Amazon S3 를 대상으로 사용합니다. S3 수명 주기 정책을 활성화하여 90 일 후에 로그를 S3 
Standard-Infrequent Access(S3 Standard-IA)로 전환합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95007-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. CloudWatch 를 VPC 흐름 로그의 대상으로 사용할 것을 제안합니다. 그러나 90 일 동안 로그 
보존을 관리한 다음 간헐적으로 액세스하는 메커니즘을 제공하지 않습니다. 
B. Kinesis 를 VPC 흐름 로그의 대상으로 사용할 것을 제안합니다. 90 일 동안 로그를 보관할 수 
있지만 로그에 대한 간헐적 액세스 요구 사항은 다루지 않습니다. 
C. CloudTrail 을 VPC 흐름 로그의 대상으로 사용할 것을 제안합니다. 그러나 CloudTrail 은 
네트워크 트래픽 로그 캡처가 아니라 API 활동을 감사 및 모니터링하도록 설계되었습니다. VPC 
흐름 로그 캡처 요구 사항을 충족하지 않습니다. 
D. S3 를 VPC 흐름 로그의 대상으로 사용하고 S3 수명 주기 정책을 활용하여 90 일 후에 로그를 
비용 효율적인 스토리지 클래스로 전환할 것을 제안합니다. 90 일 동안 로그를 유지해야 하는 요구 
사항을 충족하고 스토리지 비용을 최적화하면서 간헐적인 액세스에 대한 유연성을 제공합니다. 
설명 2: 
여기에는 VPC 흐름 로그가 S3 로 직접 이동할 수 있음을 지정하는 표가 있습니다. CloudTrail 을 
거쳐 S3 로 이동할 필요가 없습니다. CW 를 통해서도 아닙니다. 
https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resourcepolicy.ht
ml#AWS-logs-i 
Q251 
Amazon EC2 인스턴스는 새 VPC 의 프라이빗 서브넷에 있습니다. 이 서브넷에는 아웃바운드 
인터넷 액세스 권한이 없지만 EC2 인스턴스에는 외부 공급업체로부터 월별 보안 업데이트를 
다운로드할 수 있는 기능이 필요합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 인터넷 게이트웨이를 생성하고 VPC 에 연결합니다. 인터넷 게이트웨이를 기본 경로로 
사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. 
B. NAT 게이트웨이를 생성하고 퍼블릭 서브넷에 배치합니다. NAT 게이트웨이를 기본 경로로 
사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. 
C. NAT 인스턴스를 생성하고 EC2 인스턴스가 있는 동일한 서브넷에 배치합니다. NAT 인스턴스를 
기본 경로로 사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. 
D. 인터넷 게이트웨이를 생성하고 VPC 에 연결합니다. NAT 인스턴스를 생성하고 EC2 인스턴스가 
있는 동일한 서브넷에 배치합니다. 인터넷 게이트웨이를 기본 경로로 사용하도록 프라이빗 서브넷 
경로 테이블을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/95023-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. 사설 서브넷에 직접 인터넷 액세스를 제공합니다. 이는 아웃바운드 인터넷 액세스를 제한하는 
것이 목표이므로 이 경우에는 바람직하지 않습니다. 
B. 프라이빗 서브넷의 EC2 가 프록시 역할을 하는 NAT 게이트웨이를 통해 인터넷에 액세스할 수 
있습니다. 프라이빗 서브넷의 보안을 유지하면서 통제된 아웃바운드 인터넷 액세스를 제공합니다. 
C. NAT 게이트웨이를 사용하는 것과 유사하지만 NAT 인스턴스를 사용하는 것과 관련이 있습니다. 
NAT 인스턴스는 NAT 게이트웨이에 비해 더 많은 수동 구성 및 관리가 필요하므로 덜 선호되는 
옵션입니다. 
D. 필요하지 않은 인터넷 게이트웨이와 NAT 인스턴스의 사용을 결합합니다. 불필요한 복잡성이 
발생하고 추가 관리가 필요한 NAT 인스턴스가 추가됩니다. 
전반적으로 옵션 B 는 퍼블릭 서브넷에 배치된 NAT 게이트웨이를 활용하여 프라이빗 서브넷의 
EC2 인스턴스에 대해 제어된 아웃바운드 인터넷 액세스를 활성화하므로 가장 적합한 
솔루션입니다. 
NAT 게이트웨이는 AWS 및 일반적으로 NAT 인스턴스보다 선호됩니다. 
설명 2: 
이 접근 방식을 사용하면 EC2 인스턴스가 여전히 프라이빗 서브넷에 있는 동안 인터넷에 
액세스하고 월별 보안 업데이트를 다운로드할 수 있습니다. NAT 게이트웨이를 만들어 퍼블릭 
서브넷에 배치하면 프라이빗 서브넷의 인스턴스가 NAT 게이트웨이를 통해 인터넷에 액세스할 수 
있습니다. 그런 다음 NAT 게이트웨이를 기본 경로로 사용하도록 프라이빗 서브넷 경로 테이블을 
구성합니다. 이렇게 하면 모든 아웃바운드 트래픽이 NAT 게이트웨이를 통해 전달되어 EC2 
인스턴스가 프라이빗 서브넷의 보안을 유지하면서 인터넷에 액세스할 수 있습니다. 
Q252 
솔루션 설계자는 고객 사례 파일을 저장할 시스템을 설계해야 합니다. 파일은 핵심 회사 자산이며 
중요합니다. 파일 수는 시간이 지남에 따라 증가합니다. 
파일은 Amazon EC2 인스턴스에서 실행되는 여러 애플리케이션 서버에서 동시에 액세스할 수 
있어야 합니다. 솔루션에는 중복성이 내장되어 있어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Elastic File System(Amazon EFS) 
B. Amazon Elastic Block Store(Amazon EBS) 
C. Amazon S3 Glacier Deep 아카이브(Amazon S3 Glacier Deep Archive) 
D. AWS 백업(AWS Backup) 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95024-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
EFS 는 여러 EC2 에서 동시에 액세스할 수 있는 확장 가능하고 완벽하게 관리되는 파일 스토리지 
서비스를 제공합니다. 리전 내의 여러 AZ 에 데이터를 저장하여 기본 제공 중복성을 제공합니다. 
EFS 를 사용하면 여러 애플리케이션 서버에서 클라이언트 사례 파일에 동시에 액세스할 수 
있으므로 시간이 지남에 따라 파일 수가 증가함에 따라 고가용성과 확장성이 보장됩니다. 
옵션 B 인 EBS 는 일반적으로 개별 EC2 에 연결하는 데 사용되는 블록 수준 스토리지 서비스이며 
여러 인스턴스에 대한 동시 액세스를 제공하지 않으므로 이 시나리오에 적합하지 않습니다. 
옵션 C, S3 Glacier Deep Archive 는 장기 아카이브 스토리지 서비스이며 활성 파일 액세스 및 여러 
애플리케이션 서버의 동시 액세스에 적합하지 않을 수 있습니다. 
옵션 D, AWS Backup 은 중앙 집중식 백업 관리 서비스이며 필요한 동시 파일 액세스 및 중복 
기능을 제공하지 않습니다. 
따라서 가장 적합한 솔루션은 Amazon EFS(옵션 A)입니다. 
설명 2: 
Amazon EFS 는 여러 EC2 인스턴스에서 동시에 액세스할 수 있는 간단하고 확장 가능한 완전 
관리형 파일 시스템을 제공하며 내장된 중복성을 제공합니다. 동일한 파일에 액세스하기 위해 여러 
EC2 인스턴스에 최적화되어 있으며 가용성, 내구성 및 보안성이 우수하도록 설계되었습니다. 
데이터를 페타바이트까지 확장할 수 있고 수천 개의 동시 연결을 처리할 수 있으며 대량의 
데이터를 저장하고 액세스하기 위한 비용 효율적인 솔루션입니다. 
Q253 
솔루션 아키텍트가 Policy1 과 Policy2 라는 두 가지 IAM 정책을 만들었습니다. 두 정책 모두 IAM 
그룹에 연결됩니다. 
클라우드 엔지니어가 IAM 그룹에 IAM 사용자로 추가됩니다. 클라우드 엔지니어는 어떤 작업을 
수행할 수 있습니까? 
A. IAM 사용자 삭제 
B. 디렉토리 삭제 
C. Amazon EC2 인스턴스 삭제 
D. Amazon CloudWatch Logs 에서 로그 삭제 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95008-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q254 
한 회사에서 최근 3 계층 애플리케이션을 VPC 로 마이그레이션하는 것을 검토하고 있습니다. 보안 
팀은 최소 권한 원칙이 애플리케이션 계층 간의 Amazon EC2 보안 그룹 수신 및 송신 규칙에 
적용되지 않는다는 사실을 발견했습니다. 
솔루션 설계자는 이 문제를 해결하기 위해 무엇을 해야 합니까? 
A. 인스턴스 ID 를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. 
B. 보안 그룹 ID 를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. 
C. VPC CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. 
D. 서브넷 CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/95009-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. 특정 인스턴스를 기반으로 트래픽을 제한하므로 애플리케이션 계층 간에 최소 권한 원칙을 
적용하는 데 가장 적합한 솔루션이 아닐 수 있습니다. 
B. 규칙에서 보안 그룹 ID 를 사용하면 필요한 통신만 허용하고 최소 권한 원칙을 준수하여 
애플리케이션 계층 간의 트래픽을 정밀하게 제어할 수 있습니다. 
C. 전체 VPC CIDR 블록을 기반으로 광범위한 규칙을 적용하여 특정 애플리케이션 계층 간의 보안 
통신에 필요한 수준의 세분성을 제공하지 못할 수 있습니다. 
D. 서브넷 CIDR 블록을 기반으로 트래픽을 제한하므로 애플리케이션 계층 간의 적절한 보안을 
보장하기에 충분하지 않을 수 있습니다. 
요약하면 보안 그룹 ID(옵션 B)를 사용하면 최소 권한 원칙에 따라 애플리케이션 계층 간의 
트래픽을 정밀하게 제어할 수 있으므로 권장되는 접근 방식입니다. 
참고 
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/security-group-rules.html 
Q255 
회사에는 데이터베이스에 주문을 작성하고 지불을 처리하기 위해 서비스를 호출하는 전자 상거래 
체크아웃 워크플로우가 있습니다. 사용자는 체크아웃 프로세스 중에 시간 초과를 경험하고 
있습니다. 사용자가 체크아웃 양식을 다시 제출하면 동일한 원하는 거래에 대해 여러 고유 주문이 
생성됩니다. 
여러 주문 생성을 방지하기 위해 솔루션 설계자는 이 워크플로우를 어떻게 리팩터링해야 합니까? 
A. Amazon Kinesis Data Firehose 로 주문 메시지를 보내도록 웹 애플리케이션을 구성합니다. 
Kinesis Data Firehose 에서 메시지를 검색하고 주문을 처리하도록 결제 서비스를 설정합니다. 
B. 로깅된 애플리케이션 경로 요청을 기반으로 AWS Lambda 함수를 호출하기 위해 AWS 
CloudTrail 에서 규칙을 생성합니다. Lambda 를 사용하여 데이터베이스를 쿼리하고 결제 서비스를 
호출하고 주문 정보를 전달합니다. 
C. 데이터베이스에 주문을 저장합니다. 주문 번호가 포함된 메시지를 Amazon Simple Notification 
Service(Amazon SNS)로 보냅니다. Amazon SNS 를 폴링하고 메시지를 검색하고 주문을 처리하도록 
결제 서비스를 설정합니다. 
D. 데이터베이스에 주문을 저장합니다. 주문 번호가 포함된 메시지를 Amazon Simple Queue 
Service(Amazon SQS) FIFO 대기열로 보냅니다. 메시지를 검색하고 주문을 처리하도록 결제 
서비스를 설정합니다. 대기열에서 메시지를 삭제합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95026-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. 다중 주문 생성 방지에 적합한 솔루션이 아닙니다. 이 접근 방식은 순차적이고 안정적인 주문 
처리를 보장하지 않습니다. 
B. 다중 주문 생성을 방지하기 위한 적절한 해결책이 아닙니다. CloudTrail 은 주로 API 활동을 
기록하고 감사하는 데 사용되며 기록된 요청을 기반으로 Lambda 를 호출하면 올바른 주문 처리가 
보장되지 않습니다. 
C.는 적절한 솔루션이 아닙니다. SNS 는 게시-구독 메시징 서비스이며 이를 폴링하면 처리가 
지연되고 잠재적인 주문 중복이 발생할 수 있습니다. 
D.가 정답입니다. SQS FIFO 를 사용하면 주문이 순차적이고 안정적인 방식으로 처리되어 동일한 
거래에 대해 여러 주문이 생성되는 것을 방지할 수 있습니다. 
설명 2: 
VPC 내에 있는 프라이빗 서브넷의 EC2 인스턴스와 DynamoDB 간 가장 안전한 AWS 네트워크 
통신 = VPC Gateway Endpoint. 
게이트웨이 엔드포인트는 VPC 용 인터넷 게이트웨이 또는 NAT 디바이스가 없어도 Amazon S3 및 
DynamoDB 에 대한 안정적인 연결을 제공합니다. 
https://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpce-gateway.html#vpc-endpoints-li
mitations 
설명 3: 
DynamoDB 용 VPC 엔드포인트를 사용하면 VPC 의 Amazon EC2 인스턴스가 프라이빗 IP 주소를 
사용하여 퍼블릭 인터넷에 노출되지 않고 DynamoDB 에 액세스할 수 있습니다. EC2 인스턴스에는 
퍼블릭 IP 주소가 필요하지 않으며 VPC 에 인터넷 게이트웨이, NAT 디바이스 또는 가상 프라이빗 
게이트웨이가 필요하지 않습니다. 엔드포인트 정책을 사용하여 DynamoDB 에 대한 액세스를 
제어합니다. VPC 와 AWS 서비스 간의 트래픽은 Amazon 네트워크를 벗어나지 않습니다. 
Q256 
솔루션 설계자는 Amazon S3 버킷을 저장용으로 사용하여 문서 검토 애플리케이션을 구현하고 
있습니다. 솔루션은 우발적인 문서 삭제를 방지하고 문서의 모든 버전을 사용할 수 있도록 
보장해야 합니다. 사용자는 문서를 다운로드, 수정 및 업로드할 수 있어야 합니다. 
이러한 요구 사항을 충족하려면 어떤 조합의 조치를 취해야 합니까? (2 개 선택) 
A. 읽기 전용 버킷 ACL 을 활성화합니다. 
B. 버킷에서 버전 관리를 활성화합니다. 
C. IAM 정책을 버킷에 연결합니다. 
D. 버킷에서 MFA 삭제를 활성화합니다. 
E. AWS KMS 를 사용하여 버킷을 암호화합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/95460-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
B. S3 버킷에 여러 버전의 객체를 저장할 수 있습니다. 이렇게 하면 문서를 실수로 덮어쓰거나 
삭제하더라도 모든 버전의 문서를 사용할 수 있습니다. 
D. 버킷의 객체를 우발적으로 삭제하지 않도록 추가 보호 계층을 추가합니다. MFA 삭제가 
활성화된 상태에서 사용자는 버킷에서 객체를 성공적으로 삭제하려면 추가 인증 요소를 제공해야 
합니다. 이를 통해 우발적 삭제 또는 무단 삭제를 방지하고 중요한 문서에 대한 추가 보안 수준을 
제공합니다. 
A. 사용자가 문서를 수정하거나 업로드하는 것을 제한합니다. 사용자가 문서를 다운로드, 수정 및 
업로드할 수 있도록 허용하는 요구 사항을 충족하지 않습니다. 
C. 버킷에 대한 액세스 권한을 제어할 수 있지만 우발적인 삭제를 방지하거나 문서의 모든 버전의 
가용성을 보장하는 요구 사항을 구체적으로 다루지는 않습니다. 
E. 암호화는 버전 관리 및 삭제 방지보다는 데이터 보호에 중점을 둡니다. 
Q257 
회사는 AWS 계정의 모든 애플리케이션에서 Amazon EC2 Auto Scaling 이벤트를 보고하는 
솔루션을 구축하고 있습니다. 회사는 Amazon S3 에 EC2 Auto Scaling 상태 데이터를 저장하기 
위해 서버리스 솔루션을 사용해야 합니다. 그런 다음 회사는 Amazon S3 의 데이터를 사용하여 
대시보드에서 거의 실시간 업데이트를 제공합니다. 솔루션은 EC2 인스턴스 시작 속도에 영향을 
미치지 않아야 합니다. 
회사는 이러한 요구 사항을 충족하기 위해 어떻게 데이터를 Amazon S3 로 이동해야 합니까? 
A. Amazon CloudWatch 지표 스트림을 사용하여 EC2 Auto Scaling 상태 데이터를 Amazon Kinesis 
Data Firehose 로 보냅니다. 데이터를 Amazon S3 에 저장합니다. 
B. Amazon EMR 클러스터를 시작하여 EC2 Auto Scaling 상태 데이터를 수집하고 데이터를 
Amazon Kinesis Data Firehose 로 보냅니다. 데이터를 Amazon S3 에 저장합니다. 
C. Amazon EventBridge 규칙을 생성하여 일정에 따라 AWS Lambda 함수를 호출합니다. EC2 Auto 
Scaling 상태 데이터를 Amazon S3 로 직접 보내도록 Lambda 함수를 구성합니다. 
D. EC2 인스턴스를 시작하는 동안 부트스트랩 스크립트를 사용하여 Amazon Kinesis 에이전트를 
설치합니다. EC2 Auto Scaling 상태 데이터를 수집하고 데이터를 Amazon Kinesis Data Firehose 로 
보내도록 Kinesis 에이전트를 구성합니다. 데이터를 Amazon S3 에 저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95027-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
B. EC2 Auto Scaling 상태 데이터를 수집하고 S3 로 보내는 데 불필요한 복잡성과 오버헤드가 
발생합니다. 이 특정 요구 사항에 가장 효율적인 서버리스 솔루션은 아닙니다. 
C. 실시간으로 트리거되지 않기 때문에 데이터 업데이트가 지연될 수 있습니다. 또한 직접 데이터 
스트림을 사용하는 것과 비교할 때 불필요한 오버헤드와 복잡성이 추가됩니다. 
D. 추가 종속성 및 관리 오버헤드를 도입합니다. 또한 피해야 할 요구 사항인 EC2 인스턴스 시작 
속도에 영향을 미칠 수 있습니다. 
전반적으로 옵션 A 는 CloudWatch 지표 스트림과 Kinesis Data Firehose 를 활용하여 EC2 
인스턴스 시작 속도에 영향을 주지 않고 S3 에서 EC2 Auto Scaling 상태 데이터를 효율적으로 
캡처하고 저장함으로써 간소화된 서버리스 솔루션을 제공합니다. 
설명 2: 
지표 스트림을 사용하여 CloudWatch 지표를 거의 실시간으로 제공하고 낮은 지연 시간으로 
선택한 대상으로 지속적으로 스트리밍할 수 있습니다. 사용 사례 중 하나는 데이터 레이크입니다. 
지표 스트림을 생성하고 CloudWatch 지표를 Amazon S3 와 같은 데이터 레이크에 전달하는 
Amazon Kinesis Data Firehose 전달 스트림으로 보냅니다. 
https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Metric-Stream
s.html 
Q258 
회사에는 매시간 수백 개의 .csv 파일을 Amazon S3 버킷에 배치하는 애플리케이션이 있습니다. 
파일 크기는 1GB 입니다. 파일이 업로드될 때마다 회사는 파일을 Apache Parquet 형식으로 
변환하고 출력 파일을 S3 버킷에 배치해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. .csv 파일을 다운로드하고 파일을 Parquet 형식으로 변환하고 출력 파일을 S3 버킷에 배치하는 
AWS Lambda 함수를 생성합니다. 각 S3 PUT 이벤트에 대해 Lambda 함수를 호출합니다. 
B. Apache Spark 작업을 생성하여 .csv 파일을 읽고, 파일을 Parquet 형식으로 변환하고, 출력 
파일을 S3 버킷에 배치합니다. Spark 작업을 호출하기 위해 각 S3 PUT 이벤트에 대한 AWS 
Lambda 함수를 생성합니다. 
C. 애플리케이션이 .csv 파일을 배치하는 S3 버킷에 대한 AWS Glue 테이블과 AWS Glue 크롤러를 
생성합니다. Amazon Athena 를 주기적으로 사용하여 AWS Glue 테이블을 쿼리하고, 쿼리 결과를 
Parquet 형식으로 변환하고, 출력 파일을 S3 버킷에 배치하도록 AWS Lambda 함수를 예약합니다. 
D. AWS Glue 추출, 변환 및 로드(ETL) 작업을 생성하여 .csv 파일을 Parquet 형식으로 변환하고 
출력 파일을 S3 버킷에 배치합니다. 각 S3 PUT 이벤트에 대한 AWS Lambda 함수를 생성하여 ETL 
작업을 호출합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95028-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. 상당한 운영 오버헤드가 발생합니다. 이 접근 방식에는 Lambda 관리, 동시성 처리, 큰 파일 
크기에 대한 적절한 오류 처리 보장이 필요하며 이는 어려울 수 있습니다. 
B. 불필요한 복잡성과 운영 오버헤드를 추가합니다. Spark 작업 관리, 확장성 처리 및 각 파일 
업로드에 대한 Lambda 호출 조정은 번거로울 수 있습니다. 
C. 추가 복잡성을 도입하고 가장 효율적인 솔루션이 아닐 수 있습니다. 여기에는 Glue 리소스 
관리, Lambda 예약, 새 파일이 업로드되지 않은 경우에도 데이터 쿼리가 포함됩니다. 
옵션 D 는 AWS Glue 의 ETL 기능을 활용하여 규모에 맞게 데이터 변환 작업을 정의하고 실행할 수 
있습니다. 각 S3 PUT 이벤트에 대해 Lambda 함수를 사용하여 ETL 작업을 호출하면 수동 개입 
없이 파일이 Parquet 형식으로 효율적으로 변환되도록 할 수 있습니다. 이 접근 방식은 운영 
오버헤드를 최소화하고 간소화되고 확장 가능한 솔루션을 제공합니다. 
참고: 
https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/patterns/three-aws-glue-etl-j
ob-types-for-converting-data-to-apache-parquet.html 
Q259 
회사는 Amazon RDS DB 인스턴스에서 실행되는 모든 데이터베이스에 대해 새로운 데이터 보존 
정책을 구현하고 있습니다. 회사는 최소 2 년 동안 일일 백업을 유지해야 합니다. 백업은 일관되고 
복원 가능해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 솔루션을 권장해야 합니까? 
A. RDS 백업을 유지하기 위해 AWS Backup 에서 백업 볼트를 생성합니다. 일일 일정과 생성 후 
2 년의 만료 기간으로 새 백업 계획을 생성합니다. 백업 계획에 RDS DB 인스턴스를 할당합니다. 
B. 일일 스냅샷을 위해 RDS DB 인스턴스의 백업 기간을 구성합니다. 각 RDS DB 인스턴스에 
2 년의 스냅샷 보존 정책을 할당합니다. Amazon DLM(Amazon Data Lifecycle Manager)을 사용하여 
스냅샷 삭제를 예약합니다. 
C. 만료 기간이 2 년인 Amazon CloudWatch Logs 에 자동으로 백업되도록 데이터베이스 트랜잭션 
로그를 구성합니다. 
D. AWS Database Migration Service(AWS DMS) 복제 작업을 구성합니다. 복제 인스턴스를 
배포하고 변경 데이터 캡처(CDC) 작업을 구성하여 데이터베이스 변경 사항을 대상으로 Amazon 
S3 에 스트리밍합니다. 2 년 후 스냅샷을 삭제하도록 S3 수명 주기 정책을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95030-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. 중앙 집중식 백업 관리 서비스인 AWS Backup 을 사용하여 RDS 백업을 유지할 것을 
제안합니다. 백업 볼트가 생성되고 일일 일정과 2 년의 백업 보존 기간으로 백업 계획이 
정의됩니다. RDS DB 인스턴스가 이 백업 계획에 할당됩니다. 
B. 일관되고 복원 가능한 백업에 대한 요구 사항을 다루지 않습니다. 스냅샷은 시점 백업이며 
원하는 수준의 일관성을 제공하지 못할 수 있습니다. 
C. 데이터베이스에 필요한 백업 및 복원 기능을 제공하도록 설계되지 않았습니다. 백업의 일관성을 
보장하거나 쉬운 복원 메커니즘을 제공하지 않습니다. 
D. 일일 백업 및 일관된 백업 보존에 대한 요구 사항을 다루지 않습니다. 백업 및 복원보다는 복제 
및 변경 데이터 캡처에 더 중점을 둡니다. 
설명 2: 
AWS Backup 은 사용자가 AWS 서비스 전체에서 데이터 백업을 중앙 집중화하고 자동화할 수 있는 
완전 관리형 서비스입니다. 백업 빈도 및 보존 기간을 지정하는 백업 계획을 생성하고 관리할 수 
있습니다. 또한 백업 데이터를 저장하는 컨테이너인 백업 볼트에 백업 리소스를 할당할 수도 
있습니다 1. 솔루션은 AWS Backup 을 사용하여 RDS 백업이 일관되고 복원 가능하며 최소 2 년 
동안 유지되도록 할 수 있습니다. 
1. 일일 스냅샷을 위해 RDS DB 인스턴스의 백업 기간을 구성합니다. 각 RDS DB 인스턴스에 
2 년의 스냅샷 보존 정책을 할당합니다. Amazon DLM(Amazon Data Lifecycle Manager)을 사용하여 
스냅샷 삭제를 예약합니다. Amazon DLM 은 RDS 스냅샷과 호환되지 않고 스냅샷 삭제를 예약하는 
데 사용할 수 없기 때문에 이 솔루션은 백업의 일관성과 복원 가능성을 보장해야 하는 요구 
사항을 충족하지 않습니다. 
2. 만료 기간이 2 년인 Amazon CloudWatch Logs 에 자동으로 백업되도록 데이터베이스 트랜잭션 
로그를 구성합니다. 이 솔루션은 데이터베이스를 특정 시점으로 복원하는 데 데이터베이스 
트랜잭션 로그가 충분하지 않기 때문에 백업이 일관되고 복원 가능한지 확인해야 하는 요구 
사항을 충족하지 않습니다. 데이터베이스의 전체 상태가 아니라 데이터베이스에 대한 변경 사항만 
캡처합니다. 
3. AWS Database Migration Service(AWS DMS) 복제 작업을 구성합니다. 복제 인스턴스를 배포하고 
변경 데이터 캡처(CDC) 작업을 구성하여 데이터베이스 변경 사항을 대상으로 Amazon S3 에 
스트리밍합니다. 2 년 후 스냅샷을 삭제하도록 S3 수명 주기 정책을 구성합니다. AWS DMS 는 
사용자가 데이터베이스를 백업하는 것이 아니라 AWS 로 데이터베이스를 마이그레이션하는 데 
도움이 되는 서비스이므로 이 솔루션은 백업의 일관성과 복원 가능성을 보장해야 하는 요구 
사항을 충족하지 않습니다. 또한 복제 인스턴스 및 CDC 작업과 같은 추가 리소스 및 구성이 
필요합니다. 
참조 URL: 
https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html 
Q260 
회사의 규정 준수 팀은 파일 공유를 AWS 로 이동해야 합니다. 공유는 Windows Server SMB 파일 
공유에서 실행됩니다. 자체 관리형 온프레미스 Active Directory 는 파일 및 폴더에 대한 액세스를 
제어합니다. 
이 회사는 Windows File Server 용 Amazon FSx 를 솔루션의 일부로 사용하려고 합니다. 회사는 
온프레미스 Active Directory 그룹이 AWS 로 이동한 후 FSx for Windows File Server SMB 규정 준수 
공유, 폴더 및 파일에 대한 액세스를 제한하는지 확인해야 합니다. 이 회사는 Windows 파일 서버 
파일 시스템용 FSx 를 만들었습니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Active Directory 에 연결할 Active Directory 커넥터를 만듭니다. Active Directory 그룹을 IAM 
그룹에 매핑하여 액세스를 제한합니다. 
B. 제한 태그 키와 규정 준수 태그 값을 사용하여 태그를 할당합니다. Active Directory 그룹을 IAM 
그룹에 매핑하여 액세스를 제한합니다. 
C. 액세스를 제한하기 위해 FSx for Windows File Server 에 직접 연결된 IAM 서비스 연결 역할을 
생성합니다. 
D. 파일 시스템을 Active Directory 에 연결하여 액세스를 제한합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95343-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
D. 파일 시스템이 인증 및 액세스 제어를 위해 기존 AD 인프라를 활용할 수 있습니다. 
이 시나리오에서는 AD 그룹을 IAM 그룹에 매핑하는 것이 적용되지 않기 때문에 옵션 A 가 
올바르지 않습니다. IAM 은 주로 AWS 리소스에 대한 액세스를 관리하는 데 사용되지만 요구 
사항은 액세스 제어를 위해 온프레미스 AD 와 통합하는 것입니다. 
Restrict 태그 키와 규정 준수 태그 값이 있는 태그를 할당하면 액세스 제어를 위해 온프레미스 
AD 와의 필수 통합이 제공되지 않기 때문에 옵션 B 는 올바르지 않습니다. 태그는 리소스를 
구성하고 분류하는 데 사용되며 인증 또는 액세스 제어 메커니즘을 제공하지 않습니다. 
FSx for Windows File Server 에 직접 연결된 IAM 서비스 연결 역할 생성이 온프레미스 AD 와 
통합되지 않기 때문에 옵션 C 는 올바르지 않습니다. IAM 역할은 권한 관리를 위해 AWS 내에서 
사용되며 외부 AD 시스템과의 필수 통합을 제공하지 않습니다. 
설명 2: 
FSx for Windows File Server 파일 시스템을 온프레미스 Active Directory 에 결합하면 회사에서 기존 
Active Directory 그룹을 사용하여 AWS 로 이동한 후 파일 공유, 폴더 및 파일에 대한 액세스를 
제한할 수 있습니다. 이 옵션을 사용하면 회사는 기존 액세스 제어 및 관리 구조를 계속 사용하여 
AWS 로 보다 원활하게 전환할 수 있습니다. 
Q261 
한 회사가 최근 전 세계 고객을 대상으로 소매 웹 사이트를 배포한다고 발표했습니다. 웹 사이트는 
Elastic Load Balancer 뒤에 있는 여러 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 
가용 영역의 Auto Scaling 그룹에서 실행됩니다. 
회사는 고객이 웹 사이트에 액세스하는 데 사용하는 장치에 따라 다양한 버전의 콘텐츠를 
고객에게 제공하려고 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? (2 개 
선택) 
A. 여러 버전의 콘텐츠를 캐시하도록 Amazon CloudFront 를 구성합니다. 
B. 트래픽을 다른 인스턴스로 전달하도록 Network Load Balancer 에서 호스트 헤더를 구성합니다. 
C. User-Agent 헤더를 기반으로 사용자에게 특정 객체를 보내도록 Lambda@Edge 함수를 
구성합니다. 
D. AWS Global Accelerator 를 구성합니다. NLB(Network Load Balancer)에 요청을 전달합니다. 다른 
EC2 인스턴스에 대한 호스트 기반 라우팅을 설정하도록 NLB 를 구성합니다. 
E. AWS Global Accelerator 를 구성합니다. NLB(Network Load Balancer)에 요청을 전달합니다. 다른 
EC2 인스턴스에 대한 경로 기반 라우팅을 설정하도록 NLB 를 구성합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/95011-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. 고객이 위치 및 장치 유형에 따라 적절한 버전의 콘텐츠를 받을 수 있습니다. 
C. Lambda@Edge 를 생성하면 들어오는 요청의 User-Agent 헤더를 검사하고 사용 중인 장치 
유형을 확인할 수 있습니다. 이 정보를 기반으로 응답을 사용자 지정하고 적절한 버전의 콘텐츠를 
사용자에게 보낼 수 있습니다. 
B. 장치 유형에 따라 다른 콘텐츠 버전을 제공해야 하는 요구 사항을 다루지 않습니다. 
D. & E.는 장치별 콘텐츠 요구 사항을 다루지 않습니다. 
따라서 옵션 A 와 C 는 고객이 웹 사이트에 액세스하는 데 사용하는 장치에 따라 다양한 버전의 
콘텐츠를 제공해야 하는 요구 사항을 충족하기 위한 올바른 작업 조합입니다. 
설명 
C 의 경우: 향상된 사용자 경험 Lambda@Edge 는 성능 저하 없이 콘텐츠를 개인화할 수 있도록 
하여 전 세계 웹 사이트 및 웹 애플리케이션에 대한 사용자 경험을 개선하는 데 도움을 줄 수 
있습니다. 실시간 이미지 변환 사용자 특성에 따라 즉시 이미지를 변환하여 사용자 경험을 사용자 
정의할 수 있습니다. 예를 들어 뷰어의 장치 유형(모바일, 데스크톱 또는 태블릿)에 따라 이미지 
크기를 조정할 수 있습니다. 또한 CloudFront Edge 위치에서 변환된 이미지를 캐싱하여 이미지를 
제공할 때 성능을 더욱 향상시킬 수 있습니다.  
https://aws.amazon.com/lambda/edge/ 
Q262 
회사에서 다중 계층 웹 애플리케이션에 Amazon ElastiCache 를 사용할 계획입니다. 솔루션 
설계자는 ElastiCache 클러스터용 캐시 VPC 와 애플리케이션의 Amazon EC2 인스턴스용 앱 
VPC 를 생성합니다. 두 VPC 모두 us-east-1 리전에 있습니다. 
솔루션 설계자는 애플리케이션의 EC2 인스턴스에 ElastiCache 클러스터에 대한 액세스 권한을 
제공하는 솔루션을 구현해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. VPC 간에 피어링 연결을 생성합니다. 두 VPC 모두에서 피어링 연결을 위한 라우팅 테이블 
항목을 추가합니다. 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하도록 ElastiCache 
클러스터의 보안 그룹에 대한 인바운드 규칙을 구성합니다. 
B. 전송 VPC 를 생성합니다. 전송 VPC 를 통해 트래픽을 라우팅하도록 캐시 VPC 및 앱 VPC 의 
VPC 라우팅 테이블을 업데이트합니다. 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하도록 
ElastiCache 클러스터의 보안 그룹에 대한 인바운드 규칙을 구성합니다. 
C. VPC 간에 피어링 연결을 생성합니다. 두 VPC 모두에서 피어링 연결을 위한 라우팅 테이블 
항목을 추가합니다. 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하도록 피어링 연결의 
보안 그룹에 대한 인바운드 규칙을 구성합니다. 
D. 전송 VPC 를 생성합니다. 전송 VPC 를 통해 트래픽을 라우팅하도록 캐시 VPC 및 앱 VPC 의 
VPC 라우팅 테이블을 업데이트합니다. 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하도록 
Transit VPC 의 보안 그룹에 대한 인바운드 규칙을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95463-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
VPC 간에 피어링 연결을 생성하는 것은 연결을 설정하는 비용 효율적인 방법입니다. 두 VPC 에서 
피어링 연결을 위한 라우팅 테이블 항목을 추가하면 두 VPC 간에 트래픽이 흐를 수 있습니다. 
ElastiCache 클러스터의 보안 그룹에서 인바운드 규칙을 구성하면 애플리케이션 보안 그룹의 
인바운드 연결이 허용되어 앱 VPC 의 EC2 인스턴스에서 ElastiCache 클러스터에 액세스할 수 
있습니다. 
옵션 B 는 이 시나리오에 불필요한 복잡성과 비용을 추가하는 Transit VPC 생성을 제안합니다. 
옵션 C 는 인바운드 연결을 제어하는 데 ElastiCache 클러스터의 보안 그룹을 사용해야 하므로 
필요하지 않은 피어링 연결의 보안 그룹에 대한 인바운드 규칙 구성을 제안합니다. 
옵션 D 는 Transit VPC 의 보안 그룹에 대한 인바운드 규칙 구성을 제안하며, 이는 이 경우에 
필요하지 않으며 불필요한 복잡성을 추가합니다. 
따라서 옵션 A 는 애플리케이션의 EC2 인스턴스에 ElastiCache 클러스터에 대한 액세스 권한을 
제공하는 가장 비용 효율적인 솔루션입니다. 
설명 2: 
두 VPC 간에 피어링 연결을 생성하고 ElastiCache 클러스터의 보안 그룹에 대한 인바운드 규칙을 
구성하여 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하는 것이 가장 비용 효율적인 
솔루션입니다. 피어링 연결은 무료이며 보안 그룹 규칙을 구성하는 비용만 발생합니다. Transit VPC 
솔루션에는 추가 비용이 발생하는 추가 VPC 및 관련 리소스가 필요합니다. 
https://aws.amazon.com/certification/policies/before-testing/ 
Q263 
회사에서 여러 마이크로서비스로 구성된 애플리케이션을 구축하고 있습니다. 이 회사는 컨테이너 
기술을 사용하여 AWS 에 소프트웨어를 배포하기로 결정했습니다. 회사는 유지 관리 및 확장을 
위한 지속적인 노력을 최소화하는 솔루션이 필요합니다. 회사는 추가 인프라를 관리할 수 
없습니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? (2 개 
선택) 
A. Amazon Elastic Container Service(Amazon ECS) 클러스터를 배포합니다. 
B. 여러 가용 영역에 걸쳐 있는 Amazon EC2 인스턴스에 Kubernetes 제어 평면을 배포합니다. 
C. Amazon EC2 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 서비스를 
배포합니다. 2 보다 크거나 같은 원하는 태스크 번호 레벨을 지정하십시오. 
D. Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 서비스를 배포합니다. 
2 보다 크거나 같은 원하는 태스크 번호 레벨을 지정하십시오. 
E. 여러 가용 영역에 걸쳐 있는 Amazon EC2 인스턴스에 Kubernetes 작업자 노드를 배포합니다. 
각 마이크로 서비스에 대해 두 개 이상의 복제본을 지정하는 배포를 만듭니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/95012-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
옵션 B 와 E 는 Kubernetes 컨트롤 플레인과 작업자 노드를 EC2 인스턴스에 배포할 것을 
제안합니다. 이렇게 하려면 노력을 최소화해야 한다는 요구 사항과 달리 인프라를 관리하고 
지속적인 유지 관리 오버헤드를 추가해야 합니다. 
옵션 C 는 ECS 에 대해 Amazon EC2 시작 유형을 사용할 것을 제안합니다. 이 유형은 여전히 EC2 
인스턴스 관리가 필요하고 Fargate 를 사용하는 것만큼 비용 효율적이고 확장 가능하지 않습니다. 
따라서 Amazon ECS 클러스터와 ECS 서비스를 Fargate 시작 유형(옵션 A 및 D)으로 배포하는 
조합은 추가 인프라를 관리하지 않고 유지 관리 및 확장 노력을 최소화하는 데 가장 적합합니다. 
설명 2: 
AWS Fargate 는 Amazon EC2 인스턴스의 서버 또는 클러스터를 관리할 필요 없이 컨테이너를 
실행하기 위해 Amazon ECS 와 함께 사용할 수 있는 기술입니다. Fargate 를 사용하면 더 이상 
컨테이너를 실행하기 위해 가상 머신의 클러스터를 프로비저닝, 구성 또는 확장할 필요가 
없습니다. 
https://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html 
Q264 
회사에는 Amazon Route 53 에서 전달하는 트래픽이 있는 10 개 이상의 Amazon EC2 인스턴스를 
호스팅하는 웹 애플리케이션이 있습니다. 회사에서 애플리케이션을 검색하려고 할 때 때때로 시간 
초과 오류가 발생합니다. 네트워킹 팀은 일부 DNS 쿼리가 비정상 인스턴스의 IP 주소를 반환하여 
시간 초과 오류가 발생했음을 발견했습니다. 
이러한 시간 초과 오류를 극복하기 위해 솔루션 설계자는 무엇을 구현해야 합니까? 
A. 각 EC2 인스턴스에 대해 Route 53 단순 라우팅 정책 레코드를 생성합니다. 상태 확인을 각 
레코드와 연결합니다. 
B. 각 EC2 인스턴스에 대해 Route 53 장애 조치 라우팅 정책 레코드를 생성합니다. 상태 확인을 
각 레코드와 연결합니다. 
C. EC2 인스턴스를 원본으로 사용하여 Amazon CloudFront 배포를 생성합니다. 상태 확인을 EC2 
인스턴스와 연결합니다. 
D. EC2 인스턴스 앞에서 상태 확인을 통해 Application Load Balancer(ALB)를 생성합니다. 루트 
53 에서 ALB 로 이동합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95345-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
설계자는 ALB 를 생성하고 상태 확인을 구성하여 정상 인스턴스만 트래픽을 수신하도록 합니다. 
ALB 는 구성된 상태 확인 설정을 기반으로 EC2 인스턴스의 상태를 주기적으로 확인합니다. 
Route 53 에서 ALB 로 트래픽을 라우팅하면 DNS 쿼리가 개별 인스턴스 대신 ALB 의 IP 주소를 
반환합니다. 이를 통해 ALB 는 정상 인스턴스에만 트래픽을 분산하여 비정상 인스턴스로 인한 시간 
초과를 방지할 수 있습니다. 
A & B: 상태 확인을 각 레코드와 연결하면 비정상 인스턴스를 식별하는 데 도움이 될 수 있지만 
자동 로드 밸런싱 및 정상 인스턴스에 대한 트래픽 배포를 제공하지 않습니다. 
C: CloudFront 는 성능과 가용성을 향상시킬 수 있지만 기본적으로 CDN 이며 로드 밸런싱 및 정상 
인스턴스에 대한 트래픽 분산 문제를 직접적으로 해결하지 못할 수 있습니다. 
따라서 옵션 D 는 상태 확인이 포함된 ALB 를 구현하고 Route 53 을 통해 트래픽을 라우팅하여 
시간 초과 오류를 극복하는 데 가장 적합한 솔루션입니다. 
설명 2: 
ALB(Application Load Balancer)를 사용하면 들어오는 트래픽을 여러 백엔드 인스턴스에 분산하고 
비정상 인스턴스에서 트래픽을 제거하면서 정상 인스턴스로 트래픽을 자동으로 라우팅할 수 
있습니다. EC2 인스턴스 앞에 ALB 를 사용하고 Route 53 에서 ALB 로 트래픽을 라우팅함으로써 
로드 밸런서는 인스턴스에 대한 상태 확인을 수행하고 정상 인스턴스로만 트래픽을 라우팅할 수 
있으므로 비정상 인스턴스로 인한 시간 초과 오류를 줄이거나 제거하는 데 도움이 됩니다.  
Q265 
솔루션 설계자는 웹, 애플리케이션 및 데이터베이스 계층으로 구성된 고가용성 애플리케이션을 
설계해야 합니다. HTTPS 콘텐츠 전송은 전송 시간을 최소화하면서 가능한 한 에지에 가까워야 
합니다. 
이러한 요구 사항을 충족하고 가장 안전한 솔루션은 무엇입니까? 
A. 퍼블릭 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 Application Load 
Balancer(ALB)를 구성합니다. 퍼블릭 ALB 를 오리진으로 사용하여 HTTPS 콘텐츠를 제공하도록 
Amazon CloudFront 를 구성합니다. 
B. 프라이빗 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 Application Load Balancer 를 
구성합니다. EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 제공하도록 Amazon 
CloudFront 를 구성합니다. 
C. 프라이빗 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 ALB(Application Load 
Balancer)를 구성합니다. 퍼블릭 ALB 를 오리진으로 사용하여 HTTPS 콘텐츠를 제공하도록 
Amazon CloudFront 를 구성합니다. 
D. 퍼블릭 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 Application Load Balancer 를 
구성합니다. EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 제공하도록 Amazon 
CloudFront 를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95013-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. EC2 인스턴스를 퍼블릭 인터넷에 직접 노출하므로 보안이 손상될 수 있습니다. 
B. 효율적인 부하 분산과 고가용성을 위해 필요한 퍼블릭 서브넷의 부하 분산 장치가 부족합니다. 
D. 로드 밸런싱 및 HTTPS 콘텐츠 전송을 제공하며 EC2 인스턴스를 공용 인터넷에 직접 
노출하므로 보안 위험이 발생할 수 있습니다. 
C. 퍼블릭 ALB 를 오리진으로 하는 CloudFront 를 사용하여 고가용성, 프라이빗 서브넷을 통한 
보안 액세스 및 최적화된 HTTPS 콘텐츠 전송을 제공합니다. 
설명 2: 
이 솔루션은 웹, 애플리케이션 및 데이터베이스 계층이 있는 고가용성 애플리케이션에 대한 요구 
사항을 충족할 뿐만 아니라 에지 기반 콘텐츠 전달을 제공합니다. 또한 웹 서버에 대한 직접 
액세스를 제한하는 프라이빗 서브넷에 ALB 를 두어 보안을 최대화하는 동시에 퍼블릭 ALB 를 통해 
인터넷을 통해 트래픽을 제공할 수 있습니다. 이렇게 하면 웹 서버가 공용 인터넷에 노출되지 
않으므로 공격 표면이 줄어들고 애플리케이션에 안전하게 액세스할 수 있습니다. 
Q266 
회사에는 AWS 에서 실행되는 인기 있는 게임 플랫폼이 있습니다. 대기 시간은 사용자 경험에 
영향을 미치고 일부 플레이어에게 부당한 이점을 제공할 수 있기 때문에 애플리케이션은 대기 
시간에 민감합니다. 애플리케이션은 모든 AWS 리전에 배포됩니다. Application Load Balancer(ALB) 
뒤에 구성된 Auto Scaling 그룹의 일부인 Amazon EC2 인스턴스에서 실행됩니다. 솔루션 설계자는 
애플리케이션의 상태를 모니터링하고 트래픽을 정상 엔드포인트로 리디렉션하는 메커니즘을 
구현해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Global Accelerator 에서 액셀러레이터를 구성합니다. 애플리케이션이 청취하는 포트에 대한 
리스너를 추가하고 각 리전의 리전 엔드포인트에 연결합니다. ALB 를 엔드포인트로 추가하십시오. 
B. Amazon CloudFront 배포를 생성하고 ALB 를 원본 서버로 지정합니다. 원본 캐시 헤더를 
사용하도록 캐시 동작을 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화하십시오. 
C. Amazon CloudFront 배포를 생성하고 Amazon S3 를 원본 서버로 지정합니다. 원본 캐시 헤더를 
사용하도록 캐시 동작을 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화하십시오. 
D. 애플리케이션의 데이터 저장소 역할을 하도록 Amazon DynamoDB 데이터베이스를 구성합니다. 
애플리케이션 데이터를 호스팅하는 DynamoDB 의 인 메모리 캐시 역할을 할 DynamoDB 
Accelerator(DAX) 클러스터를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95014-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
B. CloudFront 는 캐싱 및 콘텐츠 전송에 도움이 될 수 있지만 애플리케이션의 상태를 
모니터링하거나 상태 확인을 기반으로 트래픽 리디렉션을 수행하는 메커니즘을 제공하지 않습니다. 
C. 이 구성은 정적 콘텐츠 전달에 적합하지만 응용 프로그램의 상태 모니터링 및 트래픽 리디렉션 
요구 사항을 다루지 않습니다. 
D. 이렇게 하면 성능이 향상될 수 있지만 애플리케이션의 상태를 모니터링하거나 상태 확인을 
기반으로 트래픽을 리디렉션하지 않습니다. 
따라서 옵션 A 는 AWS Global Accelerator 를 활용하여 애플리케이션 상태를 모니터링하고, 
트래픽을 정상 엔드포인트로 라우팅하고, 지연 시간 문제를 해결하면서 사용자 경험을 
최적화하므로 가장 적합한 솔루션입니다. 
설명 2: 
AWS Global Accelerator 는 상태 확인을 기반으로 최적의 정상 엔드포인트로 트래픽을 전달하고 
클라이언트의 지리적 위치를 기반으로 가장 가까운 정상 엔드포인트로 트래픽을 라우팅할 수도 
있습니다. 액셀러레이터를 구성하고 이를 각 리전의 지역 엔드포인트에 연결하고 ALB 를 
엔드포인트로 추가함으로써 솔루션은 트래픽을 정상 엔드포인트로 리디렉션하여 대기 시간을 
줄이고 애플리케이션이 최적으로 실행되도록 함으로써 사용자 경험을 개선합니다. 이 솔루션은 
트래픽이 가장 가까운 정상 엔드포인트로 전달되도록 하고 전반적인 사용자 경험을 개선하는 데 
도움이 됩니다. 
Q267 
회사에 모바일 앱을 사용하는 백만 명의 사용자가 있습니다. 회사는 거의 실시간으로 데이터 
사용량을 분석해야 합니다. 회사는 또한 거의 실시간으로 데이터를 암호화하고 추가 처리를 위해 
데이터를 Apache Parquet 형식의 중앙 위치에 저장해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Kinesis 데이터 스트림을 생성하여 Amazon S3 에 데이터를 저장합니다. 데이터를 
분석할 Amazon Kinesis Data Analytics 애플리케이션을 생성합니다. AWS Lambda 함수를 호출하여 
데이터를 Kinesis Data Analytics 애플리케이션으로 보냅니다. 
B. Amazon Kinesis 데이터 스트림을 생성하여 Amazon S3 에 데이터를 저장합니다. 데이터를 
분석할 Amazon EMR 클러스터를 생성합니다. AWS Lambda 함수를 호출하여 데이터를 EMR 
클러스터로 보냅니다. 
C. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 Amazon S3 에 데이터를 저장합니다. 
데이터를 분석할 Amazon EMR 클러스터를 생성합니다. 
D. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 Amazon S3 에 데이터를 저장합니다. 
데이터를 분석할 Amazon Kinesis Data Analytics 애플리케이션을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/95347-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. 데이터를 분석 애플리케이션으로 보내려면 Lambda 를 호출해야 합니다. 이로 인해 추가적인 
운영 오버헤드와 복잡성이 발생합니다. 
B. EMR 은 빅 데이터 처리를 위한 강력한 도구이지만 Kinesis Data Analytics 에 비해 더 많은 운영 
관리 및 구성이 필요합니다. 
C. Kinesis Data Analytics 가 보다 간소화되고 자동화된 방식으로 분석을 수행할 때 데이터 분석에 
EMR 을 포함하여 불필요한 복잡성을 도입합니다. 
따라서 옵션 D 는 데이터 수집에 Kinesis Data Firehose 를 활용하고 S3 에 데이터를 저장하며 거의 
실시간 분석을 위해 Kinesis Data Analytics 를 활용하여 데이터 사용 분석 및 암호화를 위한 운영 
오버헤드가 낮은 솔루션을 제공하므로 가장 적합한 솔루션입니다. . 
설명 2: 
이 솔루션은 거의 실시간으로 데이터 수집, 데이터 변환, 암호화 및 데이터 저장을 자동으로 
처리할 수 있는 완전관리형 서비스인 Amazon Kinesis Data Firehose 를 사용하므로 최소한의 운영 
오버헤드로 요구 사항을 충족합니다. Kinesis Data Firehose 는 추가 처리를 위해 Amazon S3 에 
Apache Parquet 형식으로 데이터를 자동으로 저장할 수 있습니다. 
또한 Amazon Kinesis Data Analytics 애플리케이션을 생성하여 인프라를 관리하거나 Lambda 
함수를 호출할 필요 없이 거의 실시간으로 데이터를 분석할 수 있습니다. 이렇게 하면 최소한의 
운영 오버헤드로 많은 양의 데이터를 처리할 수 있습니다. 
Q268 
게임 회사에는 점수를 표시하는 웹 애플리케이션이 있습니다. 애플리케이션은 Application Load 
Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon RDS for MySQL 
데이터베이스에 데이터를 저장합니다. 사용자는 데이터베이스 읽기 성능으로 인해 긴 지연과 
중단을 경험하기 시작했습니다. 회사는 애플리케이션 아키텍처의 변경을 최소화하면서 사용자 
경험을 개선하고자 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 데이터베이스 앞에서 Amazon ElastiCache 를 사용하십시오. 
B. 애플리케이션과 데이터베이스 간에 RDS 프록시를 사용합니다. 
C. 애플리케이션을 EC2 인스턴스에서 AWS Lambda 로 마이그레이션합니다. 
D. MySQL 용 Amazon RDS 에서 Amazon DynamoDB 로 데이터베이스를 마이그레이션합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/95016-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A. ElastiCache 는 자주 액세스하는 데이터를 캐싱하여 읽기 성능을 향상시킬 수 있지만 
애플리케이션 아키텍처를 변경해야 합니다. 또한 특히 애플리케이션의 데이터베이스 사용에 복잡한 
쿼리 또는 빈번한 데이터 업데이트가 포함되는 경우 RDS Proxy 와 동일한 수준의 읽기 성능 
향상을 제공하지 못할 수 있습니다. 
C. Lambda 는 확장성 및 운영 오버헤드 감소와 같은 이점을 제공할 수 있지만 데이터베이스 읽기 
성능 문제를 직접 해결하지 못할 수 있습니다. Lambda 로 마이그레이션하려면 애플리케이션의 
아키텍처 및 코드베이스를 크게 변경해야 합니다. 
D. DynamoDB 는 확장 가능한 고성능 NoSQL 데이터베이스이지만 MySQL 과 같은 관계형 
데이터베이스에서 DynamoDB 로 마이그레이션하려면 애플리케이션의 데이터 모델과 쿼리 패턴을 
크게 변경해야 합니다. 
따라서 옵션 B 는 RDS Proxy 를 활용하여 데이터베이스 연결을 최적화하고 읽기 성능을 개선하고 
애플리케이션 아키텍처의 변경을 최소화하며 데이터베이스 읽기 성능 문제를 해결하기 위한 확장 
가능하고 효율적인 솔루션을 제공하므로 가장 적합한 솔루션입니다. 
Q269 
전자 상거래 회사는 Amazon RDS 기반 웹 애플리케이션의 성능 저하를 발견했습니다. 성능 저하의 
원인은 비즈니스 분석가가 트리거하는 읽기 전용 SQL 쿼리 수가 증가했기 때문입니다. 솔루션 
설계자는 기존 웹 애플리케이션에 대한 최소한의 변경으로 문제를 해결해야 합니다. 
솔루션 설계자는 무엇을 추천해야 합니까? 
A. 데이터를 Amazon DynamoDB 로 내보내고 비즈니스 분석가가 쿼리를 실행하도록 합니다. 
B. Amazon ElastiCache 에 데이터를 로드하고 비즈니스 분석가가 쿼리를 실행하도록 합니다. 
C. 기본 데이터베이스의 읽기 복제본을 생성하고 비즈니스 분석가가 쿼리를 실행하도록 합니다. 
D. 데이터를 Amazon Redshift 클러스터로 복사하고 비즈니스 분석가가 쿼리를 실행하도록 합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95032-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 1: 
A. DynamoDB 는 확장 가능한 NoSQL 데이터베이스이지만 애플리케이션의 데이터 모델 및 쿼리 
패턴을 변경해야 합니다. 
B. ElastiCache 는 쿼리 성능을 향상시킬 수 있는 인메모리 데이터 저장소이지만 주로 복잡한 
쿼리를 실행하기보다는 캐싱에 사용됩니다. 
D. Redshift 는 강력한 데이터 웨어하우징 솔루션이지만 데이터를 마이그레이션하고 쿼리를 
Redshift 의 열 기반 아키텍처에 적용하려면 애플리케이션 및 쿼리 논리를 크게 변경해야 합니다. 
따라서 옵션 C 는 RDS 의 읽기 전용 복제본을 활용하여 기본 데이터베이스에서 읽기 전용 쿼리 
트래픽을 오프로드하므로 비즈니스 분석가가 웹 애플리케이션의 성능에 영향을 주지 않고 쿼리를 
실행할 수 있으므로 가장 적합한 권장 사항입니다. 기존 웹 애플리케이션에 대한 최소한의 
변경으로 확장 가능하고 효율적인 솔루션을 제공합니다. 
설명 2: 
기본 RDS 데이터베이스의 읽기 복제본을 생성하면 기본 데이터베이스에서 읽기 전용 SQL 쿼리를 
오프로드하여 웹 애플리케이션의 성능을 향상시키는 데 도움이 됩니다. 읽기 복제본은 읽기 전용 
트래픽을 처리하는 데 사용할 수 있는 기본 데이터베이스의 정확한 복사본으로, 기본 
데이터베이스의 부하를 줄이고 웹 애플리케이션의 성능을 향상시킵니다. 이 솔루션은 기존 웹 
애플리케이션에 대한 최소한의 변경으로 구현할 수 있습니다. 
분석가는 코드를 수정하지 않고 읽기 복제본에서 쿼리를 계속 실행할 수 있습니다. 
Q270 
회사는 중앙 집중식 AWS 계정을 사용하여 다양한 Amazon S3 버킷에 로그 데이터를 저장합니다. 
솔루션 설계자는 데이터가 S3 버킷에 업로드되기 전에 미사용 데이터가 암호화되었는지 확인해야 
합니다. 또한 데이터는 전송 중에 암호화되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 클라이언트 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다. 
B. 서버 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다. 
C. S3 업로드를 위해 S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용해야 하는 버킷 
정책을 만듭니다. 
D. 기본 AWS Key Management Service(AWS KMS) 키를 사용하여 S3 버킷을 암호화하는 보안 
옵션을 활성화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/95031-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
클라이언트 측 암호화는 데이터를 Amazon S3 에 업로드하기 전에 데이터를 암호화하는 방법입니다. 
이를 통해 사용자는 암호화 프로세스, 암호화 키 및 관련 도구를 관리할 수 있습니다. 클라이언트 
측 암호화를 사용하면 Amazon S3 가 암호화 키나 암호화되지 않은 데이터에 액세스할 수 없기 
때문에 솔루션은 유휴 및 전송 중에 데이터를 암호화할 수 있습니다. 
Q271 
솔루션 설계자는 원하는 Amazon EC2 용량에 도달하기 전에 야간 배치 처리 작업이 1 시간 동안 
자동으로 확장되는 것을 관찰합니다. 최대 용량은 '매일 밤 동일하고 배치 작업은 항상 오전 1 시에 
시작됩니다. 솔루션 설계자는 원하는 EC2 용량에 빠르게 도달하고 배치 작업이 완료된 후 Auto 
Scaling 그룹이 축소될 수 있는 비용 효율적인 솔루션을 찾아야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Auto Scaling 그룹의 최소 용량을 늘립니다. 
B. Auto Scaling 그룹의 최대 용량을 늘립니다. 
C. 원하는 컴퓨팅 수준으로 확장하도록 예약된 확장을 구성합니다. 
D. 각 조정 작업 중에 더 많은 EC2 인스턴스를 추가하도록 조정 정책을 변경합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/95018-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
예약된 조정을 구성하여 솔루션 설계자는 배치 작업이 시작될 때 특정 시간(IAM)에 원하는 컴퓨팅 
수준으로 자동으로 확장한 다음 작업이 완료되면 자동으로 축소하도록 Auto Scaling 그룹을 설정할 
수 있습니다. 이렇게 하면 원하는 EC2 용량에 빠르게 도달할 수 있고 비용 절감에도 도움이 
됩니다. 
Q272 
회사는 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 인스턴스 플릿에서 동적 웹 
사이트를 제공합니다. 웹 사이트는 전 세계 고객에게 서비스를 제공하기 위해 여러 언어를 
지원해야 합니다. 웹 사이트의 아키텍처는 us-west-1 지역에서 실행 중이며 세계의 다른 지역에 
있는 사용자에 대해 높은 요청 지연 시간을 보이고 있습니다. 
웹사이트는 사용자의 위치에 관계없이 빠르고 효율적으로 요청을 처리해야 합니다. 그러나 회사는 
여러 지역에 걸쳐 기존 아키텍처를 다시 생성하기를 원하지 않습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 기존 아키텍처를 Amazon S3 버킷에서 제공되는 웹 사이트로 교체하십시오. S3 버킷을 
오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. Accept-Language 요청 헤더를 
기반으로 캐시 동작 설정을 캐시로 설정합니다. 
B. ALB 를 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. Accept-Language 요청 
헤더를 기반으로 캐시 동작 설정을 캐시로 설정합니다. 
C. ALB 와 통합되는 Amazon API Gateway API 를 생성합니다. HTTP 통합 유형을 사용하도록 API 를 
구성합니다. Accept-Language 요청 헤더를 기반으로 API 캐시를 활성화하도록 API Gateway 
단계를 설정합니다. 
D. 각 추가 지역에서 EC2 인스턴스를 시작하고 해당 지역의 캐시 서버 역할을 하도록 NGINX 를 
구성합니다. 지리적 위치 라우팅 정책을 사용하여 Amazon Route 53 레코드 세트 뒤에 모든 EC2 
인스턴스와 ALB 를 배치합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99865-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고:・ 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/header-caching.
html 
Q273 
빠르게 성장하는 전자상거래 회사는 단일 AWS 리전에서 워크로드를 실행하고 있습니다. 솔루션 
설계자는 다른 AWS 리전을 포함하는 재해 복구(DR) 전략을 생성해야 합니다. 회사는 대기 시간을 
최소화하면서 DR 지역에서 데이터베이스를 최신 상태로 유지하기를 원합니다. DR 지역의 나머지 
인프라는 감소된 용량으로 실행되어야 하며 필요한 경우 확장할 수 있어야 합니다. 
가장 낮은 RTO(복구 시간 목표)로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 파일럿 라이트 배포와 함께 Amazon Aurora 글로벌 데이터베이스를 사용합니다. 
B. 웜 대기 배포와 함께 Amazon Aurora 글로벌 데이터베이스를 사용합니다. 
C. 파일럿 라이트 배포와 함께 Amazon RDS 다중 AZ DB 인스턴스를 사용합니다. 
D. 웜 대기 배포와 함께 Amazon RDS 다중 AZ DB 인스턴스를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99505-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
・웜 스탠바이는 감소된 수준의 트래픽을 즉시 처리할 수 있습니다. 그런 다음 이 기존 배포를 
확장해야 하므로 파일럿 라이트보다 RTO 시간이 더 짧습니다. 파일럿 라이트를 사용하려면 먼저 
인프라를 배포한 다음 워크로드가 요청을 처리할 수 있기 전에 리소스를 확장해야 하기 
때문입니다. 
https://aws.amazon.com/ko/blogs/architecture/disaster-recovery-dr-architecture-on-aws-part-
iii-pilot-light-and-warm-standby/ 
A(X) : 파일럿 라이트를 사용하기 때문에 오답. 
B(O) : Amazon Aurora 글로벌 데이터베이스는 여러 리전에 걸쳐 자동으로 복제를 진행 
Amazon Aurora Global Database 는 단일 Amazon Aurora 데이터베이스를 여러 AWS 리전으로 
확장할 수 있는 기능입니다. 데이터베이스 성능에 전혀 영향을 주지 않고 데이터를 복제하고, 각 
리전에서 보통 1 초 미만의 짧은 대기 시간으로 빠른 로컬 읽기를 지원하며, 리전 규모의 가동 
중단 발생 시 재해 복구를 제공합니다."" https://aws.amazon.com/ko/rds/aurora/faqs/ 
C(X) : 파일럿 라이트를 사용하기 때문에 오답. 
D(X) : RDS Multi AZ 는 동일 리전 내로 한정됨. 
Amazon RDS 다중 AZ 배포는 단일 AWS 리전 내의 데이터베이스 인스턴스에 대한 향상된 
가용성을 제공합니다. 
https://aws.amazon.com/ko/about-aws/whats-new/2018/01/amazon-rds-read-replicas-now-s
upport-multi-az-deployments/ 
Q274 
회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 애플리케이션에 재해 
복구(DR) 솔루션을 구현해야 합니다. DR 솔루션은 RTO(복구 시간 목표)가 4 시간 미만이어야 
합니다. 또한 DR 솔루션은 정상 작동 중에 가능한 한 적은 AWS 리소스를 사용해야 합니다. 
운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon 머신 이미지(AMI)를 생성하여 EC2 인스턴스를 백업합니다. AMI 를 보조 AWS 리전에 
복사합니다. AWS Lambda 및 사용자 지정 스크립트를 사용하여 보조 리전에서 인프라 배포를 
자동화합니다. 
B. Amazon 머신 이미지(AMI)를 생성하여 EC2 인스턴스를 백업합니다. AMI 를 보조 AWS 리전에 
복사합니다. AWS CloudFormation 을 사용하여 보조 리전에서 인프라 배포를 자동화합니다. 
C. 보조 AWS 리전에서 EC2 인스턴스를 시작합니다. 보조 리전의 EC2 인스턴스를 항상 활성 
상태로 유지하십시오. 
D. 보조 가용 영역에서 EC2 인스턴스를 시작합니다. 보조 가용 영역의 EC2 인스턴스를 항상 활성 
상태로 유지합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99459-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이를 통해 회사는 RTO(복구 시간 목표)가 4 시간 미만이고 정상 운영 중에 AWS 리소스를 최대한 
적게 사용하는 애플리케이션에 대한 재해 복구(DR) 솔루션을 구현할 수 있습니다. Amazon 머신 
이미지(AMI)를 생성하여 EC2 인스턴스를 백업하고 AMI 를 보조 AWS 리전에 복사함으로써 회사는 
애플리케이션의 특정 시점 스냅샷을 생성하고 이를 다른 지리적 위치에 저장할 수 있습니다. AWS 
CloudFormation 을 사용하여 보조 지역의 인프라 배포를 자동화함으로써 회사는 재해 발생 시 
템플릿에서 리소스 스택을 신속하게 시작할 수 있습니다. 이는 EC2 인스턴스용 DR 솔루션을 
구현하는 비용 효율적이고 운영 효율적인 방법입니다. 
Q275 
회사에서 내부 브라우저 기반 애플리케이션을 실행합니다. 애플리케이션은 Application Load 
Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 가용 영역에 걸쳐 
Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 근무 시간 동안 최대 20 개의 
인스턴스로 확장되지만 밤에는 2 개의 인스턴스로 축소됩니다. 오전 중반까지는 잘 돌아가는데도 
하루가 시작되면 애플리케이션이 매우 느리다고 직원들이 불평하고 있다. 
직원 불만을 해결하고 비용을 최소화하기 위해 확장을 어떻게 변경해야 합니까? 
A. 사무실이 열리기 직전에 원하는 수용 인원을 20 명으로 설정하는 예약 작업을 구현합니다. 
B. 더 낮은 CPU 임계값에서 트리거되는 단계 조정 작업을 구현하고 휴지 기간을 줄입니다. 
C. 더 낮은 CPU 임계값에서 트리거되는 대상 추적 작업을 구현하고 휴지 기간을 줄입니다. 
D. 사무실이 열리기 직전에 최소 및 최대 수용 인원을 20 명으로 설정하는 예약 조치를 
구현합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99584-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 아침에 용량을 더 빠르게 확장하여 성능을 개선하지만 작업 외 시간에도 여전히 용량을 
축소할 수 있습니다. 다음과 같이 이를 달성합니다. 
* 대상 추적 작업은 CPU 사용률 대상에 따라 확장됩니다. 아침에 더 낮은 CPU 임계값에서 
트리거함으로써 Auto Scaling 그룹은 트래픽이 증가함에 따라 더 빨리 확장을 시작하여 사용률이 
너무 높아져 성능에 영향을 미치기 전에 인스턴스를 시작합니다. 
* 휴지 기간을 줄이면 Auto Scaling 이 보다 적극적으로 확장하여 목표에 도달할 때까지 더 많은 
인스턴스를 더 빠르게 시작할 수 있습니다. 이렇게 하면 용량 증가 속도가 빨라집니다. 
* 그러나 고정된 최소/최대 용량을 설정하는 예약된 작업과 달리 대상 추적을 사용하면 수요에 
따라 근무 외 시간에도 그룹을 축소할 수 있습니다. 이는 비용을 최소화하는 데 도움이 됩니다. 
Q276 
한 회사에 Auto Scaling 그룹의 여러 Amazon EC2 인스턴스에 배포된 다중 계층 애플리케이션이 
있습니다. Amazon RDS for Oracle 인스턴스는 Oracle 관련 PL/SQL 기능을 사용하는 
애플리케이션의 데이터 계층입니다. 애플리케이션에 대한 트래픽은 꾸준히 증가하고 있습니다. 
이로 인해 EC2 인스턴스가 과부하되고 RDS 인스턴스의 스토리지가 부족해집니다. Auto Scaling 
그룹에는 조정 지표가 없으며 최소 정상 인스턴스 수만 정의합니다. 이 회사는 트래픽이 안정되기 
전에 꾸준하지만 예측할 수 없는 속도로 계속 증가할 것이라고 예측합니다. 
증가된 트래픽에 대해 시스템이 자동으로 확장될 수 있도록 하려면 솔루션 설계자가 무엇을 해야 
합니까? (2 개 선택) 
A. RDS for Oracle 인스턴스에서 스토리지 Auto Scaling 을 구성합니다. 
B. Auto Scaling 스토리지를 사용하려면 데이터베이스를 Amazon Aurora 로 마이그레이션하십시오. 
C. 사용 가능한 저장 공간 부족에 대해 Oracle 인스턴스용 RDS 에서 경보를 구성합니다. 
D. 평균 CPU 를 조정 지표로 사용하도록 Auto Scaling 그룹을 구성합니다. 
E. 평균 여유 메모리를 조정 지표로 사용하도록 Auto Scaling 그룹을 구성합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/99739-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Auto Scaling Storage RDS 는 스토리지 문제를 완화하고 Oracle Pl/Sql 을 Aurora 로 
마이그레이션하는 것은 번거롭습니다. 또한 Aurora 에는 기본적으로 자동 스토리지 확장 기능이 
있습니다. 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#U
SER_PIOPS.Autoscaling 
Q277 
회사는 비디오 콘텐츠를 게시하고 모든 모바일 플랫폼에서 사용할 수 있도록 트랜스코딩하는 
온라인 서비스를 제공합니다. 애플리케이션 아키텍처는 Amazon Elastic File System(Amazon EFS) 
Standard 를 사용하여 여러 Amazon EC2 Linux 인스턴스가 처리를 위해 비디오 콘텐츠에 액세스할 
수 있도록 비디오를 수집하고 저장합니다. 시간이 지남에 따라 서비스의 인기가 높아짐에 따라 
스토리지 비용이 너무 비싸졌습니다. 
가장 비용 효율적인 스토리지 솔루션은 무엇입니까? 
A. 파일용 AWS Storage Gateway 를 사용하여 동영상 콘텐츠를 저장하고 처리합니다. 
B. 볼륨에 AWS Storage Gateway 를 사용하여 비디오 콘텐츠를 저장하고 처리합니다. 
C. Amazon EFS 를 사용하여 비디오 콘텐츠를 저장합니다. 처리가 완료되면 파일을 Amazon Elastic 
Block Store(Amazon EBS)로 전송합니다. 
D. 동영상 콘텐츠 저장을 위해 Amazon S3 를 사용합니다. 처리를 위해 파일을 서버에 연결된 
Amazon Elastic Block Store(Amazon EBS) 볼륨으로 임시로 이동합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99509-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
* 비디오 콘텐츠의 대규모, 내구성 및 저렴한 스토리지를 위한 Amazon S3. S3 스토리지 비용은 
EFS 보다 훨씬 저렴합니다. 
* Amazon EBS 는 처리 중에 일시적으로만 가능합니다. 비디오를 처리해야 할 때만 EBS 볼륨을 
마운트하고 그 후에 마운트를 해제함으로써 컨텐츠가 고가의 EBS 스토리지에 소요되는 시간을 
최소화합니다. 
* EBS 볼륨은 활성 처리에 필요한 워크로드에 맞게 크기를 조정하여 비용을 낮출 수 있습니다. 
볼륨은 전체 비디오 라이브러리를 장기간 저장할 필요가 없습니다. 
Q278 
회사에서 계층적 구조 관계로 직원 데이터를 저장하는 애플리케이션을 만들고자 합니다. 회사는 
직원 데이터에 대한 트래픽이 많은 쿼리에 대한 최소 대기 시간 응답이 필요하며 민감한 데이터를 
보호해야 합니다. 회사는 또한 직원 데이터에 재무 정보가 있는 경우 월별 이메일 메시지를 받아야 
합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (2 개 
선택) 
A. Amazon Redshift 를 사용하여 직원 데이터를 계층에 저장하십시오. 매월 Amazon S3에 데이터를 
언로드합니다. 
B. Amazon DynamoDB 를 사용하여 직원 데이터를 계층에 저장합니다. 매월 데이터를 Amazon 
S3 로 내보냅니다. 
C. AWS 계정에 대해 Amazon Macie 를 구성합니다. Macie 를 Amazon EventBridge 와 통합하여 
월별 이벤트를 AWS Lambda 로 전송합니다. 
D. Amazon Athena 를 사용하여 Amazon S3 에서 직원 데이터를 분석합니다. Athena 를 Amazon 
QuickSight 와 통합하여 분석 대시보드를 게시하고 사용자와 대시보드를 공유합니다. 
E. AWS 계정에 대해 Amazon Macie 를 구성합니다. Macie 를 Amazon EventBridge 와 통합하여 
Amazon Simple Notification Service(Amazon SNS) 구독을 통해 월별 알림을 보냅니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/99940-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고: 
https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/dynamodb-hierarchical-data-
model/introduction.html 
Q279 
회사에 Amazon DynamoDB 테이블이 지원하는 애플리케이션이 있습니다. 회사의 규정 준수 요구 
사항은 데이터베이스 백업을 매월 수행하고 6개월 동안 사용할 수 있어야 하며 7년 동안 유지해야 
한다고 지정합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 매월 1 일에 DynamoDB 테이블을 백업하는 AWS Backup 계획을 생성합니다. 6 개월 후 백업을 
콜드 스토리지로 전환하는 수명 주기 정책을 지정합니다. 각 백업의 보존 기간을 7 년으로 
설정합니다. 
B. 매월 1 일에 DynamoDB 테이블의 DynamoDB 온디맨드 백업을 생성합니다. 6 개월 후 백업을 
Amazon S3 Glacier Flexible Retrieval 로 전환합니다. 7 년보다 오래된 백업을 삭제하려면 S3 수명 
주기 정책을 생성하십시오. 
C. AWS SDK 를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성하는 스크립트를 개발합니다. 
매월 1 일에 스크립트를 실행하는 Amazon EventBridge 규칙을 설정합니다. 6 개월 이상 된 
DynamoDB 백업을 콜드 스토리지로 전환하고 7 년 이상 된 백업을 삭제하기 위해 매월 2 일에 
실행할 두 번째 스크립트를 생성합니다. 
D. AWS CLI 를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성합니다. Cron 표현식을 
사용하여 매월 1 일에 명령을 실행하는 Amazon EventBridge 규칙을 설정합니다. 6 개월 후 백업을 
콜드 스토리지로 전환하고 7 년 후 백업을 삭제하도록 명령에 지정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99793-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 솔루션은 다음과 같은 요구 사항을 충족합니다. 
* AWS Backup 은 백업 계획에 정의된 일정(매월 1 일)에 따라 DynamoDB 테이블의 전체 백업을 
자동으로 수행합니다. 
* 수명 주기 정책은 6 개월 후에 백업을 콜드 스토리지로 전환하여 해당 요구 사항을 충족할 수 
있습니다. 
* 백업 계획에서 7 년 보존 기간을 설정하면 필요에 따라 각 백업이 7 년 동안 보존됩니다. 
* AWS Backup 은 백업 작업 및 수명 주기 정책을 관리하므로 사용자 지정 스크립팅 또는 관리가 
필요하지 않습니다. 
Q280 
회사는 웹 사이트에서 Amazon CloudFront 를 사용하고 있습니다. 회사는 CloudFront 배포에서 
로깅을 활성화했으며 로그는 회사의 Amazon S3 버킷 중 하나에 저장됩니다. 회사는 로그에 대한 
고급 분석을 수행하고 시각화를 구축해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon Athena 에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 
AWS Glue 로 결과를 시각화합니다. 
B. Amazon Athena 에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 
Amazon QuickSight 로 결과를 시각화합니다. 
C. Amazon DynamoDB 에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 
AWS Glue 로 결과를 시각화합니다. 
D. Amazon DynamoDB 에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 
Amazon QuickSight 로 결과를 시각화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99508-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
https://docs.aws.amazon.com/quicksight/latest/user/welcome.html 
Athena 를 사용하여 S3 버킷의 CloudFront 로그를 쿼리하고 QuickSight 를 사용하여 결과를 
시각화하는 것이 비용 효율적이고 확장 가능하며 인프라 설정이 필요하지 않기 때문에 최상의 
솔루션입니다. 또한 전담 개발자 팀 없이 회사에서 고급 분석을 수행하고 대화형 시각화를 구축할 
수 있는 강력한 솔루션을 제공합니다. 
Q281 
회사는 PostgreSQL DB 인스턴스용 Amazon RDS 를 사용하여 웹 서버 플릿을 실행합니다. 
일상적인 규정 준수 검사 후 회사는 모든 프로덕션 데이터베이스에 대해 1 초 미만의 복구 지점 
목표(RPO)를 요구하는 표준을 설정합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. DB 인스턴스에 대해 다중 AZ 배포를 활성화합니다. 
B. 하나의 가용 영역에서 DB 인스턴스에 대해 Auto Scaling 을 활성화합니다. 
C. 하나의 가용 영역에서 DB 인스턴스를 구성하고 별도의 가용 영역에서 여러 읽기 전용 
복제본을 생성합니다. 
D. 하나의 가용 영역에서 DB 인스턴스를 구성하고 AWS DMS(AWS Database Migration Service) 
변경 데이터 캡처(CDC) 작업을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99511-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 다른 가용 영역에 있는 대기 인스턴스에 데이터를 자동으로 복제하여 RDS 
데이터베이스 인스턴스에 향상된 가용성과 내구성을 제공하는 DB 인스턴스용 다중 AZ 배포를 
사용하기 때문에 가장 효율적입니다. 또한 대기 인스턴스가 동기식 물리적 복제를 사용하여 기본 
인스턴스와 동기화 상태를 유지하므로 모든 프로덕션 데이터베이스에 대해 1 초 미만의 복구 지점 
목표(RPO)를 제공합니다. 이 솔루션은 모든 프로덕션 데이터베이스에 대해 1 초 미만의 RPO 요구 
사항을 충족합니다. 
옵션 B 는 로드 또는 일정에 따라 DB 인스턴스의 컴퓨팅 용량을 자동으로 조정하는 방법인 하나의 
가용 영역에서 DB 인스턴스에 대해 Auto Scaling 을 사용하기 때문에 효율성이 떨어집니다. 
그러나 이것은 데이터를 다른 가용 영역에 복제하지 않기 때문에 모든 프로덕션 데이터베이스에 
대해 1 초 미만의 RPO 를 제공하지 않습니다. 
옵션 C 는 읽기 트래픽을 제공하고 조정을 지원할 수 있는 기본 데이터베이스의 읽기 전용 
복사본인 별도의 가용 영역에서 읽기 전용 복제본을 사용하기 때문에 효율성이 떨어집니다. 그러나 
읽기 전용 복제본은 비동기식 복제를 사용하고 기본 데이터베이스보다 지연될 수 있으므로 모든 
프로덕션 데이터베이스에 대해 1 초 미만의 RPO 를 제공하지 않습니다. 
옵션 D 는 원본 데이터에 대한 변경 사항을 캡처하고 대상 데이터에 적용하는 작업인 AWS 
DMS(AWS Database Migration Service) 변경 데이터 캡처(CDC) 작업을 사용하기 때문에 효율성이 
떨어집니다. 그러나 AWS DMS 는 비동기식 복제를 사용하고 소스 데이터베이스보다 지연될 수 
있으므로 모든 프로덕션 데이터베이스에 대해 1 초 미만의 RPO 를 제공하지 않습니다. 
Q282 
회사는 VPC 의 프라이빗 서브넷에 있는 Amazon EC2 인스턴스에 배포된 웹 애플리케이션을 
실행합니다. 퍼블릭 서브넷에서 확장되는 ALB(Application Load Balancer)는 웹 트래픽을 EC2 
인스턴스로 보냅니다. 회사는 ALB 에서 EC2 인스턴스로의 인바운드 트래픽을 제한하는 동시에 
EC2 인스턴스의 프라이빗 서브넷 내부 또는 외부의 다른 소스로부터의 액세스를 방지하는 새로운 
보안 조치를 구현하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 인터넷에서 EC2 인스턴스의 프라이빗 IP 주소로 트래픽을 보내도록 라우팅 테이블의 경로를 
구성합니다. 
B. ALB 의 보안 그룹에서 오는 트래픽만 허용하도록 EC2 인스턴스의 보안 그룹을 구성합니다. 
C. EC2 인스턴스를 퍼블릭 서브넷으로 이동합니다. EC2 인스턴스에 탄력적 IP 주소 집합을 
제공합니다. 
D. 모든 포트에서 모든 TCP 트래픽을 허용하도록 ALB 에 대한 보안 그룹을 구성합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/99660-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
ALB 에서 EC2 인스턴스로의 인바운드 트래픽을 제한하려면 EC2 인스턴스의 보안 그룹은 ALB 의 
보안 그룹에서 들어오는 트래픽만 허용해야 합니다. 이렇게 하면 EC2 인스턴스는 ALB 에서만 
요청을 받을 수 있으며 프라이빗 서브넷 내부 또는 외부의 다른 소스에서는 요청을 받을 수 
없습니다. 
Q283 
연구 회사는 시뮬레이션 응용 프로그램과 시각화 응용 프로그램으로 구동되는 실험을 실행합니다. 
시뮬레이션 애플리케이션은 Linux 에서 실행되며 5 분마다 NFS 공유에 중간 데이터를 출력합니다. 
시각화 응용 프로그램은 시뮬레이션 출력을 표시하고 SMB 파일 시스템이 필요한 Windows 
데스크톱 응용 프로그램입니다. 
회사는 두 개의 동기화된 파일 시스템을 유지 관리합니다. 이 전략은 데이터 중복 및 비효율적인 
리소스 사용을 유발합니다. 회사는 애플리케이션에 코드를 변경하지 않고 애플리케이션을 AWS 로 
마이그레이션해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 두 애플리케이션을 모두 AWS Lambda 로 마이그레이션합니다. 애플리케이션 간에 데이터를 
교환할 Amazon S3 버킷을 생성합니다. 
B. 두 애플리케이션을 모두 Amazon Elastic Container Service(Amazon ECS)로 마이그레이션합니다. 
스토리지용 Amazon FSx 파일 게이트웨이를 구성합니다. 
C. 시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로 마이그레이션합니다. 시각화 
애플리케이션을 Windows EC2 인스턴스로 마이그레이션합니다. 애플리케이션 간에 데이터를 
교환하도록 Amazon Simple Queue Service(Amazon SQS)를 구성합니다. 
D. 시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로 마이그레이션합니다. 시각화 
애플리케이션을 Windows EC2 인스턴스로 마이그레이션합니다. 스토리지용 NetApp ONTAP 용 
Amazon FSx 를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99512-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q284 
예산 계획의 일환으로 경영진은 사용자별로 나열된 AWS 청구 항목에 대한 보고서를 원합니다. 
데이터는 부서 예산을 만드는 데 사용됩니다. 솔루션 설계자는 이 보고서 정보를 얻는 가장 
효율적인 방법을 결정해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Athena 로 쿼리를 실행하여 보고서를 생성합니다. 
B. Cost Explorer 에서 보고서를 생성하고 보고서를 다운로드합니다. 
C. 청구 대시보드에서 청구서 세부 정보에 액세스하고 청구서를 다운로드합니다. 
D. Amazon Simple Email Service(Amazon SES)로 알리도록 AWS 예산에서 비용 예산을 
수정합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/99513-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q285 
회사는 Amazon S3 를 사용하여 정적 웹 사이트를 호스팅합니다. 회사는 웹 페이지에 연락처 
양식을 추가하려고 합니다. 연락처 양식에는 사용자가 이름, 이메일 주소, 전화번호 및 사용자 
메시지를 입력할 수 있는 동적 서버 측 구성 요소가 있습니다. 회사는 매월 100 회 미만의 사이트 
방문이 있을 것으로 예상합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Container Service(Amazon ECS)에서 동적 문의 양식 페이지를 호스팅합니다. 
타사 이메일 공급자에 연결하도록 Amazon Simple Email Service(Amazon SES)를 설정합니다. 
B. Amazon Simple Email Service(Amazon SES)를 호출하는 AWS Lambda 백엔드로 Amazon API 
Gateway 엔드포인트를 생성합니다. 
C. Amazon Lightsail 을 배포하여 정적 웹 페이지를 동적으로 변환합니다. 클라이언트 측 
스크립팅을 사용하여 연락처 양식을 작성하십시오. 양식을 Amazon WorkMail 과 통합합니다. 
D. t2.micro Amazon EC2 인스턴스를 생성합니다. LAMP(Linux, Apache, MySQL, PHP/Perl/Python) 
스택을 배포하여 웹 페이지를 호스팅합니다. 클라이언트 측 스크립팅을 사용하여 연락처 양식을 
작성하십시오. 양식을 Amazon WorkMail 과 통합합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99680-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 시간 경과에 따른 AWS 비용 및 사용량을 시각화, 이해 및 관리할 수 있는 도구인 Cost 
Explorer 를 사용하기 때문에 가장 효율적입니다. 비용 탐색기에서 사용자 이름 태그를 필터로 
사용하여 사용자별로 AWS 청구 항목을 나열하는 보고서를 생성할 수 있습니다. 그런 다음 
보고서를 CSV 파일로 다운로드하여 예산 계획에 사용할 수 있습니다. 
옵션 A 는 표준 SQL 을 사용하여 Amazon S3 의 데이터를 분석할 수 있는 서버리스 대화형 쿼리 
서비스인 Amazon Athena 를 사용하기 때문에 효율성이 떨어집니다. S3 에서 AWS 비용 및 사용 
보고서 데이터를 가리키는 Athena 테이블을 설정한 다음 쿼리를 실행하여 보고서를 생성해야 
합니다. 이렇게 하면 추가 비용과 복잡성이 발생합니다. 
옵션 C 는 AWS 비용 및 사용량에 대한 높은 수준의 요약을 제공하는 결제 대시보드를 사용하기 
때문에 효율성이 떨어집니다. 청구 대시보드에서 청구 세부 정보에 액세스하고 청구서를 통해 
다운로드할 수 있지만 사용자별로 청구 항목이 나열되지 않습니다. 추가 단계가 필요한 사용자 
이름별로 비용을 그룹화하려면 태그를 사용해야 합니다. 
옵션 D 는 서비스 사용량, 서비스 비용 및 인스턴스 예약을 계획할 수 있는 도구인 AWS 예산을 
사용하기 때문에 효율성이 떨어집니다. Amazon Simple Email Service(Amazon SES)로 알리도록 
AWS 예산에서 비용 예산을 수정할 수 있지만 이렇게 하면 사용자별로 AWS 청구 항목 보고서가 
생성되지 않습니다. 이는 실제 또는 예상 비용이 예산 금액을 초과하거나 초과할 것으로 예상되는 
경우에만 알려줍니다. 
Q286 
회사에는 Amazon S3 앞의 Amazon CloudFront 에서 호스팅되는 정적 웹 사이트가 있습니다. 정적 
웹 사이트는 데이터베이스 백엔드를 사용합니다. 회사는 웹사이트가 웹사이트의 Git 
리포지토리에서 이루어진 업데이트를 반영하지 않는다는 사실을 알게 되었습니다. 회사는 Git 
리포지토리와 Amazon S3 간의 지속적 통합 및 지속적 전달(CI/CD) 파이프라인을 확인합니다. 
회사는 webhook 이 제대로 구성되었는지, CI/CD 파이프라인이 성공적인 배포를 나타내는 메시지를 
보내고 있는지 확인합니다. 
솔루션 설계자는 웹 사이트에 업데이트를 표시하는 솔루션을 구현해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Application Load Balancer 를 추가합니다. 
B. Redis 또는 Memcached 용 Amazon ElastiCache 를 웹 애플리케이션의 데이터베이스 계층에 
추가합니다. 
C. CloudFront 캐시를 무효화합니다. 
D. AWS Certificate Manager(ACM)를 사용하여 웹 사이트의 SSL 인증서를 확인합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99669-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q287 
회사에서 Windows 기반 애플리케이션을 온프레미스에서 AWS 클라우드로 마이그레이션하려고 
합니다. 애플리케이션에는 애플리케이션 계층, 비즈니스 계층 및 Microsoft SQL Server 가 포함된 
데이터베이스 계층의 세 가지 계층이 있습니다. 회사는 기본 백업 및 데이터 품질 서비스와 같은 
SQL Server 의 특정 기능을 사용하려고 합니다. 또한 회사는 계층 간에 처리를 위해 파일을 
공유해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까? 
A. Amazon EC2 인스턴스에서 세 계층을 모두 호스팅합니다. 계층 간 파일 공유를 위해 Amazon 
FSx File Gateway 를 사용합니다. 
B. Amazon EC2 인스턴스에서 세 계층을 모두 호스팅합니다. 계층 간 파일 공유를 위해 Amazon 
FSx for Windows File Server 를 사용하십시오. 
C. Amazon EC2 인스턴스에서 애플리케이션 계층과 비즈니스 계층을 호스팅합니다. Amazon 
RDS 에서 데이터베이스 계층을 호스팅합니다. 계층 간 파일 공유를 위해 Amazon Elastic File 
System(Amazon EFS)을 사용합니다. 
D. Amazon EC2 인스턴스에서 애플리케이션 계층과 비즈니스 계층을 호스팅합니다. Amazon 
RDS 에서 데이터베이스 계층을 호스팅합니다. 계층 간 파일 공유를 위해 프로비저닝된 IOPS 
SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99670-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 솔루션을 통해 회사는 Amazon FSx for Windows File Server 를 사용하여 계층 간에 Windows 
기반 파일 공유를 제공하면서 Amazon EC2 인스턴스에서 세 계층을 모두 호스팅할 수 있습니다. 
이를 통해 회사는 기본 백업 및 데이터 품질 서비스와 같은 SQL Server 의 특정 기능을 사용하면서 
계층 간에 처리를 위해 파일을 공유할 수 있습니다. 
Q288 
회사에서 Linux 기반 웹 서버 그룹을 AWS 로 마이그레이션하고 있습니다. 웹 서버는 일부 
콘텐츠에 대해 공유 파일 저장소의 파일에 액세스해야 합니다. 회사는 신청서를 변경해서는 
안됩니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 웹 서버에 대한 액세스 권한이 있는 Amazon S3 Standard 버킷을 생성합니다. 
B. Amazon S3 버킷을 원본으로 사용하여 Amazon CloudFront 배포를 구성합니다. 
C. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 모든 웹 서버에 EFS 파일 
시스템을 마운트합니다. 
D. 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성합니다. 모든 웹 서버에 
EBS 볼륨을 마운트합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99671-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 모든 웹 서버에 EFS 파일 
시스템을 마운트합니다. 애플리케이션을 변경하지 않고 Linux 기반 웹 서버용 공유 파일 스토어를 
제공해야 한다는 요구 사항을 충족하려면 Amazon EFS 파일 시스템을 사용하는 것이 가장 좋은 
솔루션입니다. 
Amazon EFS 는 여러 Linux 기반 인스턴스에서 파일에 대한 공유 액세스를 제공하는 관리형 NFS 
파일 시스템 서비스이므로 이 사용 사례에 적합합니다. Amazon S3 는 파일 시스템이 아닌 객체 
스토리지 서비스이고 S3 버킷을 파일 시스템으로 탑재하려면 추가 도구 또는 라이브러리가 
필요하기 때문에 이 시나리오에 적합하지 않습니다. Amazon CloudFront 는 콘텐츠 전송 성능을 
개선하는 데 사용할 수 있지만 이 요구 사항에는 필요하지 않습니다. 또한 Amazon EBS 볼륨은 한 
번에 하나의 인스턴스에만 탑재할 수 있으므로 여러 인스턴스에서 파일을 공유하는 데 적합하지 
않습니다. 
Q289 
회사에는 동일한 AWS 계정에 있는 Amazon S3 버킷에 대한 읽기 액세스 권한이 필요한 AWS 
Lambda 함수가 있습니다. 
가장 안전한 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. S3 버킷에 대한 읽기 액세스 권한을 부여하는 S3 버킷 정책을 적용합니다. 
B. Lambda 함수에 IAM 역할을 적용합니다. 역할에 IAM 정책을 적용하여 S3 버킷에 대한 읽기 
액세스 권한을 부여합니다. 
C. Lambda 함수의 코드에 액세스 키와 비밀 키를 내장하여 S3 버킷에 대한 읽기 액세스에 필요한 
IAM 권한을 부여합니다. 
D. Lambda 함수에 IAM 역할을 적용합니다. 역할에 IAM 정책을 적용하여 계정의 모든 S3 버킷에 
대한 읽기 액세스 권한을 부여합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99756-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 최소 권한 원칙을 따르고 코드의 자격 증명을 노출하지 않고 Lambda 함수에 필요한 
권한만 부여하기 때문에 가장 안전합니다. IAM 역할은 Lambda 함수의 실행 역할로 구성할 수 
있으며 IAM 정책은 S3 버킷 ARN 및 s3:GetObject 작업을 지정할 수 있습니다. 
옵션 A 는 Lambda 함수보다 더 많은 S3 버킷에 대한 액세스 권한이 있는 보안 주체에게 읽기 
액세스 권한을 부여하기 때문에 덜 안전합니다. 
옵션 C 는 손상되거나 노출될 수 있는 자격 증명을 코드에 내장하기 때문에 덜 안전합니다. 
옵션 D 는 계정의 모든 S3 버킷에 대한 읽기 액세스 권한을 부여하기 때문에 덜 안전합니다. 이는 
Lambda 함수에 필요한 것보다 많을 수 있습니다. 
Q290 
회사는 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. EC2 인스턴스는 사용자 
요구에 따라 확장되는 Auto Scaling 그룹에 있습니다. 회사는 장기적인 약정 없이 비용 절감을 
최적화하기를 원합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 EC2 인스턴스 구매 옵션은 
무엇입니까? 
A. 전용 인스턴스만 해당 
B. 온디맨드 인스턴스 전용 
C. 온디맨드 인스턴스와 스팟 인스턴스의 혼합 
D. 온디맨드 인스턴스와 예약 인스턴스의 혼합 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/100006-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
참고 
https://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instan
ces-groups.html 
Q291 
미디어 회사는 공개적으로 사용 가능한 스트리밍 비디오 콘텐츠에 Amazon CloudFront 를 
사용합니다. 이 회사는 액세스 권한이 있는 사용자를 제어하여 Amazon S3 에서 호스팅되는 비디오 
콘텐츠를 보호하려고 합니다. 회사의 일부 사용자는 쿠키를 지원하지 않는 사용자 지정 HTTP 
클라이언트를 사용하고 있습니다. 회사의 일부 사용자는 액세스에 사용하는 하드코딩된 URL 을 
변경할 수 없습니다. 
사용자에게 미치는 영향을 최소화하면서 이러한 요구 사항을 충족하는 서비스 또는 방법은 
무엇입니까? (2 개 선택) 
A. 서명된 쿠키 
B. 서명된 URL 
C. AWS 앱싱크 
D. JSON 웹 토큰(JWT) 
E. AWS Secrets Manager 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/99831-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q292 
한 회사가 여러 소스에서 실시간 스트리밍 데이터를 수집할 새로운 데이터 플랫폼을 준비하고 
있습니다. 회사는 Amazon S3 에 데이터를 쓰기 전에 데이터를 변환해야 합니다. 회사는 SQL 을 
사용하여 변환된 데이터를 쿼리할 수 있는 기능이 필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (두 가지를 선택하세요.) 
A. Amazon Kinesis Data Streams 를 사용하여 데이터를 스트리밍합니다. Amazon Kinesis Data 
Analytics 를 사용하여 데이터를 변환합니다. Amazon Kinesis Data Firehose 를 사용하여 Amazon 
S3 에 데이터를 씁니다. Amazon Athena 를 사용하여 Amazon S3 에서 변환된 데이터를 쿼리합니다. 
B. Amazon Managed Streaming for Apache Kafka(Amazon MSK)를 사용하여 데이터를 
스트리밍합니다. AWS Glue 를 사용하여 데이터를 변환하고 데이터를 Amazon S3 에 씁니다. 
Amazon Athena 를 사용하여 Amazon S3 에서 변환된 데이터를 쿼리합니다. 
C. AWS Database Migration Service(AWS DMS)를 사용하여 데이터를 수집합니다. Amazon EMR 을 
사용하여 데이터를 변환하고 Amazon S3 에 데이터를 씁니다. Amazon Athena 를 사용하여 Amazon 
S3 에서 변환된 데이터를 쿼리합니다. 
D. Amazon Managed Streaming for Apache Kafka(Amazon MSK)를 사용하여 데이터를 
스트리밍합니다. Amazon Kinesis Data Analytics 를 사용하여 데이터를 변환하고 데이터를 Amazon 
S3 에 씁니다. Amazon RDS 쿼리 편집기를 사용하여 Amazon S3 에서 변환된 데이터를 쿼리합니다. 
E. Amazon Kinesis Data Streams 를 사용하여 데이터를 스트리밍합니다. AWS Glue 를 사용하여 
데이터를 변환합니다. Amazon Kinesis Data Firehose 를 사용하여 Amazon S3 에 데이터를 씁니다. 
Amazon RDS 쿼리 편집기를 사용하여 Amazon S3 에서 변환된 데이터를 쿼리합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/99834-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
여러 소스에서 실시간 스트리밍 데이터를 수집, 변환 및 쿼리하려면 Amazon Kinesis 와 Amazon 
MSK 가 적합한 솔루션입니다. Amazon Kinesis Data Streams 는 다양한 소스의 데이터를 
스트리밍하고 다른 AWS 서비스와 통합할 수 있습니다. Amazon Kinesis Data Analytics 는 SQL 
또는 Apache Flink 를 사용하여 데이터를 변환할 수 있습니다. Amazon Kinesis Data Firehose 는 
Amazon S3 또는 다른 대상에 데이터를 쓸 수 있습니다. Amazon Athena 는 표준 SQL 을 사용하여 
Amazon S3 에서 변환된 데이터를 쿼리할 수 있습니다. 
Amazon MSK 는 데이터 스트리밍을 위한 인기 있는 오픈 소스 플랫폼인 Apache Kafka 를 사용하여 
데이터를 스트리밍할 수 있습니다. AWS Glue 는 Apache Spark 또는 Python 스크립트를 사용하여 
데이터를 변환하고 Amazon S3 또는 기타 대상에 데이터를 쓸 수 있습니다. Amazon Athena 는 
표준 SQL 을 사용하여 Amazon S3 에서 변환된 데이터를 쿼리할 수도 있습니다. 
Q293 
회사에는 수명이 다한 온프레미스 볼륨 백업 솔루션이 있습니다. 회사는 AWS 를 새로운 백업 
솔루션의 일부로 사용하고 AWS 에 백업되는 동안 모든 데이터에 대한 로컬 액세스를 유지하려고 
합니다. 회사는 AWS 에 백업된 데이터가 자동으로 안전하게 전송되기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. AWS Snowball 을 사용하여 온프레미스 솔루션에서 Amazon S3 로 데이터를 마이그레이션합니다. 
데이터에 대한 로컬 액세스를 제공하기 위해 Snowball S3 엔드포인트를 탑재하도록 온프레미스 
시스템을 구성합니다. 
B. AWS Snowball Edge 를 사용하여 온프레미스 솔루션에서 Amazon S3 로 데이터를 
마이그레이션합니다. Snowball Edge 파일 인터페이스를 사용하여 온프레미스 시스템에 데이터에 
대한 로컬 액세스를 제공합니다. 
C. AWS Storage Gateway 를 사용하고 캐시된 볼륨 게이트웨이를 구성합니다. 온프레미스에서 
Storage Gateway 소프트웨어 어플라이언스를 실행하고 로컬로 캐시할 데이터 비율을 구성합니다. 
데이터에 대한 로컬 액세스를 제공하기 위해 게이트웨이 스토리지 볼륨을 마운트합니다. 
D. AWS Storage Gateway 를 사용하고 저장된 볼륨 게이트웨이를 구성합니다. 온프레미스에서 
Storage Gateway 소프트웨어 어플라이언스를 실행하고 게이트웨이 스토리지 볼륨을 온프레미스 
스토리지에 매핑합니다. 데이터에 대한 로컬 액세스를 제공하기 위해 게이트웨이 스토리지 볼륨을 
마운트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99692-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 온프레미스 소프트웨어 어플라이언스와 클라우드 기반 스토리지를 연결하여 온프레미스 
IT 환경과 AWS 스토리지 인프라 간의 데이터 보안 기능과의 원활한 통합을 제공하는 서비스인 
AWS Storage Gateway 를 사용하기 때문에 가장 효율적입니다. . 또한 기본 데이터를 로컬에 
저장하고 데이터의 특정 시점 스냅샷을 Amazon S3 에 비동기식으로 백업하는 볼륨 게이트웨이 
유형인 저장된 볼륨 게이트웨이를 사용합니다. 또한 온프레미스에서 Storage Gateway 소프트웨어 
애플리케이션을 실행하고 게이트웨이 스토리지 볼륨을 온프레미스 스토리지에 매핑하므로 기존 
스토리지 하드웨어 및 네트워크 인프라를 사용할 수 있습니다. 또한 게이트웨이 스토리지 볼륨을 
탑재하여 데이터에 대한 로컬 액세스를 제공하므로 온프레미스에서 지연 시간이 짧은 액세스를 
위해 데이터를 사용할 수 있으며 동시에 AWS 에 백업할 수 있습니다. 이 솔루션은 AWS 에 
백업되는 동안 모든 데이터에 대한 로컬 액세스를 유지하고 AWS 에 백업된 데이터가 자동으로 
안전하게 전송되도록 하는 요구 사항을 충족합니다. 
옵션 A 는 대량의 데이터를 AWS 안팎으로 전송할 수 있는 물리적 장치인 AWS Snowball 을 
사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 장치의 수동 취급 및 배송을 필요로 하기 
때문에 주기적인 백업 솔루션을 제공하지 않습니다. 또한 데이터에 대한 로컬 액세스를 제공하기 
위해 Snowball S3 엔드포인트를 탑재하도록 온프레미스 시스템을 구성하므로 추가적인 복잡성과 
지연 시간이 발생할 수 있습니다. 
옵션 B 는 일부 AWS 기능을 위한 온보드 스토리지 및 컴퓨팅 기능이 있는 물리적 디바이스인 
AWS Snowball Edge 를 사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 장치의 수동 취급 및 
배송을 필요로 하기 때문에 주기적인 백업 솔루션을 제공하지 않습니다. 또한 Snowball Edge 파일 
인터페이스를 사용하여 온프레미스 시스템에 데이터에 대한 로컬 액세스를 제공하므로 추가적인 
복잡성과 지연 시간이 발생할 수 있습니다. 
옵션 C 는 AWS Storage Gateway 를 사용하고 기본 데이터를 Amazon S3 에 저장하고 자주 
액세스하는 데이터 하위 집합의 복사본을 로컬에 보관하는 일종의 볼륨 게이트웨이인 캐시된 볼륨 
게이트웨이를 구성하기 때문에 효율성이 떨어집니다. 그러나 일부 데이터 하위 집합만 로컬로 
캐시되기 때문에 모든 데이터에 대한 로컬 액세스를 제공하지는 않습니다. 또한 로컬로 캐시할 
데이터의 비율을 구성하므로 저장된 볼륨 게이트웨이를 사용하는 것보다 더 높은 비용과 복잡성이 
발생할 수 있습니다. 
Q294 
Amazon EC2 인스턴스에서 호스팅되는 애플리케이션은 Amazon S3 버킷에 액세스해야 합니다. 
트래픽이 인터넷을 통과하면 안 됩니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 액세스를 어떻게 구성해야 합니까? 
A. Amazon Route 53 을 사용하여 프라이빗 호스팅 영역을 생성합니다. 
B. VPC 에서 Amazon S3 에 대한 게이트웨이 VPC 엔드포인트를 설정합니다. 
C. NAT 게이트웨이를 사용하여 S3 버킷에 액세스하도록 EC2 인스턴스를 구성합니다. 
D. VPC 와 S3 버킷 간에 AWS Site-to-Site VPN 연결을 설정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99954-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 인터넷 게이트웨이나 VPC 용 NAT 장치 없이 Amazon S3 에 대한 안정적인 연결을 
제공하는 Amazon S3 용 게이트웨이 VPC 엔드포인트를 사용하기 때문에 가장 효율적입니다. 
게이트웨이 VPC 엔드포인트는 서비스의 접두사 목록을 사용하여 VPC에서 Amazon S3로 트래픽을 
라우팅하고 AWS 네트워크를 벗어나지 않습니다. 이것은 인터넷을 통과하지 않는다는 요구 사항을 
충족합니다. 
옵션 A 는 VPC 내의 리소스에 대한 사용자 지정 도메인 이름을 생성할 수 있는 DNS 서비스인 
Amazon Route 53 을 사용하여 프라이빗 호스팅 영역을 사용하기 때문에 효율성이 떨어집니다. 
그러나 이것은 인터넷 게이트웨이나 NAT 장치 없이는 Amazon S3 에 대한 연결을 제공하지 
않습니다. 
옵션 C 는 NAT 게이트웨이를 사용하여 S3 버킷에 액세스하기 때문에 효율성이 떨어집니다. S3 
버킷은 개인 서브넷의 인스턴스가 인터넷 또는 다른 AWS 서비스에 연결할 수 있도록 지원하지만 
인터넷이 이러한 인스턴스와의 연결을 시작하지 못하도록 하는 고가용성 관리형 NAT(Network 
Address Translation) 서비스입니다. 그러나 이것은 인터넷을 통과하지 않는 요구 사항을 충족하지 
못합니다.그러나 이것은 인터넷을 통과하지 않는다는 요구 사항을 충족하지 않습니다. 
옵션 D 는 온프레미스 네트워크와 VPC 간의 안전하고 암호화된 네트워크 연결인 S3 버킷과 VPC 
간에 AWS Site-to-Site VPN 연결을 사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 
인터넷을 통과하지 않는다는 요구 사항을 충족하지 않습니다. 
Q295 
전자상거래 회사는 테라바이트 규모의 고객 데이터를 AWS 클라우드에 저장합니다. 데이터에는 
개인 식별 정보(PII)가 포함되어 있습니다. 회사는 세 가지 응용 프로그램에서 데이터를 사용하려고 
합니다. 애플리케이션 중 하나만 PII 를 처리해야 합니다. 다른 두 애플리케이션이 데이터를 
처리하기 전에 PII 를 제거해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon DynamoDB 테이블에 데이터를 저장합니다. 각 애플리케이션이 요청하는 데이터를 
가로채서 처리할 프록시 애플리케이션 계층을 생성합니다. 
B. 데이터를 Amazon S3 버킷에 저장합니다. 요청 애플리케이션에 데이터를 반환하기 전에 S3 
객체 Lambda 를 사용하여 데이터를 처리하고 변환합니다. 
C. 데이터를 처리하고 변환된 데이터를 3 개의 개별 Amazon S3 버킷에 저장하여 각 
애플리케이션이 고유한 사용자 지정 데이터 세트를 갖도록 합니다. 각 애플리케이션이 해당 S3 
버킷을 가리키도록 합니다. 
D. 데이터를 처리하고 변환된 데이터를 3 개의 별도 Amazon DynamoDB 테이블에 저장하여 각 
애플리케이션이 자체 사용자 지정 데이터 세트를 갖도록 합니다. 각 애플리케이션이 해당 
DynamoDB 테이블을 가리키도록 합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99956-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q296 
개발 팀이 개발 VPC 내부의 Amazon EC2 인스턴스에서 호스팅되는 새로운 애플리케이션을 
출시했습니다. 솔루션 설계자는 동일한 계정에 새 VPC를 생성해야 합니다. 새 VPC는 개발 VPC와 
피어링됩니다. 개발용 VPC 의 VPC CIDR 블록은 192.168.0.0/24 입니다. 솔루션 설계자는 새 
VPC 에 대한 CIDR 블록을 생성해야 합니다. CIDR 블록은 개발 VPC 에 대한 VPC 피어링 연결에 
대해 유효해야 합니다. 
이러한 요구 사항을 충족하는 가장 작은 CIDR 블록은 무엇입니까? 
A. 10.0.1.0/32 
B. 192.168.0.0/24 
C. 192.168.1.0/32 
D. 10.0.1.0/24 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99651-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
허용되는 블록 크기는 /28 넷마스크와 /16 넷마스크 사이입니다. CIDR 블록은 VPC 와 연결된 기존 
CIDR 블록과 겹치지 않아야 합니다. 
https://docs.aws.amazon.com/vpc/latest/userguide/configure-your-vpc.html 
Q297 
회사에서 5 개의 Amazon EC2 인스턴스에 애플리케이션을 배포합니다. ALB(Application Load 
Balancer)는 대상 그룹을 사용하여 인스턴스에 트래픽을 분산합니다. 각 인스턴스의 평균 CPU 
사용량은 대부분 10% 미만이며 때때로 65%까지 급증합니다. 
솔루션 설계자는 애플리케이션의 확장성을 자동화하는 솔루션을 구현해야 합니다. 솔루션은 
아키텍처의 비용을 최적화하고 급증이 발생할 때 애플리케이션에 충분한 CPU 리소스가 있는지 
확인해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. CPUUtilization 지표가 20% 미만일 때 ALARM 상태로 들어가는 Amazon CloudWatch 경보를 
생성합니다. ALB 대상 그룹의 EC2 인스턴스 중 하나를 종료하기 위해 CloudWatch 경보가 
호출하는 AWS Lambda 함수를 생성합니다. 
B. EC2 Auto Scaling 그룹을 생성합니다. 기존 ALB 를 로드 밸런서로 선택하고 기존 대상 그룹을 
대상 그룹으로 선택하십시오. ASGAverageCPUUtilization 지표를 기반으로 하는 대상 추적 조정 
정책을 설정합니다. 최소 인스턴스를 2 로, 원하는 용량을 3 으로, 최대 인스턴스를 6 으로, 목표 
값을 50%로 설정합니다. Auto Scaling 그룹에 EC2 인스턴스를 추가합니다. 
C. EC2 Auto Scaling 그룹을 생성합니다. 기존 ALB 를 로드 밸런서로 선택하고 기존 대상 그룹을 
대상 그룹으로 선택하십시오. 최소 인스턴스를 2 로, 원하는 용량을 3 으로, 최대 인스턴스를 6 으로 
설정합니다. Auto Scaling 그룹에 EC2 인스턴스를 추가합니다. 
D. 두 개의 Amazon CloudWatch 경보를 생성합니다. 평균 CPUUtilization 지표가 20% 미만일 때 
ALARM 상태로 들어가도록 첫 번째 CloudWatch 경보를 구성합니다. 평균 CPUUtilization 지표가 
50%를 초과하면 ALARM 상태로 들어가도록 두 번째 CloudWatch 경보를 구성합니다. 이메일 
메시지를 보내기 위해 Amazon Simple Notification Service(Amazon SNS) 주제에 게시하도록 
경보를 구성합니다. 메시지를 받은 후 로그인하여 실행 중인 EC2 인스턴스 수를 줄이거나 
늘립니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99652-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
* Auto Scaling 그룹은 수요 변화에 맞춰 EC2 인스턴스를 자동으로 확장합니다. 이는 필요한 
만큼의 인스턴스만 실행하여 비용을 최적화합니다. 
* 대상 추적 조정 정책은 ASGAverageCPUUtilization 지표를 모니터링하고 평균 CPU 를 약 50% 
대상 값으로 유지하도록 조정합니다. 이렇게 하면 CPU 가 급증하는 동안 리소스가 충분해집니다. 
* ALB 와 대상 그룹은 재사용되므로 애플리케이션 아키텍처가 변경되지 않습니다. Auto Scaling 
그룹은 기존 로드 밸런서 설정에 연결됩니다. 
* 최소 2개에서 최대 6개의 인스턴스는 수요에 따라 필요에 따라 3개에서 6개 사이의 인스턴스를 
확장할 수 있는 기능을 제공합니다. 
* 단 3 개의 인스턴스(원하는 용량)로 시작하고 필요에 따라 확장하여 비용을 최적화합니다. CPU 
사용량이 떨어지면 원하는 용량에 맞게 인스턴스가 종료됩니다. 
Q298 
회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 중요한 비즈니스 
애플리케이션을 실행하고 있습니다. EC2 인스턴스는 Auto Scaling 그룹에서 실행되며 Amazon RDS 
DB 인스턴스에 액세스합니다. 
EC2 인스턴스와 DB 인스턴스가 모두 단일 가용 영역에 있기 때문에 설계가 운영 검토를 통과하지 
못했습니다. 솔루션 설계자는 두 번째 가용 영역을 사용하도록 설계를 업데이트해야 합니다. 
애플리케이션의 가용성을 높이는 솔루션은 무엇입니까? 
A. 각 가용 영역에서 서브넷을 프로비저닝합니다. 두 가용 영역에 EC2 인스턴스를 배포하도록 
Auto Scaling 그룹을 구성합니다. 각 네트워크에 대한 연결로 DB 인스턴스를 구성합니다. 
B. 두 가용 영역에 걸쳐 확장되는 두 개의 서브넷을 프로비저닝합니다. 두 가용 영역에 EC2 
인스턴스를 배포하도록 Auto Scaling 그룹을 구성합니다. 각 네트워크에 대한 연결로 DB 
인스턴스를 구성합니다. 
C. 각 가용 영역에서 서브넷을 프로비저닝합니다. 두 가용 영역에 EC2 인스턴스를 배포하도록 
Auto Scaling 그룹을 구성합니다. 다중 AZ 배포를 위해 DB 인스턴스를 구성합니다. 
D. 두 가용 영역에 걸쳐 확장되는 서브넷을 프로비저닝합니다. 두 가용 영역에 EC2 인스턴스를 
배포하도록 Auto Scaling 그룹을 구성합니다. 다중 AZ 배포를 위해 DB 인스턴스를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99653-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고: 
https://aws.amazon.com/ko/vpc/faqs/#:~:text=Can%20a%20subnet%20span%20Availability 
Q299 
연구소는 약 8TB 의 데이터를 처리해야 합니다. 실험실에는 스토리지 하위 시스템에 대해 1 밀리초 
미만의 대기 시간과 최소 6GBps 의 처리량이 필요합니다. Amazon Linux 를 실행하는 수백 개의 
Amazon EC2 인스턴스가 데이터를 배포하고 처리합니다. 
성능 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. NetApp ONTAP 파일 시스템용 Amazon FSx 를 생성합니다. 각 볼륨의 계층화 정책을 ALL 로 
설정했습니다. 원시 데이터를 파일 시스템으로 가져옵니다. EC2 인스턴스에 fila 시스템을 
탑재합니다. 
B. 원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. 영구 SSD 스토리지를 사용하는 Amazon 
FSx for Lustre 파일 시스템을 생성합니다. Amazon S3 에서 데이터를 가져오고 내보내는 옵션을 
선택합니다. EC2 인스턴스에 파일 시스템을 탑재합니다. 
C. 원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. 영구 HDD 스토리지를 사용하는 
Amazon FSx for Lustre 파일 시스템을 생성합니다. Amazon S3 에서 데이터를 가져오고 내보내는 
옵션을 선택합니다. EC2 인스턴스에 파일 시스템을 탑재합니다. 
D. NetApp ONTAP 파일 시스템용 Amazon FSx 를 생성합니다. 각 볼륨의 계층화 정책을 
NONE 으로 설정합니다. 원시 데이터를 파일 시스템으로 가져옵니다. EC2 인스턴스에 파일 
시스템을 탑재합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99676-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
원시 데이터를 저장할 Amazon S3 버킷 생성 영구 SSD 스토리지를 사용하는 Amazon FSx for 
Lustre 파일 시스템 생성 Amazon S3 에서 데이터를 가져오고 내보내는 옵션 선택 EC2 인스턴스에 
파일 시스템을 탑재합니다. Amazon FSx for Lustre 는 밀리초 미만의 지연 시간과 최대 6GBps 의 
처리량을 위해 SSD 스토리지를 사용하고 Amazon S3 에서 데이터를 가져오고 내보낼 수 있습니다. 
또한 영구 SSD 스토리지를 선택하는 옵션은 데이터가 디스크에 저장되고 파일 시스템이 
중지되어도 손실되지 않도록 합니다. 
Q300 
회사는 하드웨어 용량 제약으로 인해 온프레미스 데이터 센터에서 AWS 클라우드로 레거시 
애플리케이션을 마이그레이션해야 합니다. 응용 프로그램은 하루 24 시간, 주 7 일 실행됩니다. 
애플리케이션의 데이터베이스 스토리지는 시간이 지남에 따라 계속 증가합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. 애플리케이션 계층을 Amazon EC2 스팟 인스턴스로 마이그레이션합니다. 데이터 스토리지 
계층을 Amazon S3 로 마이그레이션합니다. 
B. 애플리케이션 계층을 Amazon EC2 예약 인스턴스로 마이그레이션합니다. 데이터 스토리지 
계층을 Amazon RDS 온디맨드 인스턴스로 마이그레이션합니다. 
C. 애플리케이션 계층을 Amazon EC2 예약 인스턴스로 마이그레이션합니다. 데이터 스토리지 
계층을 Amazon Aurora 예약 인스턴스로 마이그레이션합니다. 
D. 애플리케이션 계층을 Amazon EC2 온디맨드 인스턴스로 마이그레이션합니다. 데이터 스토리지 
계층을 Amazon RDS 예약 인스턴스로 마이그레이션합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99948-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고: 
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.AuroraMySQL.html 
Q301 
대학 연구소는 온프레미스 Windows 파일 서버에서 Amazon FSx for Windows File Server 로 
30TB 의 데이터를 마이그레이션해야 합니다. 실험실에는 대학의 다른 많은 부서에서 공유하는 
1Gbps 네트워크 링크가 있습니다. 
실험실은 데이터 전송 성능을 최대화할 데이터 마이그레이션 서비스를 구현하려고 합니다. 그러나 
실험실은 서비스가 다른 부서에 미치는 영향을 최소화하기 위해 사용하는 대역폭의 양을 제어할 
수 있어야 합니다. 데이터 마이그레이션은 향후 5 일 이내에 이루어져야 합니다. 
이러한 요구 사항을 충족하는 AWS 솔루션은 무엇입니까? 
A. AWS 스노우콘 
B. Amazon FSx 파일 게이트웨이 
C. AWS 데이터싱크 
D. AWS Transfer Family 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99659-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q302 
회사에서 사용자가 모바일 장치에서 슬로우 모션 비디오 클립을 스트리밍할 수 있는 모바일 앱을 
만들고자 합니다. 현재 이 앱은 비디오 클립을 캡처하고 원시 형식의 비디오 클립을 Amazon S3 
버킷에 업로드합니다. 앱은 S3 버킷에서 직접 이러한 비디오 클립을 검색합니다. 그러나 비디오는 
원시 형식이 큽니다. 
사용자는 모바일 장치에서 버퍼링 및 재생 문제를 겪고 있습니다. 회사는 운영 오버헤드를 
최소화하면서 앱의 성능과 확장성을 극대화하는 솔루션을 구현하고자 합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (2 개 선택) 
A. 콘텐츠 전송 및 캐싱을 위해 Amazon CloudFront 를 배포합니다. 
B. AWS DataSync 를 사용하여 다른 S3 버킷의 AW'S 지역 전체에 비디오 파일을 복제합니다. 
C. Amazon Elastic Transcoder 를 사용하여 비디오 파일을 보다 적절한 형식으로 변환합니다. 
D. 콘텐츠 전송 및 캐싱을 위해 로컬 영역에 Amazon EC2 인스턴스의 Auto Sealing 그룹을 
배포합니다. 
E. Amazon EC2 인스턴스의 Auto Scaling 그룹을 배포하여 비디오 파일을 보다 적절한 형식으로 
변환합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/99693-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q303 
회사에서 Amazon Elastic Container Service(Amazon ECS) 클러스터에 배포된 새 애플리케이션을 
시작하고 ECS 작업에 Fargate 시작 유형을 사용하고 있습니다. 회사는 실행 시 애플리케이션에 
대한 높은 트래픽이 예상되기 때문에 CPU 및 메모리 사용량을 모니터링하고 있습니다. 그러나 
회사는 활용도가 감소할 때 비용을 절감하기를 원합니다. 
솔루션 설계자는 무엇을 추천해야 합니까? 
A. Amazon EC2 Auto Scaling 을 사용하여 이전 트래픽 패턴을 기반으로 특정 기간에 조정합니다. 
B. AWS Lambda 함수를 사용하여 Amazon CloudWatch 경보를 트리거하는 메트릭 위반을 
기반으로 Amazon ECS 를 확장합니다. 
C. 간단한 조정 정책과 함께 Amazon EC2 Auto Scaling 을 사용하여 ECS 메트릭 위반이 Amazon 
CloudWatch 경보를 트리거할 때 조정합니다. 
D. 대상 추적 정책과 함께 AWS Application Auto Scaling 을 사용하여 ECS 메트릭 위반이 Amazon 
CloudWatch 경보를 트리거할 때 조정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99813-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고 
https://docs.aws.amazon.com/ko_kr/autoscaling/application/userguide/what-is-application-aut
o-scaling.html 
Q304 
한 회사가 최근 다른 AWS 리전에 재해 복구 사이트를 만들었습니다. 회사는 정기적으로 두 
리전의 NFS 파일 시스템 간에 대량의 데이터를 주고 받아야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS DataSync 를 사용하십시오. 
B. AWS Snowball 디바이스를 사용합니다. 
C. Amazon EC2 에서 SFTP 서버를 설정합니다. 
D. AWS 데이터베이스 마이그레이션 서비스(AWS DMS)를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99949-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 온프레미스와 AWS 스토리지 서비스 간에 데이터 이동을 자동화하고 가속화하는 안전한 
온라인 서비스인 AWS DataSync 를 사용하기 때문에 가장 효율적입니다. 또한 DataSync 를 
사용하여 정기적으로 두 리전의 NFS 파일 시스템 간에 대량의 데이터를 주고받으며 최소한의 
운영 오버헤드로 데이터 전송 프로세스를 단순화하고 가속화합니다. 이 솔루션은 최소한의 운영 
오버헤드로 정기적으로 두 리전의 NFS 파일 시스템 간에 대량의 데이터를 주고받는 요구 사항을 
충족합니다. 
옵션 B 는 대량의 데이터를 AWS 안팎으로 전송할 수 있는 물리적 디바이스인 AWS Snowball 
디바이스를 사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 장치의 수동 취급 및 배송을 
필요로 하기 때문에 주기적인 데이터 전송 솔루션을 제공하지 않습니다. 
옵션 C 는 Amazon S33 에 저장된 파일에 대한 보안 파일 전송 프로토콜(SFTP) 액세스를 제공하는 
방법인 Amazon EC2 에 SFTP 서버를 설정하기 때문에 효율성이 떨어집니다. 그러나 파일 전송을 
수동으로 시작하고 모니터링해야 하므로 주기적인 데이터 전송 솔루션을 제공하지 않습니다. 
옵션 D 는 데이터베이스를 AWS 로 빠르고 안전하게 마이그레이션하는 데 도움이 되는 서비스인 
AWS DMS(AWS Database Migration Service)를 사용하기 때문에 효율성이 떨어집니다. 그러나 
이것은 관계형 데이터베이스 및 비관계형 데이터 저장소만 지원하므로 NFS 파일 시스템용 데이터 
전송 솔루션을 제공하지 않습니다. 
Q305 
회사는 AWS 클라우드에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 솔루션을 
설계하고 있습니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 
필요합니다. 솔루션은 완전히 관리되어야 합니다. 
어떤 AWS 솔루션이 이러한 요구 사항을 충족합니까? 
A. 탑재 가능한 파일 시스템으로 데이터를 공유하는 AWS DataSync 작업을 생성합니다. 파일 
시스템을 애플리케이션 서버에 마운트하십시오. 
B. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 
설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다. 
C. Windows 파일 서버 파일 시스템용 Amazon FSx 를 생성합니다. 원본 서버에 파일 시스템을 
연결합니다. 애플리케이션 서버를 파일 시스템에 연결하십시오. 
D. Amazon S3 버킷을 생성합니다. 애플리케이션에 IAM 역할을 할당하여 S3 버킷에 대한 액세스 
권한을 부여합니다. S3 버킷을 애플리케이션 서버에 마운트합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99809-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon FSx for Windows File Server(Amazon FSx)는 서버 메시지 블록(SMB) 프로토콜을 사용하는 
Windows Server 에 구축된 완전 관리형, 고가용성 및 확장 가능한 파일 스토리지 솔루션입니다. 
다른 중요한 엔터프라이즈 기능 중에서 Microsoft Active Directory 통합, 데이터 중복 제거 및 
완전히 관리되는 백업을 허용합니다.  
https://aws.amazon.com/blogs/storage/accessing-smb-fileshares-remotely-with-amazon-fsx-f
or-windows-file-server/ 
Q306 
회사는 Amazon EC2 인스턴스에서 실행되는 지연 시간에 민감한 애플리케이션을 위해 인 메모리 
데이터베이스를 실행하려고 합니다. 애플리케이션은 분당 100,000 개 이상의 트랜잭션을 처리하며 
높은 네트워크 처리량이 필요합니다. 솔루션 설계자는 데이터 전송 비용을 최소화하는 비용 
효율적인 네트워크 설계를 제공해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 동일한 AWS 리전 내의 동일한 가용 영역에서 모든 EC2 인스턴스를 시작합니다. EC2 
인스턴스를 시작할 때 클러스터 전략으로 배치 그룹을 지정합니다. 
B. 동일한 AWS 지역 내의 다른 가용 영역에서 모든 EC2 인스턴스를 시작합니다. EC2 인스턴스를 
시작할 때 파티션 전략으로 배치 그룹을 지정합니다. 
C. Auto Scaling 그룹을 배포하여 네트워크 활용 목표에 따라 다른 가용 영역에서 EC2 인스턴스를 
시작합니다. 
D. 서로 다른 가용 영역에서 EC2 인스턴스를 시작하기 위해 단계 조정 정책으로 Auto Scaling 
그룹을 배포합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99807-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
* 단일 AZ 내에서 인스턴스를 시작하고 클러스터 배치 그룹을 사용하면 네트워크 대기 시간이 
가장 짧고 인스턴스 간 대역폭이 가장 높습니다. 이는 메모리 데이터베이스 및 처리량이 많은 
애플리케이션의 성능을 최대화합니다. 
* 동일한 AZ 에 있는 인스턴스와 배치 그룹 간의 통신은 무료이므로 데이터 전송 요금이 
최소화됩니다. AZ 간 및 퍼블릭 IP 트래픽에는 요금이 발생할 수 있습니다. 
* 클러스터 배치 그룹을 사용하면 인스턴스를 AZ 내에서 서로 가깝게 배치할 수 있으므로 필요한 
높은 네트워크 처리량이 가능합니다. 파티션 그룹은 AZ 에 걸쳐 있으므로 대역폭이 줄어듭니다. 
* 영역 간 Auto Scaling 은 AZ 에서 인스턴스를 시작하여 데이터 전송 요금을 증가시킬 수 있습니다. 
네트워크 처리량이 줄어들어 성능에 영향을 미칠 수 있습니다. 
Q307 
주로 온프레미스에서 애플리케이션 서버를 실행하는 회사가 AWS 로 마이그레이션하기로 
결정했습니다. 회사는 온프레미스에서 iSCSI(Internet Small Computer Systems Interface) 
스토리지를 확장해야 할 필요성을 최소화하려고 합니다. 회사는 최근에 액세스한 데이터만 로컬에 
저장하기를 원합니다. 
회사는 이러한 요구 사항을 충족하기 위해 어떤 AWS 솔루션을 사용해야 합니까? 
A. Amazon S3 파일 게이트웨이 
B. AWS Storage Gateway 테이프 게이트웨이 
C. AWS Storage Gateway 볼륨 게이트웨이 저장 볼륨 
D. AWS Storage Gateway 볼륨 게이트웨이 캐시 볼륨 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99611-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS Storage Gateway Volume Gateway 는 iSCSI 스토리지에 연결하기 위한 두 가지 구성, 즉 저장 
볼륨과 캐시 볼륨을 제공합니다. 저장된 볼륨 구성은 전체 데이터 세트를 온프레미스에 저장하고 
데이터를 AWS 에 비동기식으로 백업합니다. 캐싱된 볼륨 구성은 최근에 액세스한 데이터를 
온프레미스에 저장하고 나머지 데이터는 Amazon S3 에 저장합니다. 회사는 최근에 액세스한 
데이터만 로컬에 저장하기를 원하므로 캐시된 볼륨 구성이 가장 적절할 것입니다. 이를 통해 
회사는 자주 액세스하는 데이터를 온프레미스에 보관하고 iSCSI 스토리지 확장의 필요성을 
줄이면서 AWS 클라우드를 통해 모든 데이터에 대한 액세스를 계속 제공할 수 있습니다. 또한 이 
구성은 자주 액세스하는 데이터에 대한 짧은 대기 시간 액세스와 자주 액세스하지 않는 데이터에 
대한 비용 효율적인 오프사이트 백업을 제공합니다. 
https://docs.amazonaws.cn/en_us/storagegateway/latest/vgw/StorageGatewayConcepts.html#st
ora 
Q308 
회사에 통합 결제를 사용하는 여러 AWS 계정이 있습니다. 이 회사는 90 일 동안 여러 개의 활성 
고성능 Amazon RDS for Oracle 온디맨드 DB 인스턴스를 실행합니다. 회사의 재무 팀은 통합 결제 
계정 및 기타 모든 AWS 계정에서 AWS Trusted Advisor 에 액세스할 수 있습니다. 
재무 팀은 적절한 AWS 계정을 사용하여 RDS 에 대한 Trusted Advisor 확인 권장 사항에 
액세스해야 합니다. 재무팀은 적절한 Trusted Advisor 수표를 검토하여 RDS 비용을 줄여야 합니다. 
이러한 요구 사항을 충족하기 위해 재무 팀은 어떤 조합의 단계를 수행해야 합니까? (2 개 선택) 
A. RDS 인스턴스가 실행 중인 계정의 Trusted Advisor 권장 사항을 사용합니다. 
B. 통합 결제 계정의 Trusted Advisor 권장 사항을 사용하여 모든 RDS 인스턴스 확인을 동시에 
확인합니다. 
C. Amazon RDS 예약 인스턴스 최적화에 대한 Trusted Advisor 검사를 검토합니다. 
D. Amazon RDS 유휴 DB 인스턴스에 대한 Trusted Advisor 검사를 검토합니다. 
E. Amazon Redshift 예약 노드 최적화에 대한 Trusted Advisor 검사를 검토합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/99936-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q309 
솔루션 설계자는 스토리지 비용을 최적화해야 합니다. 솔루션 설계자는 더 이상 액세스하지 않거나 
거의 액세스하지 않는 Amazon S3 버킷을 식별해야 합니다. 
최소한의 운영 오버헤드로 이 목표를 달성할 수 있는 솔루션은 무엇입니까? 
A. 고급 활동 메트릭에 대한 S3 Storage Lens 대시보드를 사용하여 버킷 액세스 패턴을 
분석합니다. 
B. AWS Management Console 에서 S3 대시보드를 사용하여 버킷 액세스 패턴을 분석합니다. 
C. 버킷에 대한 Amazon CloudWatch BucketSizeBytes 지표를 켭니다. Amazon Athena 에서 메트릭 
데이터를 사용하여 버킷 액세스 패턴을 분석합니다. 
D. S3 객체 모니터링을 위해 AWS CloudTrail 을 켭니다. Amazon CloudWatch Logs 와 통합된 
CloudTrail 로그를 사용하여 버킷 액세스 패턴을 분석합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99803-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
S3 Storage Lens 는 객체 스토리지 사용량, 활동 추세 및 비용 최적화를 위한 권장 사항에 대한 
종합적인 보기를 제공하는 완전관리형 S3 스토리지 분석 솔루션입니다. Storage Lens 를 사용하면 
모든 S3 버킷에서 객체 액세스 패턴을 분석하고 자세한 지표와 보고서를 생성할 수 있습니다. 
Q310 
회사에서 인공 지능 및 기계 학습(AI/ML)을 연구하는 고객에게 데이터 세트를 판매합니다. 데이터 
세트는 us-east-1 리전의 Amazon S3 버킷에 저장되는 형식이 지정된 대용량 파일입니다. 회사는 
고객이 주어진 데이터 세트에 대한 액세스를 구매하는 데 사용하는 웹 애플리케이션을 
호스팅합니다. 웹 애플리케이션은 Application Load Balancer 뒤의 여러 Amazon EC2 인스턴스에 
배포됩니다. 구매 후 고객은 파일에 대한 액세스를 허용하는 S3 서명 URL 을 받습니다. 
고객은 북미와 유럽 전역에 분산되어 있습니다. 회사는 데이터 전송과 관련된 비용을 줄이고 
성능을 유지하거나 개선하고자 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 기존 S3 버킷에서 S3 Transfer Acceleration 을 구성합니다. 고객 요청을 S3 Transfer 
Acceleration 엔드포인트로 안내합니다. 액세스 제어를 위해 S3 서명 URL 을 계속 사용하십시오. 
B. 기존 S3 버킷을 원본으로 사용하여 Amazon CloudFront 배포를 배포합니다. 고객 요청을 
CloudFront URL 로 전달합니다. 액세스 제어를 위해 CloudFront 서명 URL 로 전환하십시오. 
C. 버킷 사이에 S3 교차 리전 복제가 있는 eu-central-1 리전에서 두 번째 S3 버킷을 설정합니다. 
가장 가까운 지역으로 고객 요청을 전달합니다. 액세스 제어를 위해 S3 서명 URL 을 계속 
사용하십시오. 
D. 데이터세트를 최종 사용자에게 스트리밍할 수 있도록 웹 애플리케이션을 수정합니다. 기존 S3 
버킷에서 데이터를 읽도록 웹 애플리케이션을 구성합니다. 애플리케이션에서 직접 액세스 제어를 
구현합니다. 
Answer: B  
https://www.examtopics.com/discussions/amazon/view/99697-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고: 
https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.ht
ml 
Q311 
한 회사에서 AWS 를 사용하여 보험 견적을 처리할 웹 애플리케이션을 설계하고 있습니다. 
사용자는 애플리케이션에서 견적을 요청합니다. 견적은 견적 유형별로 구분되어야 하며, 24 시간 
이내에 응답해야 하며 분실해서는 안 됩니다. 솔루션은 운영 효율성을 극대화하고 유지 보수를 
최소화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 견적 유형에 따라 여러 Amazon Kinesis 데이터 스트림을 생성합니다. 적절한 데이터 
스트림으로 메시지를 보내도록 웹 애플리케이션을 구성합니다. Kinesis Client Library(KCL)를 
사용하여 자체 데이터 스트림에서 메시지를 풀링하도록 애플리케이션 서버의 각 백엔드 그룹을 
구성합니다. 
B. 각 견적 유형에 대해 AWS Lambda 함수 및 Amazon Simple Notification Service(Amazon SNS) 
주제를 생성합니다. 연결된 SNS 주제에 Lambda 함수를 구독합니다. 견적 요청을 적절한 SNS 
주제에 게시하도록 애플리케이션을 구성합니다. 
C. 단일 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. SNS 주제에 대한 
Amazon Simple Queue Service(Amazon SQS) 대기열을 구독합니다. 견적 유형에 따라 적절한 SQS 
대기열에 메시지를 게시하도록 SNS 메시지 필터링을 구성합니다. 자체 SQS 대기열을 사용하도록 
각 백엔드 애플리케이션 서버를 구성합니다. 
D. 데이터 스트림을 Amazon OpenSearch Service 클러스터로 전달하기 위해 견적 유형을 
기반으로 여러 Amazon Kinesis Data Firehose 전달 스트림을 생성합니다. 적절한 전송 스트림으로 
메시지를 보내도록 애플리케이션을 구성합니다. OpenSearch Service 에서 메시지를 검색하고 그에 
따라 처리하도록 애플리케이션 서버의 각 백엔드 그룹을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99627-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고: 
https://aws.amazon.com/getting-started/hands-on/filter-messages-published-to-topics/ 
Q312 
한 회사에 여러 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 각 EC2 
인스턴스에는 여러 Amazon Elastic Block Store(Amazon EBS) 데이터 볼륨이 연결되어 있습니다. 
애플리케이션의 EC2 인스턴스 구성 및 데이터는 야간에 백업해야 합니다. 또한 애플리케이션은 
다른 AWS 리전에서 복구 가능해야 합니다. 
운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 애플리케이션 EBS 볼륨의 야간 스냅샷을 예약하고 스냅샷을 다른 리전에 복사하는 AWS 
Lambda 함수를 작성하십시오. 
B. 야간 백업을 수행하기 위해 AWS Backup 을 사용하여 백업 계획을 생성합니다. 백업을 다른 
리전에 복사합니다. 애플리케이션의 EC2 인스턴스를 리소스로 추가합니다. 
C. 야간 백업을 수행하기 위해 AWS Backup 을 사용하여 백업 계획을 만듭니다. 백업을 다른 
리전에 복사합니다. 애플리케이션의 EBS 볼륨을 리소스로 추가합니다. 
D. 애플리케이션 EBS 볼륨의 야간 스냅샷을 예약하고 스냅샷을 다른 가용 영역에 복사하는 AWS 
Lambda 함수를 작성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99785-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이러한 요구 사항을 충족하는 운영상 가장 효율적인 솔루션은 AWS Backup 을 사용하여 야간 
백업을 수행하고 백업을 다른 리전에 복사하는 백업 계획을 만드는 것입니다. 애플리케이션의 EBS 
볼륨을 리소스로 추가하면 애플리케이션의 EC2 인스턴스 구성 및 데이터가 백업되고 백업을 다른 
리전에 복사하면 애플리케이션을 다른 AWS 리전에서 복구할 수 있습니다. 
Q313 
회사가 AWS 에서 모바일 앱을 구축하고 있습니다. 회사는 수백만 명의 사용자에게 도달 범위를 
확장하려고 합니다. 회사는 승인된 사용자가 모바일 장치에서 회사의 콘텐츠를 볼 수 있도록 
플랫폼을 구축해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. 퍼블릭 Amazon S3 버킷에 콘텐츠를 게시합니다. AWS Key Management Service(AWS KMS) 
키를 사용하여 콘텐츠를 스트리밍합니다. 
B. 모바일 앱과 AWS 환경 간에 IPsec VPN 을 설정하여 콘텐츠를 스트리밍합니다. 
C. Amazon CloudFront 를 사용합니다. 스트리밍 콘텐츠에 서명된 URL 을 제공합니다. 
D. 모바일 앱과 AWS 환경 간에 AWS Client VPN 을 설정하여 콘텐츠를 스트리밍합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/100130-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon CloudFront 는 짧은 지연 시간과 높은 전송 속도로 데이터, 비디오, 애플리케이션 및 
API 를 전 세계 고객에게 안전하게 전달하는 콘텐츠 전송 네트워크(CDN)입니다. CloudFront 는 
콘텐츠에 대한 인증된 액세스를 제공하는 서명된 URL 을 지원합니다. 이 기능을 통해 회사는 
콘텐츠에 액세스할 수 있는 사람과 기간을 제어하여 수백만 명의 사용자에게 안전하고 확장 
가능한 솔루션을 제공할 수 있습니다. 
Q314 
회사에는 드물게 액세스하는 패턴으로 글로벌 영업 팀에서 사용하는 온프레미스 MySQL 
데이터베이스가 있습니다. 영업팀은 데이터베이스의 가동 중지 시간을 최소화해야 합니다. 
데이터베이스 관리자는 향후 더 많은 사용자를 예상하여 특정 인스턴스 유형을 선택하지 않고 이 
데이터베이스를 AWS 로 마이그레이션하려고 합니다. 
솔루션 설계자는 어떤 서비스를 추천해야 합니까? 
A. 아마존 오로라 MySQL 
B. MySQL 용 Amazon Aurora 서버리스 
C. 아마존 레드시프트 스펙트럼 
D. MySQL 용 Amazon RDS 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99769-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon Aurora Serverless for MySQL 은 애플리케이션 수요에 따라 자동으로 확장 또는 축소되는 
완전관리형 자동 확장 관계형 데이터베이스 서비스입니다. 이 서비스는 고객이 데이터베이스 
인스턴스를 프로비저닝할 필요 없이 고가용성, 내구성 및 보안과 같은 Amazon Aurora 의 모든 
기능을 제공합니다. Amazon Aurora Serverless for MySQL 을 사용하면 증가한 트래픽을 수용할 수 
있도록 데이터베이스가 자동으로 확장되도록 설계되었기 때문에 영업 팀은 다운타임을 최소화할 
수 있습니다. 또한 이 서비스를 통해 고객은 사용한 용량에 대해서만 비용을 지불할 수 있으므로 
자주 사용하지 않는 액세스 패턴에 대해 비용 효율적입니다. Amazon RDS for MySQL 도 옵션이 될 
수 있지만 고객이 인스턴스 유형을 선택해야 하고 데이터베이스 관리자는 증가하는 트래픽을 
수용하기 위해 수동으로 인스턴스 크기를 모니터링하고 조정해야 합니다. 
Q315 
회사는 온프레미스 데이터 센터의 여러 애플리케이션에 영향을 미치는 위반을 경험했습니다. 
공격자는 서버에서 실행 중인 맞춤형 애플리케이션의 취약점을 이용했습니다. 이 회사는 현재 
Amazon EC2 인스턴스에서 실행되도록 애플리케이션을 마이그레이션하고 있습니다. 이 회사는 
EC2 인스턴스의 취약성을 능동적으로 스캔하고 결과를 자세히 설명하는 보고서를 보내는 솔루션을 
구현하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Shield 를 배포하여 EC2 인스턴스의 취약점을 스캔합니다. 결과를 AWS CloudTrail 에 
기록하는 AWS Lambda 함수를 생성합니다. 
B. Amazon Macie 및 AWS Lambda 함수를 배포하여 EC2 인스턴스의 취약점을 스캔합니다. 
결과를 AWS CloudTrail 에 기록합니다. 
C. Amazon GuardDuty 를 켭니다. GuardDuty 에이전트를 EC2 인스턴스에 배포합니다. 결과를 
자세히 설명하는 보고서의 생성 및 배포를 자동화하도록 AWS Lambda 함수를 구성합니다. 
D. Amazon Inspector 를 켭니다. Amazon Inspector 에이전트를 EC2 인스턴스에 배포합니다. 
결과를 자세히 설명하는 보고서의 생성 및 배포를 자동화하도록 AWS Lambda 함수를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99808-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon Inspector(Amazon 검사기): 
* EC2 인스턴스의 활성 취약성 스캔을 수행합니다. 소프트웨어 취약성, 의도하지 않은 네트워크 
접근성 및 기타 보안 문제를 찾습니다. 
* 스캔을 수행하려면 EC2 인스턴스에 에이전트를 설치해야 합니다. 에이전트는 각 인스턴스에 
배포되어야 합니다. 
* 보안 위험 또는 취약점에 대한 발견 사항을 자세히 설명하는 예약 검사 보고서를 제공합니다. 
이러한 보고서는 문제를 패치하거나 수정하는 데 사용할 수 있습니다. 
* AWS 환경에서 보안 취약점 및 잘못된 구성을 사전에 감지하는 데 가장 적합합니다. 
Q316 
회사는 Amazon EC2 인스턴스를 사용하여 스크립트를 실행하여 Amazon Simple Queue 
Service(Amazon SQS) 대기열에서 메시지를 폴링하고 처리합니다. 이 회사는 대기열에 추가되는 
점점 더 많은 수의 메시지를 처리할 수 있는 능력을 유지하면서 운영 비용을 절감하고자 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. 메시지를 더 빠르게 처리하려면 EC2 인스턴스의 크기를 늘리십시오. 
B. 인스턴스가 충분히 활용되지 않을 때 Amazon EventBridge 를 사용하여 EC2 인스턴스를 
끕니다. 
C. EC2 인스턴스의 스크립트를 적절한 런타임이 있는 AWS Lambda 함수로 마이그레이션합니다. 
D. AWS Systems Manager Run Command 를 사용하여 요청 시 스크립트를 실행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99698-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q317 
회사에서 레거시 애플리케이션을 사용하여 데이터를 CSV 형식으로 생성합니다. 레거시 
애플리케이션은 출력 데이터를 Amazon S3 에 저장합니다. 이 회사는 복잡한 SQL 쿼리를 수행하여 
Amazon Redshift 및 Amazon S3 에만 저장된 데이터를 분석할 수 있는 새로운 상용 기성품(COTS) 
애플리케이션을 배포하고 있습니다. 그러나 COTS 애플리케이션은 레거시 애플리케이션이 
생성하는 .csv 파일을 처리할 수 없습니다. 
회사는 레거시 애플리케이션을 업데이트하여 다른 형식으로 데이터를 생성할 수 없습니다. 회사는 
COTS 애플리케이션이 레거시 애플리케이션이 생성하는 데이터를 사용할 수 있도록 솔루션을 
구현해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 일정에 따라 실행되는 AWS Glue 추출, 변환 및 로드(ETL) 작업을 생성합니다. .csv 파일을 
처리하고 처리된 데이터를 Amazon Redshift 에 저장하도록 ETL 작업을 구성합니다. 
B. Amazon EC2 인스턴스에서 실행되는 Python 스크립트를 개발하여 .csv 파일을 .sql 파일로 
변환합니다. Cron 일정에서 Python 스크립트를 호출하여 출력 파일을 Amazon S3 에 저장합니다. 
C. AWS Lambda 함수와 Amazon DynamoDB 테이블을 생성합니다. S3 이벤트를 사용하여 Lambda 
함수를 호출합니다. ETL(추출, 변환 및 로드) 작업을 수행하여 .csv 파일을 처리하고 처리된 
데이터를 DynamoDB 테이블에 저장하도록 Lambda 함수를 구성합니다. 
D. Amazon EventBridge 를 사용하여 매주 일정에 따라 Amazon EMR 클러스터를 시작합니다. 추출, 
변환 및 로드(ETL) 작업을 수행하여 .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift 
테이블에 저장하도록 EMR 클러스터를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99817-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 솔루션은 COTS 애플리케이션이 최소한의 운영 오버헤드로 레거시 애플리케이션이 생성하는 
데이터를 사용할 수 있도록 솔루션 구현 요구 사항을 충족합니다. AWS Glue 는 분석을 위해 
데이터를 준비하고 로드하는 서버리스 ETL 플랫폼을 제공하는 완전 관리형 서비스입니다. 
AWS Glue 는 .csv 파일을 비롯한 다양한 형식의 데이터를 처리하고 복잡한 SQL 쿼리를 지원하는 
완전관리형 데이터 웨어하우스 서비스인 Amazon Redshift 에 처리된 데이터를 저장할 수 있습니다. 
AWS Glue 는 데이터 처리 및 로드 프로세스를 자동화할 수 있는 일정에 따라 ETL 작업을 실행할 
수 있습니다. 
옵션 B 는 올바르지 않습니다. Amazon EC2 인스턴스에서 실행되는 Python 스크립트를 
개발하여 .csv 파일을 sql 파일로 변환하면 운영 오버헤드와 복잡성이 증가하고 COTS 
애플리케이션에 일관된 데이터 처리 및 로드를 제공하지 못할 수 있기 때문입니다. 
.csv 파일을 처리하고 처리된 데이터를 DynamoDB 테이블에 저장하기 위해 AWS Lambda 함수 및 
Amazon DynamoDB 테이블을 생성하는 것은 Amazon Redshift 를 COTS 애플리케이션의 데이터 
소스로 사용하기 위한 요구 사항을 충족하지 않기 때문에 옵션 C 는 올바르지 않습니다. 
Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 주간 일정에 따라 Amazon EMR 
클러스터를 시작하여 .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift 테이블에 저장할 수 
있으므로 옵션 D 는 올바르지 않습니다. COTS 애플리케이션에 적시에 데이터 처리 및 로드를 
제공하지 않습니다. 
참조: 
https://aws.amazon.com/glue/ 
https://aws.amazon.com/redshift/ 
Q318 
한 회사가 최근 전체 IT 환경을 AWS 클라우드로 마이그레이션했습니다. 회사는 사용자가 적절한 
변경 제어 프로세스를 사용하지 않고 과도한 크기의 Amazon EC2 인스턴스를 프로비저닝하고 
보안 그룹 규칙을 수정하고 있음을 발견했습니다. 솔루션 설계자는 이러한 인벤토리 및 구성 변경 
사항을 추적하고 감사하기 위한 전략을 고안해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (2 개 선택) 
A. AWS CloudTrail 을 활성화하고 감사에 사용하십시오. 
B. Amazon EC2 인스턴스에 대한 데이터 수명 주기 정책을 사용합니다. 
C. AWS Trusted Advisor 를 활성화하고 보안 대시보드를 참조합니다. 
D. AWS Config 를 활성화하고 감사 및 규정 준수를 위한 규칙을 생성합니다. 
E. AWS CloudFormation 템플릿을 사용하여 이전 리소스 구성을 복원합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/99804-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
A) AWS CloudTrail 을 활성화하고 감사에 사용합니다. AWS CloudTrail 은 API 호출 기록을 제공하며 
EC2 인스턴스 및 보안 그룹에 대한 변경 사항을 감사하는 데 사용할 수 있습니다. 솔루션 
설계자는 CloudTrail 로그를 분석하여 적절한 승인 없이 누가 대규모 인스턴스를 프로비저닝했거나 
보안 그룹을 수정했는지 추적할 수 있습니다. 
D) AWS Config 를 활성화하고 감사 및 규정 준수를 위한 규칙을 생성합니다. AWS Config 는 EC2 
인스턴스 및 보안 그룹과 같은 리소스에 대한 구성 변경 사항을 기록할 수 있습니다. 솔루션 
설계자는 특정 인스턴스 유형을 시작하거나 권한 없이 보안 그룹 포트를 여는 것과 같은 비준수 
변경 사항을 모니터링하기 위해 AWS Config 규칙을 생성할 수 있습니다. AWS Config 는 이러한 
규칙 위반에 대해 경고합니다. 
Q319 
회사는 AWS 클라우드에 수백 개의 Amazon EC2 Linux 기반 인스턴스를 보유하고 있습니다. 
시스템 관리자는 공유 SSH 키를 사용하여 인스턴스를 관리했습니다. 최근 감사 후 회사의 보안 
팀은 모든 공유 키를 제거하도록 지시하고 있습니다. 솔루션 설계자는 EC2 인스턴스에 대한 보안 
액세스를 제공하는 솔루션을 설계해야 합니다. 
최소한의 관리 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Systems Manager Session Manager 를 사용하여 EC2 인스턴스에 연결합니다. 
B. AWS Security Token Service(AWS STS)를 사용하여 온디맨드 방식으로 일회성 SSH 키를 
생성합니다. 
C. 배스천 인스턴스 집합에 대한 공유 SSH 액세스를 허용합니다. 배스천 인스턴스에서 SSH 
액세스만 허용하도록 다른 모든 인스턴스를 구성합니다. 
D. Amazon Cognito 사용자 지정 권한 부여자를 사용하여 사용자를 인증합니다. AWS Lambda 
함수를 호출하여 임시 SSH 키를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99628-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Session Manager 는 완전히 관리되는 AWS Systems Manager 기능입니다. Session Manager 를 
사용하여 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스, 에지 장치, 온프레미스 서버 및 
가상 머신(VM)을 관리할 수 있습니다. 대화형 원클릭 브라우저 기반 셸 또는 AWS Command Line 
Interface(AWS CLI)를 사용할 수 있습니다. Session Manager 는 인바운드 포트를 열거나 배스천 
호스트를 유지하거나 SSH 키를 관리할 필요 없이 안전하고 감사 가능한 노드 관리를 제공합니다. 
또한 Session Manager 를 사용하면 관리 노드에 대한 제어된 액세스, 엄격한 보안 관행, 노드 
액세스 세부 정보가 포함된 완전히 감사 가능한 로그가 필요한 기업 정책을 준수하는 동시에 최종 
사용자에게 관리 노드에 대한 간단한 원클릭 교차 플랫폼 액세스를 제공할 수 있습니다. 
https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html 
Q320 
회사에서 Amazon EC2 인스턴스 플릿을 사용하여 온프레미스 데이터 소스에서 데이터를 수집하고 
있습니다. 데이터는 JSON 형식이며 수집 속도는 최대 1MB/s 입니다. EC2 인스턴스가 재부팅되면 
진행 중인 데이터가 손실됩니다. 회사의 데이터 과학 팀은 거의 실시간으로 수집된 데이터를 
쿼리하려고 합니다. 
데이터 손실을 최소화하면서 확장 가능한 거의 실시간 데이터 쿼리를 제공하는 솔루션은 
무엇입니까? 
A. Amazon Kinesis Data Streams에 데이터를 게시하고 Kinesis Data Analytics를 사용하여 데이터를 
쿼리합니다. 
B. Amazon Redshift 를 대상으로 사용하여 Amazon Kinesis Data Firehose 에 데이터를 게시합니다. 
Amazon Redshift 를 사용하여 데이터를 쿼리합니다. 
C. 수집된 데이터를 EC2 인스턴스 스토어에 저장합니다. Amazon S3 를 대상으로 Amazon Kinesis 
Data Firehose 에 데이터를 게시합니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다. 
D. 수집된 데이터를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. Redis 용 
Amazon ElastiCache 에 데이터를 게시합니다. Redis 채널을 구독하여 데이터를 쿼리합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99752-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
참고 
https://docs.aws.amazon.com/ko_kr/kinesisanalytics/latest/dev/what-is.html 
Q321 
솔루션 설계자는 Amazon S3 버킷에 업로드된 모든 객체가 암호화되도록 하려면 어떻게 해야 
합니까? 
A. PutObject 에 s3:x-amz-acl 헤더 세트가 없는 경우 거부하도록 버킷 정책을 업데이트합니다. 
B. PutObject 에 프라이빗으로 설정된 s3:x-amz-acl 헤더가 없는 경우 거부하도록 버킷 정책을 
업데이트합니다. 
C. PutObject 에 true 로 설정된 aws:SecureTransport 헤더가 없는 경우 거부하도록 버킷 정책을 
업데이트합니다. 
D. PutObject 에 x-amz-server-side-encryption 헤더 세트가 없는 경우 거부하도록 버킷 정책을 
업데이트합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99685-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q322 
솔루션 설계자는 회사를 위한 다중 계층 애플리케이션을 설계하고 있습니다. 애플리케이션 
사용자는 모바일 장치에서 이미지를 업로드합니다. 애플리케이션은 각 이미지의 썸네일을 생성하고 
이미지가 성공적으로 업로드되었음을 확인하는 메시지를 사용자에게 반환합니다. 
썸네일 생성에는 최대 60 초가 소요될 수 있지만 회사는 사용자에게 원본 이미지가 수신되었음을 
알리기 위해 더 빠른 응답 시간을 제공하고자 합니다. 솔루션 설계자는 서로 다른 애플리케이션 
계층에 요청을 비동기식으로 전달하도록 애플리케이션을 설계해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 사용자 지정 AWS Lambda 함수를 작성하여 썸네일을 생성하고 사용자에게 알립니다. 이미지 
업로드 프로세스를 이벤트 소스로 사용하여 Lambda 함수를 호출합니다. 
B. AWS Step Functions 워크플로를 생성합니다. 애플리케이션 계층 간의 오케스트레이션을 
처리하고 썸네일 생성이 완료되면 사용자에게 알리도록 Step Functions 를 구성합니다. 
C. Amazon Simple Queue Service(Amazon SQS) 메시지 대기열을 생성합니다. 이미지가 
업로드되면 썸네일 생성을 위해 SQS 대기열에 메시지를 배치합니다. 이미지가 수신되었음을 
애플리케이션 메시지를 통해 사용자에게 알립니다. 
D. Amazon Simple Notification Service(Amazon SNS) 알림 주제 및 구독을 생성합니다. 
애플리케이션과 함께 하나의 구독을 사용하여 이미지 업로드가 완료된 후 썸네일을 생성하십시오. 
섬네일 생성이 완료된 후 푸시 알림을 통해 사용자의 모바일 앱에 메시지를 보내려면 두 번째 
구독을 사용하십시오. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99753-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
이 옵션은 메시지 손실이나 다른 서비스를 사용할 필요 없이 모든 볼륨의 소프트웨어 구성 요소 
간에 메시지를 전송, 저장 및 수신할 수 있는 완전 관리형 메시지 대기열 서비스인 Amazon 
SQS 를 사용하기 때문에 가장 효율적입니다. 또한 SQS 메시지 대기열을 사용하여 서로 다른 
애플리케이션 계층에 요청을 비동기식으로 전달하여 썸네일 생성 프로세스에서 이미지 업로드 
프로세스를 분리하고 확장성과 안정성을 활성화합니다. 또한 이미지가 수신되었다는 애플리케이션 
메시지를 통해 사용자에게 경고하므로 섬네일 생성이 완료될 때까지 기다리는 것보다 사용자에게 
더 빠른 응답 시간을 제공합니다. 
옵션 A 는 서버를 프로비저닝하거나 관리하지 않고 코드를 실행하는 방법인 사용자 지정 AWS 
Lambda 함수를 사용하여 썸네일을 생성하고 사용자에게 경고하기 때문에 효율성이 떨어집니다. 
그러나 이것은 썸네일 생성 프로세스에서 이미지 업로드 프로세스를 분리하기 위해 비동기 
디스패치 메커니즘을 사용하지 않습니다. 또한 이미지 업로드 프로세스를 이벤트 소스로 사용하여 
Lambda 함수를 호출하므로 한 번에 업로드된 이미지가 많은 경우 동시성 문제가 발생할 수 
있습니다. 
옵션 B 는 애플리케이션의 구성 요소를 일련의 단계로 배열하고 시각화하는 그래픽 콘솔을 
제공하는 완전관리형 서비스인 AWS Step Functions 를 사용하기 때문에 효율성이 떨어집니다. 
그러나 이것은 썸네일 생성 프로세스에서 이미지 업로드 프로세스를 분리하기 위해 비동기 
디스패치 메커니즘을 사용하지 않습니다. 또한 Step Functions를 사용하여 애플리케이션 계층 간의 
오케스트레이션을 처리하고 썸네일 생성이 완료되면 사용자에게 경고하므로 추가적인 복잡성과 
대기 시간이 발생할 수 있습니다. 
옵션 D 는 SMS 문자 메시지 또는 이메일을 통해 메시지 또는 알림을 사용자에게 직접 보낼 수 
있는 완전 관리형 메시징 서비스인 Amazon SNS 를 사용하기 때문에 효율성이 떨어집니다. 그러나 
이것은 썸네일 생성 프로세스에서 이미지 업로드 프로세스를 분리하기 위해 비동기 디스패치 
메커니즘을 사용하지 않습니다. 또한 SNS 알림 주제 및 구독을 사용하여 이미지 업로드가 완료된 
후 썸네일을 생성하고 썸네일 생성이 완료된 후 푸시 알림을 통해 사용자의 모바일 앱에 메시지를 
보내므로 추가적인 복잡성과 대기 시간이 발생할 수 있습니다. 
Q323 
회사 시설에는 건물 전체의 모든 입구에 배지 판독기가 있습니다. 배지를 스캔하면 판독기가 
HTTPS 를 통해 메시지를 보내 누가 해당 입구에 액세스하려고 시도했는지 나타냅니다. 
솔루션 설계자는 센서에서 보내는 이러한 메시지를 처리하는 시스템을 설계해야 합니다. 솔루션은 
가용성이 높아야 하며 회사의 보안 팀이 분석할 수 있도록 결과를 제공해야 합니다. 
솔루션 설계자는 어떤 시스템 아키텍처를 추천해야 합니까? 
A. Amazon EC2 인스턴스를 시작하여 HTTPS 엔드포인트 역할을 하고 메시지를 처리합니다. 
결과를 Amazon S3 버킷에 저장하도록 EC2 인스턴스를 구성합니다. 
B. Amazon API Gateway 에서 HTTPS 엔드포인트를 생성합니다. AWS Lambda 함수를 호출하여 
메시지를 처리하고 결과를 Amazon DynamoDB 테이블에 저장하도록 API Gateway 엔드포인트를 
구성합니다. 
C. Amazon Route 53 을 사용하여 들어오는 센서 메시지를 AWS Lambda 함수로 보냅니다. 
메시지를 처리하고 결과를 Amazon DynamoDB 테이블에 저장하도록 Lambda 함수를 구성합니다. 
D. Amazon S3 용 게이트웨이 VPC 엔드포인트를 생성합니다. 센서 데이터가 VPC 엔드포인트를 
통해 S3 버킷에 직접 기록될 수 있도록 시설 네트워크에서 VPC 로의 Site-to-Site VPN 연결을 
구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99699-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon API Gateway 를 HTTPS 엔드포인트로 배포하고 AWS Lambda 를 배포하여 메시지를 
처리하고 Amazon DynamoDB 테이블에 저장합니다. 이 옵션은 대량의 데이터를 쉽게 처리할 수 
있는 가용성과 확장성이 뛰어난 솔루션을 제공합니다. 또한 다른 AWS 서비스와 통합되어 보안 
팀의 데이터를 보다 쉽게 분석하고 시각화할 수 있습니다. 
Q324 
회사는 기본 온프레미스 파일 스토리지 볼륨에 대한 재해 복구 계획을 구현하려고 합니다. 파일 
스토리지 볼륨은 로컬 스토리지 서버의 iSCSI(Internet Small Computer Systems Interface) 장치에서 
마운트됩니다. 파일 스토리지 볼륨은 수백 테라바이트(TB)의 데이터를 보유합니다. 
회사는 최종 사용자가 대기 시간 없이 온프레미스 시스템의 모든 파일 유형에 즉시 액세스할 수 
있기를 원합니다. 
회사의 기존 인프라를 최소한으로 변경하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 온프레미스에서 호스팅되는 가상 머신(VM)으로 Amazon S3 파일 게이트웨이를 
프로비저닝합니다. 로컬 캐시를 10TB 로 설정합니다. NFS 프로토콜을 통해 파일에 액세스하도록 
기존 애플리케이션을 수정합니다. 재해에서 복구하려면 Amazon EC2 인스턴스를 프로비저닝하고 
파일이 포함된 S3 버킷을 탑재합니다. 
B. AWS Storage Gateway 테이프 게이트웨이를 프로비저닝합니다. 데이터 백업 솔루션을 사용하여 
모든 기존 데이터를 가상 테이프 라이브러리에 백업하십시오. 초기 백업이 완료된 후 야간에 
실행되도록 데이터 백업 솔루션을 구성합니다. 재해에서 복구하려면 Amazon EC2 인스턴스를 
프로비저닝하고 가상 테이프 라이브러리의 볼륨에서 Amazon Elastic Block Store(Amazon EBS) 
볼륨으로 데이터를 복원합니다. 
C. AWS Storage Gateway 볼륨 게이트웨이 캐시 볼륨을 프로비저닝합니다. 로컬 캐시를 10TB 로 
설정합니다. iSCSI 를 사용하여 볼륨 게이트웨이 캐싱 볼륨을 기존 파일 서버에 마운트하고 모든 
파일을 스토리지 볼륨에 복사합니다. 스토리지 볼륨의 예약된 스냅샷을 구성합니다. 재해에서 
복구하려면 스냅샷을 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 복원하고 EBS 볼륨을 
Amazon EC2 인스턴스에 연결합니다. 
D. 기존 파일 스토리지 볼륨과 동일한 양의 디스크 공간으로 AWS Storage Gateway 볼륨 
게이트웨이 저장 볼륨을 프로비저닝합니다. iSCSI 를 사용하여 볼륨 게이트웨이 저장 볼륨을 기존 
파일 서버에 마운트하고 모든 파일을 스토리지 볼륨에 복사합니다. 스토리지 볼륨의 예약된 
스냅샷을 구성합니다. 재해에서 복구하려면 스냅샷을 Amazon Elastic Block Store(Amazon EBS) 
볼륨으로 복원하고 EBS 볼륨을 Amazon EC2 인스턴스에 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99711-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
"회사는 최종 사용자가 온프레미스 시스템의 모든 파일 유형에 즉시 액세스할 수 있기를 
원합니다." 
- 캐싱된 볼륨(Cached volumes): 가장 최근 데이터에 대한 액세스 대기 시간이 짧습니다. 
- 저장 볼륨(Stored volumes): 전체 데이터 세트는 온프레미스이며 S3 로 예약 백업되므로 볼륨 
게이트웨이 저장 볼륨이 적절한 선택입니다. 
Q325 
회사는 Amazon S3 버킷에서 웹 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon 
Cognito 를 자격 증명 공급자로 사용하여 사용자를 인증하고 다른 S3 버킷에 저장된 보호된 
리소스에 대한 액세스를 제공하는 JSON 웹 토큰(JWT)을 반환합니다. 
응용 프로그램 배포 시 사용자는 오류를 보고하고 보호된 콘텐츠에 액세스할 수 없습니다. 솔루션 
설계자는 사용자가 보호된 콘텐츠에 액세스할 수 있도록 적절한 권한을 제공하여 이 문제를 
해결해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon Cognito 자격 증명 풀을 업데이트하여 보호된 콘텐츠에 액세스하기 위한 적절한 IAM 
역할을 맡습니다. 
B. 애플리케이션이 보호된 콘텐츠에 액세스할 수 있도록 S3 ACL 을 업데이트합니다. 
C. 애플리케이션을 Amazon S3 에 재배포하여 S3 버킷의 최종적으로 일관된 읽기가 보호된 
콘텐츠에 액세스하는 사용자의 기능에 영향을 미치지 않도록 합니다. 
D. 자격 증명 풀 내에서 사용자 지정 속성 매핑을 사용하고 사용자에게 보호된 콘텐츠에 액세스할 
수 있는 적절한 권한을 부여하도록 Amazon Cognito 풀을 업데이트합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99754-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon Cognito 자격 증명 풀은 인증된 사용자에게 AWS 리소스에 액세스할 수 있는 권한이 
제한된 임시 자격 증명 세트를 할당합니다. 각 사용자의 권한은 생성한 IAM 역할을 통해 
제어됩니다. 
https://docs.aws.amazon.com/cognito/latest/developerguide/role-basedaccess-control.html 
Q326 
이미지 호스팅 회사는 대규모 자산을 Amazon S3 Standard 버킷에 업로드합니다. 회사는 S3 API 를 
사용하여 멀티파트 업로드를 병렬로 사용하고 동일한 객체가 다시 업로드되면 덮어씁니다. 업로드 
후 처음 30 일 동안 개체에 자주 액세스합니다. 개체는 30 일 후에 덜 자주 사용되지만 각 개체에 
대한 액세스 패턴은 일관되지 않습니다. 회사는 저장된 자산의 고가용성과 탄력성을 유지하면서 
S3 스토리지 비용을 최적화해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 작업 조합은 무엇입니까? (두 
가지를 선택하세요.) 
A. 30 일 후에 자산을 S3 Intelligent-Tiering 으로 이동합니다. 
B. 불완전한 멀티파트 업로드를 정리하도록 S3 수명 주기 정책을 구성합니다. 
C. 만료된 개체 삭제 마커를 정리하도록 S3 수명 주기 정책을 구성합니다. 
D. 30 일 후에 자산을 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다. 
E. 30 일 후 자산을 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 이동합니다. 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/99755-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
S3 Intelligent-Tiering 은 성능 영향, 검색 비용 또는 운영 오버헤드 없이 액세스 빈도에 따라 가장 
비용 효율적인 액세스 계층으로 데이터를 자동으로 이동하는 스토리지 클래스입니다. 회사 자산과 
같이 액세스 패턴을 알 수 없거나 변경하는 데이터에 이상적입니다. 30 일 후에 자산을 S3 
Intelligent-Tiering 으로 이동함으로써 회사는 저장된 자산의 고가용성과 복원력을 유지하면서 
스토리지 비용을 최적화할 수 있습니다. 
S3 수명 주기는 개체가 수명 주기 동안 비용 효율적으로 저장되도록 개체를 관리할 수 있게 
해주는 기능입니다. 수명 주기 규칙을 생성하여 Amazon S3 가 객체 그룹에 적용하는 작업을 
정의할 수 있습니다. 작업 중 하나는 업로드가 중단될 때 발생할 수 있는 불완전한 멀티파트 
업로드를 중단하는 것입니다. 불완전한 멀티파트 업로드를 정리하도록 S3 수명 주기 정책을 
구성함으로써 회사는 스토리지 비용을 줄이고 사용하지 않는 부분에 대한 비용 지불을 피할 수 
있습니다. 
만료된 객체 삭제 마커는 Amazon S3 에서 자동으로 삭제되고 스토리지 비용이 발생하지 않기 
때문에 옵션 C 는 올바르지 않습니다. 따라서 만료된 객체 삭제 마커를 정리하도록 S3 수명 주기 
정책을 구성해도 회사의 스토리지 비용에는 영향을 미치지 않습니다. 
옵션 D 는 올바르지 않습니다. S3 Standard-IA 는 자주 액세스하지 않지만 필요할 때 신속하게 
액세스해야 하는 데이터용 스토리지 클래스이기 때문입니다. S3 Standard 보다 저장 비용은 낮지만 
검색 비용은 더 높고 최소 저장 기간 요금은 30 일입니다. 따라서 30 일 후에 자산을 S3 
Standard-IA 로 이동해도 자산에 여전히 가끔 액세스하는 경우 회사의 스토리지 비용이 최적화되지 
않을 수 있습니다. 
옵션 E 는 올바르지 않습니다. S3 One Zone-IA 는 자주 액세스하지 않지만 필요할 때 신속하게 
액세스해야 하는 데이터용 스토리지 클래스이기 때문입니다. S3 Standard-IA 보다 스토리지 비용이 
저렴하지만 하나의 가용 영역에만 데이터를 저장하고 다른 스토리지 클래스보다 복원력이 
떨어집니다. 또한 검색 비용이 더 높고 최소 저장 기간 요금이 30 일입니다. 따라서 30 일 후에 
자산을 S3 One Zone-IA 로 이동하면 자산이 여전히 가끔씩 액세스되거나 고가용성이 필요한 경우 
회사의 스토리지 비용이 최적화되지 않을 수 있습니다. 
참조 URL: 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/delete-or-empty-bucket.html#delete
bucket-considerations 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html 
https://aws.amazon.com/certification/certified-solutions-architect-associate/ 
Q327 
솔루션 설계자는 Amazon EC2 인스턴스를 호스팅하는 VPC 네트워크를 보호해야 합니다. EC2 
인스턴스는 매우 민감한 데이터를 포함하고 프라이빗 서브넷에서 실행됩니다. 회사 정책에 따라 
VPC 에서 실행되는 EC2 인스턴스는 타사 URL 을 사용하는 소프트웨어 제품 업데이트를 위해 
인터넷에서 승인된 타사 소프트웨어 리포지토리에만 액세스할 수 있습니다. 다른 인터넷 트래픽은 
차단되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 아웃바운드 트래픽을 AWS 네트워크 방화벽 방화벽으로 라우팅하도록 프라이빗 서브넷의 
라우팅 테이블을 업데이트합니다. 도메인 목록 규칙 그룹을 구성합니다. 
B. AWS WAF 웹 ACL 을 설정합니다. 소스 및 대상 IP 주소 범위 집합을 기반으로 트래픽 요청을 
필터링하는 사용자 지정 규칙 집합을 만듭니다. 
C. 엄격한 인바운드 보안 그룹 규칙을 구현합니다. URL 을 지정하여 인터넷에서 승인된 소프트웨어 
리포지토리에 대한 트래픽만 허용하는 아웃바운드 규칙을 구성합니다. 
D. EC2 인스턴스 앞에 Application Load Balancer(ALB)를 구성합니다. 모든 아웃바운드 트래픽을 
ALB 로 보냅니다. 인터넷에 대한 아웃바운드 액세스를 위해 ALB 의 대상 그룹에서 URL 기반 규칙 
리스너를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99795-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
EC2 에서 네트워크 방화벽으로 아웃바운드 연결을 보냅니다. 네트워크 방화벽에서 소프트웨어 패치 
다운로드를 위해 특정 도메인을 허용하고 다른 모든 도메인을 거부하는 상태 저장 아웃바운드 
규칙을 생성합니다. 
Q328 
한 회사가 AWS 클라우드에서 3 계층 전자상거래 애플리케이션을 호스팅하고 있습니다. 회사는 
Amazon S3 에서 웹사이트를 호스팅하고 웹사이트를 판매 요청을 처리하는 API 와 통합합니다. 이 
회사는 ALB(Application Load Balancer) 뒤에 있는 3 개의 Amazon EC2 인스턴스에서 API 를 
호스팅합니다. API 는 판매 요청을 비동기식으로 처리하는 백엔드 작업자와 함께 정적 및 동적 
프런트 엔드 콘텐츠로 구성됩니다. 
회사는 신제품 출시 이벤트 기간 동안 판매 요청 건수가 급격하게 급증할 것으로 예상하고 있다. 
모든 요청이 성공적으로 처리되도록 하려면 솔루션 설계자가 무엇을 권장해야 합니까? 
A. 동적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. 트래픽 증가를 처리하기 위해 EC2 
인스턴스 수를 늘립니다. 
B. 정적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. Auto Scaling 그룹에 EC2 
인스턴스를 배치하여 네트워크 트래픽을 기반으로 새 인스턴스를 시작합니다. 
C. 동적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. ALB 앞에 Amazon ElastiCache 
인스턴스를 추가하여 API 가 처리할 트래픽을 줄입니다. 
D. 정적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. Amazon Simple Queue 
Service(Amazon SQS) 대기열을 추가하여 나중에 EC2 인스턴스에서 처리할 수 있도록 웹 
사이트에서 요청을 수신합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99704-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q329 
보안 감사 결과 Amazon EC2 인스턴스가 정기적으로 패치되지 않는 것으로 나타났습니다. 솔루션 
설계자는 대규모 EC2 인스턴스 전체에 대해 정기적인 보안 스캔을 실행할 솔루션을 제공해야 
합니다. 또한 솔루션은 정기적으로 EC2 인스턴스를 패치하고 각 인스턴스의 패치 상태에 대한 
보고서를 제공해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EC2 인스턴스에서 소프트웨어 취약성을 스캔하도록 Amazon Macie 를 설정합니다. 각 EC2 
인스턴스에서 cron 작업을 설정하여 정기적인 일정에 따라 인스턴스를 패치합니다. 
B. 계정에서 Amazon GuardDuty 를 켭니다. 소프트웨어 취약성에 대해 EC2 인스턴스를 스캔하도록 
GuardDuty 를 구성합니다. 정기적인 일정에 따라 EC2 인스턴스를 패치하도록 AWS Systems 
Manager Session Manager 를 설정합니다. 
C. 소프트웨어 취약성에 대해 EC2 인스턴스를 스캔하도록 Amazon Detective 를 설정합니다. 
정기적인 일정에 따라 EC2 인스턴스를 패치하도록 Amazon EventBridge 예약 규칙을 설정합니다. 
D. 계정에서 Amazon Inspector 를 켭니다. 소프트웨어 취약성에 대해 EC2 인스턴스를 스캔하도록 
Amazon Inspector 를 구성합니다. 정기적인 일정에 따라 EC2 인스턴스를 패치하도록 AWS 
Systems Manager Patch Manager 를 설정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99796-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q330 
회사에서 Amazon RDS DB 인스턴스에 데이터를 저장할 계획입니다. 회사는 미사용 데이터를 
암호화해야 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Key Management Service(AWS KMS)에서 키를 생성합니다. DB 인스턴스에 대한 암호화를 
활성화합니다. 
B. 암호화 키를 생성합니다. AWS Secrets Manager 에 키를 저장합니다. 키를 사용하여 DB 
인스턴스를 암호화합니다. 
C. AWS Certificate Manager(ACM)에서 인증서를 생성합니다. 인증서를 사용하여 DB 인스턴스에서 
SSL/TLS 를 활성화합니다. 
D. AWS Identity and Access Management(IAM)에서 인증서를 생성합니다. 인증서를 사용하여 DB 
인스턴스에서 SSL/TLS 를 활성화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99702-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon RDS 의 유휴 데이터를 암호화하려면 AWS Key Management Service(AWS KMS)를 
사용하는 Amazon RDS 의 암호화 기능을 사용할 수 있습니다. 이 기능을 통해 Amazon RDS 는 
고유한 키로 각 데이터베이스 인스턴스를 암호화합니다. 이 키는 AWS KMS 에 의해 안전하게 
저장됩니다. 자체 키를 관리하거나 기본 AWS 관리형 키를 사용할 수 있습니다. DB 인스턴스에 
대한 암호화를 활성화하면 Amazon RDS 가 자동 백업, 읽기 전용 복제본 및 스냅샷을 비롯한 기본 
스토리지를 암호화합니다. 
Q331 
회사는 30 일 이내에 데이터 센터에서 AWS 클라우드로 20TB 의 데이터를 마이그레이션해야 
합니다. 회사의 네트워크 대역폭은 15Mbps 로 제한되며 사용률이 70%를 초과할 수 없습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Snowball 을 사용하십시오. 
B. AWS DataSync 를 사용합니다. 
C. 안전한 VPN 연결을 사용하십시오. 
D. Amazon S3 Transfer Acceleration 을 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99603-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
AWS Snowball 은 AWS 클라우드 안팎으로 대량의 데이터 이동을 가속화하는 안전한 데이터 전송 
솔루션입니다. 한 번에 최대 80TB 의 데이터를 이동할 수 있고 최대 50Mbps 의 네트워크 대역폭을 
제공하므로 작업에 적합합니다. 또한 안전하고 사용하기 쉬우므로 이 마이그레이션에 이상적인 
솔루션입니다. 
Q332 
회사는 직원들에게 기밀 및 민감한 파일에 대한 안전한 액세스를 제공해야 합니다. 회사는 권한이 
있는 사용자만 파일에 액세스할 수 있기를 원합니다. 파일은 직원의 장치에 안전하게 
다운로드되어야 합니다. 
파일은 온프레미스 Windows 파일 서버에 저장됩니다. 그러나 원격 사용량의 증가로 인해 파일 
서버의 용량이 부족합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 파일 서버를 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 인바운드 트래픽을 
직원의 IP 주소로 제한하도록 보안 그룹을 구성합니다. 
B. 파일을 Amazon FSx for Windows File Server 파일 시스템으로 마이그레이션합니다. Amazon FSx 
파일 시스템을 온프레미스 Active Directory 와 통합합니다. AWS 클라이언트 VPN 을 구성합니다. 
C. 파일을 Amazon S3 로 마이그레이션하고 프라이빗 VPC 엔드포인트를 생성합니다. 다운로드를 
허용하려면 서명된 URL 을 만듭니다. 
D. 파일을 Amazon S3 로 마이그레이션하고 퍼블릭 VPC 엔드포인트를 생성합니다. 직원이 AWS 
IAM Identity Center(AWS Single Sign-On)로 로그인하도록 허용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99792-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Windows 파일 서버는 온프레미스이며 데이터를 클라우드에 복제할 무언가가 필요합니다. 우리가 
가진 유일한 옵션은 Windows 파일 서버용 AWS FSx 입니다. 또한 정보가 기밀이고 민감하기 
때문에 적절한 사용자가 안전한 방식으로 정보에 액세스할 수 있도록 해야 합니다. 
https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html 
Q333 
회사의 애플리케이션은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 
실행됩니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 
매월 1 일 자정에 월말 재무 계산 일괄 처리가 실행되면 응용 프로그램이 훨씬 느려집니다. 이로 
인해 EC2 인스턴스의 CPU 사용률이 즉시 100%에 도달하여 애플리케이션이 중단됩니다. 
애플리케이션이 워크로드를 처리하고 다운타임을 방지할 수 있도록 하기 위해 솔루션 설계자는 
무엇을 권장해야 합니까? 
A. ALB 앞에 Amazon CloudFront 배포를 구성합니다. 
B. CPU 사용률을 기반으로 EC2 Auto Scaling 단순 조정 정책을 구성합니다. 
C. 월별 일정을 기반으로 EC2 Auto Scaling 예약 조정 정책을 구성합니다. 
D. EC2 인스턴스에서 일부 워크로드를 제거하도록 Amazon ElastiCache 를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99791-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
월별 일정을 기반으로 EC2 Auto Scaling 예약 조정 정책을 구성하는 것이 가장 좋은 옵션입니다. 
이는 월별 배치 실행이 시작되기 전에 EC2 인스턴스의 사전 조정을 허용하기 때문입니다. 이렇게 
하면 애플리케이션이 다운타임 없이 증가된 워크로드를 처리할 수 있습니다. 예약된 조정 정책은 
배치 실행 몇 시간 전에 Auto Scaling 그룹의 인스턴스 수를 늘리고 배치 실행이 완료된 후 
인스턴스 수를 줄이도록 구성할 수 있습니다. 이렇게 하면 필요할 때 리소스를 사용할 수 있고 
필요하지 않을 때 리소스를 낭비하지 않을 수 있습니다. 월별 배치 실행 중에 증가된 워크로드를 
처리하고 다운타임을 방지하는 가장 적절한 솔루션은 월별 일정을 기반으로 EC2 Auto Scaling 
예약 조정 정책을 구성하는 것입니다. 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-scheduled-scaling.
html 
Q334 
회사는 고객이 온프레미스 Microsoft Active Directory 를 사용하여 Amazon S3 에 저장된 파일을 
다운로드할 수 있는 기능을 제공하려고 합니다. 고객의 애플리케이션은 SFTP 클라이언트를 
사용하여 파일을 다운로드합니다. 
운영 오버헤드를 최소화하고 고객의 애플리케이션을 변경하지 않으면서 이러한 요구 사항을 
충족하는 솔루션은 무엇입니까? 
A. Amazon S3 용 SFTP 로 AWS Transfer Family 를 설정합니다. 통합된 Active Directory 인증을 
구성합니다. 
B. 온프레미스 클라이언트를 Amazon S3 와 동기화하도록 AWS DMS(AWS Database Migration 
Service)를 설정합니다. 통합된 Active Directory 인증을 구성합니다. 
C. AWS IAM Identity Center(AWS Single Sign-On)를 사용하여 온프레미스 위치와 S3 위치 간에 
동기화하도록 AWS DataSync 를 설정합니다. 
D. SFTP 로 Windows Amazon EC2 인스턴스를 설정하여 온프레미스 클라이언트를 Amazon S3 와 
연결합니다. AWS Identity and Access Management(IAM)를 통합합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99703-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q335 
회사에서 갑자기 수요가 증가하고 있습니다. 회사는 Amazon 머신 이미지(AMI)에서 대규모 
Amazon EC2 인스턴스를 프로비저닝해야 합니다. 인스턴스는 Auto Scaling 그룹에서 실행됩니다. 
회사는 요구 사항을 충족하기 위해 최소 초기화 대기 시간을 제공하는 솔루션이 필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. aws ec2 register-image 명령을 사용하여 스냅샷에서 AMI 를 생성합니다. AWS Step Functions 를 
사용하여 Auto Scaling 그룹의 AMI 를 교체하십시오. 
B. 스냅샷에서 Amazon Elastic Block Store(Amazon EBS) 빠른 스냅샷 복원을 활성화합니다. 
스냅샷을 사용하여 AMI 를 프로비저닝합니다. Auto Scaling 그룹의 AMI 를 새 AMI 로 교체합니다. 
C. Amazon Data Lifecycle Manager(Amazon DLM)에서 AMI 생성을 활성화하고 수명 주기 규칙을 
정의합니다. Auto Scaling 그룹에서 AMI 를 수정하는 AWS Lambda 함수를 생성합니다. 
D. Amazon EventBridge 를 사용하여 AMI 를 프로비저닝하는 AWS Backup 수명 주기 정책을 
호출합니다. EventBridge 에서 Auto Scaling 그룹 용량 제한을 이벤트 소스로 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99686-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명 
스냅샷에서 Amazon Elastic Block Store(Amazon EBS) 빠른 스냅샷 복원을 활성화하면 스냅샷에서 
새 Amazon Machine Image(AMI)를 빠르게 생성할 수 있으므로 새 인스턴스를 프로비저닝할 때 
초기화 지연 시간을 줄이는 데 도움이 됩니다. AMI 가 프로비저닝되면 Auto Scaling 그룹의 AMI 를 
새 AMI 로 교체할 수 있습니다. 이렇게 하면 업데이트된 AMI 에서 새 인스턴스가 시작되고 증가된 
수요를 신속하게 충족할 수 있습니다. 
Q336 
회사는 Amazon Aurora MySQL DB 클러스터를 스토리지로 사용하는 다중 계층 웹 애플리케이션을 
호스팅합니다. 애플리케이션 계층은 Amazon EC2 인스턴스에서 호스팅됩니다. 회사의 IT 보안 
지침에 따라 데이터베이스 자격 증명을 암호화하고 14 일마다 교체해야 합니다. 
최소한의 운영 노력으로 이 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 새 AWS Key Management Service(AWS KMS) 암호화 키를 생성합니다. AWS Secrets Manager 를 
사용하여 적절한 자격 증명과 함께 KMS 키를 사용하는 새 암호를 생성합니다. 암호를 Aurora DB 
클러스터와 연결합니다. 14 일의 사용자 지정 순환 기간을 구성합니다. 
B. AWS Systems Manager Parameter Store 에서 두 개의 매개변수를 생성합니다. 하나는 사용자 
이름을 문자열 매개변수로 사용하고 다른 하나는 SecureString 유형을 암호로 사용합니다. 암호 
매개변수에 대해 AWS Key Management Service(AWS KMS) 암호화를 선택하고 애플리케이션 
계층에서 이러한 매개변수를 로드합니다. 14 일마다 암호를 교체하는 AWS Lambda 함수를 
구현합니다. 
C. 자격 증명이 포함된 파일을 AWS KMS(AWS Key Management Service) 암호화 Amazon Elastic 
File System(Amazon EFS) 파일 시스템에 저장합니다. 애플리케이션 계층의 모든 EC2 인스턴스에 
EFS 파일 시스템을 탑재합니다. 응용 프로그램이 파일을 읽을 수 있고 슈퍼 사용자만 파일을 
수정할 수 있도록 파일 시스템의 파일에 대한 액세스를 제한합니다. 14 일마다 Aurora 에서 키를 
교체하고 새 자격 증명을 파일에 쓰는 AWS Lambda 함수를 구현합니다. 
D. 애플리케이션이 자격 증명을 로드하는 데 사용하는 AWS KMS(AWS Key Management Service) 
암호화 Amazon S3 버킷에 자격 증명이 포함된 파일을 저장합니다. 올바른 자격 증명이 
사용되도록 정기적으로 파일을 응용 프로그램에 다운로드하십시오. 14 일마다 Aurora 자격 증명을 
교체하고 이 자격 증명을 S3 버킷의 파일에 업로드하는 AWS Lambda 함수를 구현합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99790-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q337 
회사에서 AWS 에 웹 애플리케이션을 배포했습니다. 이 회사는 조정 요구 사항을 지원하기 위해 
기본 DB 인스턴스와 5 개의 읽기 전용 복제본을 사용하여 MySQL 용 Amazon RDS 에서 백엔드 
데이터베이스를 호스팅합니다. 읽기 전용 복제본은 기본 DB 인스턴스보다 1 초 이상 뒤처져서는 
안 됩니다. 데이터베이스는 정기적으로 예약된 저장 프로시저를 실행합니다. 
웹 사이트의 트래픽이 증가함에 따라 복제본은 피크 로드 기간 동안 추가 지연을 경험합니다. 
솔루션 설계자는 복제 지연을 최대한 줄여야 합니다. 솔루션 설계자는 애플리케이션 코드에 대한 
변경을 최소화하고 지속적인 운영 오버헤드를 최소화해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 데이터베이스를 Amazon Aurora MySQL 로 마이그레이션합니다. 읽기 전용 복제본을 Aurora 
복제본으로 교체하고 Aurora Auto Scaling 을 구성합니다. 저장 프로시저를 Aurora MySQL 기본 
함수로 바꿉니다. 
B. 데이터베이스 앞에 Redis 클러스터용 Amazon ElastiCache 를 배포합니다. 응용 프로그램이 
데이터베이스를 쿼리하기 전에 캐시를 확인하도록 응용 프로그램을 수정하십시오. 저장 프로시저를 
AWS Lambda 함수로 바꿉니다. 
C. 데이터베이스를 Amazon EC2 인스턴스에서 실행되는 MySQL 데이터베이스로 
마이그레이션합니다. 모든 복제본 노드에 대해 컴퓨팅에 최적화된 대규모 EC2 인스턴스를 
선택합니다. EC2 인스턴스에서 저장 프로시저를 유지합니다. 
D. 데이터베이스를 Amazon DynamoDB 로 마이그레이션합니다. 필요한 처리량을 지원하고 
온디맨드 용량 확장을 구성하기 위해 많은 수의 RCU(읽기 용량 단위)를 프로비저닝합니다. 저장 
프로시저를 DynamoDB 스트림으로 바꿉니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99871-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
옵션 A 는 애플리케이션 코드를 크게 변경하지 않고 복제 지연을 줄이고 진행 중인 운영 
오버헤드를 최소화하는 가장 적합한 솔루션입니다. 데이터베이스를 Amazon Aurora MySQL 로 
마이그레이션하면 MySQL 용 Amazon RDS 에 비해 복제 성능과 확장성이 향상됩니다. Aurora 
복제본은 더 빠른 복제를 제공하여 복제 지연을 줄이고 Aurora Auto Scaling 은 들어오는 트래픽을 
처리하기에 충분한 Aurora 복제본이 있는지 확인합니다. 또한 Aurora MySQL 기본 기능은 저장 
프로시저를 대체하여 데이터베이스의 부하를 줄이고 성능을 향상시킬 수 있습니다. 
Q338 
솔루션 설계자는 대용량 SaaS(Software as a Service) 플랫폼에 대한 재해 복구(DR) 계획을 
만들어야 합니다. 플랫폼의 모든 데이터는 Amazon Aurora MySQL DB 클러스터에 저장됩니다. 
DR 계획은 데이터를 보조 AWS 리전에 복제해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 보조 리전의 Aurora 클러스터에 MySQL 바이너리 로그 복제를 사용합니다. 보조 리전에서 
Aurora 클러스터용 DB 인스턴스 1 개를 프로비저닝합니다. 
B. DB 클러스터에 대한 Aurora 글로벌 데이터베이스를 설정합니다. 설정이 완료되면 보조 
리전에서 DB 인스턴스를 제거합니다. 
C. AWS Database Migration Service(AWS DMS)를 사용하여 데이터를 보조 리전의 Aurora 
클러스터에 지속적으로 복제합니다. 보조 리전에서 DB 인스턴스를 제거합니다. 
D. DB 클러스터에 대한 Aurora 글로벌 데이터베이스를 설정합니다. 보조 리전에서 최소 하나의 
DB 인스턴스를 지정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/99758-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q339 
회사에는 Amazon RDS MySQL DB 인스턴스에서 정보를 검색하는 자격 증명이 내장된 사용자 지정 
애플리케이션이 있습니다. 경영진은 최소한의 프로그래밍 노력으로 애플리케이션을 더 안전하게 
만들어야 한다고 말합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Key Management Service(AWS KMS)를 사용하여 키를 생성합니다. AWS KMS 에서 
데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. 자동 키 순환을 활성화합니다. 
B. 애플리케이션 사용자를 위해 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 자격 
증명을 AWS Secrets Manager 에 저장합니다. Secrets Manager 에서 데이터베이스 자격 증명을 
로드하도록 애플리케이션을 구성합니다. Secret Manager 에서 자격 증명을 교체하는 AWS Lambda 
함수를 생성합니다. 
C. 애플리케이션 사용자를 위해 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 자격 
증명을 AWS Secrets Manager 에 저장합니다. Secrets Manager 에서 데이터베이스 자격 증명을 
로드하도록 애플리케이션을 구성합니다. Secrets Manager 를 사용하여 RDS for MySQL 
데이터베이스에서 애플리케이션 사용자의 자격 증명 교체 일정을 설정합니다. 
D. 애플리케이션 사용자를 위해 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 자격 
증명을 AWS Systems Manager Parameter Store 에 저장합니다. Parameter Store 에서 데이터베이스 
자격 증명을 로드하도록 애플리케이션을 구성합니다. Parameter Store 를 사용하여 RDS for MySQL 
데이터베이스에서 애플리케이션 사용자에 대한 자격 증명 교체 일정을 설정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/99705-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q340 
미디어 회사는 AWS 에서 웹 사이트를 호스팅합니다. 웹 사이트 애플리케이션의 아키텍처에는 
Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 인스턴스 플릿과 Amazon Aurora 에서 
호스팅되는 데이터베이스가 포함됩니다. 회사의 사이버 보안 팀은 애플리케이션이 SQL 주입에 
취약하다고 보고합니다. 
회사는 이 문제를 어떻게 해결해야 할까요? 
A. ALB 앞에서 AWS WAF 를 사용합니다. 적절한 웹 ACL 을 AWS WAF 와 연결합니다. 
B. 고정 응답으로 SQL 주입에 응답하는 ALB 수신기 규칙을 생성합니다. 
C. 모든 SQL 삽입 시도를 자동으로 차단하려면 AWS Shield Advanced 에 가입하십시오. 
D. 모든 SQL 주입 시도를 자동으로 차단하도록 Amazon Inspector 를 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/99708-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
Q341 
회사에는 AWS Lake Formation 에서 관리하는 Amazon S3 데이터 레이크가 있습니다. 이 회사는 
데이터 레이크의 데이터를 Amazon Aurora MySQL 데이터베이스에 저장된 운영 데이터와 결합하여 
Amazon QuickSight 에서 시각화를 생성하려고 합니다. 회사는 회사의 마케팅 팀이 데이터베이스의 
열 하위 집합에만 액세스할 수 있도록 열 수준 권한을 적용하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon EMR 을 사용하여 데이터베이스에서 QuickSight SPICE 엔진으로 직접 데이터를 
수집하십시오. 필요한 열만 포함합니다. 
B. AWS Glue Studio 를 사용하여 데이터베이스에서 S3 데이터 레이크로 데이터를 수집합니다. IAM 
정책을 QuickSight 사용자에게 연결하여 열 수준 액세스 제어를 적용합니다. QuickSight 에서 
Amazon S3 를 데이터 원본으로 사용합니다. 
C. AWS Glue Elastic Views 를 사용하여 Amazon S3 의 데이터베이스에 대한 구체화된 보기를 
생성합니다. QuickSight 사용자에 대한 열 수준 액세스 제어를 적용하려면 S3 버킷 정책을 
생성합니다. QuickSight 에서 Amazon S3 를 데이터 원본으로 사용합니다. 
D. Lake Formation 청사진을 사용하여 데이터베이스에서 S3 데이터 레이크로 데이터를 수집합니다. 
Lake Formation 을 사용하여 QuickSight 사용자에 대한 열 수준 액세스 제어를 적용합니다. 
QuickSight 에서 Amazon Athena 를 데이터 원본으로 사용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/99710-exam-aws-certified-solutions-a
rchitect-associate-saa-c03/ 
설명: 
Amazon QuickSight 및 AWS Lake Formation 을 사용하여 열 수준 권한 부여를 시행합니다. 
https://aws.amazon.com/ko/blogs/big-data/enforce-column-level-authorization-with-amazon-
quicksight-and-aws-lake-formation/ 
Q342 
트랜잭션 처리 회사에는 Amazon EC2 인스턴스에서 실행되는 매주 스크립팅된 배치 작업이 
있습니다. EC2 인스턴스는 Auto Scaling 그룹에 있습니다. 트랜잭션 수는 다를 수 있지만 각 
실행에서 기록되는 기준 CPU 사용률은 60% 이상입니다. 회사는 작업이 실행되기 30 분 전에 
용량을 프로비저닝해야 합니다. 
현재 엔지니어는 Auto Scaling 그룹 파라미터를 수동으로 수정하여 이 작업을 완료합니다. 
회사에는 Auto Scaling 그룹 수에 필요한 용량 추세를 분석할 리소스가 없습니다. 회사는 Auto 
Scaling 그룹의 원하는 용량을 수정하는 자동화된 방법이 필요합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Auto Scaling 그룹에 대한 동적 조정 정책을 생성합니다. CPU 사용률 메트릭을 기반으로 
확장하도록 정책을 구성합니다. 지표의 대상 값을 60%로 설정합니다. 
B. Auto Scaling 그룹에 대한 예약 조정 정책을 생성합니다. 원하는 적정 용량, 최소 용량, 최대 
용량을 설정합니다. 반복을 매주로 설정합니다. 일괄 작업이 실행되기 전 30 분으로 시작 시간을 
설정합니다. 
C. Auto Scaling 그룹에 대한 예측 조정 정책을 생성합니다. 예측을 기반으로 확장하도록 정책을 
구성합니다. 스케일링 지표를 CPU 사용률로 설정합니다. 지표의 대상 값을 60%로 설정합니다. 
정책에서 작업이 실행되기 30 분 전에 사전 실행되도록 인스턴스를 설정합니다. 
D. Auto Scaling 그룹의 CPU 사용률 지표 값이 60%에 도달하면 AWS Lambda 함수를 호출하는 
Amazon EventBridge 이벤트를 생성합니다. Auto Scaling 그룹의 원하는 용량과 최대 용량을 20% 
늘리도록 Lambda 함수를 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/100204-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 옵션은 기계 학습을 사용하여 CloudWatch 의 기록 데이터를 기반으로 용량 요구 사항을 
예측하는 일종의 조정 정책인 Auto Scaling 그룹에 대한 예측 조정 정책을 사용하기 때문에 가장 
효율적입니다. 또한 Auto Scaling 그룹이 트래픽 변경에 앞서 용량을 조정할 수 있도록 예측을 
기반으로 확장하도록 정책을 구성합니다. 또한 조정 메트릭을 CPU 사용률로 설정하고 메트릭의 
대상 값을 60%로 설정합니다. 이는 각 실행에서 기록되는 기준 CPU 사용률과 일치합니다. 또한 
작업이 실행되기 30 분 전에 인스턴스를 사전 실행하도록 설정하여 매주 스크립팅된 배치 작업이 
시작되기 전에 충분한 용량이 프로비저닝되도록 합니다. 이 솔루션은 최소한의 운영 오버헤드로 
작업이 실행되기 30 분 전에 용량을 프로비저닝해야 하는 요구 사항을 충족합니다. 
옵션 A 는 변화하는 수요에 대응하여 Auto Scaling 그룹의 용량을 조정하는 일종의 조정 정책인 
Auto Scaling 그룹에 대한 동적 조정 정책을 사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 
변화하는 트래픽에만 반응하기 때문에 작업 실행 30 분 전에 용량을 프로비저닝하는 방법을 
제공하지 않습니다. 
옵션 B 는 생성한 일정에 따라 Auto Scaling 그룹을 조정할 수 있는 조정 정책 유형인 Auto 
Scaling 그룹에 대해 예약된 조정 정책을 사용하기 때문에 효율성이 떨어집니다. 그러나 미리 
정의된 지표 및 정책에 따라서만 확장되므로 예측 또는 CPU 사용률을 기반으로 확장하는 방법을 
제공하지 않습니다. 
옵션 D 는 Auto Scaling 그룹의 CPU 사용률 지표 값이 60%에 도달할 때 Amazon EventBridge 
이벤트를 사용하여 AWS Lambda 함수를 호출하기 때문에 효율성이 떨어집니다. 이는 이벤트를 
기반으로 서버리스 함수를 트리거하는 방법입니다. 그러나 이것은 변화하는 트래픽에만 반응하기 
때문에 작업 실행 30 분 전에 용량을 프로비저닝하는 방법을 제공하지 않습니다. 
Q343 
솔루션 설계자는 회사의 재해 복구(DR) 아키텍처를 설계하고 있습니다. 이 회사에는 예약된 
백업이 있는 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행되는 MySQL 데이터베이스가 
있습니다. DR 설계에는 여러 AWS 리전이 포함되어야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. MySQL 데이터베이스를 여러 EC2 인스턴스로 마이그레이션합니다. DR 지역에서 대기 EC2 
인스턴스를 구성합니다. 복제를 켭니다. 
B. MySQL 데이터베이스를 Amazon RDS 로 마이그레이션합니다. 다중 AZ 배포를 사용합니다. 다른 
가용 영역에서 기본 DB 인스턴스에 대한 읽기 복제를 켭니다. 
C. MySQL 데이터베이스를 Amazon Aurora 글로벌 데이터베이스로 마이그레이션합니다. 기본 
리전에서 기본 DB 클러스터를 호스팅합니다. DR 리전에서 보조 DB 클러스터를 호스팅합니다. 
D. S3 CRR(Cross-Region Replication)용으로 구성된 Amazon S3 버킷에 MySQL 데이터베이스의 
예약된 백업을 저장합니다. 데이터 백업을 사용하여 DR 지역에서 데이터베이스를 복원하십시오. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/100302-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
MySQL 데이터베이스를 Amazon Aurora 글로벌 데이터베이스로 마이그레이션하는 것이 최소한의 
운영 오버헤드가 필요하기 때문에 최상의 솔루션입니다. Aurora 는 자동 장애 조치를 제공하는 
관리형 서비스이므로 대기 인스턴스를 수동으로 구성할 필요가 없습니다. 기본 DB 클러스터는 
기본 리전에서 호스팅할 수 있고 보조 DB 클러스터는 DR 리전에서 호스팅할 수 있습니다. 이 
접근 방식을 통해 상당한 수동 개입 없이 데이터를 여러 리전에서 항상 사용 가능하고 최신 
상태로 유지할 수 있습니다. 
Q344 
회사에는 Amazon Simple Queue Service(Amazon SQS)를 사용하여 메시지를 구문 분석하는 Java 
애플리케이션이 있습니다. 애플리케이션은 크기가 256KB 보다 큰 메시지를 구문 분석할 수 
없습니다. 회사는 응용 프로그램이 50MB 만큼 큰 메시지를 구문 분석할 수 있는 기능을 제공하는 
솔루션을 구현하려고 합니다. 
코드를 가장 적게 변경하여 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Java 용 Amazon SQS 확장 클라이언트 라이브러리를 사용하여 Amazon S3 에서 256KB 보다 큰 
메시지를 호스팅합니다. 
B. Amazon SQS 대신 Amazon EventBridge를 사용하여 애플리케이션에서 큰 메시지를 게시합니다. 
C. 256KB 보다 큰 메시지를 처리하도록 Amazon SQS 의 제한을 변경합니다. 
D. Amazon Elastic File System(Amazon EFS)에 256KB 보다 큰 메시지를 저장합니다. 메시지에서 
이 위치를 참조하도록 Amazon SQS 를 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/100202-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q345 
회사에서 주요 웹 애플리케이션 중 하나의 콘텐츠에 대한 액세스를 제한하고 AWS 에서 사용할 수 
있는 권한 부여 기술을 사용하여 콘텐츠를 보호하려고 합니다. 이 회사는 서버리스 아키텍처와 
100 명 미만의 사용자를 위한 인증 솔루션을 구현하려고 합니다. 솔루션은 기본 웹 애플리케이션과 
통합하고 웹 콘텐츠를 전역적으로 제공해야 합니다. 솔루션은 또한 회사의 사용자 기반이 성장함에 
따라 확장되어야 하며 가능한 한 가장 낮은 로그인 대기 시간을 제공해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 인증에 Amazon Cognito 를 사용하십시오. 인증을 위해 Lambda@Edge 를 사용합니다. Amazon 
CloudFront 를 사용하여 전 세계적으로 웹 애플리케이션을 제공합니다. 
B. 인증을 위해 Microsoft Active Directory 용 AWS Directory Service 를 사용합니다. 승인을 위해 
AWS Lambda 를 사용합니다. Application Load Balancer 를 사용하여 웹 애플리케이션을 전역적으로 
제공합니다. 
C. 인증에 Amazon Cognito 를 사용합니다. 승인을 위해 AWS Lambda 를 사용합니다. Amazon S3 
Transfer Acceleration 을 사용하여 전 세계적으로 웹 애플리케이션을 제공합니다. 
D. 인증을 위해 Microsoft Active Directory 용 AWS Directory Service 를 사용합니다. 인증을 위해 
Lambda@Edge 를 사용합니다. AWS Elastic Beanstalk 를 사용하여 전 세계적으로 웹 
애플리케이션을 제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/100341-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
https://aws.amazon.com/blogs/networking-and-content-delivery/adding-http-security-headers
using-lambdaedge-and-amazon-cloudfront/ 
Amazon CloudFront 는 웹 콘텐츠, 비디오 및 API 를 대규모로 안전하게 전송할 수 있는 글로벌 
콘텐츠 전송 네트워크(CDN) 서비스입니다. 인증을 위해 Cognito 와 통합하고 인증을 위해 
Lambda@Edge 와 통합하므로 전 세계적으로 웹 콘텐츠를 제공하는 데 이상적인 선택입니다. 
Lambda@Edge 는 AWS Lambda 기능을 사용자에게 더 가까운 곳에서 전역적으로 실행할 수 있는 
서비스로, 지연 시간을 줄이고 응답 시간을 단축합니다. 또한 CloudFront 의 콘텐츠를 보호하기 
위해 에지에서 인증 로직을 처리할 수 있습니다. 이 시나리오에서 Lambda@Edge 는 에지에서 
실행하는 짧은 대기 시간 이점을 활용하면서 웹 애플리케이션에 대한 권한 부여를 제공할 수 
있습니다. 
Q346 
회사의 데이터 센터에 노후화된 NAS(Network-Attached Storage) 어레이가 있습니다. NAS 
어레이는 SMB 공유 및 NFS 공유를 클라이언트 워크스테이션에 제공합니다. 회사는 새 NAS 
어레이를 구매하기를 원하지 않습니다. 회사는 또한 NAS 어레이의 지원 계약을 갱신하는 데 드는 
비용을 원하지 않습니다. 일부 데이터는 자주 액세스되지만 대부분의 데이터는 비활성 상태입니다. 
솔루션 설계자는 데이터를 Amazon S3 로 마이그레이션하고 S3 수명 주기 정책을 사용하며 
클라이언트 워크스테이션에 대해 동일한 모양과 느낌을 유지하는 솔루션을 구현해야 합니다. 
솔루션 설계자는 AWS Storage Gateway 를 솔루션의 일부로 식별했습니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 유형의 스토리지 게이트웨이를 
프로비저닝해야 합니까? 
A. 볼륨 게이트웨이 
B. 테이프 게이트웨이 
C. Amazon FSx 파일 게이트웨이 
D. Amazon S3 파일 게이트웨이 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/100220-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q347 
회사에는 Amazon EC2 인스턴스에서 실행 중인 애플리케이션이 있습니다. 솔루션 설계자는 회사의 
현재 요구 사항을 기반으로 특정 인스턴스 제품군 및 다양한 인스턴스 크기로 회사를 
표준화했습니다. 
회사는 향후 3 년 동안 애플리케이션의 비용 절감을 극대화하고자 합니다. 회사는 애플리케이션 
인기도 및 사용량에 따라 향후 6 개월 내에 인스턴스 패밀리 및 크기를 변경할 수 있어야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 컴퓨팅 절감 플랜(Compute Savings Plan) 
B. EC2 인스턴스 절감 계획(EC2 Instance Savings Plan) 
C. 영역 예약 인스턴스(Zonal Reserved Instances) 
D. 표준 예약 인스턴스(Standard Reserved Instances) 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/100221-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q348 
회사는 웨어러블 장치를 사용하는 많은 참가자로부터 데이터를 수집합니다. 회사는 데이터를 
Amazon DynamoDB 테이블에 저장하고 애플리케이션을 사용하여 데이터를 분석합니다. 데이터 
워크로드는 일정하고 예측 가능합니다. 회사는 DynamoDB 에 대한 예상 예산 이하를 유지하려고 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 프로비저닝 모드와 DynamoDB Standard-Infrequent Access(DynamoDB Standard-IA)를 
사용합니다. 예상 워크로드에 대한 용량을 예약합니다. 
B. 프로비저닝 모드를 사용합니다. RCU(읽기 용량 단위) 및 WCU(쓰기 용량 단위)를 지정합니다. 
C. 주문형 모드를 사용합니다. 읽기 용량 단위(RCU) 및 쓰기 용량 단위(WCU)를 워크로드의 변경 
사항을 수용할 수 있을 만큼 높게 설정합니다. 
D. 주문형 모드를 사용합니다. 예약 용량이 있는 RCU(읽기 용량 단위) 및 WCU(쓰기 용량 단위)를 
지정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/100222-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 옵션은 테이블에서 읽기 및 쓰기를 처리하기 위한 읽기/쓰기 용량 모드인 프로비저닝 모드를 
사용하기 때문에 가장 효율적입니다. 이를 통해 애플리케이션이 수행할 것으로 예상되는 읽기 및 
쓰기 처리량을 지정할 수 있습니다. 또한 애플리케이션이 초당 읽거나 써야 하는 데이터의 양인 
RCU(읽기 용량 단위) 및 WCU(쓰기 용량 단위)를 지정합니다. 또한 프로비저닝 모드는 예측 
가능한 워크로드에 대해 온디맨드 모드보다 비용이 낮기 때문에 DynamoDB 에 대한 예상 예산 
이하로 유지해야 하는 요구 사항을 충족합니다. 
이 솔루션은 일정하고 예측 가능한 데이터 워크로드가 있는 웨어러블 장치를 사용하는 많은 
참여자로부터 데이터를 수집해야 하는 요구 사항을 충족합니다. 
옵션 A 는 프로비저닝 모드와 DynamoDB Standard-Infrequent Access(DynamoDB Standard-IA)를 
사용하기 때문에 덜 효율적입니다. DynamoDB Standard-Infrequent Access 는 밀리초의 지연 
시간이 필요한 자주 액세스하지 않는 항목을 위한 스토리지 클래스입니다. 그러나 이는 일정하고 
예측 가능한 데이터 워크로드가 있는 웨어러블 장치를 사용하는 많은 참여자로부터 데이터를 
수집해야 하는 요구 사항을 충족하지 않습니다. DynamoDB Standard-IA 는 액세스 빈도가 30 일에 
한 번 미만인 항목에 더 적합하기 때문입니다. 
옵션 C 는 수요 변화에 따라 테이블 용량을 자동으로 조정하여 사용한 만큼만 비용을 지불하는 
읽기/쓰기 용량 모드인 온디맨드 모드를 사용하기 때문에 효율성이 떨어집니다. 그러나 온디맨드 
모드는 예측 가능한 워크로드에 대해 프로비저닝된 모드보다 비용이 높기 때문에 DynamoDB 에 
대한 예상 예산 이하로 유지해야 하는 요구 사항을 충족하지 않습니다. 
옵션 D는 온디맨드 모드를 사용하고 예약 용량이 있는 RCU 및 WCU를 지정하기 때문에 효율성이 
떨어집니다. 이는 할인된 시간당 요금과 교환하여 테이블에 대한 읽기 및 쓰기 용량을 예약하는 
방법입니다. 그러나 온디맨드 모드는 예측 가능한 워크로드에 대해 프로비저닝된 모드보다 비용이 
높기 때문에 DynamoDB 에 대한 예상 예산 이하로 유지해야 하는 요구 사항을 충족하지 않습니다. 
또한 예약된 용량이 있는 RCU 및 WCU 를 지정하는 것은 프로비저닝 모드에만 적용되므로 
온디맨드 모드에서는 불가능합니다. 
Q349 
회사는 ap-southeast-3 리전의 Amazon Aurora PostgreSQL 데이터베이스에 기밀 데이터를 
저장합니다. 데이터베이스는 AWS Key Management Service(AWS KMS) 고객 관리형 키로 
암호화됩니다. 이 회사는 최근에 인수되었으며 ap-southeast-3 에서 인수 회사의 AWS 계정과 
데이터베이스 백업을 안전하게 공유해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 데이터베이스 스냅샷을 생성합니다. 스냅샷을 암호화되지 않은 새 스냅샷에 복사합니다. 인수 
회사의 AWS 계정과 새 스냅샷을 공유합니다. 
B. 데이터베이스 스냅샷을 생성합니다. 인수 회사의 AWS 계정을 KMS 키 정책에 추가합니다. 
인수 회사의 AWS 계정과 스냅샷을 공유합니다. 
C. 다른 AWS 관리형 KMS 키를 사용하는 데이터베이스 스냅샷을 생성합니다. 인수 회사의 AWS 
계정을 KMS 키 별칭에 추가합니다. 인수 회사의 AWS 계정과 스냅샷을 공유합니다. 
D. 데이터베이스 스냅샷을 생성합니다. 데이터베이스 스냅샷을 다운로드합니다. Amazon S3 버킷에 
데이터베이스 스냅샷을 업로드합니다. 인수 회사의 AWS 계정에서 액세스를 허용하도록 S3 버킷 
정책을 업데이트합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/100299-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/key-policy-modifying-external-
accounts.html 
다른 사용자 지정 AWS KMS 키를 생성할 필요가 없습니다. 
https://aws.amazon.com/premiumsupport/knowledge-center/aurora-share-encrypted-snapshot/ 
원본 계정 내에서 대상 계정에 사용자 지정 AWS KMS 키에 대한 액세스 권한을 부여합니다. 
1. 원본 계정에 로그인하고 DB 클러스터 스냅샷과 동일한 리전의 AWS KMS 콘솔로 이동합니다. 
2. 탐색 창에서 고객 관리형 키를 선택합니다. 
3. 사용자 지정 AWS KMS 키(이미 생성됨)를 선택합니다. 
4. 다른 AWS 계정 섹션에서 다른 AWS 계정 추가를 선택한 다음 대상 계정의 AWS 계정 번호를 
입력합니다. 
그런 다음 DB 클러스터 스냅샷을 복사하고 공유합니다. 
Q350 
한 회사에서 us-east-1 리전의 Microsoft SQL Server 단일 AZ DB 인스턴스용 100GB Amazon 
RDS 를 사용하여 고객 트랜잭션을 저장합니다. 회사는 DB 인스턴스에 대한 고가용성 및 자동 
복구가 필요합니다. 
또한 회사는 1 년에 여러 번 RDS 데이터베이스에 대한 보고서를 실행해야 합니다. 보고 
프로세스로 인해 트랜잭션이 고객 계정에 게시되는 데 평소보다 오래 걸립니다. 회사는 보고 
프로세스의 성능을 향상시킬 솔루션이 필요합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 단일 AZ DB 인스턴스에서 다중 AZ 배포로 DB 인스턴스를 수정합니다. 
B. 현재 DB 인스턴스의 스냅샷을 찍습니다. 다른 가용 영역의 새 RDS 배포로 스냅샷을 
복원합니다. 
C. 다른 가용 영역에서 DB 인스턴스의 읽기 전용 복제본을 생성합니다. 보고서에 대한 모든 
요청은 읽기 전용 복제본을 가리킵니다. 
D. 데이터베이스를 RDS Custom 으로 마이그레이션합니다. 
E. RDS Proxy 를 사용하여 보고 요청을 유지 관리 기간으로 제한합니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/100300-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q351 
회사에서 데이터 관리 애플리케이션을 AWS 로 이전하고 있습니다. 회사는 이벤트 기반 아키텍처로 
전환하려고 합니다. 아키텍처는 워크플로의 다양한 측면을 수행하면서 더 많이 분산되고 서버리스 
개념을 사용해야 합니다. 회사는 또한 운영 오버헤드를 최소화하기를 원합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Glue 에서 워크플로를 구축합니다. AWS Glue 를 사용하여 AWS Lambda 함수를 호출하여 
워크플로 단계를 처리합니다. 
B. AWS Step Functions 에서 워크플로를 구축합니다. Amazon EC2 인스턴스에 애플리케이션을 
배포합니다. Step Functions 를 사용하여 EC2 인스턴스에서 워크플로 단계를 호출합니다. 
C. Amazon EventBridge 에서 워크플로를 구축합니다. EventBridge 를 사용하여 일정에 따라 AWS 
Lambda 함수를 호출하여 워크플로 단계를 처리합니다. 
D. AWS Step Functions 에서 워크플로를 구축합니다. Step Functions 를 사용하여 상태 머신을 
생성합니다. 상태 시스템을 사용하여 AWS Lambda 함수를 호출하여 워크플로 단계를 처리합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/100371-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 대답은 서버리스 개념을 사용하고 운영 오버헤드를 최소화하는 이벤트 기반 아키텍처로의 전환 
요구 사항을 충족하기 때문에 정확합니다. AWS Step Functions 는 상태 시스템을 사용하여 여러 
AWS 서비스를 워크플로로 조정할 수 있는 서버리스 서비스입니다. 상태 머신은 워크플로 단계의 
실행 논리와 순서를 정의하는 작업 및 전환으로 구성됩니다. AWS Lambda 는 서버를 
프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 서버리스 FaaS(function-as-a-service) 
플랫폼입니다. Lambda 함수는 Step Functions 에서 상태 시스템의 작업으로 호출할 수 있으며 
데이터 수집, 변환, 검증 및 분석과 같은 데이터 관리 워크플로의 다양한 측면을 수행할 수 
있습니다. Step Functions 및 Lambda 를 사용함으로써 회사는 다음과 같은 이점을 얻을 수 
있습니다. 
이벤트 기반: Step Functions 는 타이머, API 호출 또는 기타 AWS 서비스 이벤트와 같은 이벤트를 
기반으로 Lambda 함수를 트리거할 수 있습니다. Lambda 함수는 이벤트 기반 아키텍처를 
생성하여 다른 서비스나 상태 시스템에 이벤트를 내보낼 수도 있습니다. 
서버리스: Step Functions 및 Lambda 는 AWS 에서 완전히 관리하므로 회사에서 서버 또는 
인프라를 프로비저닝하거나 관리할 필요가 없습니다. 회사는 워크플로 및 기능에서 사용하는 
리소스에 대해서만 비용을 지불하고 수요에 따라 자동으로 확장 또는 축소할 수 있습니다. 
운영 오버헤드: Step Functions 및 Lambda 는 모니터링, 로깅, 추적, 오류 처리, 재시도 논리 및 
보안과 같은 기본 제공 기능을 제공하므로 워크플로 및 기능의 개발 및 배포를 단순화합니다. 
회사는 운영 세부 사항보다는 비즈니스 논리 및 데이터 처리에 집중할 수 있습니다. 
Q352 
한 회사에서 온라인 멀티플레이어 게임용 네트워크를 설계하고 있습니다. 이 게임은 UDP 네트워킹 
프로토콜을 사용하며 8 개의 AWS 리전에 배포됩니다. 네트워크 아키텍처는 최종 사용자에게 
고품질 게임 경험을 제공하기 위해 대기 시간과 패킷 손실을 최소화해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 각 리전에서 전송 게이트웨이를 설정합니다. 각 전송 게이트웨이 간에 리전 간 피어링 연결을 
생성합니다. 
B. 각 리전에서 UDP 리스너 및 엔드포인트 그룹으로 AWS Global Accelerator 를 설정합니다. 
C. UDP 를 켠 상태에서 Amazon CloudFront 를 설정합니다. 각 리전에서 오리진을 구성합니다. 
D. 각 지역 간에 VPC 피어링 메시를 설정합니다. 각 VPC 에 대해 UDP 를 켭니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/100197-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 상황에 가장 적합한 솔루션은 각 리전에서 UDP 리스너 및 엔드포인트 그룹으로 AWS Global 
Accelerator 를 설정하는 옵션 B 입니다. AWS Global Accelerator 는 사용자 요청을 가장 가까운 
AWS 지역[1]으로 라우팅하여 인터넷 애플리케이션의 가용성과 성능을 향상시키는 네트워킹 
서비스입니다. 또한 대기 시간이 짧고 패킷 손실이 적은 더 빠르고 안정적인 데이터 전송을 
제공하여 UDP 응용 프로그램의 성능을 향상시킵니다. 각 리전에서 UDP 리스너와 엔드포인트 
그룹을 설정함으로써 Global Accelerator 는 더 빠른 응답 시간과 더 나은 사용자 경험을 위해 가장 
가까운 리전으로 트래픽을 라우팅합니다. 
Q353 
회사는 단일 가용 영역의 Amazon EC2 인스턴스에서 3 계층 웹 애플리케이션을 호스팅합니다. 웹 
애플리케이션은 EC2 인스턴스에서 호스팅되는 자체 관리형 MySQL 데이터베이스를 사용하여 
Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. MySQL 데이터베이스는 
현재 1TB 프로비저닝된 IOPS SSD(io2) EBS 볼륨을 사용합니다. 이 회사는 피크 트래픽에서 읽기 
및 쓰기 모두에 대해 1,000 IOPS 의 트래픽을 예상합니다. 
회사는 두 배의 IOPS 용량을 유지하면서 중단을 최소화하고 성능을 안정화하며 비용을 절감하고자 
합니다. 이 회사는 데이터베이스 계층을 가용성이 높고 내결함성이 있는 완전 관리형 솔루션으로 
이동하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. io2 Block Express EBS 볼륨이 있는 MySQL DB 인스턴스용 Amazon RDS 의 다중 AZ 배포를 
사용합니다. 
B. 범용 SSD(gp2) EBS 볼륨이 있는 MySQL DB 인스턴스용 Amazon RDS 의 다중 AZ 배포를 
사용합니다. 
C. Amazon S3 Intelligent-Tiering 액세스 계층을 사용합니다. 
D. 두 개의 큰 EC2 인스턴스를 사용하여 활성-수동 모드에서 데이터베이스를 호스팅합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/100225-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
RDS 지원 스토리지: 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html 
GP2 최대 IOPS: 
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/general-purpose.html#gp2-performan
ce 
Amazon RDS 는 범용 SSD(gp2 및 gp3 라고도 함), 프로비저닝된 IOPS SSD(io1 이라고도 함) 및 
마그네틱(표준이라고도 함)의 세 가지 스토리지 유형을 제공합니다. 성능 특성과 가격이 다르기 
때문에 스토리지 성능과 비용을 데이터베이스 워크로드의 요구 사항에 맞게 조정할 수 있습니다. 
최대 64TiB 의 스토리지로 MySQL, MariaDB, Oracle 및 PostgreSQL RDS DB 인스턴스를 생성할 수 
있습니다. 최대 16TiB 의 스토리지로 SQL Server RDS DB 인스턴스를 생성할 수 있습니다. 이 
스토리지 용량에는 프로비저닝된 IOPS SSD 및 범용 SSD 스토리지 유형을 사용하십시오. 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html 
Q354 
회사는 AWS 에서 서버리스 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon API 
Gateway, AWS Lambda 및 Amazon RDS for PostgreSQL 데이터베이스를 사용합니다. 회사는 최대 
트래픽 또는 예측할 수 없는 트래픽 시간 동안 데이터베이스 연결 시간 초과로 인해 발생하는 
애플리케이션 오류의 증가를 확인했습니다. 회사는 최소한의 코드 변경으로 애플리케이션 오류를 
줄이는 솔루션이 필요합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Lambda 동시성 비율을 줄입니다. 
B. RDS DB 인스턴스에서 RDS 프록시를 활성화합니다. 
C. 더 많은 연결을 허용하도록 RDS DB 인스턴스 클래스의 크기를 조정합니다. 
D. 온디맨드 확장을 통해 데이터베이스를 Amazon DynamoDB 로 마이그레이션합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/100198-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
RDS Proxy 를 사용하면 예측할 수 없는 데이터베이스 트래픽 급증을 처리할 수 있습니다. 그렇지 
않으면 이러한 급증으로 인해 연결 초과 구독 또는 빠른 속도로 새 연결 생성으로 인해 문제가 
발생할 수 있습니다. RDS Proxy 는 데이터베이스 연결 풀을 설정하고 이 풀에서 연결을 
재사용합니다. 이 접근 방식은 매번 새 데이터베이스 연결을 여는 메모리 및 CPU 오버헤드를 
방지합니다. 초과 구독으로부터 데이터베이스를 보호하기 위해 생성되는 데이터베이스 연결 수를 
제어할 수 있습니다.  
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-proxy.html 
Q355 
회사에서 기존 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 애플리케이션은 매시간 일괄 
작업을 실행하며 CPU 를 많이 사용합니다. 온프레미스 서버를 사용하면 일괄 작업에 평균 15 분이 
소요됩니다. 서버에는 64 개의 가상 CPU(vCPU)와 512GiB 의 메모리가 있습니다. 
최소한의 운영 오버헤드로 15 분 이내에 일괄 작업을 실행하는 솔루션은 무엇입니까? 
A. 기능 확장과 함께 AWS Lambda 를 사용하십시오. 
B. AWS Fargate 와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용하십시오. 
C. AWS Auto Scaling 과 함께 Amazon Lightsail 을 사용하십시오. 
D. Amazon EC2 에서 AWS Batch 를 사용하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/100227-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon EC2 에서 AWS Batch 를 사용합니다. AWS Batch 는 Amazon EC2 인스턴스에서 배치 
작업을 쉽게 실행하는 데 사용할 수 있는 완전 관리형 배치 처리 서비스입니다. 워크로드에 맞게 
인스턴스 수를 확장할 수 있으므로 최소한의 운영 오버헤드로 원하는 시간 내에 배치 작업을 
완료할 수 있습니다. 
Amazon API Gateway 에서 AWS Lambda 사용 - AWS Lambda 
https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html 
AWS Lambda FAQ 
https://aws.amazon.com/lambda/faqs/ 
Q356 
회사는 데이터 객체를 Amazon S3 Standard 스토리지에 저장합니다. 한 솔루션 설계자는 데이터의 
75%가 30 일 후에 거의 액세스되지 않는다는 사실을 발견했습니다. 회사는 동일한 고가용성 및 
복원력으로 모든 데이터에 즉시 액세스할 수 있어야 하지만 스토리지 비용을 최소화하기를 
원합니다. 
이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까? 
A. 30 일 후에 데이터 객체를 S3 Glacier Deep Archive 로 이동합니다. 
B. 30 일 후에 데이터 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다. 
C. 30 일 후에 데이터 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 이동합니다. 
D. 데이터 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 즉시 이동합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/100229-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
30 일 후에 데이터 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동하면 스토리지 
비용을 최소화하면서 고가용성 및 복원력으로 데이터에 즉시 액세스할 수 있어야 한다는 요구 
사항을 충족합니다. S3 Standard-IA 는 자주 액세스하지 않는 데이터를 위해 설계되었으며 S3 
Standard 보다 낮은 스토리지 비용을 제공하는 동시에 S3 Standard 와 동일한 짧은 지연 시간, 
높은 처리량 및 높은 내구성을 제공합니다. 
Q357 
게임 회사는 공개 점수판을 데이터 센터에서 AWS 클라우드로 옮기고 있습니다. 이 회사는 
Application Load Balancer 뒤에 Amazon EC2 Windows Server 인스턴스를 사용하여 동적 
애플리케이션을 호스팅합니다. 회사는 애플리케이션을 위한 고가용성 스토리지 솔루션이 
필요합니다. 애플리케이션은 정적 파일과 동적 서버 측 코드로 구성됩니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (2 개 
선택) 
A. Amazon S3 에 정적 파일을 저장합니다. Amazon CloudFront 를 사용하여 엣지에서 객체를 
캐싱합니다. 
B. 정적 파일을 Amazon S3 에 저장합니다. Amazon ElastiCache 를 사용하여 엣지에서 객체를 
캐싱합니다. 
C. Amazon Elastic File System(Amazon EFS)에 서버 측 코드를 저장합니다. 파일을 공유할 각 EC2 
인스턴스에 EFS 볼륨을 탑재합니다. 
D. Windows File Server 용 Amazon FSx 에 서버 측 코드를 저장합니다. 파일을 공유할 각 EC2 
인스턴스에 FSx for Windows File Server 볼륨을 탑재합니다. 
E. 범용 SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 서버 측 코드를 저장합니다. 
각 EC2 인스턴스에 EBS 볼륨을 탑재하여 파일을 공유합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/100230-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
A: Elasticache 는 Amazon 당 순위표에 이상적임에도 불구하고 에지 위치에서 캐싱하지 않기 
때문입니다. 
D: FSx 가 대기 시간이 짧은 요구 사항에 대해 더 높은 성능을 제공하기 때문입니다. 
https://www.techtarget.com/searchaws/tip/Amazon-FSx-vs-EFS-Compare-the-AWS-file-servic
es 
FSx 는 솔리드 스테이트 드라이브 스토리지 볼륨을 사용하여 고성능 및 1 밀리초 미만의 대기 
시간을 위해 구축되었습니다. 이 설계를 통해 사용자는 스토리지 용량과 대기 시간을 독립적으로 
선택할 수 있습니다. 따라서 테라바이트 이하의 파일 시스템도 256Mbps 이상의 처리량을 가질 수 
있으며 최대 64TB 의 볼륨을 지원할 수 있습니다. Amazon S3 는 이미지, 동영상, 문서 등과 같은 
정적 파일을 저장할 수 있는 객체 스토리지 서비스입니다. Amazon EFS 는 파일을 계층 구조로 
저장할 수 있는 파일 스토리지 서비스이며 NFS 프로토콜을 지원합니다. 
Amazon FSx for Windows File Server 는 파일을 계층 구조로 저장할 수 있고 SMB 프로토콜을 
지원하는 파일 스토리지 서비스입니다. Amazon EBS 는 데이터를 고정 크기 블록에 저장하고 EC2 
인스턴스에 연결할 수 있는 블록 스토리지 서비스입니다. 
이러한 정의에 따라 요구 사항을 충족하기 위해 취해야 하는 단계 조합은 다음과 같습니다. 
1. 정적 파일을 Amazon S3 에 저장합니다. Amazon CloudFront 를 사용하여 엣지에서 객체를 
캐싱합니다. 
2. Windows File Server 용 Amazon FSx 에 서버 측 코드를 저장합니다. 파일을 공유할 각 EC2 
인스턴스에 FSx for Windows File Server 볼륨을 탑재합니다. 
Q358 
소셜 미디어 회사는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 
애플리케이션을 실행합니다. ALB 는 Amazon CloudFront 배포의 오리진입니다. 이 애플리케이션은 
Amazon S3 버킷에 10 억 개 이상의 이미지가 저장되어 있으며 초당 수천 개의 이미지를 
처리합니다. 회사는 이미지 크기를 동적으로 조정하고 고객에게 적절한 형식을 제공하기를 
원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EC2 인스턴스에 외부 이미지 관리 라이브러리를 설치합니다. 이미지 관리 라이브러리를 
사용하여 이미지를 처리합니다. 
B. CloudFront 오리진 요청 정책을 생성합니다. 정책을 사용하여 자동으로 이미지 크기를 조정하고 
요청의 User-Agent HTTP 헤더를 기반으로 적절한 형식을 제공합니다. 
C. 외부 이미지 관리 라이브러리와 함께 Lambda@Edge 함수를 사용합니다. Lambda@Edge 
함수를 이미지를 제공하는 CloudFront 동작과 연결합니다. 
D. CloudFront 응답 헤더 정책을 생성합니다. 정책을 사용하여 자동으로 이미지 크기를 조정하고 
요청의 User-Agent HTTP 헤더를 기반으로 적절한 형식을 제공합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/100231-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Lambda@Edge 는 CloudFront 엣지 위치에서 Lambda 함수를 실행할 수 있게 해주는 
서비스입니다. CloudFront 를 통과하는 요청 및 응답을 수정하는 데 사용할 수 있습니다. 
CloudFront 오리진 요청 정책은 CloudFront 가 오리진으로 보내는 요청에 포함된 값(URL 쿼리 
문자열, HTTP 헤더 및 쿠키)을 제어하는 정책입니다. 오리진에서 추가 정보를 수집하거나 오리진 
응답을 사용자 정의하는 데 사용할 수 있습니다. CloudFront 응답 헤더 정책은 CloudFront 가 최종 
사용자에게 보내는 응답에서 제거하거나 추가하는 HTTP 헤더를 지정하는 정책입니다. 응답에 보안 
또는 사용자 지정 헤더를 추가하는 데 사용할 수 있습니다. 
이러한 정의에 따라 최소한의 운영 오버헤드로 요구 사항을 충족하는 솔루션은 다음과 같습니다. 
외부 이미지 관리 라이브러리와 함께 Lambda@Edge 함수를 사용합니다. Lambda@Edge 함수를 
이미지를 제공하는 CloudFront 동작과 연결합니다. 
이 솔루션을 사용하면 애플리케이션이 Lambda@Edge 함수를 사용하여 이미지 크기를 동적으로 
조정하고 요청의 User-Agent HTTP 헤더를 기반으로 클라이언트에 적절한 형식을 제공할 수 
있습니다. Lambda@Edge 기능은 엣지 위치에서 실행되어 오리진의 대기 시간과 부하를 줄입니다. 
애플리케이션 코드는 이미지 조작 작업을 수행할 수 있는 외부 이미지 관리 라이브러리만 
포함하면 됩니다. 
Q359 
병원은 환자 기록을 Amazon S3 버킷에 저장해야 합니다. 병원의 컴플라이언스 팀은 모든 보호 
건강 정보(PHI)가 전송 및 저장 중에 암호화되도록 해야 합니다. 규정 준수 팀은 미사용 데이터에 
대한 암호화 키를 관리해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Certificate Manager(ACM)에서 퍼블릭 SSL/TLS 인증서를 생성합니다. 인증서를 Amazon 
S3 와 연결합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 각 S3 버킷에 대한 
기본 암호화를 구성합니다. KMS 키를 관리할 규정 준수 팀을 할당합니다. 
B. S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 
허용합니다. S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하도록 각 S3 버킷에 대한 
기본 암호화를 구성합니다. SSE-S3 키를 관리할 규정 준수 팀을 할당합니다. 
C. S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 
허용합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 각 S3 버킷에 대한 기본 
암호화를 구성합니다. KMS 키를 관리할 규정 준수 팀을 할당합니다. 
D. S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 
허용합니다. Amazon Macie 를 사용하여 Amazon S3 에 저장된 민감한 데이터를 보호하십시오. 
Macie 를 관리할 규정 준수 팀을 지정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/100232-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이를 통해 규정 준수 팀은 서버 측 암호화에 사용되는 KMS 키를 관리할 수 있으므로 암호화 키에 
필요한 제어 기능을 제공합니다. 또한 버킷 정책에서 "aws:SecureTransport" 조건을 사용하면 S3 
버킷에 대한 모든 연결이 전송 중에 암호화됩니다. 
Q360 
회사는 Amazon API Gateway 를 사용하여 동일한 VPC 에서 두 개의 REST API 로 프라이빗 
게이트웨이를 실행합니다. BuyStock RESTful 웹 서비스는 CheckFunds RESTful 웹 서비스를 
호출하여 주식을 구매하기 전에 충분한 자금을 사용할 수 있는지 확인합니다. 회사는 VPC 흐름 
로그에서 BuyStock RESTful 웹 서비스가 VPC 대신 인터넷을 통해 CheckFunds RESTful 웹 
서비스를 호출한다는 사실을 확인했습니다. 솔루션 설계자는 API 가 VPC 를 통해 통신하도록 
솔루션을 구현해야 합니다. 
코드를 가장 적게 변경하여 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 인증을 위해 HTTP 헤더에 X-API-Key 헤더를 추가합니다. 
B. 인터페이스 엔드포인트를 사용합니다. 
C. 게이트웨이 엔드포인트를 사용합니다. 
D. 두 REST API 사이에 Amazon Simple Queue Service(Amazon SQS) 대기열을 추가합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/100238-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
인터페이스 엔드포인트를 사용하면 BuyStock RESTful 웹 서비스와 CheckFunds RESTful 웹 
서비스가 코드를 변경하지 않고도 VPC 를 통해 통신할 수 있습니다. 인터페이스 엔드포인트는 
고객의 VPC 에 탄력적 네트워크 인터페이스(ENI)를 생성한 다음 API 에서 ENI 로 트래픽을 
라우팅하도록 라우팅 테이블을 구성합니다. 이렇게 하면 코드를 변경하지 않고도 두 API 가 VPC 를 
통해 통신할 수 있습니다. 
Q361 
한 회사가 AWS 에서 멀티플레이어 게임 애플리케이션을 호스팅하고 있습니다. 회사는 
애플리케이션이 밀리초 미만의 대기 시간으로 데이터를 읽고 기록 데이터에 대해 일회성 쿼리를 
실행하기를 원합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 자주 액세스하는 데이터에는 Amazon RDS 를 사용하십시오. 정기적인 사용자 지정 스크립트를 
실행하여 데이터를 Amazon S3 버킷으로 내보냅니다. 
B. 데이터를 Amazon S3 버킷에 직접 저장합니다. 장기 저장을 위해 오래된 데이터를 S3 Glacier 
Deep Archive 로 이동하는 S3 수명 주기 정책을 구현합니다. Amazon Athena 를 사용하여 Amazon 
S3 의 데이터에 대해 일회성 쿼리를 실행합니다. 
C. 자주 액세스하는 데이터에는 DynamoDB Accelerator(DAX)와 함께 Amazon DynamoDB 를 
사용하십시오. DynamoDB 테이블 내보내기를 사용하여 데이터를 Amazon S3 버킷으로 내보냅니다. 
Amazon Athena 를 사용하여 Amazon S3 의 데이터에 대해 일회성 쿼리를 실행합니다. 
D. 자주 액세스하는 데이터에는 Amazon DynamoDB 를 사용하십시오. Amazon Kinesis Data 
Streams 로의 스트리밍을 활성화합니다. Amazon Kinesis Data Firehose 를 사용하여 Kinesis Data 
Streams 에서 데이터를 읽습니다. Amazon S3 버킷에 레코드를 저장합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102119-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q362 
회사는 특정 지불 ID 에 대한 메시지가 전송된 순서대로 수신되어야 하는 지불 처리 시스템을 
사용합니다. 그렇지 않으면 결제가 잘못 처리될 수 있습니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (2 개 선택) 
A. 결제 ID 를 파티션 키로 사용하여 Amazon DynamoDB 테이블에 메시지를 씁니다. 
B. 결제 ID 를 파티션 키로 사용하여 Amazon Kinesis 데이터 스트림에 메시지를 씁니다. 
C. 결제 ID 를 키로 사용하여 Amazon ElastiCache for Memcached 클러스터에 메시지를 씁니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 씁니다. 결제 ID 를 사용하도록 
메시지 속성을 설정합니다. 
E. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 메시지를 씁니다. 결제 ID 를 
사용할 메시지 그룹을 설정합니다. 
Answer: B, E 
https://www.examtopics.com/discussions/amazon/view/102121-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
1) SQS FIFO 대기열은 메시지가 전송된 정확한 순서대로 수신되도록 보장합니다. 지불 ID 를 
메시지 그룹으로 사용하면 지불 ID 에 대한 모든 메시지가 순차적으로 수신됩니다. 
2) Kinesis 데이터 스트림은 파티션 키별로 순서를 지정할 수도 있습니다. 지불 ID 를 파티션 키로 
사용하면 각 지불 ID 에 대한 메시지의 엄격한 순서가 보장됩니다. 
Q363 
회사는 고유한 이벤트를 별도의 리더보드, 매치메이킹 및 인증 서비스로 동시에 전송해야 하는 
게임 시스템을 구축하고 있습니다. 회사에는 이벤트 순서를 보장하는 AWS 이벤트 기반 시스템이 
필요합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon EventBridge 이벤트 버스 
B. Amazon Simple Notification Service(Amazon SNS) FIFO 주제 
C. Amazon Simple Notification Service(Amazon SNS) 표준 주제 
D. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102124-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q364 
한 병원에서 환자의 증상을 수집하는 새로운 애플리케이션을 설계하고 있습니다. 병원은 
아키텍처에서 Amazon Simple Queue Service(Amazon SQS)와 Amazon Simple Notification 
Service(Amazon SNS)를 사용하기로 결정했습니다. 
솔루션 설계자가 인프라 설계를 검토하고 있습니다. 저장 및 전송 중에 데이터를 암호화해야 
합니다. 병원의 승인된 직원만 데이터에 액세스할 수 있어야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? (2 개 
선택) 
A. SQS 구성 요소에서 서버 측 암호화를 켭니다. 기본 키 정책을 업데이트하여 인증된 보안 주체 
집합으로 키 사용을 제한합니다. 
B. AWS Key Management Service(AWS KMS) 고객 관리 키를 사용하여 SNS 구성 요소에서 서버 
측 암호화를 켭니다. 키 정책을 적용하여 인증된 보안 주체 집합으로 키 사용을 제한합니다. 
C. SNS 구성 요소에서 암호화를 켭니다. 기본 키 정책을 업데이트하여 인증된 보안 주체 집합으로 
키 사용을 제한합니다. TLS 를 통한 암호화된 연결만 허용하도록 주제 정책에서 조건을 설정합니다. 
D. AWS Key Management Service(AWS KMS) 고객 관리 키를 사용하여 SQS 구성 요소에서 서버 
측 암호화를 켭니다. 키 정책을 적용하여 인증된 보안 주체 집합으로 키 사용을 제한합니다. TLS 를 
통한 암호화된 연결만 허용하도록 대기열 정책에서 조건을 설정합니다. 
E. AWS Key Management Service(AWS KMS) 고객 관리 키를 사용하여 SQS 구성 요소에서 서버 
측 암호화를 켭니다. IAM 정책을 적용하여 인증된 보안 주체 집합으로 키 사용을 제한합니다. 
TLS 를 통한 암호화된 연결만 허용하도록 대기열 정책에서 조건을 설정합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/102125-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
참고: 
https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html 
https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s
erver-side-encryption.html 
Q365 
회사는 Amazon RDS 에서 지원하는 웹 애플리케이션을 실행합니다. 새로운 데이터베이스 관리자가 
실수로 데이터베이스 테이블의 정보를 편집하여 데이터 손실을 일으켰습니다. 이러한 유형의 
사고에서 복구하는 데 도움이 되도록 회사는 지난 30 일 동안 변경이 발생하기 5 분 전의 상태로 
데이터베이스를 복원할 수 있는 기능을 원합니다. 
이 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 기능을 디자인에 포함해야 합니까? 
A. 읽기 복제본 
B. 수동 스냅샷 
C. 자동 백업 
D. 다중 AZ 배포 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102127-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
https://aws.amazon.com/rds/features/backup/ 
자동 백업은 요구 사항을 충족합니다. Amazon RDS 를 사용하면 DB 인스턴스의 백업을 자동으로 
생성할 수 있습니다. 자동 백업을 사용하면 DB 인스턴스에 대한 PITR(특정 시점 복구)을 보존 
기간(최대 35일) 내의 특정 초 단위로 낮출 수 있습니다. 보존 기간을 30일로 설정하면 최근 30일 
이내 변경 전 최대 5 분 전의 상태로 데이터베이스를 복원할 수 있습니다. 
Q366 
회사의 웹 애플리케이션은 AWS Lambda 함수 앞의 Amazon API Gateway API 와 Amazon 
DynamoDB 데이터베이스로 구성됩니다. Lambda 함수는 비즈니스 로직을 처리하고 DynamoDB 
테이블은 데이터를 호스팅합니다. 애플리케이션은 Amazon Cognito 사용자 풀을 사용하여 
애플리케이션의 개별 사용자를 식별합니다. 솔루션 설계자는 구독이 있는 사용자만 프리미엄 
콘텐츠에 액세스할 수 있도록 애플리케이션을 업데이트해야 합니다. 
최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. API Gateway API 에서 API 캐싱 및 제한을 활성화합니다. 
B. API Gateway API 에서 AWS WAF 를 설정합니다. 구독이 있는 사용자를 필터링하는 규칙을 
만듭니다. 
C. DynamoDB 테이블의 프리미엄 콘텐츠에 세분화된 IAM 권한을 적용합니다. 
D. 구독하지 않은 사용자의 액세스를 제한하기 위해 API 사용 계획 및 API 키를 구현하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102128-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 옵션은 API 사용 계획 및 API 키를 사용하기 때문에 가장 효율적입니다. API 에 액세스할 수 
있는 사람과 API 에 액세스할 수 있는 양과 속도를 제어할 수 있는 Amazon API Gateway 의 
기능입니다. 또한 API 사용 계획 및 API 키를 구현하여 구독하지 않은 사용자의 액세스를 
제한하므로 API 에 대한 다양한 액세스 계층을 생성하고 그에 따라 사용자에게 요금을 청구할 수 
있습니다. 이 솔루션은 구독이 있는 사용자만 프리미엄 콘텐츠에 액세스할 수 있도록 애플리케이션 
업데이트 요구 사항을 충족합니다. 
옵션 A 는 Amazon API Gateway 의 기능인 API Gateway API 에서 API 캐싱 및 제한을 사용하기 
때문에 효율성이 떨어집니다. 
API 의 성능과 가용성을 개선하고 트래픽 급증으로부터 백엔드 시스템을 보호할 수 있습니다. 
그러나 이는 가입하지 않은 사용자의 액세스를 제한하는 방법을 제공하지 않습니다. 
옵션 B 는 가용성에 영향을 미치거나 보안을 손상시키거나 과도한 리소스를 소비할 수 있는 
일반적인 웹 악용으로부터 웹 애플리케이션 또는 API 를 보호하는 웹 애플리케이션 방화벽 
서비스인 API Gateway API 에서 AWS WAF 를 사용하기 때문에 효율성이 떨어집니다. 그러나 이는 
가입하지 않은 사용자의 액세스를 제한하는 방법을 제공하지 않습니다. 
옵션 C 는 테이블 내의 특정 항목 또는 속성에 대한 액세스를 제어할 수 있는 권한인 DynamoDB 
테이블의 프리미엄 콘텐츠에 대한 세분화된 IAM 권한을 사용하기 때문에 효율성이 떨어집니다. 
그러나 이는 API 수준에서 구독하지 않은 사용자의 액세스를 제한하는 방법을 제공하지 않습니다. 
Q367 
한 회사에서 Amazon Route 53 지연 시간 기반 라우팅을 사용하여 전 세계 사용자를 위해 UDP 
기반 애플리케이션으로 요청을 라우팅하고 있습니다. 이 애플리케이션은 미국, 아시아 및 유럽에 
있는 회사의 온프레미스 데이터 센터에 있는 중복 서버에서 호스팅됩니다. 회사의 규정 준수 요구 
사항에 따르면 애플리케이션은 온프레미스에서 호스팅되어야 합니다. 회사는 애플리케이션의 
성능과 가용성을 개선하고자 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 3 개의 AWS 리전에서 3 개의 NLB(Network Load Balancer)를 구성하여 온프레미스 엔드포인트를 
처리합니다. AWS Global Accelerator 를 사용하여 가속기를 생성하고 NLB 를 엔드포인트로 
등록합니다. 가속기 DNS 를 가리키는 CNAME 을 사용하여 애플리케이션에 대한 액세스를 
제공합니다. 
B. 3 개의 AWS 리전에서 3 개의 Application Load Balancer(ALB)를 구성하여 온프레미스 
엔드포인트를 처리합니다. AWS Global Accelerator 를 사용하여 가속기를 생성하고 ALB 를 
엔드포인트로 등록합니다. 가속기 DNS 를 가리키는 CNAME 을 사용하여 애플리케이션에 대한 
액세스를 제공합니다. 
C. 3 개의 AWS 리전에서 3 개의 NLB(Network Load Balancer)를 구성하여 온프레미스 엔드포인트를 
처리합니다. Route 53 에서 3 개의 NLB 를 가리키는 지연 시간 기반 레코드를 생성하고 이를 
Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS 를 가리키는 CNAME 을 
사용하여 애플리케이션에 대한 액세스를 제공합니다. 
D. 온프레미스 엔드포인트를 처리하기 위해 3 개의 AWS 리전에서 3 개의 ALB(Application Load 
Balancer)를 구성합니다. Route 53 에서 3 개의 ALB 를 가리키는 지연 시간 기반 레코드를 생성하고 
이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS 를 가리키는 CNAME 을 
사용하여 애플리케이션에 대한 액세스를 제공합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102131-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
https://aws.amazon.com/ko/step-functions/#:~:text=AWS%20Step%20Functions%20is%20a 
AWS Step Functions 의 일반적인 사용 사례는 사람의 개입이 필요한 작업입니다(예: 승인 
프로세스). Step Functions 를 사용하면 분산 애플리케이션의 구성 요소를 상태 머신이라고 하는 
시각적 워크플로의 일련의 단계로 쉽게 조정할 수 있습니다. 안정적이고 확장 가능한 방식으로 
애플리케이션의 단계를 실행하기 위해 상태 시스템을 신속하게 구축하고 실행할 수 있습니다. 
Q368 
솔루션 설계자는 모든 신규 사용자가 특정 복잡성 요구 사항과 IAM 사용자 암호에 대한 필수 교체 
기간을 갖기를 원합니다. 
이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. 전체 AWS 계정에 대한 전반적인 암호 정책을 설정합니다. 
B. AWS 계정의 각 IAM 사용자에 대한 암호 정책을 설정합니다. 
C. 타사 공급업체 소프트웨어를 사용하여 암호 요구 사항을 설정합니다. 
D. Amazon CloudWatch 규칙을 Create_newuser 이벤트에 연결하여 적절한 요구 사항으로 암호를 
설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102132-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 옵션은 IAM 사용자 암호에 대한 복잡성 요구 사항 및 필수 교체 기간을 지정하는 방법인 전체 
AWS 계정에 대한 전체 암호 정책을 설정하기 때문에 가장 효율적입니다. 또한 암호 정책은 
계정의 모든 IAM 사용자에게 적용되므로 모든 새 사용자에 대한 암호 정책 설정 요구 사항을 
충족합니다. 이 솔루션은 IAM 사용자 암호에 대한 특정 복잡성 요구 사항 및 필수 교체 기간 설정 
요구 사항을 충족합니다. 
옵션 B 는 AWS 계정의 각 IAM 사용자에 대해 암호 정책을 설정하기 때문에 효율성이 떨어집니다. 
암호 정책은 계정 수준에서만 설정할 수 있으므로 불가능합니다. 
옵션 C 는 타사 공급업체 소프트웨어를 사용하여 암호 요구 사항을 설정하기 때문에 효율성이 
떨어집니다. IAM 은 암호 정책을 설정하는 기본 제공 방법을 제공하므로 필요하지 않습니다. 
옵션 D 는 Amazon CloudWatch 규칙을 Create_newuser 이벤트에 연결하여 적절한 요구 사항으로 
암호를 설정하기 때문에 효율성이 떨어집니다. 이는 CloudWatch 규칙이 IAM 사용자 암호를 
수정할 수 없기 때문에 불가능합니다. 
Q369 
회사에서 애플리케이션을 Amazon EC2 Linux 인스턴스로 마이그레이션했습니다. 이러한 EC2 
인스턴스 중 하나는 일정에 따라 여러 개의 1 시간 작업을 실행합니다. 이러한 작업은 서로 다른 
팀에서 작성했으며 공통 프로그래밍 언어가 없습니다. 회사는 이러한 작업이 단일 인스턴스에서 
실행되는 동안 성능과 확장성에 대해 우려하고 있습니다. 솔루션 설계자는 이러한 문제를 해결하기 
위한 솔루션을 구현해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Batch 를 사용하여 작업을 작업으로 실행합니다. Amazon EventBridge(Amazon CloudWatch 
Events)를 사용하여 작업을 예약합니다. 
B. EC2 인스턴스를 컨테이너로 변환합니다. AWS App Runner 를 사용하여 작업을 작업으로 실행할 
온디맨드 컨테이너를 생성합니다. 
C. 작업을 AWS Lambda 함수에 복사합니다. Amazon EventBridge(Amazon CloudWatch Events)를 
사용하여 Lambda 함수를 예약합니다. 
D. 작업을 실행하는 EC2 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI 로 Auto 
Scaling 그룹을 생성하여 인스턴스의 여러 복사본을 실행합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102133-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS Batch 는 사용자가 AWS 에서 배치 작업을 실행할 수 있게 해주는 완전관리형 서비스입니다. 
다른 언어로 작성된 다양한 유형의 작업을 처리하고 EC2 인스턴스에서 실행할 수 있습니다. 또한 
Amazon EventBridge(Amazon CloudWatch Events)와 통합되어 시간 또는 이벤트 트리거를 
기반으로 작업을 예약합니다. 이 솔루션은 성능, 확장성 및 낮은 운영 오버헤드 요구 사항을 
충족합니다. 
1. EC2 인스턴스를 컨테이너로 변환합니다. AWS App Runner 를 사용하여 작업을 작업으로 실행할 
온디맨드 컨테이너를 생성합니다. 이 솔루션은 EC2 인스턴스를 컨테이너로 변환하고 웹 
애플리케이션을 자동으로 빌드 및 배포하고 트래픽 부하를 분산하는 서비스인 AWS App Runner 를 
사용하므로 낮은 운영 오버헤드 요구 사항을 충족하지 않습니다. 배치 작업을 실행하는 데는 
필요하지 않습니다. 
2. 작업을 AWS Lambda 함수에 복사합니다. Amazon EventBridge(Amazon CloudWatch Events)를 
사용하여 Lambda 함수를 예약합니다. AWS Lambda 에는 실행 시간이 15 분, 메모리 할당이 
10GB 로 제한되어 있으므로 이 솔루션은 성능 요구 사항을 충족하지 않습니다. 이러한 제한은 
1 시간 작업을 실행하는 데 충분하지 않을 수 있습니다. 
3. 작업을 실행하는 EC2 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI 로 Auto Scaling 
그룹을 생성하여 인스턴스의 여러 복사본을 실행합니다. 이 솔루션은 구성 및 관리가 필요한 추가 
리소스인 AMI 및 Auto Scaling 그룹을 생성하고 유지 관리하므로 낮은 운영 오버헤드 요구 사항을 
충족하지 않습니다. 
참조 URL:  
https://docs.aws.amazon.com/ko_kr/whitepapers/latest/aws-overview/compute-services.html 
설명: 
NAT 게이트웨이는 프라이빗 서브넷의 인스턴스가 인터넷이나 다른 AWS 서비스에 연결할 수 있게 
해주지만 인터넷이 해당 인스턴스와의 연결을 시작하지 못하도록 하는 네트워크 주소 변환(NAT) 
장치 유형입니다. NAT 게이트웨이는 최소한의 운영 유지 관리가 필요하고 최대 45Gbps 의 버스트 
트래픽을 처리할 수 있는 관리형 서비스입니다. NAT 게이트웨이는 시나리오의 3 계층 웹 
애플리케이션과 같이 프라이빗 서브넷의 EC2 인스턴스가 인터넷을 통해 라이선스 서버와 통신해야 
하는 시나리오에 적합합니다. 
시나리오의 요구 사항을 충족하려면 솔루션 설계자가 퍼블릭 서브넷에서 NAT 게이트웨이를 
프로비저닝해야 합니다. 솔루션 설계자는 또한 NAT 게이트웨이를 가리키는 기본 경로로 각 
프라이빗 서브넷의 경로 테이블을 수정해야 합니다. 이렇게 하면 프라이빗 서브넷에서 실행되는 
EC2 인스턴스가 NAT 게이트웨이를 통해 인터넷을 통해 라이선스 서버에 액세스할 수 있습니다. 
Q370 
회사는 VPC 에서 공용 3 계층 웹 애플리케이션을 실행합니다. 애플리케이션은 여러 가용 영역의 
Amazon EC2 인스턴스에서 실행됩니다. 프라이빗 서브넷에서 실행되는 EC2 인스턴스는 인터넷을 
통해 라이선스 서버와 통신해야 합니다. 회사는 운영 유지 보수를 최소화하는 관리형 솔루션이 
필요합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 퍼블릭 서브넷에서 NAT 인스턴스를 프로비저닝합니다. NAT 인스턴스를 가리키는 기본 경로로 
각 프라이빗 서브넷의 경로 테이블을 수정합니다. 
B. 프라이빗 서브넷에서 NAT 인스턴스를 프로비저닝합니다. NAT 인스턴스를 가리키는 기본 
경로로 각 프라이빗 서브넷의 경로 테이블을 수정합니다. 
C. 퍼블릭 서브넷에서 NAT 게이트웨이를 프로비저닝합니다. NAT 게이트웨이를 가리키는 기본 
경로로 각 프라이빗 서브넷의 경로 테이블을 수정합니다. 
D. 프라이빗 서브넷에서 NAT 게이트웨이를 프로비저닝합니다. NAT 게이트웨이를 가리키는 기본 
경로로 각 프라이빗 서브넷의 경로 테이블을 수정합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102134-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q371 
회사는 디지털 미디어 스트리밍 애플리케이션을 호스팅하기 위해 Amazon Elastic Kubernetes 
Service(Amazon EKS) 클러스터를 생성해야 합니다. EKS 클러스터는 저장을 위해 Amazon Elastic 
Block Store(Amazon EBS) 볼륨이 지원하는 관리형 노드 그룹을 사용합니다. 회사는 AWS Key 
Management Service(AWS KMS)에 저장된 고객 관리형 키를 사용하여 유휴 상태의 모든 데이터를 
암호화해야 합니다. 
최소한의 운영 오버헤드로 이 요구 사항을 충족하는 작업 조합은 무엇입니까? (2 개 선택) 
A. 고객 관리 키를 사용하는 Kubernetes 플러그인을 사용하여 데이터 암호화를 수행합니다. 
B. EKS 클러스터 생성 후 EBS 볼륨을 찾습니다. 고객 관리형 키를 사용하여 암호화를 
활성화합니다. 
C. EKS 클러스터가 생성될 AWS 리전에서 기본적으로 EBS 암호화를 활성화합니다. 고객 관리형 
키를 기본 키로 선택합니다. 
D. EKS 클러스터를 생성합니다. 고객 관리형 키에 대한 권한을 부여하는 정책이 있는 IAM 역할을 
생성합니다. 역할을 EKS 클러스터와 연결합니다. 
E. 고객 관리형 키를 EKS 클러스터에 Kubernetes 비밀로 저장합니다. 고객 관리형 키를 사용하여 
EBS 볼륨을 암호화합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/102135-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q372 
회사에서 Oracle 데이터베이스를 AWS 로 마이그레이션하려고 합니다. 데이터베이스는 지리 코드로 
식별되는 고해상도 지리 정보 시스템(GIS) 이미지 수백만 개가 포함된 단일 테이블로 구성됩니다. 
자연 재해가 발생하면 몇 분마다 수만 개의 이미지가 업데이트됩니다. 각 지리적 코드에는 연결된 
단일 이미지 또는 행이 있습니다. 회사는 이러한 이벤트 중에 가용성과 확장성이 뛰어난 솔루션을 
원합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 이미지와 지리적 코드를 데이터베이스 테이블에 저장합니다. Amazon RDS 다중 AZ DB 
인스턴스에서 실행되는 Oracle 을 사용합니다. 
B. Amazon S3 버킷에 이미지를 저장합니다. 지리적 코드를 키로, 이미지 S3 URL 을 값으로 
사용하여 Amazon DynamoDB 를 사용합니다. 
C. Amazon DynamoDB 테이블에 이미지와 지리적 코드를 저장합니다. 부하가 높은 시간 동안 
DynamoDB Accelerator(DAX)를 구성합니다. 
D. Amazon S3 버킷에 이미지를 저장합니다. 지리 코드와 이미지 S3 URL 을 데이터베이스 테이블에 
저장합니다. Amazon RDS 다중 AZ DB 에서 실행되는 Oracle 사용 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102136-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon S3 는 수백만 개의 이미지 1 를 저장할 수 있는 확장성과 내구성이 뛰어나고 비용 효율적인 
객체 스토리지 서비스입니다. Amazon DynamoDB 는 키-값 및 문서 데이터에 대해 높은 처리량과 
짧은 지연 시간을 처리할 수 있는 완전관리형 NoSQL 데이터베이스입니다. S3 를 사용하여 
이미지를 저장하고 DynamoDB 를 사용하여 지리적 코드와 이미지 S3 URL 을 저장함으로써 
솔루션은 자연 재해 중에 고가용성과 확장성을 달성할 수 있습니다. 또한 캐싱, 자동 확장, 글로벌 
테이블과 같은 DynamoDB 의 기능을 활용하여 성능을 개선하고 비용을 절감할 수 있습니다. 
1. 데이터베이스 테이블에 이미지와 지리적 코드를 저장합니다. Amazon RDS 다중 AZ DB 
인스턴스에서 실행되는 Oracle 을 사용합니다. Oracle 은 이미지와 같은 대량의 비정형 데이터를 
효율적으로 처리하지 못할 수 있는 관계형 데이터베이스이므로 이 솔루션은 확장성 및 비용 
효율성 요구 사항을 충족하지 않습니다. 또한 S3 및 DynamoDB 보다 라이선스 및 운영 비용이 더 
많이 듭니다. 
2. Amazon DynamoDB 테이블에 이미지와 지리적 코드를 저장합니다. 로드가 많은 시간 동안 
DynamoDB Accelerator(DAX)를 구성합니다. 이 솔루션은 DynamoDB 에 이미지를 저장하면 
S312 에 저장하는 것보다 더 많은 스토리지 공간을 사용하고 더 많은 비용이 발생하므로 비용 
효율성 요구 사항을 충족하지 않습니다. 또한 높은 부하를 처리하기 위해 DAX 클러스터의 추가 
구성 및 관리가 필요합니다. 
3. Amazon S3 버킷에 이미지를 저장합니다. 지리적 코드와 이미지 S3 URL 을 데이터베이스 
테이블에 저장합니다. Amazon RDS 다중 AZ DB 인스턴스에서 실행되는 Oracle 을 사용합니다. 
Oracle 은 지리적 코드와 같은 키-값 데이터에 대한 높은 처리량과 낮은 대기 시간을 효율적으로 
처리하지 못할 수 있는 관계형 데이터베이스이므로 이 솔루션은 확장성 및 비용 효율성 요구 
사항을 충족하지 않습니다. 또한 DynamoDB2 보다 라이선스 및 운영 비용이 더 많이 듭니다. 
참조 URL: https://dynobase.dev/dynamodb-vs-s3/ 
Q373 
회사에 자동차의 loT 센서에서 데이터를 수집하는 애플리케이션이 있습니다. 데이터는 Amazon 
Kinesis Data 를 통해 Amazon S3 에 스트리밍 및 저장됩니다. 
소방 호스. 데이터는 매년 수조 개의 S3 객체를 생성합니다. 매일 아침 회사는 지난 30 일 동안의 
데이터를 사용하여 일련의 기계 학습(ML) 모델을 재교육합니다. 
매년 4 회 회사는 이전 12 개월의 데이터를 사용하여 분석을 수행하고 다른 ML 모델을 교육합니다. 
데이터는 최대 1 년 동안 최소한의 지연으로 사용할 수 있어야 합니다. 1 년 후에는 데이터를 보관 
목적으로 보관해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까? 
A. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1 년 후 객체를 S3 Glacier Deep Archive 로 
전환하는 S3 수명 주기 정책을 생성합니다. 
B. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1 년 후 자동으로 객체를 S3 Glacier Deep 
Archive 로 이동하도록 S3 Intelligent-Tiering 을 구성합니다. 
C. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용합니다. 1 년 후 객체를 
S3 Glacier Deep Archive 로 전환하는 S3 수명 주기 정책을 생성합니다. 
D. S3 Standard 스토리지 클래스를 사용합니다. 30 일 후에 객체를 S3 Standard-Infrequent 
Access(S3 Standard-IA)로 전환한 다음 1 년 후에 S3 Glacier Deep Archive 로 전환하는 S3 수명 
주기 정책을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102137-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q374 
한 회사가 us-east-1 리전 내의 3 개의 별도 VPC 에서 여러 비즈니스 애플리케이션을 실행하고 
있습니다. 애플리케이션은 VPC 간에 통신할 수 있어야 합니다. 또한 애플리케이션은 단일 
온프레미스 데이터 센터에서 실행되는 대기 시간에 민감한 애플리케이션에 매일 수백 
기가바이트의 데이터를 지속적으로 보낼 수 있어야 합니다. 
솔루션 설계자는 비용 효율성을 극대화하는 네트워크 연결 솔루션을 설계해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터 센터에서 AWS 로 3 개의 AWS Site-to-Site VPN 연결을 구성합니다. 각 VPC 에 대해 
하나의 VPN 연결을 구성하여 연결을 설정합니다. 
B. 각 VPC 에서 타사 가상 네트워크 어플라이언스를 시작합니다. 데이터 센터와 각 가상 
어플라이언스 간에 IPsec VPN 터널을 설정합니다. 
C. 데이터 센터에서 us-east-1 의 Direct Connect 게이트웨이로 3 개의 AWS Direct Connect 
연결을 설정합니다. Direct Connect 연결 중 하나를 사용하도록 각 VPC 를 구성하여 연결을 
설정합니다. 
D. 데이터 센터에서 AWS 로 하나의 AWS Direct Connect 연결을 설정합니다. 전송 게이트웨이를 
생성하고 각 VPC 를 전송 게이트웨이에 연결합니다. Direct Connect 연결과 transit gateway 간의 
연결을 설정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102138-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
A(X) : VPC-온프레미스 간 통신은 이루어지나 VPC 간 통신은 이루어지지 않고 있음. 
B(X) : A 와 같은 이유로 오답. 
C(X) : A 와 같은 이유로 오답. 
D(O) : Transit Gateway 는 동일한 리전 내에 있는 여러 VPC 들을 연결하는 전송 '허브'이므로 
Transit Gateway 를 거쳐 VPC 끼리 통신이 가능 
AWS Transit Gateway 는 동일한 리전의 VPC 를 상호 연결하여 Amazon VPC 라우팅 구성을 한 
곳에 통합하는 네트워크 전송 허브입니다. 
https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-co
nnect-aws-transit-gateway.html 
Q375 
전자상거래 회사는 주문 처리 작업을 완료하기 위해 여러 서버리스 기능과 AWS 서비스를 
포함하는 분산 애플리케이션을 구축하고 있습니다. 이러한 작업에는 워크플로의 일부로 수동 
승인이 필요합니다. 솔루션 설계자는 주문 처리 애플리케이션을 위한 아키텍처를 설계해야 합니다. 
솔루션은 여러 AWS Lambda 기능을 반응형 서버리스 애플리케이션으로 결합할 수 있어야 합니다. 
솔루션은 또한 Amazon EC2 인스턴스, 컨테이너 또는 온프레미스 서버에서 실행되는 데이터 및 
서비스를 오케스트레이션해야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Step Functions 를 사용하여 애플리케이션을 구축하십시오. 
B. AWS Glue 작업에서 모든 애플리케이션 구성 요소를 통합합니다. 
C. Amazon Simple Queue Service(Amazon SQS)를 사용하여 애플리케이션을 구축합니다. 
D. AWS Lambda 함수와 Amazon EventBridge 이벤트를 사용하여 애플리케이션을 구축합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102139-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS Step Functions 는 시각적 워크플로를 사용하여 분산 애플리케이션 및 마이크로 서비스의 
구성 요소를 조정하여 애플리케이션을 쉽게 구축할 수 있게 해주는 완전 관리형 서비스입니다. 
Step Functions 를 사용하면 여러 AWS Lambda 함수를 반응형 서버리스 애플리케이션에 결합하고 
Amazon EC2 인스턴스, 컨테이너 또는 온프레미스 서버에서 실행되는 데이터 및 서비스를 
오케스트레이션할 수 있습니다. Step Functions 는 또한 워크플로의 일부로 수동 승인을 허용합니다. 
이 솔루션은 최소한의 운영 오버헤드로 모든 요구 사항을 충족합니다. 
https://aws.amazon.com/ko/step-functions/#:~:text=AWS%20Step%20Functions%20is%20a 
Q376 
한 회사에서 MySQL DB 인스턴스용 Amazon RDS 를 출시했습니다. 데이터베이스에 대한 대부분의 
연결은 서버리스 애플리케이션에서 발생합니다. 데이터베이스에 대한 애플리케이션 트래픽은 
임의의 간격으로 크게 변경됩니다. 수요가 많을 때 사용자는 애플리케이션에 데이터베이스 연결 
거부 오류가 발생한다고 보고합니다. 
최소한의 운영 오버헤드로 이 문제를 해결하는 솔루션은 무엇입니까? 
A. RDS Proxy 에서 프록시를 생성합니다. RDS Proxy 를 통해 DB 인스턴스를 사용하도록 사용자 
애플리케이션을 구성합니다. 
B. 사용자 애플리케이션과 DB 인스턴스 간에 Amazon ElastiCache for Memcached 를 배포합니다. 
C. I/O 용량이 더 큰 다른 인스턴스 클래스로 DB 인스턴스를 마이그레이션합니다. 새 DB 
인스턴스를 사용하도록 사용자 애플리케이션을 구성합니다. 
D. DB 인스턴스에 대한 다중 AZ 를 구성합니다. DB 인스턴스 간에 전환하도록 사용자 
애플리케이션을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102140-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
최신 서버리스 아키텍처에 구축된 애플리케이션을 포함하여 많은 애플리케이션은 데이터베이스 
서버에 대해 많은 수의 열린 연결을 가질 수 있으며 빠른 속도로 데이터베이스 연결을 열고 닫을 
수 있으므로 데이터베이스 메모리와 컴퓨팅 리소스가 고갈될 수 있습니다. Amazon RDS Proxy 를 
사용하면 애플리케이션이 데이터베이스와 설정된 연결을 풀링하고 공유하여 데이터베이스 
효율성과 애플리케이션 확장성을 개선할 수 있습니다.  
(https://aws.amazon.com/pt/rds/proxy/) 
Q377 
한 회사는 최근 Amazon EC2 인스턴스에 대해 운영 체제 버전, 패치 및 설치된 소프트웨어에 대한 
정보를 중앙 집중화하기 위해 새로운 감사 시스템을 배포했습니다. 솔루션 설계자는 EC2 Auto 
Scaling 그룹을 통해 프로비저닝된 모든 인스턴스가 시작 및 종료되는 즉시 성공적으로 감사 
시스템에 보고서를 보내도록 해야 합니다. 
이러한 목표를 가장 효율적으로 달성하는 솔루션은 무엇입니까? 
A. 예약된 AWS Lambda 함수를 사용하고 모든 EC2 인스턴스에서 원격으로 스크립트를 실행하여 
데이터를 감사 시스템으로 보냅니다. 
B. EC2 Auto Scaling 수명 주기 후크를 사용하여 인스턴스가 시작되고 종료될 때 감사 시스템에 
데이터를 보내는 사용자 지정 스크립트를 실행합니다. 
C. EC2 Auto Scaling 시작 구성을 사용하여 사용자 데이터를 통해 사용자 지정 스크립트를 
실행하여 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 보냅니다. 
D. 인스턴스 운영 체제에서 사용자 지정 스크립트를 실행하여 데이터를 감사 시스템으로 보냅니다. 
인스턴스가 시작되고 종료될 때 EC2 Auto Scaling 그룹에서 호출할 스크립트를 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102142-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon EC2 Auto Scaling 은 Auto Scaling 그룹에 수명 주기 후크를 추가하는 기능을 제공합니다. 
이러한 후크를 사용하면 Auto Scaling 인스턴스 수명 주기의 이벤트를 인식하는 솔루션을 생성한 
다음 해당 수명 주기 이벤트가 발생할 때 인스턴스에서 사용자 지정 작업을 수행할 수 있습니다. 
(https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html) 
Q378 
한 회사에서 Auto Scaling 그룹의 클라이언트와 서버 간의 통신에 UDP 를 사용하는 실시간 
멀티플레이어 게임을 개발하고 있습니다. 하루 동안 수요가 급증할 것으로 예상되므로 게임 서버 
플랫폼은 그에 따라 적응해야 합니다. 개발자는 개입 없이 확장되는 데이터베이스 솔루션에 게이머 
점수 및 기타 비관계형 데이터를 저장하기를 원합니다. 
솔루션 설계자는 어떤 솔루션을 추천해야 합니까? 
A. 트래픽 분산에는 Amazon Route 53 을 사용하고 데이터 저장에는 Amazon Aurora Serverless 를 
사용하십시오. 
B. 트래픽 분산을 위해 Network Load Balancer 를 사용하고 데이터 저장을 위해 주문형 Amazon 
DynamoDB 를 사용합니다. 
C. 트래픽 분산을 위해 Network Load Balancer 를 사용하고 데이터 저장을 위해 Amazon Aurora 
Global Database 를 사용합니다. 
D. 트래픽 분산을 위해 Application Load Balancer 를 사용하고 데이터 저장을 위해 Amazon 
DynamoDB 전역 테이블을 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102143-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Network Load Balancer 는 연결 수준(계층 4)에서 작동하고 TCP 및 UDP 트래픽 모두의 부하를 
분산할 수 있는 일종의 부하 분산 장치입니다. Network Load Balancer 는 실시간 멀티플레이어 
게임과 같이 고성능과 짧은 대기 시간이 필요한 시나리오에 적합합니다. Network Load Balancer 는 
가용 영역당 단일 고정 IP 주소를 사용하면서 갑작스럽고 변동성이 큰 트래픽 패턴을 처리할 수도 
있습니다. 
시나리오의 요구 사항을 충족하려면 솔루션 설계자는 Auto Scaling 그룹의 EC2 인스턴스 간 
트래픽 분산을 위해 Network Load Balancer 를 사용해야 합니다. Network Load Balancer 는 
클라이언트에서 적절한 포트의 서버로 UDP 트래픽을 라우팅할 수 있습니다. Network Load 
Balancer 는 클라이언트와 서버 간의 보안 통신을 위해 TLS 오프로딩도 지원할 수 있습니다. 
Amazon DynamoDB 는 일관된 성능과 짧은 지연 시간으로 모든 양의 데이터를 저장하고 검색할 수 
있는 완전 관리형 NoSQL 데이터베이스 서비스입니다. Amazon DynamoDB 온디맨드는 용량 
계획이 필요 없고 테이블에서 수행되는 읽기 및 쓰기 요청에 대해서만 요금을 부과하는 유연한 
결제 옵션입니다 3. Amazon DynamoDB 온디맨드는 게임 애플리케이션과 같이 애플리케이션 
트래픽을 예측할 수 없거나 산발적인 시나리오에 이상적입니다. 
시나리오의 요구 사항을 충족하려면 솔루션 설계자는 데이터 스토리지에 Amazon DynamoDB 
온디맨드를 사용해야 합니다. Amazon DynamoDB 온디맨드는 개발자의 개입 없이 게이머 점수 및 
기타 비관계형 데이터를 저장할 수 있습니다. Amazon DynamoDB 온디맨드는 자동으로 확장하여 
성능이나 가용성에 영향을 주지 않고 모든 수준의 요청 트래픽을 처리할 수 있습니다. 
Q379 
회사는 AWS Lambda 와 통합된 Amazon API Gateway API 백엔드를 사용하는 프런트엔드 
애플리케이션을 호스팅합니다. API 가 요청을 받으면 Lambda 함수는 많은 라이브러리를 
로드합니다. 그런 다음 Lambda 함수는 Amazon RDS 데이터베이스에 연결하여 데이터를 처리하고 
프런트엔드 애플리케이션에 데이터를 반환합니다. 회사는 회사 운영에 대한 변경 횟수를 
최소화하면서 모든 사용자의 응답 대기 시간을 가능한 한 낮추고자 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. API 를 우회하여 쿼리 속도를 높이려면 프런트엔드 애플리케이션과 데이터베이스 사이에 연결을 
설정합니다. 
B. 요청을 처리하는 Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. 
C. 유사한 데이터 세트를 더 빠르게 검색하기 위해 쿼리 결과를 Amazon S3 에 캐시합니다. 
D. Lambda 가 한 번에 설정할 수 있는 연결 수를 늘리려면 데이터베이스 크기를 늘립니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102144-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
요청을 처리하는 Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. 프로비저닝된 동시성을 
사용하면 Lambda 함수에서 사용할 수 있는 컴퓨팅 리소스의 양을 설정할 수 있으므로 한 번에 더 
많은 요청을 처리하고 지연 시간을 줄일 수 있습니다. 쿼리 결과를 Amazon S3 에 캐싱하면 대기 
시간을 줄이는 데 도움이 되지만 프로비저닝된 동시성을 설정하는 것만큼 효과적이지는 않습니다. 
데이터베이스 크기를 늘려도 지연 시간을 줄이는 데 도움이 되지 않습니다. 이는 Lambda 함수가 
설정할 수 있는 연결 수를 늘리지 않고 프런트엔드 애플리케이션과 데이터베이스 사이에 직접 
연결을 설정하면 API 를 우회하기 때문입니다. 최고의 솔루션 중 하나입니다. 
https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html 
Using AWS Lambda with Amazon API Gateway - AWS Lambda 
https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html 
https://aws.amazon.com/lambda/faqs/ 
AWS Lambda FAQs 
https://aws.amazon.com/lambda/faqs/ 
Q380 
회사에서 온프레미스 워크로드를 AWS 클라우드로 마이그레이션하고 있습니다. 이 회사는 이미 
여러 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 사용하고 있습니다. 회사는 업무 시간 
외에 EC2 인스턴스와 DB 인스턴스를 자동으로 시작하고 중지하는 솔루션을 원합니다. 솔루션은 
비용 및 인프라 유지 관리를 최소화해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 탄력적 크기 조정을 사용하여 EC2 인스턴스를 확장합니다. 업무 시간 외에는 DB 인스턴스를 
0 으로 조정합니다. 
B. 일정에 따라 EC2 인스턴스와 DB 인스턴스를 자동으로 시작 및 중지하는 파트너 솔루션에 대한 
AWS Marketplace 를 살펴보십시오. 
C. 다른 EC2 인스턴스를 시작합니다. 일정에 따라 기존 EC2 인스턴스와 DB 인스턴스를 시작 및 
중지하는 셸 스크립트를 실행하도록 crontab 일정을 구성합니다. 
D. EC2 인스턴스와 DB 인스턴스를 시작하고 중지할 AWS Lambda 함수를 생성합니다. 일정에 
따라 Lambda 함수를 호출하도록 Amazon EventBridge 를 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102145-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
비용 및 인프라 유지 관리를 최소화하면서 일정에 따라 EC2 인스턴스 및 DB 인스턴스를 자동으로 
시작 및 중지하는 가장 효율적인 솔루션은 AWS Lambda 함수를 생성하고 일정에 따라 함수를 
호출하도록 Amazon EventBridge 를 구성하는 것입니다. 
옵션 A, 탄력적 크기 조정을 사용하여 EC2 인스턴스를 확장하고 업무 시간 외에 DB 인스턴스를 
0 으로 확장하는 것은 DB 인스턴스를 0 으로 확장할 수 없기 때문에 실행 불가능합니다. 
파트너 솔루션에 대한 AWS Marketplace 를 탐색하는 옵션 B 가 옵션일 수 있지만 가장 효율적인 
솔루션이 아닐 수 있으며 잠재적으로 추가 비용이 추가될 수 있습니다. 
다른 EC2 인스턴스를 시작하고 일정에 따라 기존 EC2 인스턴스 및 DB 인스턴스를 시작 및 
중지하는 셸 스크립트를 실행하도록 crontab 일정을 구성하는 옵션 C 는 불필요한 인프라 및 유지 
관리를 추가합니다. 
Q381 
회사에서 PostgreSQL 데이터베이스를 포함하는 3 계층 웹 애플리케이션을 호스팅합니다. 
데이터베이스는 문서의 메타데이터를 저장합니다. 회사는 매달 보고서에서 회사가 검토하는 문서를 
검색하기 위해 핵심 용어에 대한 메타데이터를 검색합니다. 문서는 Amazon S3 에 저장됩니다. 
문서는 일반적으로 한 번만 작성되지만 자주 업데이트됩니다. 
보고 프로세스는 관계형 쿼리를 사용하여 몇 시간이 걸립니다. 보고 프로세스는 문서 수정 또는 새 
문서 추가를 방해해서는 안 됩니다. 솔루션 설계자는 보고 프로세스의 속도를 높이는 솔루션을 
구현해야 합니다. 
애플리케이션 코드를 최소한으로 변경하여 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 읽기 전용 복제본이 포함된 새로운 Amazon DocumentDB(MongoDB 호환) 클러스터를 
설정합니다. 읽기 복제본을 확장하여 보고서를 생성합니다. 
B. Aurora 복제본이 포함된 새로운 Amazon Aurora PostgreSQL DB 클러스터를 설정합니다. Aurora 
복제본에 쿼리를 실행하여 보고서를 생성합니다. 
C. PostgreSQL 다중 AZ DB 인스턴스용 새 Amazon RDS 를 설정합니다. 보고 모듈이 기본 노드에 
영향을 주지 않도록 보조 RDS 노드를 쿼리하도록 보고 모듈을 구성합니다. 
D. 문서를 저장할 새 Amazon DynamoDB 테이블을 설정합니다. 새 문서 항목을 지원하려면 
고정된 쓰기 용량을 사용하십시오. 보고서를 지원하기 위해 읽기 용량을 자동으로 확장합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102147-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q382 
회사는 AWS 에 사용자 장치에서 센서 데이터를 수집하는 3 계층 애플리케이션을 보유하고 
있습니다. 트래픽은 NLB(Network Load Balancer)를 거쳐 웹 계층용 Amazon EC2 인스턴스로 
이동한 다음 마지막으로 애플리케이션 계층용 EC2 인스턴스로 이동합니다. 애플리케이션 계층은 
데이터베이스를 호출합니다. 
솔루션 설계자는 전송 중인 데이터의 보안을 개선하기 위해 무엇을 해야 합니까? 
A. TLS 수신기를 구성합니다. NLB 에 서버 인증서를 배포합니다. 
B. AWS Shield Advanced 를 구성합니다. NLB 에서 AWS WAF 를 활성화합니다. 
C. 로드 밸런서를 Application Load Balancer(ALB)로 변경합니다. ALB 에서 AWS WAF 를 
활성화합니다. 
D. AWS Key Management Service(AWS KMS)를 사용하여 EC2 인스턴스에서 Amazon Elastic Block 
Store(Amazon EBS) 볼륨을 암호화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102149-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명 1: 
전송 중인 데이터의 보안을 개선하는 가장 좋은 옵션은 TLS 수신기를 구성하고 NLB 에 서버 
인증서를 배포하는 것입니다. 이렇게 하면 데이터가 네트워크를 통해 이동할 때 암호화되고 
안전해집니다. 또한 AWS Shield Advanced를 구성하고 NLB에서 AWS WAF를 활성화하여 악의적인 
공격으로부터 네트워크를 추가로 보호할 수도 있습니다. 또는 로드 밸런서를 Application Load 
Balancer(ALB)로 변경하고 ALB 에서 AWS WAF 를 활성화할 수도 있습니다. 
마지막으로 AWS Key Management Service(AWS KMS)를 사용하여 EC2 인스턴스에서 Amazon 
Elastic Block Store(Amazon EBS) 볼륨을 암호화할 수도 있습니다. 
TLS 수신기에 대한 SSL 인증서를 지정해야 합니다. 로드 밸런서는 인증서를 사용하여 연결을 
종료하고 대상으로 라우팅하기 전에 클라이언트의 요청을 해독합니다. 
https://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-listener.html 
Q383 
한 회사가 온프레미스 데이터 센터에서 AWS 로 상용 기성 애플리케이션을 마이그레이션할 
계획입니다. 이 소프트웨어에는 용량 및 가동 시간 요구 사항을 예측할 수 있는 소켓과 코어를 
사용하는 소프트웨어 라이센스 모델이 있습니다. 회사는 올해 초에 구입한 기존 라이센스를 
사용하려고 합니다. 
가장 비용 효율적인 Amazon EC2 요금 옵션은 무엇입니까? 
A. 전용 예약 호스트(Dedicated Reserved Hosts) 
B. 전용 온디맨드 호스트(Dedicated On-Demand Hosts) 
C. 전용 예약 인스턴스(Dedicated Reserved Instances) 
D. 전용 온디맨드 인스턴스(Dedicated On-Demand Instances) 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102150-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
https://aws.amazon.com/ec2/dedicated-hosts/ 
Amazon EC2 전용 호스트를 사용하면 Amazon EC2 에서 Microsoft 및 Oracle 과 같은 공급업체의 
적격 소프트웨어 라이선스를 사용할 수 있으므로 자체 라이선스 사용의 유연성과 비용 효율성을 
얻으면서도 AWS 의 탄력성, 단순성 및 탄력성을 얻을 수 있습니다. 
Q384 
회사는 여러 가용 영역에 걸쳐 Amazon EC2 Linux 인스턴스에서 애플리케이션을 실행합니다. 
애플리케이션에는 고가용성 및 POSIX(Portable Operating System Interface) 호환 스토리지 계층이 
필요합니다. 스토리지 계층은 최대 데이터 내구성을 제공해야 하며 EC2 인스턴스 간에 공유 
가능해야 합니다. 저장소 계층의 데이터는 처음 30 일 동안 자주 액세스되고 그 이후에는 드물게 
액세스됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon S3 Standard 스토리지 클래스를 사용하십시오. S3 수명 주기 정책을 생성하여 자주 
액세스하지 않는 데이터를 S3 Glacier 로 이동합니다. 
B. Amazon S3 Standard 스토리지 클래스를 사용합니다. S3 수명 주기 정책을 생성하여 자주 
액세스하지 않는 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다. 
C. Amazon Elastic File System(Amazon EFS) Standard 스토리지 클래스를 사용합니다. 자주 
액세스하지 않는 데이터를 EFS Standard-Infrequent Access(EFS Standard-IA)로 이동하는 수명 
주기 관리 정책을 만듭니다. 
D. Amazon Elastic File System(Amazon EFS) One Zone 스토리지 클래스를 사용합니다. 자주 
액세스하지 않는 데이터를 EFS One Zone-Infrequent Access(EFS One Zone-IA)로 이동하는 수명 
주기 관리 정책을 만듭니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102152-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
참고: 
https://aws.amazon.com/efs/features/infrequent-access/ 
Q385 
솔루션 아키텍트가 새로운 VPC 디자인을 만들고 있습니다. 로드 밸런서용 퍼블릭 서브넷 2 개, 웹 
서버용 프라이빗 서브넷 2 개, MySQL 용 프라이빗 서브넷 2 개가 있습니다. 웹 서버는 HTTPS 만 
사용합니다. 솔루션 설계자는 이미 0.0.0.0/0 에서 포트 443 을 허용하는 로드 밸런서용 보안 
그룹을 생성했습니다. 회사 정책에서는 각 리소스가 작업을 수행하는 데 필요한 최소한의 액세스 
권한을 갖도록 요구합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자가 사용해야 하는 추가 구성 전략은 무엇입니까? 
A. 웹 서버용 보안 그룹을 생성하고 0.0.0.0/0 에서 포트 443 을 허용합니다. MySQL 서버용 보안 
그룹을 만들고 웹 서버 보안 그룹에서 포트 3306 을 허용합니다. 
B. 웹 서버용 네트워크 ACL 을 생성하고 0.0.0.0/0 에서 포트 443 을 허용합니다. MySQL 서버용 
네트워크 ACL 을 생성하고 웹 서버 보안 그룹에서 포트 3306 을 허용합니다. 
C. 웹 서버용 보안 그룹을 만들고 로드 밸런서에서 포트 443 을 허용합니다. MySQL 서버용 보안 
그룹을 만들고 웹 서버 보안 그룹에서 포트 3306 을 허용합니다. 
D. 웹 서버에 대한 네트워크 ACL 을 생성하고 로드 밸런서에서 포트 443 을 허용합니다. MySQL 
서버용 네트워크 ACL 을 생성하고 웹 서버 보안 그룹에서 포트 3306 을 허용합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102153-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 답변은 Windows IIS 웹 서버와 호환되는 온-프레미스 파일 공유에 대한 탄력적이고 내구성 
있는 대체를 제공하기 때문에 정확합니다. Amazon FSx for Windows File Server 는 Windows 
Server 에 구축된 공유 파일 스토리지를 제공하는 완전관리형 서비스입니다. SMB 프로토콜을 
지원하고 Windows 기반 애플리케이션에 대한 원활한 액세스 및 인증을 가능하게 하는 Microsoft 
Active Directory 와 통합됩니다. Amazon FSx for Windows File Server 는 또한 다음과 같은 이점을 
제공합니다. 
복원력: Amazon FSx for Windows File Server 는 고가용성 및 장애 조치 보호를 제공하는 여러 가용 
영역에 배포할 수 있습니다. 또한 자동 백업 및 복원은 물론 문제를 감지하고 수정하는 자가 치유 
기능을 지원합니다. 
내구성: Windows File Server 용 Amazon FSx 는 가용 영역 내외에서 데이터를 복제하고 내구성이 
뛰어난 스토리지 장치에 데이터를 저장합니다. 또한 유휴 및 전송 중 암호화는 물론 파일 액세스 
감사 및 데이터 중복 제거를 지원합니다. 
성능: Windows File Server 용 Amazon FSx 는 파일 작업을 위한 일관된 1 밀리초 미만의 지연 
시간과 높은 처리량을 제공합니다. 또한 SSD 스토리지, 분산 파일 시스템(DFS) 네임스페이스 및 
복제와 같은 기본 Windows 기능, 사용자 중심 성능 확장을 지원합니다. 
AWS KMS CMK 를 사용하여 파일 공유의 이미지를 암호화하도록 Amazon FSx 파일 공유를 
구성함으로써 회사는 무단 액세스로부터 이미지를 보호하고 회사 정책을 준수할 수 있습니다. 
이미지에 대한 NTFS 권한 집합을 사용하여 회사는 이미지를 수정하거나 삭제할 수 있는 사람을 
제한하여 실수로 이미지를 삭제하는 것을 방지할 수 있습니다. 
Q386 
전자상거래 회사는 AWS 에서 다중 계층 애플리케이션을 실행하고 있습니다. 프런트 엔드 및 
백엔드 계층은 모두 Amazon EC2 에서 실행되고 데이터베이스는 Amazon RDS for MySQL 에서 
실행됩니다. 백엔드 계층은 RDS 인스턴스와 통신합니다. 성능 저하를 일으키는 데이터베이스에서 
동일한 데이터 세트를 반환하라는 호출이 자주 있습니다. 
백엔드의 성능을 개선하려면 어떤 조치를 취해야 합니까? 
A. Amazon SNS 를 구현하여 데이터베이스 호출을 저장합니다. 
B. Amazon ElastiCache 를 구현하여 대규모 데이터 세트를 캐싱합니다. 
C. 데이터베이스 호출을 캐시하기 위해 RDS for MySQL 읽기 전용 복제본을 구현합니다. 
D. Amazon Kinesis Data Firehose 를 구현하여 호출을 데이터베이스로 스트리밍합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102154-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
가장 좋은 솔루션은 Amazon ElastiCache 를 구현하여 대용량 데이터 세트를 캐시하는 것입니다. 
이렇게 하면 자주 액세스하는 데이터를 메모리에 저장하여 검색 시간을 단축할 수 있습니다. 이는 
데이터베이스에 대한 빈번한 호출을 완화하고 대기 시간을 줄이며 백엔드 계층의 전반적인 성능을 
향상시키는 데 도움이 될 수 있습니다. 
Q387 
신입 사원이 배포 엔지니어로 회사에 합류했습니다. 배포 엔지니어는 AWS CloudFormation 
템플릿을 사용하여 여러 AWS 리소스를 생성합니다. 솔루션 설계자는 배포 엔지니어가 최소 권한 
원칙에 따라 작업 활동을 수행하기를 원합니다. 
이 목표를 달성하기 위해 솔루션 설계자가 취해야 하는 작업 조합은 무엇입니까? (2 개 선택) 
A. 배포 엔지니어가 AWS CloudFormation 스택 작업을 수행하기 위해 AWS 계정 루트 사용자 
자격 증명을 사용하도록 합니다. 
B. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 PowerUsers IAM 정책이 연결된 그룹에 IAM 
사용자를 추가합니다. 
C. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AdministratorAccess IAM 정책이 연결된 
그룹에 IAM 사용자를 추가합니다. 
D. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AWS CloudFormation 작업만 허용하는 IAM 
정책이 있는 그룹에 IAM 사용자를 추가합니다. 
E. 배포 엔지니어를 위한 IAM 역할을 생성하여 해당 IAM 역할을 사용하여 AWS CloudFormation 
스택 및 시작 스택에 특정한 권한을 명시적으로 정의합니다. 
Answer: D, E 
https://www.examtopics.com/discussions/amazon/view/102155-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
배포 엔지니어가 CloudFormation 을 사용하여 필요한 작업을 전부 해결할 수 있으므로 관련 
작업만 허용해주면 최소 권한의 원칙이 충족됨. 
A(X) : 루트 사용자 자격 증명으로 최소 권한의 원칙에 어긋나서 제외. 
B(X) : PowerUsers 는 PowerUser 사용자 그룹의 멤버는 사용자 관리 작업(예: IAM 및 
Organizations)을 제공하는 일부 서비스를 제외한 모든 서비스에 대해 전체 권한을 갖 으므로 최소 
권한의 원칙에 어긋나서 제외 
https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/getting-started_create-delegated-us
er.html 
C(X) : 관리/액세스 권한을 굳이 줄 필요없음. CloudFormation 관련 권한만 부여하면 됨. 
D(O) : CloudFormation 작업만 허용하도록 하여 최소 권한 부여 조건 충족. 
E(O) : D 와 마찬가지 이유로 정답. 
참고: 
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html 
https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html 
Q388 
회사에서 VPC 에 2 계층 웹 애플리케이션을 배포하고 있습니다. 웹 계층은 여러 가용 영역에 걸쳐 
있는 퍼블릭 서브넷이 있는 Amazon EC2 Auto Scaling 그룹을 사용하고 있습니다. 데이터베이스 
계층은 별도의 프라이빗 서브넷에 있는 MySQL DB 인스턴스용 Amazon RDS 로 구성됩니다. 웹 
계층은 제품 정보를 검색하기 위해 데이터베이스에 액세스해야 합니다. 
웹 응용 프로그램이 의도한 대로 작동하지 않습니다. 웹 애플리케이션에서 데이터베이스에 연결할 
수 없다고 보고합니다. 데이터베이스가 가동 및 실행 중인 것으로 확인되었습니다. 네트워크 ACL, 
보안 그룹 및 라우팅 테이블에 대한 모든 구성은 여전히 기본 상태입니다. 
애플리케이션 수정을 위해 솔루션 아키텍트는 무엇을 추천해야 합니까? 
A. 프라이빗 서브넷의 네트워크 ACL 에 명시적 규칙을 추가하여 웹 티어의 EC2 인스턴스에서 
오는 트래픽을 허용합니다. 
B. 웹 계층의 EC2 인스턴스와 데이터베이스 계층 간의 트래픽을 허용하도록 VPC 경로 테이블에 
경로를 추가합니다. 
C. 웹 계층의 EC2 인스턴스와 데이터베이스 계층의 RDS 인스턴스를 두 개의 개별 VPC 에 
배포하고 VPC 피어링을 구성합니다. 
D. 데이터베이스 계층 RDS 인스턴스의 보안 그룹에 인바운드 규칙을 추가하여 웹 계층 보안 
그룹의 트래픽을 허용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102156-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 대답은 웹 계층이 보안 그룹을 소스로 사용하여 데이터베이스 계층에 액세스할 수 있도록 
허용하기 때문에 정확합니다. 이는 VPC 연결에 권장되는 모범 사례입니다. 보안 그룹은 상태 
저장이며 동일한 VPC 에 있는 다른 보안 그룹을 참조할 수 있으므로 방화벽 규칙의 구성 및 유지 
관리가 간소화됩니다. 데이터베이스 계층의 보안 그룹에 인바운드 규칙을 추가하면 웹 계층의 EC2 
인스턴스가 IP 주소나 서브넷에 관계없이 포트 3306 에서 RDS 인스턴스에 연결할 수 있습니다. 
Q389 
회사는 단일 가용 영역의 Amazon RDS for MySQL DB 인스턴스에 저장된 온라인 광고 비즈니스용 
대규모 데이터 세트를 보유하고 있습니다. 회사는 프로덕션 DB 인스턴스에 대한 쓰기 작업에 
영향을 주지 않고 비즈니스 보고 쿼리를 실행하기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. RDS 읽기 복제본을 배포하여 비즈니스 보고 쿼리를 처리합니다. 
B. DB 인스턴스를 Elastic Load Balancer 뒤에 배치하여 수평으로 확장합니다. 
C. DB 인스턴스를 더 큰 인스턴스 유형으로 확장하여 쓰기 작업 및 쿼리를 처리합니다. 
D. 비즈니스 보고 쿼리를 처리하기 위해 여러 가용 영역에 DB 인스턴스를 배포합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102157-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
읽기 전용 복제본 사용 사례 - 일반 로드를 수행하는 프로덕션 데이터베이스가 있고 일부 분석을 
실행하기 위해 보고 애플리케이션을 실행하려고 합니다. * 읽기 전용 복제본을 생성하여 그곳에서 
새 워크로드를 실행합니다. * 프로덕션 애플리케이션은 영향을 받지 않습니다. SELECT(=읽기) 
종류의 문에만 사용됨(INSERT, UPDATE, DELETE 아님) 
Q390 
회사는 Amazon EC2 인스턴스 플릿에서 3 계층 전자상거래 애플리케이션을 호스팅합니다. 
인스턴스는 Application Load Balancer(ALB) 뒤의 Auto Scaling 그룹에서 실행됩니다. 모든 
전자상거래 데이터는 MariaDB 다중 AZ DB 인스턴스용 Amazon RDS 에 저장됩니다. 
회사는 트랜잭션 중에 고객 세션 관리를 최적화하려고 합니다. 애플리케이션은 세션 데이터를 
지속적으로 저장해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) 
A. ALB 에서 고정 세션 기능(세션 선호도)을 켭니다. 
B. Amazon DynamoDB 테이블을 사용하여 고객 세션 정보를 저장합니다. 
C. Amazon Cognito 사용자 풀을 배포하여 사용자 세션 정보를 관리합니다. 
D. Amazon ElastiCache for Redis 클러스터를 배포하여 고객 세션 정보를 저장합니다. 
E. 애플리케이션에서 AWS Systems Manager Application Manager 를 사용하여 사용자 세션 정보를 
관리합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/102213-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
참고: 
https://aws.amazon.com/caching/session-management/ 
Q391 
회사는 3 계층 상태 비저장 웹 애플리케이션을 위한 백업 전략이 필요합니다. 웹 애플리케이션은 
조정 이벤트에 응답하도록 구성된 동적 조정 정책이 있는 Auto Scaling 그룹의 Amazon EC2 
인스턴스에서 실행됩니다. 데이터베이스 계층은 PostgreSQL 용 Amazon RDS 에서 실행됩니다. 웹 
애플리케이션은 EC2 인스턴스에 임시 로컬 스토리지가 필요하지 않습니다. 회사의 복구 지점 
목표(RPO)는 2 시간입니다. 
백업 전략은 확장성을 최대화하고 이 환경에 대한 리소스 활용을 최적화해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. RPO 를 충족하기 위해 2 시간마다 EC2 인스턴스 및 데이터베이스의 Amazon Elastic Block 
Store(Amazon EBS) 볼륨의 스냅샷을 생성합니다. 
B. Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성하도록 스냅샷 수명 주기 정책을 
구성합니다. RPO 를 충족하기 위해 Amazon RDS 에서 자동 백업을 활성화합니다. 
C. 웹 및 애플리케이션 계층의 최신 Amazon 머신 이미지(AMI)를 유지합니다. Amazon RDS 에서 
자동 백업을 활성화하고 지정 시간 복구를 사용하여 RPO 를 충족합니다. 
D. 2 시간마다 EC2 인스턴스의 Amazon Elastic Block Store(Amazon EBS) 볼륨의 스냅샷을 
생성합니다. Amazon RDS 에서 자동 백업을 활성화하고 지정 시간 복구를 사용하여 RPO 를 
충족합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102212-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
애플리케이션에는 인스턴스에 대한 로컬 데이터가 없으므로 AMI 만으로는 최신 AMI 백업에서 
인스턴스를 복원하여 RPO 를 충족할 수 있습니다. 데이터베이스에 대한 자동화된 RDS 백업과 
결합하면 이 환경에 대한 완벽한 백업 솔루션을 제공합니다. EBS 스냅샷과 관련된 다른 옵션은 
인스턴스의 상태 비저장 특성을 고려할 때 불필요합니다. AMI 는 앱 계층에 필요한 모든 백업을 
제공합니다. 이는 최소한의 지속적인 관리가 필요한 기본 자동 AWS 백업 기능을 사용합니다. - 
AMI 자동 백업은 상태 비저장 앱 계층에 대한 특정 시점 복구를 제공합니다. - RDS 자동 백업은 
데이터베이스에 대한 특정 시점 복구를 제공합니다. 
Q392 
회사에서 AWS 에 새로운 퍼블릭 웹 애플리케이션을 배포하려고 합니다. 애플리케이션에는 Amazon 
EC2 인스턴스를 사용하는 웹 서버 계층이 포함되어 있습니다. 이 애플리케이션에는 Amazon RDS 
for MySQL DB 인스턴스를 사용하는 데이터베이스 계층도 포함되어 있습니다. 
응용 프로그램은 동적 IP 주소가 있는 글로벌 고객이 안전하고 액세스할 수 있어야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 보안 그룹을 어떻게 구성해야 합니까? 
A. 0.0.0.0/0 에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 그룹을 
구성합니다. 웹 서버의 보안 그룹에서 포트 3306 의 인바운드 트래픽을 허용하도록 DB 인스턴스에 
대한 보안 그룹을 구성합니다. 
B. 고객의 IP 주소에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 그룹을 
구성합니다. 웹 서버의 보안 그룹에서 포트 3306 의 인바운드 트래픽을 허용하도록 DB 인스턴스에 
대한 보안 그룹을 구성합니다. 
C. 고객의 IP 주소에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 그룹을 
구성합니다. 고객의 IP 주소에서 포트 3306 의 인바운드 트래픽을 허용하도록 DB 인스턴스에 대한 
보안 그룹을 구성합니다. 
D. 0.0.0.0/0 에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 그룹을 
구성합니다. 0.0.0.0/0 에서 포트 3306 의 인바운드 트래픽을 허용하도록 DB 인스턴스에 대한 보안 
그룹을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102160-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명 1: 
A(O) : S3 에 넣으면 Lambda 를 통해 자동으로 처리가 되도록 하는 거라 OK. S3 는 저렴함. 
B(X) : dynamodb 는 이미지 저장용으론… 
C(X) : 저렴한 S3 가 있는데 굳이... 인스턴스 비용도 나감. 
D(x) : C 와 마찬가지. 
설명 2: 
웹 서버에 대한 인바운드 액세스를 HTTPS 트래픽에 사용되는 포트 443 으로만 제한하고 
애플리케이션이 공개되어 글로벌 고객이 액세스할 수 있으므로 모든 IP 주소(0.0.0.0/0)에서 
액세스를 허용합니다. 
DB 인스턴스에 대한 인바운드 액세스를 MySQL 트래픽에 사용되는 포트 3306 으로만 제한하고 웹 
서버의 보안 그룹에서만 액세스를 허용하여 두 계층 간의 보안 연결을 생성하고 데이터베이스에 
대한 무단 액세스를 방지합니다. 
아웃바운드 액세스를 두 계층에 필요한 최소 수준으로 제한합니다. 이는 질문에 지정되지 않았지만 
인바운드 규칙과 유사하다고 가정할 수 있습니다. 
Q393 
결제 처리 회사는 고객과의 모든 음성 통신을 녹음하고 오디오 파일을 Amazon S3 버킷에 
저장합니다. 회사는 오디오 파일에서 텍스트를 캡처해야 합니다. 회사는 텍스트에서 고객에게 속한 
모든 개인 식별 정보(PII)를 제거해야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. Amazon Kinesis Video Streams 를 사용하여 오디오 파일을 처리합니다. AWS Lambda 함수를 
사용하여 알려진 PII 패턴을 스캔합니다. 
B. 오디오 파일이 S3 버킷에 업로드되면 AWS Lambda 함수를 호출하여 Amazon Textract 작업을 
시작하여 통화 녹음을 분석합니다. 
C. PII 수정을 켠 상태로 Amazon Transcribe 전사 작업을 구성합니다. 오디오 파일이 S3 버킷에 
업로드되면 AWS Lambda 함수를 호출하여 전사 작업을 시작합니다. 출력을 별도의 S3 버킷에 
저장합니다. 
D. 트랜스크립션이 켜진 오디오 파일을 수집하는 Amazon Connect 고객 응대 흐름을 생성합니다. 
알려진 PII 패턴을 스캔하기 위해 AWS Lambda 함수를 포함합니다. 오디오 파일이 S3 버킷에 
업로드되면 Amazon EventBridge 를 사용하여 고객 응대 흐름을 시작하십시오. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102322-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
민감한 데이터 수정은 텍스트 스크립트와 오디오 파일의 개인 식별 가능 정보(PII)를 대체합니다. 
수정된 내용은 원본 텍스트를 [PII]로 대체하고 수정된 오디오 파일은 음성 개인 정보를 침묵으로 
대체합니다. 이 매개 변수는 고객 정보를 보호하는 데 유용합니다. 
https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-insights.html#callanalytics-insi
ghts-redaction 
Q394 
회사는 AWS 클라우드에서 다중 계층 전자 상거래 웹 애플리케이션을 실행하고 있습니다. 
애플리케이션은 Amazon RDS for MySQL 다중 AZ DB 인스턴스와 함께 Amazon EC2 인스턴스에서 
실행됩니다. Amazon RDS 는 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨에 
2,000GB 의 스토리지가 있는 최신 세대 DB 인스턴스로 구성됩니다. 데이터베이스 성능은 수요가 
많은 기간 동안 애플리케이션에 영향을 미칩니다. 
데이터베이스 관리자는 Amazon CloudWatch Logs 의 로그를 분석하고 읽기 및 쓰기 IOPS 수가 
20,000 보다 높을 때 애플리케이션 성능이 항상 저하됨을 발견합니다. 
애플리케이션 성능을 향상시키기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. 볼륨을 마그네틱 볼륨으로 교체합니다. 
B. gp3 볼륨의 IOPS 수를 늘립니다. 
C. 프로비저닝된 IOPS SSD(io2) 볼륨으로 볼륨을 교체합니다. 
D. 2,000GB gp3 볼륨을 두 개의 1,000GB gp3 볼륨으로 교체합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102161-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
D?? 
Q395 
IAM 사용자는 지난 주 프로덕션 배포 중에 회사 계정의 AWS 리소스에 대해 몇 가지 구성을 
변경했습니다. 솔루션 설계자는 몇 가지 보안 그룹 규칙이 원하는 대로 구성되지 않았음을 알게 
되었습니다. 솔루션 설계자는 어떤 IAM 사용자가 변경을 담당했는지 확인하려고 합니다. 
솔루션 설계자는 원하는 정보를 찾기 위해 어떤 서비스를 사용해야 합니까? 
A. Amazon GuardDuty 
B. 아마존 인스펙터 
C. AWS 클라우드트레일 
D. AWS 구성 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102162-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
가장 좋은 방법은 AWS CloudTrail 을 사용하여 원하는 정보를 찾는 것입니다. AWS CloudTrail 은 
AWS 계정 활동의 거버넌스, 규정 준수, 운영 감사 및 위험 감사를 지원하는 서비스입니다. 
CloudTrail 은 IAM 사용자, EC2 인스턴스, AWS 관리 콘솔 및 기타 AWS 서비스에 의한 변경 
사항을 포함하여 AWS 계정의 리소스에 대한 모든 변경 사항을 기록하는 데 사용할 수 있습니다. 
솔루션 설계자는 CloudTrail 을 사용하여 보안 그룹 규칙의 구성을 변경한 IAM 사용자를 식별할 수 
있습니다. 
Q396 
한 회사가 AWS 에서 자체 관리형 DNS 서비스를 구현했습니다. 솔루션은 다음으로 구성됩니다. 
• 다른 AWS 지역의 Amazon EC2 인스턴스 
• AWS Global Accelerator 의 표준 가속기 엔드포인트 
회사는 DDoS 공격으로부터 솔루션을 보호하려고 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Shield Advanced 에 가입하십시오. 보호할 리소스로 액셀러레이터를 추가합니다. 
B. AWS Shield Advanced 에 가입합니다. 보호할 리소스로 EC2 인스턴스를 추가합니다. 
C. 속도 기반 규칙을 포함하는 AWS WAF 웹 ACL 을 생성합니다. 웹 ACL 을 가속기와 연결합니다. 
D. 비율 기반 규칙을 포함하는 AWS WAF 웹 ACL 을 생성합니다. 웹 ACL 을 EC2 인스턴스와 
연결합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102164-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS Shield 는 AWS 에서 실행되는 애플리케이션에 대한 DDoS(Distributed Denial of Service) 
공격으로부터 보호하는 관리형 서비스입니다. AWS Shield Standard 는 추가 비용 없이 모든 AWS 
고객에게 자동으로 활성화됩니다. AWS Shield Advanced 는 선택적 유료 서비스입니다. AWS Shield 
Advanced 는 Amazon Elastic Compute Cloud(EC2), Elastic Load Balancing(ELB), Amazon 
CloudFront, AWS Global Accelerator 및 Route 53 에서 실행되는 애플리케이션에 대해 더 정교하고 
더 큰 공격에 대한 추가 보호 기능을 제공합니다. 
https://docs.aws.amazon.com/waf/latest/developerguide/ddos-event-mitigation-logic-gax.html 
Q397 
전자상거래 회사는 분석을 위해 판매 기록을 집계하고 필터링하기 위해 예약된 일일 작업을 
실행해야 합니다. 회사는 판매 기록을 Amazon S3 버킷에 저장합니다. 각 개체의 크기는 최대 
10GB 입니다. 판매 이벤트 수에 따라 작업을 완료하는 데 최대 1 시간이 걸릴 수 있습니다. 작업의 
CPU 및 메모리 사용량은 일정하며 미리 알려져 있습니다. 
솔루션 설계자는 작업을 실행하는 데 필요한 운영 노력을 최소화해야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon EventBridge 알림이 있는 AWS Lambda 함수를 생성합니다. EventBridge 이벤트가 
하루에 한 번 실행되도록 예약합니다. 
B. AWS Lambda 함수를 생성합니다. Amazon API Gateway HTTP API 를 생성하고 API 를 함수와 
통합합니다. API 를 호출하고 함수를 호출하는 Amazon EventBridge 예약 이벤트를 생성합니다. 
C. AWS Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 클러스터를 
생성합니다. 작업을 실행하기 위해 클러스터에서 ECS 작업을 시작하는 Amazon EventBridge 예약 
이벤트를 생성합니다. 
D. Amazon EC2 시작 유형이 있는 Amazon Elastic Container Service(Amazon ECS) 클러스터와 
하나 이상의 EC2 인스턴스가 있는 Auto Scaling 그룹을 생성합니다. 작업을 실행하기 위해 
클러스터에서 ECS 작업을 시작하는 Amazon EventBridge 예약 이벤트를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102165-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
최소한의 운영 오버헤드로 요구 사항을 충족하는 솔루션은 속도 기반 규칙을 사용하여 리전 AWS 
WAF 웹 ACL 을 생성하고 웹 ACL 을 API 게이트웨이 단계와 연결하는 것입니다. 이 솔루션은 
들어오는 요청을 모니터링하고 사전 정의된 속도를 초과하는 IP 주소의 요청을 차단하여 HTTP 
플러드 공격으로부터 애플리케이션을 보호합니다. API Gateway 지역 API 엔드포인트 앞에 
Lambda@Edge 가 있는 Amazon CloudFront 배포도 좋은 솔루션이지만 이전 솔루션보다 더 많은 
운영 오버헤드가 필요합니다. Amazon CloudWatch 지표를 사용하여 개수 지표를 모니터링하고 
미리 정의된 속도에 도달했을 때 보안 팀에 알리는 것은 HTTP 플러드 공격으로부터 보호할 수 
있는 솔루션이 아닙니다. 최대 TTL 이 24 시간인 API Gateway 지역 API 엔드포인트 앞에 Amazon 
CloudFront 배포를 생성하는 것은 HTTP 플러드 공격으로부터 보호할 수 있는 솔루션이 아닙니다. 
Q398 
회사는 온프레미스 NAS(Network-Attached Storage) 시스템에서 AWS 클라우드로 600TB 의 
데이터를 전송해야 합니다. 데이터 전송은 2 주 이내에 완료되어야 합니다. 데이터는 민감하며 전송 
중에 암호화되어야 합니다. 회사의 인터넷 연결은 100Mbps 의 업로드 속도를 지원할 수 있습니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Amazon S3 멀티파트 업로드 기능을 사용하여 HTTPS 를 통해 파일을 전송합니다. 
B. 온프레미스 NAS 시스템과 가장 가까운 AWS 리전 간에 VPN 연결을 생성합니다. VPN 연결을 
통해 데이터를 전송합니다. 
C. AWS Snow Family 콘솔을 사용하여 여러 AWS Snowball Edge Storage Optimized 디바이스를 
주문합니다. 디바이스를 사용하여 데이터를 Amazon S3 로 전송합니다. 
D. 회사 위치와 가장 가까운 AWS 리전 간에 10Gbps AWS Direct Connect 연결을 설정합니다. 
VPN 연결을 통해 데이터를 리전으로 전송하여 Amazon S3 에 데이터를 저장합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102166-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
가장 좋은 방법은 AWS Snow Family 콘솔을 사용하여 여러 AWS Snowball Edge Storage Optimized 
디바이스를 주문하고 디바이스를 사용하여 데이터를 Amazon S3 로 전송하는 것입니다. Snowball 
Edge 는 많은 양의 데이터를 안전하고 빠르게 전송할 수 있는 페타바이트 규모의 데이터 전송 
디바이스입니다. 
Snowball Edge 를 사용하면 장거리에서 대량의 데이터를 전송하는 가장 비용 효율적인 솔루션이 
될 수 있으며 2 주 이내에 600TB 의 데이터를 전송해야 하는 요구 사항을 충족할 수 있습니다. 
Q399 
금융 회사는 AWS 에서 웹 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon API Gateway 
지역 API 엔드포인트를 사용하여 사용자에게 현재 주가를 검색할 수 있는 기능을 제공합니다. 
회사의 보안 팀은 API 요청 수가 증가한 것을 확인했습니다. 보안 팀은 HTTP 플러드 공격이 
애플리케이션을 오프라인 상태로 만들 수 있다고 우려하고 있습니다. 
솔루션 설계자는 이러한 유형의 공격으로부터 애플리케이션을 보호하기 위한 솔루션을 설계해야 
합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 최대 TTL 이 24 시간인 API Gateway 지역 API 엔드포인트 앞에 Amazon CloudFront 배포를 
생성합니다. 
B. 속도 기반 규칙을 사용하여 리전 AWS WAF 웹 ACL 을 생성합니다. 웹 ACL 을 API Gateway 
단계와 연결합니다. 
C. Amazon CloudWatch 지표를 사용하여 개수 지표를 모니터링하고 미리 정의된 속도에 도달하면 
보안 팀에 알립니다. 
D. API Gateway 지역 API 엔드포인트 앞에 Lambda@Edge 를 사용하여 Amazon CloudFront 
배포를 생성합니다. 사전 정의된 속도를 초과하는 IP 주소의 요청을 차단하는 AWS Lambda 함수를 
생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102167-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS WAF 의 속도 기반 규칙을 사용하면 보안 팀이 속도 기반 규칙을 트리거하는 임계값을 구성할 
수 있습니다. 이를 통해 AWS WAF 는 지정된 기간 동안 요청 속도를 추적한 다음 임계값이 
초과되면 자동으로 차단할 수 있습니다. 이는 최소한의 운영 오버헤드로 HTTP 플러드 공격을 
방지하는 기능을 제공합니다. 
참조: 
https://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html 
Q400 
기상 스타트업 회사는 사용자에게 날씨 데이터를 온라인으로 판매하는 맞춤형 웹 애플리케이션을 
보유하고 있습니다. 이 회사는 Amazon DynamoDB 를 사용하여 데이터를 저장하고 새로운 날씨 
이벤트가 기록될 때마다 4 개의 내부 팀 관리자에게 경고를 보내는 새로운 서비스를 구축하려고 
합니다. 회사는 이 새로운 서비스가 현재 애플리케이션의 성능에 영향을 미치는 것을 원하지 
않습니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. DynamoDB 트랜잭션을 사용하여 새 이벤트 데이터를 테이블에 씁니다. 내부 팀에 알리도록 
트랜잭션을 구성합니다. 
B. 현재 애플리케이션이 4 개의 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 
게시하도록 합니다. 각 팀이 하나의 주제를 구독하도록 합니다. 
C. 테이블에서 Amazon DynamoDB 스트림을 활성화합니다. 트리거를 사용하여 팀이 구독할 수 
있는 단일 Amazon Simple Notification Service(Amazon SNS) 주제에 씁니다. 
D. 각 레코드에 사용자 정의 속성을 추가하여 새 항목에 플래그를 지정합니다. 새 항목이 있는지 
매분 테이블을 스캔하고 팀이 구독할 수 있는 Amazon Simple Queue Service(Amazon SQS) 
대기열에 알리는 cron 작업을 작성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102169-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 최상의 솔루션은 테이블에서 Amazon 
DynamoDB 스트림을 활성화하고 트리거를 사용하여 팀이 구독할 수 있는 단일 Amazon Simple 
Notification Service(Amazon SNS) 주제에 쓰는 것입니다. 이 솔루션에는 최소한의 구성 및 인프라 
설정이 필요하며 Amazon DynamoDB Streams 는 DynamoDB 테이블에 대한 변경 사항을 캡처하는 
지연 시간이 짧은 방법을 제공합니다. 트리거는 자동으로 변경 사항을 캡처하고 이를 내부 팀에 
알리는 SNS 주제에 게시합니다. 
Q401 
회사는 AWS 클라우드를 사용하여 기존 애플리케이션의 가용성과 탄력성을 높이려고 합니다. 
애플리케이션의 현재 버전은 회사의 데이터 센터에 상주합니다. 예기치 않은 정전으로 인해 
데이터베이스 서버가 충돌한 후 애플리케이션에서 최근 데이터 손실이 발생했습니다. 
회사는 단일 실패 지점을 방지하는 솔루션이 필요합니다. 솔루션은 애플리케이션에 사용자 요구에 
맞게 확장할 수 있는 기능을 제공해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 
서버를 배포합니다. 다중 AZ 구성에서 Amazon RDS DB 인스턴스를 사용합니다. 
B. 단일 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 
서버를 배포합니다. EC2 인스턴스에 데이터베이스를 배포합니다. EC2 자동 복구를 활성화합니다. 
C. 여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 
서버를 배포합니다. 단일 가용 영역에서 읽기 전용 복제본이 있는 Amazon RDS DB 인스턴스를 
사용합니다. 기본 DB 인스턴스가 실패할 경우 읽기 전용 복제본을 승격하여 기본 DB 인스턴스를 
교체하십시오. 
D. 여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 
서버를 배포합니다. 여러 가용 영역에 걸쳐 EC2 인스턴스에 기본 및 보조 데이터베이스 서버를 
배포합니다. Amazon Elastic Block Store(Amazon EBS) 다중 연결을 사용하여 인스턴스 간에 공유 
스토리지를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102170-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명 1: 
A(O) : Amazon RDS 다중 AZ 배포에서 Amazon RDS 는 자동으로 프라이머리 데이터베이스 DB 
인스턴스를 생성하고 동시에 다른 AZ 의 인스턴스에 데이터를 복제합니다. 장애를 감지하면 
Amazon RDS 는 수동 개입 없이 자동으로 대기 인스턴스로 장애 조치합니다. 
https://aws.amazon.com/ko/rds/features/multi-az/ 
B(X) : Auto Scaling 을 단일 가용 영역에서 사용하므로 고가용성 조건 불충족. 
C(X) : 단일 가용 영역에서 읽기 전용 복제본이 있는 DB 인스턴스를 사용한다고 했으므로 
고가용성 조건 불충족. 
D(X) : 공유 스토리지가 아니라 read replica 나 다중 AZ 가 더 합리적. 
설명 2: 
여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 서버를 
배포합니다. 다중 AZ 구성에서 Amazon RDS DB 인스턴스를 사용합니다. 단일 장애 지점을 피하고 
사용자 요구에 맞게 애플리케이션을 확장할 수 있는 기능을 제공하면서 기존 애플리케이션의 
가용성과 탄력성을 높이려면 최상의 솔루션은 Auto Scaling 그룹의 Amazon EC2 인스턴스를 
사용하여 애플리케이션 서버를 여러 그룹에 배포하는 것입니다. 가용 영역 및 다중 AZ 구성에서 
Amazon RDS DB 인스턴스를 사용합니다. 다중 AZ 구성에서 Amazon RDS DB 인스턴스를 
사용하면 데이터베이스가 여러 가용 영역에 걸쳐 자동으로 복제되므로 데이터베이스의 가용성이 
높고 단일 가용 영역의 장애를 견딜 수 있습니다. 이는 내결함성을 제공하고 단일 실패 지점을 
방지합니다. 
Q402 
회사는 애플리케이션에서 생성하는 대량의 스트리밍 데이터를 수집하고 처리해야 합니다. 이 
애플리케이션은 Amazon EC2 인스턴스에서 실행되며 기본 설정으로 구성된 Amazon Kinesis Data 
Streams 로 데이터를 전송합니다. 격일로 애플리케이션은 데이터를 소비하고 비즈니스 
인텔리전스(BI) 처리를 위해 데이터를 Amazon S3 버킷에 기록합니다. 회사는 Amazon S3 가 
애플리케이션이 Kinesis Data Streams 로 보내는 모든 데이터를 수신하지 못하는 것을 관찰합니다. 
솔루션 설계자는 이 문제를 해결하기 위해 무엇을 해야 합니까? 
A. 데이터 보존 기간을 수정하여 Kinesis Data Streams 기본 설정을 업데이트합니다. 
B. Kinesis Producer Library(KPL)를 사용하여 Kinesis Data Streams 로 데이터를 전송하도록 
애플리케이션을 업데이트합니다. 
C. Kinesis Data Streams 로 전송되는 데이터의 처리량을 처리하도록 Kinesis 샤드 수를 
업데이트합니다. 
D. S3 버킷 내에서 S3 버전 관리를 켜서 S3 버킷에 수집된 모든 객체의 모든 버전을 보존합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/102175-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Kinesis 데이터 스트림의 데이터 보존 기간은 레코드가 추가된 시점부터 더 이상 액세스할 수 없는 
시점까지의 기간입니다. Kinesis 데이터 스트림의 기본 보존 기간은 24 시간이며 최대 
8760 시간(365 일)까지 연장할 수 있습니다. 데이터 보존 기간은 AWS Management Console, AWS 
CLI 또는 Kinesis Data Streams API 를 사용하여 업데이트할 수 있습니다. 
시나리오의 요구 사항을 충족하려면 솔루션 설계자가 데이터 보존 기간을 수정하여 Kinesis Data 
Streams 기본 설정을 업데이트해야 합니다. 솔루션 설계자는 보존 기간을 데이터를 소비하고 
S3 에 쓰는 빈도보다 크거나 같은 값으로 늘려야 합니다. 이렇게 하면 회사는 애플리케이션이 
Kinesis Data Streams 로 보내는 모든 데이터를 S3 가 수신하도록 할 수 있습니다. 
Q403 
개발자에게는 AWS Lambda 함수를 사용하여 파일을 Amazon S3 에 업로드하는 애플리케이션이 
있으며 작업을 수행하는 데 필요한 권한이 필요합니다. 개발자에게는 이미 Amazon S3 에 필요한 
유효한 IAM 자격 증명이 있는 IAM 사용자가 있습니다. 
권한을 부여하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. Lambda 함수의 리소스 정책에 필요한 IAM 권한을 추가합니다. 
B. Lambda 함수에서 기존 IAM 자격 증명을 사용하여 서명된 요청을 생성합니다. 
C. 새 IAM 사용자를 생성하고 Lambda 함수에서 기존 IAM 자격 증명을 사용합니다. 
D. 필요한 권한이 있는 IAM 실행 역할을 생성하고 IAM 역할을 Lambda 함수에 연결합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102178-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon S3 에 파일을 업로드하기 위해 AWS Lambda 함수에 필요한 권한을 부여하려면 솔루션 
설계자는 필요한 권한이 있는 IAM 실행 역할을 생성하고 IAM 역할을 Lambda 함수에 연결해야 
합니다. 이 접근 방식은 최소 권한 원칙을 따르며 Lambda 함수가 특정 작업을 수행하는 데 
필요한 리소스에만 액세스할 수 있도록 합니다. 
Q404 
회사는 새 문서가 Amazon S3 버킷에 업로드될 때 AWS Lambda 함수를 호출하는 서버리스 
애플리케이션을 배포했습니다. 애플리케이션은 Lambda 함수를 사용하여 문서를 처리합니다. 최근 
마케팅 캠페인 후 회사는 애플리케이션이 많은 문서를 처리하지 않는다는 사실을 알게 되었습니다. 
솔루션 설계자는 이 애플리케이션의 아키텍처를 개선하기 위해 무엇을 해야 합니까? 
A. Lambda 함수의 런타임 제한 시간 값을 15 분으로 설정합니다. 
B. S3 버킷 복제 정책을 구성합니다. 나중에 처리할 수 있도록 S3 버킷에 문서를 준비합니다. 
C. 추가 Lambda 함수를 배포합니다. 두 Lambda 함수에서 문서 처리 부하를 분산합니다. 
D. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 대기열에 요청을 보냅니다. 
대기열을 Lambda 에 대한 이벤트 소스로 구성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102180-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 애플리케이션의 아키텍처를 개선하기 위한 최상의 솔루션은 Amazon Simple Queue 
Service(Amazon SQS)를 사용하여 요청을 버퍼링하고 Lambda 함수에서 S3 버킷을 분리하는 
것입니다. 이렇게 하면 문서가 손실되지 않고 Lambda 함수를 사용할 수 없는 경우 나중에 처리할 
수 있습니다. 이렇게 하면 문서가 손실되지 않고 Lambda 함수를 사용할 수 없는 경우 나중에 
처리할 수 있습니다. Amazon SQS 를 사용하면 아키텍처가 분리되고 Lambda 함수가 확장 
가능하고 내결함성 있는 방식으로 문서를 처리할 수 있습니다. 
Q405 
솔루션 설계자는 소프트웨어 데모 환경을 위한 아키텍처를 설계하고 있습니다. 환경은 Application 
Load Balancer(ALB) 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 
시스템은 근무 시간 동안 트래픽이 크게 증가하지만 주말에는 작동하지 않아도 됩니다. 
수요에 맞게 시스템을 확장할 수 있도록 하기 위해 솔루션 설계자는 어떤 조치 조합을 취해야 
합니까? (2 개 선택) 
A. AWS Auto Scaling 을 사용하여 요청 속도에 따라 ALB 용량을 조정하십시오. 
B. AWS Auto Scaling 을 사용하여 VPC 인터넷 게이트웨이의 용량을 확장합니다. 
C. 여러 AWS 지역에서 EC2 인스턴스를 시작하여 여러 지역에 로드를 분산합니다. 
D. 대상 추적 조정 정책을 사용하여 인스턴스 CPU 사용률을 기반으로 Auto Scaling 그룹을 
조정합니다. 
E. 예약된 조정을 사용하여 Auto Scaling 그룹의 최소, 최대 및 원하는 용량을 주말 동안 0 으로 
변경합니다. 주의 시작 시 기본값으로 되돌립니다. 
Answer: D, E 
https://www.examtopics.com/discussions/amazon/view/102181-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
https://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/as-scaling-target-tracking.html
#target-tracking-choose-metrics 
대상 추적 조정 정책은 지정된 메트릭과 대상 값을 기반으로 Auto Scaling 그룹의 용량을 조정하는 
일종의 동적 조정 정책입니다. 대상 추적 조정 정책은 Auto Scaling 그룹에서 자동으로 확장 또는 
축소하여 실제 지표 값을 대상 값 또는 그 근처에 유지할 수 있습니다. 대상 추적 조정 정책은 
근무 시간과 같이 애플리케이션에 대한 로드가 예측할 수 없이 자주 변경되는 시나리오에 
적합합니다. 
시나리오의 요구 사항을 충족하기 위해 솔루션 설계자는 대상 추적 조정 정책을 사용하여 
인스턴스 CPU 사용률에 따라 Auto Scaling 그룹을 조정해야 합니다. 인스턴스 CPU 사용률은 
애플리케이션에 대한 수요를 반영하는 일반적인 메트릭입니다. 솔루션 설계자는 애플리케이션의 
이상적인 평균 CPU 사용률 수준(예: 50%)을 나타내는 목표 값을 지정해야 합니다. 그러면 Auto 
Scaling 그룹이 해당 수준의 CPU 사용률을 유지하기 위해 확장 또는 축소됩니다. 
예약된 조정은 날짜와 시간을 기준으로 조정 작업을 수행하는 일종의 조정 정책입니다. 
예약된 조정은 주말과 같이 애플리케이션의 부하가 주기적으로 예측 가능하게 변경되는 
시나리오에 적합합니다. 
시나리오의 요구 사항을 충족하기 위해 솔루션 설계자는 예약된 조정을 사용하여 Auto Scaling 
그룹의 최소, 최대 및 원하는 용량을 주말 동안 0 으로 변경해야 합니다. 
이렇게 하면 Auto Scaling 그룹은 작동이 필요하지 않은 주말에 모든 인스턴스를 종료합니다. 
솔루션 설계자는 Auto Scaling 그룹이 정상 작동을 재개할 수 있도록 주의 시작 시 기본값으로 
되돌려야 합니다. 
Q406 
솔루션 설계자는 공용 서브넷과 데이터베이스 서브넷을 포함하는 2 계층 아키텍처를 설계하고 
있습니다. 퍼블릭 서브넷의 웹 서버는 포트 443 에서 인터넷에 열려 있어야 합니다. 데이터베이스 
서브넷의 Amazon RDS for MySQL DB 인스턴스는 포트 3306 의 웹 서버에서만 액세스할 수 있어야 
합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? (2 개 
선택) 
A. 퍼블릭 서브넷에 대한 네트워크 ACL 을 만듭니다. 포트 3306 에서 0.0.0.0/0 에 대한 아웃바운드 
트래픽을 거부하는 규칙을 추가합니다. 
B. DB 인스턴스에 대한 보안 그룹을 생성합니다. 포트 3306 에서 퍼블릭 서브넷 CIDR 블록의 
트래픽을 허용하는 규칙을 추가합니다. 
C. 퍼블릭 서브넷의 웹 서버에 대한 보안 그룹을 생성합니다. 포트 443 에서 0.0.0.0/0 의 트래픽을 
허용하는 규칙을 추가합니다. 
D. DB 인스턴스에 대한 보안 그룹을 생성합니다. 포트 3306 에서 웹 서버 보안 그룹의 트래픽을 
허용하는 규칙을 추가합니다. 
E. DB 인스턴스에 대한 보안 그룹을 생성합니다. 포트 3306 에서 웹 서버 보안 그룹의 트래픽을 
제외한 모든 트래픽을 거부하는 규칙을 추가합니다. 
Answer: C, D 
https://www.examtopics.com/discussions/amazon/view/102183-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q407 
회사는 AWS 클라우드에서 호스팅되는 게임 애플리케이션용 공유 스토리지 솔루션을 구현하고 
있습니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 필요합니다. 
솔루션은 완전히 관리되어야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 탑재 가능한 파일 시스템으로 데이터를 공유하는 AWS DataSync 작업을 생성합니다. 파일 
시스템을 애플리케이션 서버에 마운트하십시오. 
B. AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하는 
파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다. 
C. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만들고 Lustre 를 지원하도록 
구성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 
연결하십시오. 
D. Amazon FSx for Lustre 파일 시스템을 생성합니다. 원본 서버에 파일 시스템을 연결합니다. 
애플리케이션 서버를 파일 시스템에 연결하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102184-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q408 
한 회사에서 UDP 를 사용하는 수천 개의 지리적으로 분산된 원격 장치로부터 데이터를 수신하는 
애플리케이션을 실행합니다. 애플리케이션은 데이터를 즉시 처리하고 필요한 경우 장치로 다시 
메시지를 보냅니다. 데이터가 저장되지 않습니다. 
회사는 장치에서 데이터 전송에 대한 대기 시간을 최소화하는 솔루션이 필요합니다. 솔루션은 또한 
다른 AWS 리전에 대한 빠른 장애 조치를 제공해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Route 53 장애 조치 라우팅 정책을 구성합니다. 두 리전 각각에 NLB(Network Load 
Balancer)를 생성합니다. 데이터를 처리하기 위해 AWS Lambda 함수를 호출하도록 NLB 를 
구성합니다. 
B. AWS Global Accelerator 를 사용합니다. 두 리전 각각에 NLB(Network Load Balancer)를 
엔드포인트로 생성합니다. Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 
클러스터를 생성합니다. 클러스터에서 ECS 서비스를 생성합니다. Amazon ECS 에서 데이터를 
NLProcess 하기 위한 대상으로 ECS 서비스를 설정합니다. 
C. AWS Global Accelerator 를 사용합니다. 두 리전 각각에 Application Load Balancer(ALB)를 
엔드포인트로 생성합니다. Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 
클러스터를 생성합니다. 클러스터에서 ECS 서비스를 생성합니다. ECS 서비스를 ALB 의 대상으로 
설정합니다. Amazon ECS 에서 데이터를 처리합니다. 
D. Amazon Route 53 장애 조치 라우팅 정책을 구성합니다. 두 리전 각각에 Application Load 
Balancer(ALB)를 생성합니다. Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon 
ECS) 클러스터를 생성합니다. 클러스터에서 ECS 서비스를 생성합니다. ECS 서비스를 ALB 의 
대상으로 설정합니다. Amazon ECS 에서 데이터를 처리합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102185-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
장치에서 데이터를 전송하는 지연 시간을 최소화하고 다른 AWS 영역으로 신속하게 페일오버해야 
하는 요구 사항을 충족하기 위해 가장 좋은 솔루션은 네트워크 로드 밸런서(NLB) 및 Amazon 
Elastic Container Service(Amazon ECS)와 함께 AWS Global Accelerator 를 사용하는 것입니다. 
AWS Global Accelerator 는 정적 IP 주소(Anycast)를 사용하여 트래픽을 최적의 AWS 끝점으로 
라우팅하여 애플리케이션의 가용성과 성능을 향상시키는 서비스입니다. Global Accelerator 를 
사용하면 트래픽을 여러 지역 및 끝점으로 유도하고 다른 AWS 지역으로 자동 페일오버를 제공할 
수 있습니다. 
Q409 
솔루션 설계자는 Windows 인터넷 정보 서비스(IIS) 웹 애플리케이션을 AWS 로 마이그레이션해야 
합니다. 애플리케이션은 현재 사용자의 온프레미스 NAS(Network-Attached Storage)에서 
호스팅되는 파일 공유에 의존합니다. 솔루션 설계자는 IIS 웹 서버를 스토리지 솔루션에 연결된 
여러 가용 영역의 Amazon EC2 인스턴스로 마이그레이션하고 인스턴스에 연결된 Elastic Load 
Balancer 를 구성할 것을 제안했습니다. 
온프레미스 파일 공유에 대한 어떤 대체가 가장 탄력적이고 내구성이 있습니까? 
A. 파일 공유를 Amazon RDS 로 마이그레이션합니다. 
B. 파일 공유를 AWS Storage Gateway 로 마이그레이션합니다. 
C. 파일 공유를 Amazon FSx for Windows File Server 로 마이그레이션합니다. 
D. 파일 공유를 Amazon Elastic File System(Amazon EFS)으로 마이그레이션합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102186-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 대답은 Windows IIS 웹 서버와 호환되는 온-프레미스 파일 공유에 대한 탄력적이고 내구성 
있는 대체를 제공하기 때문에 정확합니다. Amazon FSx for Windows File Server 는 Windows 
Server 에 구축된 공유 파일 스토리지를 제공하는 완전 관리형 서비스입니다. SMB 프로토콜을 
지원하고 Windows 기반 애플리케이션에 대한 원활한 액세스 및 인증을 가능하게 하는 Microsoft 
Active Directory 와 통합됩니다. Amazon FSx for Windows File Server 는 또한 다음과 같은 이점을 
제공합니다. 
복원력: Amazon FSx for Windows File Server 는 고가용성 및 장애 조치 보호를 제공하는 여러 가용 
영역에 배포할 수 있습니다. 또한 자동 백업 및 복원은 물론 문제를 감지하고 수정하는 자가 치유 
기능도 지원합니다. 
내구성: Windows File Server 용 Amazon FSx 는 가용 영역 내외에서 데이터를 복제하고 내구성이 
뛰어난 스토리지 장치에 데이터를 저장합니다. 또한 유휴 및 전송 중 암호화는 물론 파일 액세스 
감사 및 데이터 중복 제거를 지원합니다. 
성능: Windows File Server 용 Amazon FSx 는 파일 작업을 위한 일관된 1 밀리초 미만의 지연 
시간과 높은 처리량을 제공합니다. 또한 SSD 스토리지, 분산 파일 시스템(DFS) 네임스페이스 및 
복제와 같은 기본 Windows 기능, 사용자 중심 성능 확장을 지원합니다. 
Q410 
회사에서 Amazon EC2 인스턴스에 새 애플리케이션을 배포하고 있습니다. 애플리케이션은 
Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 씁니다. 회사는 EBS 볼륨에 기록된 
모든 데이터가 유휴 상태에서 암호화되도록 해야 합니다. 
이 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. EBS 암호화를 지정하는 IAM 역할을 생성합니다. 역할을 EC2 인스턴스에 연결합니다. 
B. EBS 볼륨을 암호화된 볼륨으로 생성합니다. EBS 볼륨을 EC2 인스턴스에 연결합니다. 
C. 키가 Encrypt 이고 값이 True 인 EC2 인스턴스 태그를 생성합니다. EBS 수준에서 암호화가 
필요한 모든 인스턴스에 태그를 지정합니다. 
D. 계정에서 EBS 암호화를 시행하는 AWS Key Management Service(AWS KMS) 키 정책을 
생성합니다. 키 정책이 활성 상태인지 확인하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102187-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
EBS 볼륨에 기록되는 모든 데이터가 유휴 상태에서 암호화되도록 보장하는 요구 사항을 충족하는 
솔루션은 B 입니다. EBS 볼륨을 암호화된 볼륨으로 생성하고 암호화된 EBS 볼륨을 EC2 
인스턴스에 연결합니다. EBS 볼륨을 생성할 때 볼륨 암호화 여부를 지정할 수 있습니다. 볼륨을 
암호화하도록 선택한 경우 볼륨에 기록된 모든 데이터는 AWS 관리형 키를 사용하여 유휴 
상태에서 자동으로 암호화됩니다. 또한 AWS KMS 에 저장된 고객 관리형 키(CMK)를 사용하여 EBS 
볼륨을 암호화하고 보호할 수 있습니다. 암호화된 EBS 볼륨을 생성하고 EC2 인스턴스에 연결하여 
볼륨에 기록된 모든 데이터가 유휴 상태에서 암호화되도록 할 수 있습니다. 
Q411 
회사에 산발적인 사용 패턴을 가진 웹 애플리케이션이 있습니다. 매달 초에는 사용량이 많고, 매주 
초에는 보통 사용량이 있으며, 주중에는 예측할 수 없는 사용량이 있습니다. 이 애플리케이션은 웹 
서버와 데이터 센터 내에서 실행되는 MySQL 데이터베이스 서버로 구성됩니다. 이 회사는 
애플리케이션을 AWS 클라우드로 이동하려고 하며 데이터베이스 수정이 필요하지 않은 비용 
효율적인 데이터베이스 플랫폼을 선택해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon DynamoDB 
B. MySQL 용 Amazon RDS 
C. MySQL 호환 Amazon Aurora Serverless 
D. Auto Scaling 그룹의 Amazon EC2 에 배포된 MySQL 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/102188-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon RDS for MySQL 은 클라우드에서 MySQL 배포를 쉽게 설정, 운영 및 확장할 수 있는 
완전관리형 관계형 데이터베이스 서비스입니다. Amazon Aurora Serverless 는 Amazon 
Aurora(MySQL 호환 버전)에 대한 온디맨드 자동 확장 구성으로, 데이터베이스가 애플리케이션의 
요구 사항에 따라 자동으로 시작, 종료 및 용량 확장 또는 축소됩니다. 
간헐적이거나 예측할 수 없는 워크로드를 위한 간단하고 비용 효율적인 옵션입니다. 
Q412 
이미지 호스팅 회사는 객체를 Amazon S3 버킷에 저장합니다. 회사는 S3 버킷의 개체가 대중에게 
우발적으로 노출되는 것을 방지하려고 합니다. 전체 AWS 계정의 모든 S3 객체는 비공개로 
유지되어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon GuardDuty 를 사용하여 S3 버킷 정책을 모니터링합니다. AWS Lambda 함수를 사용하여 
객체를 공개하는 변경 사항을 수정하는 자동 수정 작업 규칙을 생성합니다. 
B. AWS Trusted Advisor 를 사용하여 공개적으로 액세스 가능한 S3 버킷을 찾습니다. 변경 사항이 
감지되면 Trusted Advisor 에서 이메일 알림을 구성합니다. 퍼블릭 액세스를 허용하는 경우 S3 버킷 
정책을 수동으로 변경합니다. 
C. AWS Resource Access Manager 를 사용하여 공개적으로 액세스 가능한 S3 버킷을 찾습니다. 
변경이 감지되면 Amazon Simple Notification Service(Amazon SNS)를 사용하여 AWS Lambda 
함수를 호출합니다. 프로그래밍 방식으로 변경 사항을 수정하는 Lambda 함수를 배포합니다. 
D. 계정 수준에서 S3 퍼블릭 액세스 차단 기능을 사용합니다. AWS Organizations 를 사용하여 IAM 
사용자가 설정을 변경하지 못하도록 하는 서비스 제어 정책(SCP)을 생성합니다. 계정에 SCP 를 
적용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/102189-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
S3 퍼블릭 액세스 차단 기능을 사용하면 계정 내의 S3 버킷 및 객체에 대한 퍼블릭 액세스를 
제한할 수 있습니다. 버킷 정책 설정에 관계없이 계정 수준에서 이 기능을 활성화하여 S3 버킷이 
공개되지 않도록 할 수 있습니다. AWS Organizations 를 사용하여 IAM 사용자가 이 설정을 
변경하지 못하도록 SCP(서비스 제어 정책)를 계정에 적용하여 모든 S3 객체가 비공개로 
유지되도록 할 수 있습니다. 이는 최소한의 운영 오버헤드가 필요한 간단하고 효과적인 
솔루션입니다. 
Q413 
한 전자상거래 회사에서 사용자 트래픽이 증가하고 있습니다. 회사의 스토어는 웹 계층과 별도의 
데이터베이스 계층으로 구성된 2 계층 웹 애플리케이션으로 Amazon EC2 인스턴스에 배포됩니다. 
트래픽이 증가함에 따라 회사는 아키텍처로 인해 사용자에게 적시에 마케팅 및 주문 확인 
이메일을 보내는 데 상당한 지연이 발생하고 있음을 알게 되었습니다. 이 회사는 복잡한 이메일 
전송 문제를 해결하는 데 소요되는 시간을 줄이고 운영 오버헤드를 최소화하기를 원합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 만듭니다. 
B. Amazon Simple Email Service(Amazon SES)를 통해 이메일을 보내도록 웹 인스턴스를 
구성합니다. 
C. Amazon Simple Notification Service(Amazon SNS)를 통해 이메일을 보내도록 웹 인스턴스를 
구성합니다. 
D. 이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 생성합니다. Auto 
Scaling 그룹에 인스턴스를 배치합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/102190-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon SES 는 기업이 자체 이메일 주소와 도메인을 사용하여 이메일을 보내고 받을 수 있도록 
하는 비용 효율적이고 확장 가능한 이메일 서비스입니다. Amazon SES 를 통해 이메일을 보내도록 
웹 인스턴스를 구성하는 것은 복잡한 이메일 전송 문제를 해결하는 데 소요되는 시간을 줄이고 
운영 오버헤드를 최소화할 수 있는 간단하고 효과적인 솔루션입니다. 
Q414 
회사에는 매일 수백 개의 보고서를 생성하는 비즈니스 시스템이 있습니다. 비즈니스 시스템은 
보고서를 CSV 형식으로 네트워크 공유에 저장합니다. 회사는 분석을 위해 이 데이터를 거의 
실시간으로 AWS 클라우드에 저장해야 합니다. 
최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS DataSync 를 사용하여 파일을 Amazon S3 로 전송합니다. 매일 끝날 때 실행되는 예약된 
작업을 만듭니다. 
B. Amazon S3 파일 게이트웨이를 생성합니다. S3 파일 게이트웨이에서 새 네트워크 공유를 
사용하도록 비즈니스 시스템을 업데이트합니다. 
C. AWS DataSync 를 사용하여 파일을 Amazon S3 로 전송합니다. 자동화 워크플로에서 DataSync 
API 를 사용하는 애플리케이션을 생성합니다. 
D. SFTP 용 AWS 전송 엔드포인트를 배포합니다. 네트워크 공유에서 새 파일을 확인하고 SFTP 를 
사용하여 새 파일을 업로드하는 스크립트를 만듭니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/103452-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q415 
회사에서 Amazon S3 Standard 에 페타바이트 규모의 데이터를 저장하고 있습니다. 데이터는 여러 
S3 버킷에 저장되며 다양한 빈도로 액세스됩니다. 회사는 모든 데이터에 대한 액세스 패턴을 알지 
못합니다. 회사는 S3 사용 비용을 최적화하기 위해 각 S3 버킷에 대한 솔루션을 구현해야 합니다. 
이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? 
A. S3 버킷의 객체를 S3 Intelligent-Tiering 으로 전환하는 규칙으로 S3 수명 주기 구성을 
생성합니다. 
B. S3 스토리지 클래스 분석 도구를 사용하여 S3 버킷의 각 객체에 대한 올바른 계층을 
결정합니다. 각 개체를 식별된 스토리지 계층으로 이동합니다. 
C. S3 버킷의 객체를 S3 Glacier Instant Retrieval 로 전환하는 규칙으로 S3 수명 주기 구성을 
생성합니다. 
D. S3 버킷의 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하는 규칙으로 S3 
수명 주기 구성을 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/103404-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q416 
빠르게 성장하는 글로벌 전자상거래 회사는 AWS 에서 웹 애플리케이션을 호스팅하고 있습니다. 웹 
애플리케이션에는 정적 콘텐츠와 동적 콘텐츠가 포함됩니다. 웹사이트는 Amazon RDS 
데이터베이스에 OLTP(온라인 거래 처리) 데이터를 저장합니다. 웹사이트 사용자의 페이지 로드 
속도가 느립니다. 
이 문제를 해결하기 위해 솔루션 아키텍트가 취해야 할 조치 조합은 무엇입니까? (2 개 선택) 
A. Amazon Redshift 클러스터를 구성합니다. 
B. Amazon CloudFront 배포를 설정합니다. 
C. Amazon S3 에서 동적 웹 콘텐츠를 호스팅합니다. 
D. RDS DB 인스턴스에 대한 읽기 전용 복제본을 생성합니다. 
E. RDS DB 인스턴스에 대한 다중 AZ 배포를 구성합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/103423-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS 에서 호스팅되는 빠르게 성장하는 전자 상거래 웹 사이트의 느린 페이지 로드 문제를 
해결하기 위해 솔루션 설계자는 다음 두 가지 조치를 취할 수 있습니다. 
1. Amazon CloudFront 배포 설정 
2. RDS DB 인스턴스에 대한 읽기 전용 복제본 생성 
Amazon Redshift 클러스터 구성은 Redshift 가 데이터 웨어하우징 서비스이고 일반적으로 대량 
데이터의 분석 처리에 사용되기 때문에 이 문제와 관련이 없습니다. 
S3 는 웹 애플리케이션 서버가 아니라 객체 스토리지 서비스이기 때문에 Amazon S3 에서 동적 웹 
콘텐츠를 호스팅해도 성능이 반드시 향상되는 것은 아닙니다. S3 는 정적 웹 콘텐츠를 호스팅하는 
데 사용할 수 있지만 S3 는 서버 측 스크립팅 또는 처리를 지원하지 않기 때문에 동적 웹 콘텐츠를 
호스팅하는 데 적합하지 않을 수 있습니다. 
RDS DB 인스턴스에 대해 다중 AZ 배포를 구성하면 고가용성이 향상되지만 반드시 성능이 
향상되는 것은 아닙니다. 
Q417 
회사는 Amazon EC2 인스턴스와 AWS Lambda 함수를 사용하여 애플리케이션을 실행합니다. 
회사의 AWS 계정에는 퍼블릭 서브넷과 프라이빗 서브넷이 있는 VPC 가 있습니다. EC2 인스턴스는 
VPC 중 하나의 프라이빗 서브넷에서 실행됩니다. 애플리케이션이 작동하려면 Lambda 함수가 
EC2 인스턴스에 대한 직접 네트워크 액세스가 필요합니다. 
신청서는 최소 1 년 동안 실행됩니다. 회사는 해당 기간 동안 애플리케이션이 사용하는 Lambda 
함수 수가 증가할 것으로 예상합니다. 회사는 모든 애플리케이션 리소스에 대한 절감 효과를 
극대화하고 서비스 간의 네트워크 대기 시간을 낮게 유지하기를 원합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. EC2 Instance Savings Plan 을 구매하세요. Lambda 함수의 기간과 메모리 사용량, 호출 수를 
최적화합니다. EC2 인스턴스가 포함된 프라이빗 서브넷에 Lambda 함수를 연결합니다. 
B. EC2 인스턴스 Savings Plan 을 구매하세요. Lambda 함수의 기간과 메모리 사용량, 호출 수, 
전송되는 데이터 양을 최적화합니다. EC2 인스턴스가 실행되는 동일한 VPC 의 퍼블릭 서브넷에 
Lambda 함수를 연결합니다. 
C. Compute Savings Plan 을 구매하세요. Lambda 함수의 기간과 메모리 사용량, 호출 수, 전송되는 
데이터 양을 최적화합니다. EC2 인스턴스가 포함된 프라이빗 서브넷에 Lambda 함수를 
연결합니다. 
D. Compute Savings Plan 을 구매하세요. Lambda 함수의 기간과 메모리 사용량, 호출 수, 전송되는 
데이터 양을 최적화합니다. Lambda 서비스 VPC 에 Lambda 함수를 유지합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/103598-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Compute Savings Plan 을 구매함으로써 회사는 EC2 인스턴스와 Lambda 기능을 모두 실행하는 
비용을 절약할 수 있습니다. Lambda 함수는 AWS 서비스용 VPC 엔드포인트 또는 VPC 피어링 
연결을 통해 EC2 인스턴스가 포함된 프라이빗 서브넷에 연결할 수 있습니다. 
이렇게 하면 사설 네트워크 내에서 트래픽을 유지하면서 EC2 인스턴스에 대한 직접 네트워크 
액세스를 제공하여 네트워크 대기 시간을 최소화하는 데 도움이 됩니다. Lambda 함수의 지속 시간, 
메모리 사용량, 호출 수 및 전송된 데이터 양을 최적화하면 비용을 추가로 최소화하고 성능을 
개선하는 데 도움이 될 수 있습니다. 또한 프라이빗 서브넷을 사용하면 보안 모범 사례인 퍼블릭 
인터넷에서 EC2 인스턴스에 직접 액세스할 수 없도록 하는 데 도움이 됩니다. 
Q418 
솔루션 아키텍트는 팀 구성원이 두 개의 다른 AWS 계정(개발 계정 및 프로덕션 계정)에서 
Amazon S3 버킷에 액세스할 수 있도록 허용해야 합니다. 팀은 현재 계정에서 적절한 권한이 있는 
IAM 그룹에 할당된 고유한 IAM 사용자를 사용하여 개발 계정의 S3 버킷에 액세스할 수 있습니다. 
솔루션 설계자는 프로덕션 계정에서 IAM 역할을 생성했습니다. 이 역할에는 프로덕션 계정의 S3 
버킷에 대한 액세스 권한을 부여하는 정책이 있습니다. 
최소 권한 원칙을 준수하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 관리자 액세스 정책을 개발 계정 사용자에게 연결합니다. 
B. 생산 계정에 있는 역할의 신뢰 정책에서 개발 계정을 주체로 추가합니다. 
C. 프로덕션 계정의 S3 버킷에서 S3 퍼블릭 액세스 차단 기능을 끕니다. 
D. 각 팀 구성원에 대해 고유한 자격 증명을 사용하여 프로덕션 계정에 사용자를 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/103585-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q419 
회사는 모든 기능이 활성화된 AWS Organizations 를 사용하고 ap-southeast-2 리전에서 여러 
Amazon EC2 워크로드를 실행합니다. 회사에는 다른 리전에서 리소스가 생성되지 않도록 하는 
SCP(서비스 제어 정책)가 있습니다. 보안 정책에 따라 회사는 유휴 상태의 모든 데이터를 
암호화해야 합니다. 
감사 결과 직원이 볼륨을 암호화하지 않고 EC2 인스턴스용 Amazon Elastic Block Store(Amazon 
EBS) 볼륨을 생성한 것으로 확인되었습니다. 회사는 암호화된 EBS 볼륨을 사용하기 위해 모든 
IAM 사용자 또는 루트 사용자가 ap-southeast-2 에서 시작하는 모든 새 EC2 인스턴스를 원합니다. 
회사는 EBS 볼륨을 생성하는 직원에게 최소한의 영향을 미치는 솔루션을 원합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. Amazon EC2 콘솔에서 EBS 암호화 계정 속성을 선택하고 기본 암호화 키를 정의합니다. 
B. IAM 권한 경계를 생성합니다. 권한 경계를 루트 조직 단위(OU)에 연결합니다. ec2:Encrypted 
조건이 false 인 경우 ec2:CreateVolume 작업을 거부하도록 경계를 정의합니다. 
C. SCP 를 생성합니다. 루트 조직 단위(OU)에 SCP 를 연결합니다. ec2:Encrypted 조건이 false 인 
경우 ec2:CreateVolume 작업을 거부하도록 SCP 를 정의합니다. 
D. ec2:Encrypted 조건이 false 인 경우 ec2:CreateVolume 작업을 거부하도록 각 계정에 대한 IAM 
정책을 업데이트합니다. 
E. 조직 관리 계정에서 기본 EBS 볼륨 암호화 설정을 지정합니다. 
Answer: C, E 
https://www.examtopics.com/discussions/amazon/view/109268-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
서비스 제어 정책(SCP)은 조직에서 권한을 관리하는 데 사용할 수 있는 정책 유형입니다. SCP 는 
조직의 모든 계정에 대해 사용 가능한 최대 권한에 대한 중앙 제어를 제공하므로 계정이 조직의 
액세스 제어 지침을 준수하도록 할 수 있습니다. 
ec2:Encrypted 조건이 false 일 때 SCP 를 사용하여 ec2:CreateVolume 작업을 거부할 수 있습니다. 
즉, 루트 OU 아래 계정의 모든 사용자 또는 역할은 암호화되지 않은 EBS 볼륨을 생성할 수 
없습니다. 이 솔루션은 필요에 따라 암호화된 볼륨을 계속 생성할 수 있으므로 EBS 볼륨을 
생성하는 직원에게 최소한의 영향을 미칩니다. 
참조: 
https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html 
Q420 
회사에서 Amazon RDS for PostgreSQL DB 클러스터를 사용하여 프로덕션 데이터베이스 
워크로드에 대한 시간 소모적인 데이터베이스 관리 작업을 단순화하려고 합니다. 회사는 
데이터베이스의 고가용성을 보장하고 대부분의 시나리오에서 40 초 이내에 자동 장애 조치 지원을 
제공할 것입니다. 회사는 기본 인스턴스에서 읽기를 오프로드하고 비용을 가능한 한 낮게 
유지하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon RDS 다중 AZ DB 인스턴스 배포를 사용합니다. 하나의 읽기 복제본을 만들고 읽기 
워크로드를 읽기 복제본으로 지정합니다. 
B. Amazon RDS 다중 AZ DB 더스터 배포 사용 2 개의 읽기 전용 복제본을 생성하고 읽기 
워크로드를 읽기 전용 복제본으로 지정합니다. 
C. Amazon RDS 다중 AZ DB 인스턴스 배포를 사용합니다. 읽기 워크로드가 다중 AZ 쌍의 보조 
인스턴스를 가리키도록 합니다. 
D. Amazon RDS 다중 AZ DB 클러스터 배포 사용 읽기 워크로드를 리더 엔드포인트로 지정합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109269-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q421 
회사에서 고가용성 SFTP 서비스를 실행합니다. SFTP 서비스는 탄력적 IP 주소로 실행되는 두 개의 
Amazon EC2 Linux 인스턴스를 사용하여 인터넷에서 신뢰할 수 있는 IP 소스의 트래픽을 
허용합니다. SFTP 서비스는 인스턴스에 연결된 공유 스토리지에서 지원합니다. 사용자 계정은 
SFTP 서버에서 Linux 사용자로 생성되고 관리됩니다. 
회사는 높은 IOPS 성능과 고도로 구성 가능한 보안을 제공하는 서버리스 옵션을 원합니다. 회사는 
또한 사용자 권한에 대한 제어를 유지하기를 원합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 신뢰할 수 있는 IP 
주소만 허용하는 퍼블릭 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. EBS 
볼륨을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 
부여합니다. 
B. 암호화된 Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. 탄력적 IP 주소와 
인터넷 연결 액세스가 있는 VPC 엔드포인트를 사용하여 AWS Transfer Family SFTP 서비스를 
생성합니다. 신뢰할 수 있는 IP 주소만 허용하는 엔드포인트에 보안 그룹을 연결합니다. EFS 
볼륨을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 
부여합니다. 
C. 기본 암호화가 활성화된 Amazon S3 버킷을 생성합니다. 신뢰할 수 있는 IP 주소만 허용하는 
퍼블릭 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. S3 버킷을 SFTP 서비스 
엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 부여합니다. 
D. 기본 암호화가 활성화된 Amazon S3 버킷을 생성합니다. 프라이빗 서브넷에서 내부 액세스 
권한이 있는 VPC 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. 신뢰할 수 있는 
IP 주소만 허용하는 보안 그룹을 연결합니다. S3 버킷을 SFTP 서비스 엔드포인트에 연결합니다. 
사용자에게 SFTP 서비스에 대한 액세스 권한을 부여합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109270-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q422 
한 회사가 AWS 에서 새로운 기계 학습(ML) 모델 솔루션을 개발하고 있습니다. 모델은 시작 시 
Amazon S3 에서 약 1GB 의 모델 데이터를 가져와 메모리에 로드하는 독립적인 마이크로서비스로 
개발됩니다. 사용자는 비동기 API 를 통해 모델에 액세스합니다. 사용자는 요청 또는 요청 배치를 
보내고 결과를 보낼 위치를 지정할 수 있습니다. 
회사는 수백 명의 사용자에게 모델을 제공합니다. 모델의 사용 패턴이 불규칙합니다. 일부 모델은 
며칠 또는 몇 주 동안 사용하지 않을 수 있습니다. 다른 모델은 한 번에 수천 개의 요청 배치를 
수신할 수 있습니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 디자인을 권장해야 합니까? 
A. API 의 요청을 Network Load Balancer(NLB)로 보냅니다. NLB 에서 호출하는 AWS Lambda 
함수로 모델을 배포합니다. 
B. API 의 요청을 Application Load Balancer(ALB)로 보냅니다. Amazon Simple Queue 
Service(Amazon SQS) 대기열에서 읽는 Amazon Elastic Container Service(Amazon ECS) 서비스로 
모델을 배포합니다. AWS App Mesh 를 사용하여 SQS 대기열 크기에 따라 ECS 클러스터의 
인스턴스를 확장합니다. 
C. API 의 요청을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. SQS 이벤트에 
의해 호출되는 AWS Lambda 함수로 모델을 배포합니다. AWS Auto Scaling 을 사용하여 SQS 
대기열 크기에 따라 Lambda 함수의 vCPU 수를 늘립니다. 
D. API 의 요청을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. 대기열에서 
읽는 Amazon Elastic Container Service(Amazon ECS) 서비스로 모델을 배포합니다. 대기열 크기에 
따라 서비스의 클러스터와 복사본 모두에 대해 Amazon ECS 에서 AWS Auto Scaling 을 
활성화합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109280-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 대답은 불규칙하고 예측할 수 없는 사용 패턴을 처리할 수 있는 독립적인 마이크로 서비스로 
ML 모델을 실행하기 위한 요구 사항을 충족하기 때문에 정확합니다. API 의 요청을 Amazon SQS 
대기열로 보내면 회사는 모델 실행에서 요청 처리를 분리하고 수요 급증으로 인해 요청이 
손실되지 않도록 할 수 있습니다. 대기열에서 읽는 Amazon ECS 서비스로 모델을 배포함으로써 
회사는 컨테이너를 활용하여 각 모델을 마이크로 서비스로 격리 및 패키징하고 시작 시 S3 에서 
모델 데이터를 가져올 수 있습니다. 대기열 크기에 따라 서비스의 클러스터와 복사본 모두에 대해 
Amazon ECS 에서 AWS Auto Scaling 을 활성화함으로써 회사는 클러스터의 EC2 인스턴스 수와 각 
서비스의 작업 수를 성능을 요구하고 최적화합니다. 
참조: 
https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.ht
ml 
https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-ecs.html 
Q423 
솔루션 설계자는 다음 JSON 텍스트를 자격 증명 기반 정책으로 사용하여 특정 권한을 부여하려고 
합니다. 
솔루션 설계자가 이 정책을 연결할 수 있는 IAM 보안 주체는 무엇입니까? (2 개 선택) 
A. 역할(Role) 
B. 그룹(Group) 
C. 조직(Organization) 
D. Amazon Elastic Container Service(Amazon ECS) 리소스(resource) 
E. Amazon EC2 리소스(resource) 
Answer: A, B 
https://www.examtopics.com/discussions/amazon/view/109281-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q424 
회사는 Amazon EC2 온디맨드 인스턴스에서 사용자 지정 애플리케이션을 실행하고 있습니다. 
애플리케이션에는 하루 24 시간, 주 7 일 실행해야 하는 프런트엔드 노드와 워크로드에 따라 짧은 
시간 동안만 실행해야 하는 백엔드 노드가 있습니다. 백엔드 노드의 수는 하루 동안 다양합니다. 
회사는 워크로드에 따라 더 많은 인스턴스를 확장 및 확장해야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 프런트엔드 노드에는 예약 인스턴스를 사용합니다. 백엔드 노드에 AWS Fargate 를 사용합니다. 
B. 프런트엔드 노드에 예약 인스턴스를 사용합니다. 백엔드 노드에 스팟 인스턴스를 사용합니다. 
C. 프런트엔드 노드에 스팟 인스턴스를 사용합니다. 백엔드 노드에 예약 인스턴스를 사용합니다. 
D. 프런트엔드 노드에 스팟 인스턴스를 사용합니다. 백엔드 노드에 AWS Fargate 를 사용합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109283-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q425 
회사는 높은 블록 스토리지 용량을 사용하여 온프레미스에서 워크로드를 실행합니다. 회사의 일일 
최대 입력 및 초당 출력 트랜잭션은 15,000 IOPS 를 넘지 않습니다. 이 회사는 워크로드를 
Amazon EC2 로 마이그레이션하고 스토리지 용량과 독립적으로 디스크 성능을 프로비저닝하려고 
합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 Amazon Elastic Block Store(Amazon EBS) 
볼륨 유형은 무엇입니까? 
A. GP2 볼륨 유형 
B. io2 볼륨 유형 
C. GP3 볼륨 유형 
D. io1 볼륨 유형 
Answer: C  
https://www.examtopics.com/discussions/amazon/view/109282-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 답변은 기존 데이터를 AWS 로 안전하게 마이그레이션하는 요구 사항을 충족하고 새로운 규정을 
충족하기 때문에 정답입니다. AWS DataSync 는 온프레미스 스토리지와 Amazon S3 간에 대량의 
데이터를 온라인으로 쉽게 이동할 수 있게 해주는 서비스입니다. DataSync 는 전송 중인 데이터를 
자동으로 암호화하고 전송 중에 데이터 무결성을 확인합니다. AWS CloudTrail 은 계정에 대한 AWS 
API 호출을 기록하고 로그 파일을 Amazon S3 에 전달하는 서비스입니다. CloudTrail 은 S3 객체 
수준 API 활동과 같이 AWS 계정의 리소스에서 또는 리소스 내에서 수행된 리소스 작업을 
보여주는 데이터 이벤트를 기록할 수 있습니다. CloudTrail 을 사용하여 데이터 이벤트를 기록하면 
저장된 데이터의 모든 수준에서 액세스를 감사할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html 
https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-withcloudtrail
.html 
Q426 
회사는 의료 애플리케이션의 데이터를 저장해야 합니다. 애플리케이션의 데이터는 자주 변경됩니다. 
새로운 규정은 저장된 데이터의 모든 수준에서 감사 액세스를 요구합니다. 
회사는 스토리지 용량이 부족한 온프레미스 인프라에서 애플리케이션을 호스팅합니다. 솔루션 
설계자는 새로운 규정을 만족하면서 기존 데이터를 AWS 로 안전하게 마이그레이션해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS DataSync 를 사용하여 기존 데이터를 Amazon S3 로 이동합니다. AWS CloudTrail 을 
사용하여 데이터 이벤트를 기록합니다. 
B. AWS Snowcone 을 사용하여 기존 데이터를 Amazon S3 로 이동합니다. AWS CloudTrail 을 
사용하여 관리 이벤트를 기록합니다. 
C. Amazon S3 Transfer Acceleration 을 사용하여 기존 데이터를 Amazon S3 로 이동합니다. AWS 
CloudTrail 을 사용하여 데이터 이벤트를 기록합니다. 
D. AWS Storage Gateway 를 사용하여 기존 데이터를 Amazon S3 로 이동합니다. AWS CloudTrail 을 
사용하여 관리 이벤트를 기록합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109278-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
D?? 
Q427 
솔루션 아키텍트가 MySQL 데이터베이스로 복잡한 Java 애플리케이션을 구현하고 있습니다. Java 
애플리케이션은 Apache Tomcat 에 배포되어야 하며 고가용성이어야 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. AWS Lambda 에 애플리케이션을 배포합니다. Lambda 함수와 연결하도록 Amazon API Gateway 
API 를 구성합니다. 
B. AWS Elastic Beanstalk 를 사용하여 애플리케이션을 배포합니다. 부하 분산 환경 및 롤링 배포 
정책을 구성합니다. 
C. 데이터베이스를 Amazon ElastiCache 로 마이그레이션합니다. 애플리케이션에서 액세스를 
허용하도록 ElastiCache 보안 그룹을 구성합니다. 
D. Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스에 MySQL 서버를 설치합니다. 서버에서 
애플리케이션을 구성합니다. AMI 를 생성합니다. AMI 를 사용하여 Auto Scaling 그룹으로 시작 
템플릿을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109279-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
AWS Elastic Beanstalk 는 애플리케이션을 쉽고 빠르게 배포, 관리 및 확장할 수 있는 방법을 
제공합니다. Java 및 Apache Tomcat 을 포함한 다양한 플랫폼을 지원합니다. 솔루션 설계자는 
Elastic Beanstalk 를 사용하여 Java 애플리케이션을 업로드하고 Apache Tomcat 을 실행하도록 
환경을 구성할 수 있습니다. 
Q428 
서버리스 애플리케이션은 Amazon API Gateway, AWS Lambda 및 Amazon DynamoDB 를 
사용합니다. Lambda 함수에는 DynamoDB 테이블을 읽고 쓸 수 있는 권한이 필요합니다. 
DynamoDB 테이블에 대한 Lambda 함수 액세스를 가장 안전하게 제공하는 솔루션은 무엇입니까? 
A. Lambda 함수에 프로그래밍 방식으로 액세스할 수 있는 IAM 사용자를 생성합니다. DynamoDB 
테이블에 대한 읽기 및 쓰기 액세스를 허용하는 정책을 사용자에게 연결합니다. access_key_id 및 
secret_access_key 파라미터를 Lambda 환경 변수의 일부로 저장합니다. 다른 AWS 사용자에게 
Lambda 함수 구성에 대한 읽기 및 쓰기 액세스 권한이 없는지 확인하십시오. 
B. Lambda 를 신뢰할 수 있는 서비스로 포함하는 IAM 역할을 생성합니다. DynamoDB 테이블에 
대한 읽기 및 쓰기 액세스를 허용하는 역할에 정책을 연결합니다. 새 역할을 실행 역할로 
사용하도록 Lambda 함수의 구성을 업데이트합니다. 
C. Lambda 함수에 프로그래밍 방식으로 액세스할 수 있는 IAM 사용자를 생성합니다. DynamoDB 
테이블에 대한 읽기 및 쓰기 액세스를 허용하는 정책을 사용자에게 연결합니다. AWS Systems 
Manager Parameter Store 에 access_key_id 및 secret_access_key 파라미터를 보안 문자열 
파라미터로 저장합니다. DynamoDB 테이블에 연결하기 전에 보안 문자열 파라미터를 검색하도록 
Lambda 함수 코드를 업데이트합니다. 
D. DynamoDB 를 신뢰할 수 있는 서비스로 포함하는 IAM 역할을 생성합니다. Lambda 함수에서 
읽기 및 쓰기 액세스를 허용하는 역할에 정책을 연결합니다. 새 역할에 실행 역할로 연결되도록 
Lambda 함수의 코드를 업데이트합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109285-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
옵션 B 는 Lambda 를 신뢰할 수 있는 서비스로 포함하는 IAM 역할을 생성할 것을 제안합니다. 즉, 
이 역할은 Lambda 함수용으로 특별히 설계되었습니다. 역할에는 DynamoDB 테이블에 대한 필수 
읽기 및 쓰기 액세스 권한을 부여하는 정책이 연결되어 있어야 합니다. 
Q429 
다음 IAM 정책은 IAM 그룹에 연결됩니다. 이것은 그룹에 적용되는 유일한 정책입니다. 
그룹 구성원에 대한 이 정책의 유효 IAM 권한은 무엇입니까? 
A. 그룹 구성원은 us-east-1 지역 내 모든 Amazon EC2 작업이 허용됩니다. 허용 권한 이후의 
문은 적용되지 않습니다. 
B. 그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인하지 않는 한 us-east-1 리전에서 모든 
Amazon EC2 권한이 거부됩니다. 
C. 그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인할 때 모든 리전에 대한 ec2:StopInstances 및 
ec2:TerminateInstances 권한이 허용됩니다. 그룹 구성원은 다른 모든 Amazon EC2 작업이 
허용됩니다. 
D. 그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인한 경우에만 us-east-1 리전에 대한 
ec2:StopInstances 및 ec2:TerminateInstances 권한이 허용됩니다. 그룹 구성원은 us-east-1 
리전 내에서 다른 모든 Amazon EC2 작업이 허용됩니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109286-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 답변은 그룹 구성원에 대한 IAM 정책의 영향을 반영하기 때문에 정확합니다. 정책에는 두 개의 
문이 있습니다. 하나는 허용 효과가 있고 다른 하나는 거부 효과가 있습니다. Allow 문은 
us-east-1 지역 내의 모든 리소스에 대해 EC2 작업을 수행할 수 있는 권한을 부여합니다. Deny 
문은 Allow 문을 재정의하고 그룹 구성원이 MFA 로 로그인하지 않는 한 us-east-1 리전 내의 
모든 리소스에 대해 ec2:StopInstances 및 ec2:TerminateInstances 작업을 수행할 수 있는 권한을 
거부합니다. 따라서 그룹 구성원은 모든 작업을 수행할 수 있습니다. MFA 를 사용하지 않는 한 
us-east-1 리전에서 인스턴스 중지 또는 종료를 제외한 EC2 작업. 
Q430 
제조 회사에는 Amazon S3 버킷에 .csv 파일을 업로드하는 기계 센서가 있습니다. 이러한 .csv 
파일은 이미지로 변환되어야 하며 그래픽 보고서의 자동 생성을 위해 가능한 한 빨리 사용할 수 
있어야 합니다. 
이미지는 1 개월이 지나면 관련이 없게 되지만 1 년에 두 번 기계 학습(ML) 모델을 훈련시키기 
위해 .csv 파일을 보관해야 합니다. ML 교육 및 감사는 몇 주 전에 미리 계획됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (2 개 선택) 
A. 매시간 .csv 파일을 다운로드하고 이미지 파일을 생성하며 이미지를 S3 버킷에 업로드하는 
Amazon EC2 스팟 인스턴스를 시작합니다. 
B. .csv 파일을 이미지로 변환하고 이미지를 S3 버킷에 저장하는 AWS Lambda 함수를 
설계합니다. .csv 파일이 업로드되면 Lambda 함수를 호출합니다. 
C. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성합니다. .csv 파일을 
업로드하고 1 일 후에 S3 Standard 에서 S3 Glacier 로 전환합니다. 30 일 후에 이미지 파일을 
만료하십시오. 
D. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성합니다. 업로드 1 일 
후 .csv 파일을 S3 Standard 에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 
30 일 후에 이미지 파일을 만료하십시오. 
E. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성합니다. .csv 파일을 
업로드하고 1 일 후에 S3 Standard 에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 
전환합니다. RRS(Reduced Redundancy Storage)에 이미지 파일을 보관합니다. 
Answer: B, C 
https://www.examtopics.com/discussions/amazon/view/109288-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이러한 답변은 .csv 파일을 이미지로 변환하고 가능한 한 빨리 사용 가능하게 하며 스토리지 
비용을 최소화하기 위한 요구 사항을 충족하므로 정확합니다. AWS Lambda 는 서버를 
프로비저닝하거나 관리하지 않고 코드를 실행할 수 있는 서비스입니다. AWS Lambda 를 
사용하여 .csv 파일을 이미지로 변환하고 이미지를 S3 버킷에 저장하는 함수를 설계할 수 
있습니다. 
S3 이벤트 알림을 사용하여 .csv 파일이 S3 버킷에 업로드될 때 Lambda 함수를 호출할 수 
있습니다. 이렇게 하면 이미지가 생성되어 그래픽 보고서에 가능한 한 빨리 사용할 수 있습니다. 
S3 수명 주기는 개체가 수명 주기 동안 비용 효율적으로 저장되도록 개체를 관리할 수 있게 
해주는 기능입니다. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성하여 
비즈니스 요구 사항에 따라 다른 스토리지 클래스로 전환하거나 만료할 수 있습니다. .csv 파일은 
몇 주 전에 계획된 ML 교육 및 감사에 1 년에 두 번만 필요하므로 업로드한 지 1 일 후에 S3 
Standard 에서 S3 Glacier 로 전환할 수 있습니다. S3 Glacier 는 검색 시간이 몇 분에서 몇 시간에 
이르는 안전하고 내구성이 있으며 매우 저렴한 스토리지를 제공하는 데이터 아카이빙용 스토리지 
클래스입니다. 
이미지 파일은 1 개월이 지나면 관련성이 없어지므로 30 일 후에 만료될 수 있습니다. 
참조: 
https://docs.aws.amazon.com/lambda/latest/dg/welcome.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html#sc-glacier 
Q431 
회사에서 웹 애플리케이션으로 새로운 비디오 게임을 개발했습니다. 애플리케이션은 데이터베이스 
계층에 MySQL 용 Amazon RDS 가 있는 VPC 의 3 계층 아키텍처에 있습니다. 여러 플레이어가 
온라인에서 동시에 경쟁합니다. 게임 개발자는 거의 실시간으로 상위 10 개 점수판을 표시하고 
현재 점수를 유지하면서 게임을 중지하고 복원할 수 있는 기능을 제공하고자 합니다. 
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 웹 애플리케이션이 표시할 점수를 캐시하도록 Memcached 클러스터용 Amazon ElastiCache 를 
설정합니다. 
B. Redis 클러스터용 Amazon ElastiCache 를 설정하여 웹 애플리케이션이 표시할 점수를 계산하고 
캐시합니다. 
C. 웹 애플리케이션 앞에 Amazon CloudFront 배포를 배치하여 애플리케이션 섹션의 점수판을 
캐시합니다. 
D. MySQL 용 Amazon RDS 에서 읽기 전용 복제본을 생성하여 스코어보드를 계산하고 웹 
애플리케이션에 읽기 트래픽을 제공하는 쿼리를 실행합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109274-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 답변은 거의 실시간으로 상위 10 개 점수판을 표시하고 현재 점수를 유지하면서 게임을 
중지하고 복원할 수 있는 기능을 제공하는 요구 사항을 충족하므로 정확합니다. Redis 용 Amazon 
ElastiCache 는 인터넷 규모의 실시간 애플리케이션을 지원하기 위해 1 밀리초 미만의 지연 시간을 
제공하는 초고속 인 메모리 데이터 스토어입니다. Redis 용 Amazon ElastiCache 를 사용하여 
Redis 용 ElastiCache 클러스터를 설정하여 웹 애플리케이션이 표시할 점수를 계산하고 캐시할 수 
있습니다. 정렬된 세트 및 해시와 같은 Redis 데이터 구조를 사용하여 플레이어의 점수를 
저장하고 순위를 매길 수 있으며 ZRANGE 및 ZADD 와 같은 Redis 명령을 사용하여 점수를 
효율적으로 검색 및 업데이트할 수 있습니다. 또한 스냅샷 및 추가 전용 파일(AOF)과 같은 Redis 
지속성 기능을 사용하여 데이터의 특정 시점 복구를 활성화할 수 있으므로 현재 점수를 
유지하면서 게임을 중지하고 복원할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.html 
https://redis.io/topics/data-types 
https://redis.io/topics/persistence 
Q432 
한 전자상거래 회사에서 기계 학습(ML) 알고리즘을 사용하여 모델을 구축하고 훈련하려고 합니다. 
회사는 모델을 사용하여 복잡한 시나리오를 시각화하고 고객 데이터의 추세를 감지합니다. 
아키텍처 팀은 ML 모델을 보고 플랫폼과 통합하여 증강 데이터를 분석하고 비즈니스 인텔리전스 
대시보드에서 직접 데이터를 사용하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Glue 를 사용하여 ML 변환을 생성하여 모델을 구축하고 교육합니다. Amazon OpenSearch 
Service 를 사용하여 데이터를 시각화합니다. 
B. Amazon SageMaker 를 사용하여 모델을 구축하고 교육합니다. Amazon QuickSight 를 사용하여 
데이터를 시각화합니다. 
C. AWS Marketplace 에서 사전 구축된 ML Amazon 머신 이미지(AMI)를 사용하여 모델을 구축하고 
교육합니다. Amazon OpenSearch Service 를 사용하여 데이터를 시각화합니다. 
D. Amazon QuickSight 를 사용하여 계산된 필드를 사용하여 모델을 구축하고 교육합니다. Amazon 
QuickSight 를 사용하여 데이터를 시각화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109291-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q433 
한 회사가 여러 AWS 계정에서 프로덕션 및 비프로덕션 환경 워크로드를 실행하고 있습니다. 
계정은 AWS Organizations 의 조직에 있습니다. 회사는 비용 사용 태그의 수정을 방지하는 
솔루션을 설계해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 권한이 부여된 보안 주체 외에는 태그 수정을 방지하기 위해 사용자 지정 AWS Config 규칙을 
생성합니다. 
B. 태그 수정을 방지하기 위해 AWS CloudTrail 에서 사용자 지정 추적을 생성합니다. 
C. 인증된 주체 외에는 태그 수정을 방지하기 위해 서비스 제어 정책(SCP)을 생성합니다. 
D. 태그 수정을 방지하기 위해 사용자 지정 Amazon CloudWatch 로그를 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109384-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q434 
회사는 AWS 클라우드에서 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon DynamoDB 
테이블과 함께 Auto Scaling 그룹의 Elastic Load Balancer 뒤에 있는 Amazon EC2 인스턴스에서 
실행됩니다. 회사는 다운타임을 최소화하면서 다른 AWS 리전에서 애플리케이션을 사용할 수 
있기를 원합니다. 
가동 중지 시간을 최소화하면서 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 
합니까? 
A. 재해 복구 지역에 Auto Scaling 그룹과 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 
테이블로 구성합니다. 새 재해 복구 리전의 로드 밸런서를 가리키도록 DNS 장애 조치를 
구성합니다. 
B. 필요할 때 시작할 EC2 인스턴스, 로드 밸런서 및 DynamoDB 테이블을 생성하기 위해 AWS 
CloudFormation 템플릿을 생성합니다. 새 재해 복구 리전의 로드 밸런서를 가리키도록 DNS 장애 
조치를 구성합니다. 
C. AWS CloudFormation 템플릿을 생성하여 EC2 인스턴스와 필요할 때 실행할 로드 밸런서를 
생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 새 재해 복구 리전의 로드 밸런서를 
가리키도록 DNS 장애 조치를 구성합니다. 
D. 재해 복구 지역에서 Auto Scaling 그룹 및 로드 밸런서를 생성합니다. DynamoDB 테이블을 
전역 테이블로 구성합니다. 재해 복구 로드 밸런서를 가리키는 Amazon Route 53 을 업데이트하는 
AWS Lambda 함수를 트리거하는 Amazon CloudWatch 경보를 생성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109294-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 답변은 기존 데이터를 AWS 로 안전하게 마이그레이션하는 요구 사항을 충족하고 새로운 규정을 
충족하기 때문에 정답입니다. AWS DataSync 는 온프레미스 스토리지와 Amazon S3 간에 대량의 
데이터를 온라인으로 쉽게 이동할 수 있게 해주는 서비스입니다. DataSync 는 전송 중인 데이터를 
자동으로 암호화하고 전송 중에 데이터 무결성을 확인합니다. AWS CloudTrail 은 계정에 대한 AWS 
API 호출을 기록하고 로그 파일을 Amazon S3 에 전달하는 서비스입니다. CloudTrail 은 S3 객체 
수준 API 활동과 같이 AWS 계정의 리소스에서 또는 리소스 내에서 수행된 리소스 작업을 
보여주는 데이터 이벤트를 기록할 수 있습니다. CloudTrail 을 사용하여 데이터 이벤트를 기록하면 
저장된 데이터의 모든 수준에서 액세스를 감사할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html 
https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-withcloudtrail
.html 
Q435 
회사는 2 주 이내에 온프레미스 데이터 센터에서 AWS 로 MySQL 데이터베이스를 마이그레이션해야 
합니다. 데이터베이스 크기는 20TB 입니다. 회사는 다운타임을 최소화하면서 마이그레이션을 
완료하기를 원합니다. 
데이터베이스를 가장 비용 효율적으로 마이그레이션하는 솔루션은 무엇입니까? 
A. AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. AWS Schema Conversion 
Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 사용하여 진행 중인 변경 
사항을 복제하여 데이터베이스를 마이그레이션합니다. Snowball Edge 디바이스를 AWS 로 보내 
마이그레이션을 완료하고 진행 중인 복제를 계속합니다. 
B. AWS Snowmobile 차량을 주문합니다. AWS Schema Conversion Tool(AWS SCT)과 함께 AWS 
Database Migration Service(AWS DMS)를 사용하여 지속적인 변경 사항이 있는 데이터베이스를 
마이그레이션합니다. Snowmobile 차량을 다시 AWS 로 보내 마이그레이션을 완료하고 진행 중인 
복제를 계속합니다. 
C. GPU 장치로 AWS Snowball Edge Compute Optimized 를 주문합니다. AWS Schema Conversion 
Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 사용하여 지속적인 변경 
사항이 있는 데이터베이스를 마이그레이션합니다. Snowball 디바이스를 AWS 로 보내 
마이그레이션을 완료하고 진행 중인 복제를 계속합니다. 
D. 1GB 전용 AWS Direct Connect 연결을 주문하여 데이터 센터와의 연결을 설정합니다. AWS 
Schema Conversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 
사용하여 진행 중인 변경 사항을 복제하여 데이터베이스를 마이그레이션합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109377-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이 대답은 가동 중지 시간을 최소화하고 비용 효율적으로 2 주 이내에 20TB MySQL 
데이터베이스를 마이그레이션해야 하는 요구 사항을 충족하기 때문에 정답입니다. AWS Snowball 
Edge Storage Optimized 디바이스에는 최대 80TB 의 사용 가능한 스토리지 공간이 있으며 이는 
데이터베이스에 적합합니다. AWS Database Migration Service(AWS DMS)는 소스에서 대상으로 
변경 사항을 지속적으로 복제하여 다운타임을 최소화하면서 MySQL 에서 Amazon Aurora, Amazon 
RDS for MySQL 또는 Amazon EC2 의 MySQL 로 데이터를 마이그레이션할 수 있습니다. AWS 
Schema Conversion Tool(AWS SCT)은 소스 스키마와 코드를 대상 데이터베이스와 호환되는 
형식으로 변환할 수 있습니다. 이러한 서비스를 함께 사용함으로써 회사는 가동 중지 시간과 
비용을 최소화하면서 데이터베이스를 AWS 로 마이그레이션할 수 있습니다. 
Snowball Edge 디바이스를 다시 AWS 로 배송하여 마이그레이션을 완료하고 데이터베이스가 
완전히 마이그레이션될 때까지 지속적인 복제를 계속할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/snowball/latest/developer-guide/device-differences.html 
https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.MySQL.html 
https://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/CHAP_Source.MySQL.ht
m 
Q436 
회사에서 온프레미스 PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스로 
옮겼습니다. 회사는 신제품을 성공적으로 출시했습니다. 데이터베이스의 워크로드가 증가했습니다. 
회사는 인프라를 추가하지 않고 더 큰 워크로드를 수용하려고 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 전체 워크로드에 대해 예약된 DB 인스턴스를 구매합니다. PostgreSQL DB 인스턴스용 Amazon 
RDS 를 더 크게 만듭니다. 
B. Amazon RDS for PostgreSQL DB 인스턴스를 다중 AZ DB 인스턴스로 만듭니다. 
C. GPU 장치로 AWS Snowball Edge Compute Optimized 를 주문합니다. AWS Schema Conversion 
Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 사용하여 지속적인 변경 
사항이 있는 데이터베이스를 마이그레이션합니다. Snowball 디바이스를 AWS 로 보내 
마이그레이션을 완료하고 진행 중인 복제를 계속합니다. 
D. Amazon RDS for PostgreSQL DB 인스턴스를 온디맨드 DB 인스턴스로 만듭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109277-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 대답은 인프라를 추가하지 않고 비용을 최소화하지 않고 더 큰 워크로드를 수용하는 요구 
사항을 충족하기 때문에 맞습니다. 예약 DB 인스턴스는 계정에서 특정 온디맨드 DB 인스턴스 
사용에 적용되는 청구 할인입니다. 예약 DB 인스턴스는 온디맨드 DB 인스턴스 요금에 비해 
상당한 할인을 제공합니다. 총 워크로드에 대해 예약된 DB 인스턴스를 구입하고 선결제 없음, 
부분 선결제 또는 전체 선결제의 세 가지 결제 옵션 중에서 선택할 수 있습니다. 인스턴스 유형을 
더 높은 성능 클래스로 수정하여 Amazon RDS for PostgreSQL DB 인스턴스를 더 크게 만들 수 
있습니다. 이렇게 하면 DB 인스턴스의 CPU, 메모리 및 네트워크 용량을 늘리고 늘어난 
워크로드를 처리할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithReservedDBInst
ances.html 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html 
Q437 
회사는 Auto Scaling 그룹의 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 
인스턴스에서 전자상거래 웹 사이트를 운영합니다. 사이트에서 IP 주소가 변경되는 불법 외부 
시스템의 높은 요청 비율과 관련된 성능 문제가 발생하고 있습니다. 보안 팀은 웹 사이트에 대한 
잠재적인 DDoS 공격에 대해 걱정하고 있습니다. 회사는 합법적인 사용자에게 최소한의 영향을 
미치는 방식으로 불법적으로 들어오는 요청을 차단해야 합니다. 
솔루션 설계자는 무엇을 추천해야 합니까? 
A. Amazon Inspector 를 배포하고 ALB 와 연결합니다. 
B. AWS WAF 를 배포하고 ALB 와 연결하고 속도 제한 규칙을 구성합니다. 
C. 들어오는 트래픽을 차단하기 위해 ALB 와 연결된 네트워크 ACL 에 규칙을 배포합니다. 
D. Amazon GuardDuty 를 배포하고 GuardDuty 를 구성할 때 속도 제한 보호를 활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109378-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 답변은 합법적인 사용자에게 최소한의 영향을 미치는 방식으로 불법적으로 들어오는 요청을 
차단하는 요구 사항을 충족하기 때문에 정확합니다. AWS WAF 는 가용성에 영향을 미치거나 보안을 
손상시키거나 과도한 리소스를 소비할 수 있는 일반적인 웹 익스플로잇으로부터 웹 애플리케이션 
또는 API 를 보호하는 데 도움이 되는 웹 애플리케이션 방화벽입니다. AWS WAF 는 SQL 삽입 또는 
사이트 간 스크립팅과 같은 일반적인 공격 패턴을 차단하는 보안 규칙과 정의한 특정 트래픽 
패턴을 필터링하는 규칙을 생성할 수 있도록 하여 트래픽이 애플리케이션에 도달하는 방식을 
제어할 수 있습니다. AWS WAF 를 ALB 와 연결하여 악의적인 요청으로부터 웹 애플리케이션을 
보호할 수 있습니다. 각 발신 IP 주소에 대한 요청 속도를 추적하고 5 분 이내에 특정 제한을 
초과하는 IP 주소의 요청을 차단하도록 AWS WAF 에서 속도 제한 규칙을 구성할 수 있습니다. 
이렇게 하면 잠재적인 DDoS 공격을 완화하고 웹 사이트의 성능을 향상시킬 수 있습니다. 
참조: 
https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html 
https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-type-rate-based.
html 
Q438 
회사에서 외부 감사인과 회계 데이터를 공유하려고 합니다. 데이터는 프라이빗 서브넷에 상주하는 
Amazon RDS DB 인스턴스에 저장됩니다. 감사자는 자체 AWS 계정이 있으며 자체 데이터베이스 
사본이 필요합니다. 
회사가 감사자와 데이터베이스를 공유하는 가장 안전한 방법은 무엇입니까? 
A. 데이터베이스의 읽기 전용 복제본을 생성합니다. 감사자 액세스 권한을 부여하도록 IAM 표준 
데이터베이스 인증을 구성합니다. 
B. 데이터베이스 내용을 텍스트 파일로 내보냅니다. 파일을 Amazon S3 버킷에 저장합니다. 
감사자를 위한 새 IAM 사용자를 생성합니다. 사용자에게 S3 버킷에 대한 액세스 권한을 
부여합니다. 
C. 데이터베이스의 스냅샷을 Amazon S3 버킷에 복사합니다. IAM 사용자를 생성합니다. 사용자의 
키를 감사자와 공유하여 S3 버킷의 객체에 대한 액세스 권한을 부여합니다. 
D. 데이터베이스의 암호화된 스냅샷을 생성합니다. 감사자와 스냅샷을 공유합니다. AWS Key 
Management Service(AWS KMS) 암호화 키에 대한 액세스를 허용합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109398-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 대답은 안전한 방식으로 감사자와 데이터베이스를 공유하는 요구 사항을 충족하기 때문에 
정확합니다. AWS Key Management Service(AWS KMS)를 사용하여 데이터베이스의 암호화된 
스냅샷을 생성하여 고객 관리형 키로 스냅샷을 암호화할 수 있습니다. 스냅샷의 권한을 수정하고 
감사자의 AWS 계정 ID 를 지정하여 감사자와 스냅샷을 공유할 수 있습니다. 감사자의 계정에 
권한을 부여하는 키 정책 설명을 추가하여 AWS KMS 암호화 키에 대한 액세스를 허용할 수도 
있습니다. 이렇게 하면 감사자만 자신의 AWS 계정에서 스냅샷에 액세스하고 복원할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ShareSnapshot.html 
https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-defaulta
llow-root-enable-iam 
Q439 
솔루션 설계자는 IP 주소 범위가 작은 VPC 를 구성했습니다. VPC 에 있는 Amazon EC2 인스턴스의 
수가 증가하고 있으며 향후 워크로드를 위한 IP 주소의 수가 부족합니다. 
최소한의 운영 오버헤드로 이 문제를 해결하는 솔루션은 무엇입니까? 
A. 추가 IPv4 CIDR 블록을 추가하여 IP 주소 수를 늘리고 VPC 에 추가 서브넷을 만듭니다. 새 
CIDR 을 사용하여 새 서브넷에 새 리소스를 만듭니다. 
B. 추가 서브넷이 있는 두 번째 VPC 를 생성합니다. 피어링 연결을 사용하여 두 번째 VPC 를 첫 
번째 VPC 와 연결 경로를 업데이트하고 두 번째 VPC 의 서브넷에서 새 리소스를 생성합니다. 
C. AWS Transit Gateway 를 사용하여 transit gateway 를 추가하고 첫 번째 VPUpdate 에 두 번째 
VPC 를 연결하여 transit gateway 및 VPC 의 경로를 업데이트합니다. 두 번째 VPC 의 서브넷에 새 
리소스를 만듭니다. 
D. 두 번째 VPC 를 생성합니다. Amazon EC2 및 가상 프라이빗 게이트웨이에서 VPN 호스팅 
솔루션을 사용하여 첫 번째 VPC 와 두 번째 VPC 간에 사이트 간 VPN 연결을 생성합니다. VPC 간 
경로를 VPN 을 통한 트래픽으로 업데이트합니다. 두 번째 VPC 의 서브넷에 새 리소스를 만듭니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109400-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q440 
한 회사에서 애플리케이션 테스트 중에 Amazon RDS for MySQL DB 인스턴스를 사용했습니다. 
테스트 주기가 끝날 때 DB 인스턴스를 종료하기 전에 솔루션 설계자는 두 개의 백업을 
생성했습니다. 솔루션 설계자는 데이터베이스 덤프를 생성하기 위해 mysqldump 유틸리티를 
사용하여 첫 번째 백업을 생성했습니다. 솔루션 설계자는 RDS 종료 시 최종 DB 스냅샷 옵션을 
활성화하여 두 번째 백업을 생성했습니다. 
회사는 이제 새로운 테스트 주기를 계획하고 있으며 가장 최근 백업에서 새 DB 인스턴스를 
생성하려고 합니다. 이 회사는 DB 인스턴스를 호스팅하기 위해 Amazon Aurora 의 MySQL 호환 
에디션을 선택했습니다. 
어떤 솔루션이 새 DB 인스턴스를 생성합니까? (2 개 선택) 
A. RDS 스냅샷을 Aurora 로 직접 가져옵니다. 
B. RDS 스냅샷을 Amazon S3 에 업로드합니다. 그런 다음 RDS 스냅샷을 Aurora 로 가져옵니다. 
C. 데이터베이스 덤프를 Amazon S3 에 업로드합니다. 그런 다음 데이터베이스 덤프를 Aurora 로 
가져옵니다. 
D. AWS Database Migration Service(AWS DMS)를 사용하여 RDS 스냅샷을 Aurora 로 가져옵니다. 
E. 데이터베이스 덤프를 Amazon S3 에 업로드합니다. 그런 다음 AWS Database Migration 
Service(AWS DMS)를 사용하여 데이터베이스 덤프를 Aurora 로 가져옵니다. 
Answer: A, C 
https://www.examtopics.com/discussions/amazon/view/109297-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이러한 답변은 최신 백업에서 새 DB 인스턴스를 생성하고 Amazon Aurora 의 MySQL 호환 
에디션을 사용하여 DB 인스턴스를 호스팅해야 하는 요구 사항을 충족하기 때문에 정확합니다. 
MySQL DB 인스턴스와 Aurora DB 클러스터가 동일한 버전의 MySQL 을 실행 중인 경우 RDS 
스냅샷을 Aurora 로 직접 가져올 수 있습니다. 예를 들어 MySQL 버전 5.6 스냅샷을 Aurora MySQL 
버전 5.6 으로 직접 복원할 수 있지만 MySQL 버전 5.6 스냅샷을 Aurora MySQL 버전 5.7 로 직접 
복원할 수는 없습니다. 이 방법은 간단하고 가장 적은 수의 단계가 필요합니다. MySQL DB 
인스턴스와 Aurora DB 클러스터가 다른 버전의 MySQL 을 실행 중인 경우 데이터베이스 덤프를 
Amazon S3 에 업로드한 다음 Aurora 로 데이터베이스 덤프를 가져올 수 있습니다. 예를 들어 
MySQL 버전 5.6 데이터베이스 덤프를 Aurora MySQL 버전 5.7 로 가져올 수 있지만 MySQL 버전 
5.6 스냅샷을 Aurora MySQL 버전 5.7 로 직접 복원할 수는 없습니다. 
이 방법은 더 유연하며 다른 버전의 MySQL 간에 마이그레이션할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Migrating.RDS
MySQL.Import.html 
https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Migrating.RDS
MySQL.Dump.html 
Q441 
회사는 Application Load Balancer 뒤의 Amazon Linux Amazon EC2 인스턴스에서 다중 계층 웹 
애플리케이션을 호스팅합니다. 인스턴스는 여러 가용 영역의 Auto Scaling 그룹에서 실행됩니다. 
이 회사는 애플리케이션의 최종 사용자가 대량의 정적 웹 콘텐츠에 액세스할 때 Auto Scaling 
그룹이 더 많은 온디맨드 인스턴스를 시작하는 것을 관찰합니다. 회사는 비용을 최적화하려고 
합니다. 
애플리케이션을 가장 비용 효율적으로 재설계하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. 온디맨드 인스턴스 대신 예약 인스턴스를 사용하도록 Auto Scaling 그룹을 업데이트합니다. 
B. 온디맨드 인스턴스 대신 스팟 인스턴스를 시작하여 조정하도록 Auto Scaling 그룹을 
업데이트합니다. 
C. Amazon S3 버킷에서 정적 웹 콘텐츠를 호스팅할 Amazon CloudFront 배포를 만듭니다. 
D. Amazon API Gateway API 뒤에 AWS Lambda 함수를 생성하여 정적 웹 사이트 콘텐츠를 
호스팅합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109423-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 대답은 비용을 최적화하고 데이터베이스의 작업 부하를 줄이는 요구 사항을 충족하므로 
정확합니다. Amazon CloudFront 는 .html, .css, .js 및 이미지 파일과 같은 정적 및 동적 웹 
콘텐츠를 사용자에게 빠르게 배포하는 콘텐츠 전송 네트워크(CDN) 서비스입니다. CloudFront 는 
엣지 로케이션이라고 하는 전 세계 데이터 센터 네트워크를 통해 콘텐츠를 제공합니다. 
CloudFront 에서 제공하는 콘텐츠를 사용자가 요청하면 지연 시간(시간 지연)이 가장 짧은 엣지 
로케이션으로 요청이 라우팅되므로 콘텐츠가 가능한 최상의 성능으로 제공됩니다. Amazon 
CloudFront 배포를 생성하여 CloudFront 에 대해 정의하는 오리진인 Amazon S3 버킷에서 정적 웹 
콘텐츠를 호스팅할 수 있습니다. 
이렇게 하면 정적 웹 콘텐츠에 대한 요청을 EC2 인스턴스에서 CloudFront 로 오프로드할 수 
있으므로 웹 사이트의 성능과 가용성을 개선하고 EC2 인스턴스 실행 비용을 줄일 수 있습니다. 
참조: 
https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html 
Q442 
한 회사가 여러 AWS 계정에 몇 페타바이트의 데이터를 저장합니다. 이 회사는 AWS Lake 
Formation 을 사용하여 데이터 레이크를 관리합니다. 회사의 데이터 과학 팀은 분석 목적으로 
회사의 엔지니어링 팀과 계정에서 선택한 데이터를 안전하게 공유하려고 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 필요한 데이터를 공통 계정에 복사하십시오. 해당 계정에서 IAM 액세스 역할을 생성합니다. 
엔지니어링 팀 계정의 사용자를 신뢰할 수 있는 엔터티로 포함하는 권한 정책을 지정하여 액세스 
권한을 부여합니다. 
B. 필요한 엔지니어링 팀 사용자가 데이터에 액세스할 수 있도록 데이터가 저장된 각 계정에서 
Lake Formation 권한 부여 명령을 사용합니다. 
C. AWS Data Exchange 를 사용하여 필요한 데이터를 필요한 엔지니어링 팀 계정에 비공개로 
게시합니다. 
D. Lake Formation 태그 기반 액세스 제어를 사용하여 엔지니어링 팀 계정에 필요한 데이터에 
대한 교차 계정 권한을 승인하고 부여합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109647-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q443 
회사는 AWS 에서 확장 가능한 웹 애플리케이션을 호스팅하려고 합니다. 응용 프로그램은 전 세계 
여러 지역의 사용자가 액세스할 수 있습니다. 애플리케이션 사용자는 최대 기가바이트 크기의 
고유한 데이터를 다운로드하고 업로드할 수 있습니다. 개발 팀은 업로드 및 다운로드 대기 시간을 
최소화하고 성능을 최대화할 수 있는 비용 효율적인 솔루션을 원합니다. 
이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. Transfer Acceleration 과 함께 Amazon S3 를 사용하여 애플리케이션을 호스팅합니다. 
B. CacheControl 헤더와 함께 Amazon S3 를 사용하여 애플리케이션을 호스팅합니다. 
C. Auto Scaling 및 Amazon CloudFront 와 함께 Amazon EC2 를 사용하여 애플리케이션을 
호스팅합니다. 
D. Auto Scaling 및 Amazon ElastiCache 와 함께 Amazon EC2 를 사용하여 애플리케이션을 
호스팅합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109424-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q444 
회사에서 응용 프로그램의 안정적인 아키텍처를 설계하기 위해 솔루션 설계자를 고용했습니다. 이 
애플리케이션은 웹 서버를 실행하는 Amazon RDS DB 인스턴스 1 개와 수동으로 프로비저닝된 
Amazon EC2 인스턴스 2 개로 구성됩니다. EC2 인스턴스는 단일 가용 영역에 있습니다. 
직원이 최근 DB 인스턴스를 삭제했고 그 결과 애플리케이션을 24 시간 동안 사용할 수 없었습니다. 
회사는 환경의 전반적인 안정성에 관심이 있습니다. 
애플리케이션 인프라의 안정성을 극대화하기 위해 솔루션 설계자는 무엇을 해야 합니까? 
A. 하나의 EC2 인스턴스를 삭제하고 다른 EC2 인스턴스에서 종료 방지 기능을 활성화합니다. 
다중 AZ 가 되도록 DB 인스턴스를 업데이트하고 삭제 방지를 활성화합니다. 
B. DB 인스턴스를 다중 AZ 로 업데이트하고 삭제 방지를 활성화합니다. Application Load Balancer 
뒤에 EC2 인스턴스를 배치하고 여러 가용 영역에 걸쳐 EC2 Auto Scaling 그룹에서 실행합니다. 
C. Amazon API Gateway 및 AWS Lambda 함수와 함께 추가 DB 인스턴스를 생성합니다. API 
Gateway 를 통해 Lambda 함수를 호출하도록 애플리케이션을 구성합니다. Lambda 함수가 두 DB 
인스턴스에 데이터를 쓰도록 합니다. 
D. 여러 가용 영역에 여러 서브넷이 있는 EC2 Auto Scaling 그룹에 EC2 인스턴스를 배치합니다. 
온디맨드 인스턴스 대신 스팟 인스턴스를 사용하십시오. 인스턴스의 상태를 모니터링하도록 
Amazon CloudWatch 경보를 설정합니다. DB 인스턴스를 다중 AZ 로 업데이트하고 삭제 방지를 
활성화합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109426-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 대답은 응용 프로그램 인프라의 안정성을 최대화하기 위한 요구 사항을 충족하기 때문에 
정확합니다. DB 인스턴스를 다중 AZ 로 업데이트할 수 있습니다. 즉, Amazon RDS 가 다른 가용 
영역에서 동기식 대기 복제본을 자동으로 프로비저닝하고 유지합니다. 기본 DB 인스턴스는 가용 
영역 전체에서 대기 복제본으로 동기식으로 복제되어 데이터 중복성을 제공하고 시스템 백업 중에 
지연 시간 급증을 최소화합니다. 
고가용성으로 DB 인스턴스를 실행하면 계획된 시스템 유지 관리 중에 가용성을 높일 수 있습니다. 
또한 DB 인스턴스 장애 및 가용 영역 중단으로부터 데이터베이스를 보호하는 데 도움이 될 수 
있습니다. 또한 DB 인스턴스에서 삭제 보호를 활성화하여 어떤 사용자도 DB 인스턴스를 삭제하지 
못하도록 할 수 있습니다. 여러 가용 영역에서 EC2 인스턴스와 같은 여러 대상에 수신 
애플리케이션 트래픽을 분산하는 Application Load Balancer 뒤에 EC2 인스턴스를 배치할 수 
있습니다. 이렇게 하면 애플리케이션의 가용성과 내결함성이 향상됩니다. 
여러 가용 영역의 EC2 Auto Scaling 그룹에서 EC2 인스턴스를 실행할 수 있으므로 애플리케이션 
로드를 처리하는 데 사용할 수 있는 정확한 수의 EC2 인스턴스를 확보할 수 있습니다. 조정 
정책을 사용하여 수요 변화에 따라 Auto Scaling 그룹의 인스턴스 수를 조정할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.ht
ml 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html#USER_
DeleteInstance.DeletionProtection 
https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html 
Q445 
회사는 회사 데이터 센터의 대규모 NAS(Network-Attached Storage) 시스템에 700 테라바이트의 
데이터를 저장하고 있습니다. 이 회사는 10Gbps AWS Direct Connect 연결을 사용하는 하이브리드 
환경을 보유하고 있습니다. 
규제 기관의 감사 후 회사는 90 일 이내에 데이터를 클라우드로 옮길 수 있습니다. 회사는 
데이터를 중단 없이 효율적으로 이동해야 합니다. 회사는 여전히 이전 기간 동안 데이터에 
액세스하고 데이터를 업데이트할 수 있어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 회사 데이터 센터에서 AWS DataSync 에이전트를 생성합니다. 데이터 전송 작업 생성 Amazon 
S3 버킷으로의 전송을 시작합니다. 
B. 데이터를 AWS Snowball Edge Storage Optimized 디바이스에 백업합니다. 디바이스를 AWS 
데이터 센터로 배송합니다. 온프레미스 파일 시스템에 대상 Amazon S3 버킷을 탑재합니다. 
C. DataSync 를 사용하여 Direct Connect 연결을 통해 로컬 스토리지에서 지정된 Amazon S3 
버킷으로 데이터를 직접 복사합니다. 
D. 테이프에 데이터를 백업합니다. 테이프를 AWS 데이터 센터로 배송합니다. 온프레미스 파일 
시스템에 대상 Amazon S3 버킷을 탑재합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109403-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 답변은 중단 없이 데이터를 효율적으로 이동하고 전송 기간 동안 데이터에 계속 액세스하고 
업데이트할 수 있어야 한다는 요구 사항을 충족하기 때문에 정답입니다. AWS DataSync 는 
AWS 로의 데이터 마이그레이션을 간소화 및 가속화하고 온프레미스 스토리지, 엣지 로케이션, 
기타 클라우드 및 AWS 스토리지 간에 데이터를 빠르고 안전하게 이동할 수 있도록 지원하는 
온라인 데이터 이동 및 검색 서비스입니다. 회사 데이터 센터에서 AWS DataSync 에이전트를 
생성하여 Direct Connect 연결을 통해 NAS 시스템을 AWS 에 연결할 수 있습니다. 데이터 전송 
작업을 생성하여 소스 위치, 대상 위치 및 데이터 전송 옵션을 지정할 수 있습니다. Amazon S3 
버킷으로 전송을 시작하고 작업 진행 상황을 모니터링할 수 있습니다. 
DataSync 는 전송 중인 데이터를 자동으로 암호화하고 전송 중에 데이터 무결성을 확인합니다. 
DataSync 는 증분 전송도 지원합니다. 즉, 마지막 전송 이후 변경된 파일만 복사됩니다. 이렇게 
하면 NAS 시스템과 S3 버킷 간에 데이터가 동기화되었는지 확인할 수 있으며 전송 기간 동안 
데이터에 액세스하고 데이터를 업데이트할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html 
https://docs.aws.amazon.com/datasync/latest/userguide/how-datasync-works.html 
Q446 
회사는 데이터를 Amazon S3 버킷에 PDF 형식으로 저장합니다. 회사는 모든 신규 및 기존 
데이터를 Amazon S3 에 7 년 동안 보관해야 한다는 법적 요구 사항을 따라야 합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. S3 버킷에 대한 S3 버전 관리 기능을 켭니다. 7 년 후 데이터를 삭제하도록 S3 수명 주기를 
구성합니다. 모든 S3 객체에 대한 MFA(Multi-Factor Authentication) 삭제를 구성합니다. 
B. S3 버킷에 대한 거버넌스 보존 모드로 S3 객체 잠금을 켭니다. 7 년 후에 만료되도록 보존 
기간을 설정합니다. 모든 기존 개체를 다시 복사하여 기존 데이터를 준수하도록 합니다. 
C. S3 버킷에 대해 규정 준수 보존 모드로 S3 객체 잠금을 켭니다. 7 년 후에 만료되도록 보존 
기간을 설정합니다. 모든 기존 개체를 다시 복사하여 기존 데이터를 준수하도록 합니다. 
D. S3 버킷에 대해 규정 준수 보존 모드로 S3 객체 잠금을 켭니다. 7 년 후에 만료되도록 보존 
기간을 설정합니다. S3 배치 작업을 사용하여 기존 데이터를 규정에 맞게 가져옵니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109404-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q447 
회사에는 Amazon API Gateway 에서 호출하는 AWS Lambda 함수에서 실행되는 상태 비저장 웹 
애플리케이션이 있습니다. 회사는 지역 장애 조치 기능을 제공하기 위해 여러 AWS 지역에 
애플리케이션을 배포하려고 합니다. 
트래픽을 여러 지역으로 라우팅하려면 솔루션 설계자가 무엇을 해야 합니까? 
A. 각 지역에 대해 Amazon Route 53 상태 확인을 생성합니다. 활성-활성 장애 조치 구성을 
사용합니다. 
B. 각 리전의 오리진을 사용하여 Amazon CloudFront 배포를 생성합니다. CloudFront 상태 확인을 
사용하여 트래픽을 라우팅합니다. 
C. 전송 게이트웨이를 생성합니다. Transit Gateway 를 각 리전의 API Gateway 엔드포인트에 
연결합니다. 요청을 라우팅하도록 전송 게이트웨이를 구성합니다. 
D. 기본 지역에서 Application Load Balancer 를 생성합니다. 각 리전의 API 게이트웨이 엔드포인트 
호스트 이름을 가리키도록 대상 그룹을 설정합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109405-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q448 
회사에는 Management 및 Production 이라는 두 개의 VPC 가 있습니다. 관리 VPC 는 고객 
게이트웨이를 통해 VPN 을 사용하여 데이터 센터의 단일 디바이스에 연결합니다. 프로덕션 VPC 는 
2 개의 연결된 AWS Direct Connect 연결이 있는 가상 프라이빗 게이트웨이를 사용합니다. 관리 및 
프로덕션 VPC 는 모두 단일 VPC 피어링 연결을 사용하여 애플리케이션 간의 통신을 허용합니다. 
솔루션 아키텍트는 이 아키텍처에서 단일 실패 지점을 완화하기 위해 무엇을 해야 합니까? 
A. 관리 VPC 와 프로덕션 VPC 사이에 VPN 세트를 추가하십시오. 
B. 두 번째 가상 프라이빗 게이트웨이를 추가하고 관리 VPC 에 연결합니다. 
C. 두 번째 고객 게이트웨이 디바이스에서 관리 VPC 에 두 번째 VPN 세트를 추가합니다. 
D. 관리 VPC 와 프로덕션 VPC 간에 두 번째 VPC 피어링 연결을 추가합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109499-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이 답변은 관리 VPC 와 데이터 센터 간의 VPN 연결에 중복성을 제공하기 때문에 정답입니다. 
하나의 고객 게이트웨이 디바이스 또는 하나의 VPN 터널을 사용할 수 없게 되더라도 트래픽은 
여전히 두 번째 고객 게이트웨이 디바이스와 두 번째 VPN 터널을 통해 흐를 수 있습니다. 이렇게 
하면 VPN 연결의 단일 실패 지점이 완화됩니다. 
참조: 
https://docs.aws.amazon.com/vpn/latest/s2svpn/vpn-redundant-connection.html 
https://www.trendmicro.com/cloudoneconformity/knowledge-base/aws/VPC/vpn-tunnelredunda
ncy.html 
Q449 
회사는 Oracle 데이터베이스에서 애플리케이션을 실행합니다. 이 회사는 데이터베이스, 백업 관리 
및 데이터 센터 유지 관리를 위한 제한된 리소스로 인해 AWS 로 신속하게 마이그레이션할 
계획입니다. 응용 프로그램은 권한 있는 액세스가 필요한 타사 데이터베이스 기능을 사용합니다. 
회사가 비용 효율적으로 데이터베이스를 AWS MOST 로 마이그레이션하는 데 도움이 되는 솔루션은 
무엇입니까? 
A. 데이터베이스를 Oracle 용 Amazon RDS 로 마이그레이션합니다. 타사 기능을 클라우드 서비스로 
대체합니다. 
B. 데이터베이스를 Amazon RDS Custom for Oracle 로 마이그레이션합니다. 타사 기능을 
지원하도록 데이터베이스 설정을 사용자 지정합니다. 
C. 데이터베이스를 Oracle 용 Amazon EC2 Amazon 머신 이미지(AMI)로 마이그레이션합니다. 타사 
기능을 지원하도록 데이터베이스 설정을 사용자 지정합니다. 
D. Oracle APEX 에 대한 종속성을 제거하도록 애플리케이션 코드를 다시 작성하여 PostgreSQL 용 
Amazon RDS 로 데이터베이스를 마이그레이션합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109432-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q450 
회사에는 단일 서버에 있는 3 계층 웹 응용 프로그램이 있습니다. 회사는 애플리케이션을 AWS 
클라우드로 마이그레이션하려고 합니다. 또한 회사는 애플리케이션이 AWS Well-Architected 
프레임워크와 일치하고 보안, 확장성 및 복원력에 대한 AWS 권장 모범 사례와 일치하기를 
원합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (3 개 선택) 
A. 애플리케이션의 기존 아키텍처를 사용하여 두 가용 영역에 걸쳐 VPC 를 생성합니다. EC2 Auto 
Scaling 그룹이 있는 각 가용 영역의 프라이빗 서브넷에 있는 Amazon EC2 인스턴스의 기존 
아키텍처로 애플리케이션을 호스팅합니다. 보안 그룹 및 네트워크 액세스 제어 목록(네트워크 
ACL)을 사용하여 EC2 인스턴스를 보호합니다. 
B. 보안 그룹 및 네트워크 액세스 제어 목록(네트워크 ACL)을 설정하여 데이터베이스 계층에 대한 
액세스를 제어합니다. 프라이빗 서브넷에 단일 Amazon RDS 데이터베이스를 설정합니다. 
C. 두 가용 영역에 걸쳐 VPC 를 생성합니다. 웹 계층, 애플리케이션 계층 및 데이터베이스 계층을 
호스팅하도록 애플리케이션을 리팩터링합니다. 웹 계층 및 애플리케이션 계층에 대한 Auto Scaling 
그룹을 사용하여 자체 프라이빗 서브넷에서 각 계층을 호스팅합니다. 
D. 단일 Amazon RDS 데이터베이스를 사용합니다. 애플리케이션 계층 보안 그룹에서만 
데이터베이스 액세스를 허용합니다. 
E. 웹 티어 앞에서 Elastic Load Balancer 를 사용합니다. 각 계층의 보안 그룹에 대한 참조를 
포함하는 보안 그룹을 사용하여 액세스를 제어합니다. 
F. 프라이빗 서브넷에서 Amazon RDS 데이터베이스 다중 AZ 클러스터 배포를 사용합니다. 
애플리케이션 계층 보안 그룹에서만 데이터베이스 액세스를 허용합니다. 
Answer: C, E, F 
https://www.examtopics.com/discussions/amazon/view/109406-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q451 
회사에서 애플리케이션과 데이터베이스를 AWS 클라우드로 마이그레이션하고 있습니다. 이 회사는 
Amazon Elastic Container Service(Amazon ECS), AWS Direct Connect 및 Amazon RDS 를 
사용합니다. 
회사의 운영 팀에서 어떤 활동을 관리합니까? (3 개 선택) 
A. Amazon RDS 인프라 계층, 운영 체제 및 플랫폼 관리 
B. Amazon RDS DB 인스턴스 생성 및 예약된 유지 관리 기간 구성 
C. 모니터링, 패치 관리, 로그 관리 및 호스트 침입 탐지를 위한 Amazon ECS 의 추가 소프트웨어 
구성 요소 구성 
D. Amazon RDS 의 모든 마이너 및 메이저 데이터베이스 버전에 대한 패치 설치 
E. 데이터 센터에서 Amazon RDS 인프라의 물리적 보안 보장 
F. Direct Connect 를 통해 이동하는 데이터의 암호화 
Answer: B, C, F 
https://www.examtopics.com/discussions/amazon/view/109408-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q452 
회사는 Amazon EC2 인스턴스에서 Java 기반 작업을 실행합니다. 작업은 매시간 실행되며 
실행하는 데 10 초가 걸립니다. 작업은 예약된 간격으로 실행되며 1GB 의 메모리를 사용합니다. 
작업이 사용 가능한 최대 CPU 를 사용하는 짧은 순간을 제외하고 인스턴스의 CPU 사용률은 
낮습니다. 회사는 작업 실행 비용을 최적화하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS App2Container(A2C)를 사용하여 작업을 컨테이너화합니다. 0.5 vCPU(가상 CPU) 및 1GB 
메모리를 사용하여 AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS) 작업으로 
작업을 실행합니다. 
B. 메모리가 1GB 인 AWS Lambda 함수에 코드를 복사합니다. Amazon EventBridge 예약 규칙을 
생성하여 매시간 코드를 실행합니다. 
C. AWS App2Container(A2C)를 사용하여 작업을 컨테이너화합니다. 기존 Amazon Machine 
Image(AMI)에 컨테이너를 설치합니다. 태스크가 완료되면 스케줄이 컨테이너를 중지하는지 
확인하십시오. 
D. 작업 완료 시 EC2 인스턴스를 중지하고 다음 작업이 시작될 때 EC2 인스턴스를 다시 
시작하도록 기존 일정을 구성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109521-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q453 
회사에서 Amazon EC2 데이터 및 여러 Amazon S3 버킷에 대한 백업 전략을 구현하려고 합니다. 
규정 요구 사항으로 인해 회사는 특정 기간 동안 백업 파일을 보존해야 합니다. 회사는 보유기간 
동안 파일을 변조해서는 안됩니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Backup 을 사용하여 거버넌스 모드에서 볼트 잠금이 있는 백업 볼트를 생성합니다. 필요한 
백업 계획을 생성합니다. 
B. Amazon Data Lifecycle Manager 를 사용하여 필요한 자동 스냅샷 정책을 생성합니다. 
C. Amazon S3 파일 게이트웨이를 사용하여 백업을 생성합니다. 적절한 S3 수명 주기 관리를 
구성합니다. 
D. AWS Backup 을 사용하여 규정 준수 모드에서 볼트 잠금이 있는 백업 볼트를 생성합니다. 
필요한 백업 계획을 생성합니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109410-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS Backup 은 컴퓨팅, 스토리지 및 데이터베이스 전반에서 AWS 서비스의 데이터 보호를 중앙 
집중화하고 자동화할 수 있는 완전 관리형 서비스입니다. AWS Backup Vault Lock 은 백업 볼트에 
대한 보안 및 제어를 강화하는 데 도움이 되는 백업 볼트의 선택적 기능입니다. 규정 준수 
모드에서 잠금이 활성화되고 유예 시간이 끝나면 고객, 계정/데이터 소유자 또는 AWS 가 볼트 
구성을 변경하거나 삭제할 수 없습니다. 이렇게 하면 보존 기간이 만료되고 규정 요구 사항을 
충족할 때까지 백업을 사용할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/aws-backup/latest/devguide/vaultlock.html 
Q454 
회사는 여러 AWS 리전 및 계정에 걸쳐 리소스를 보유하고 있습니다. 새로 고용된 솔루션 
설계자는 이전 직원이 리소스 인벤토리에 대한 세부 정보를 제공하지 않은 것을 발견했습니다. 
솔루션 설계자는 모든 계정에서 다양한 워크로드의 관계 세부 정보를 구축하고 매핑해야 합니다. 
운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Systems Manager Inventory 를 사용하여 상세 보기 보고서에서 맵 보기를 생성합니다. 
B. AWS Step Functions 를 사용하여 워크로드 세부 정보를 수집합니다. 워크로드의 아키텍처 
다이어그램을 수동으로 작성합니다. 
C. Workload Discovery on AWS 를 사용하여 워크로드의 아키텍처 다이어그램을 생성합니다. 
D. AWS X-Ray 를 사용하여 워크로드 세부 정보를 봅니다. 관계를 사용하여 아키텍처 다이어그램을 
구축합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109433-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Workload Discovery on AWS(이전에는 AWS Perspective 라고 함)는 AWS 클라우드 워크로드를 
시각화하는 도구입니다. 계정과 리전 전체에서 AWS 리소스의 인벤토리를 유지하고 이들 간의 
관계를 매핑하고 웹 UI 에 표시합니다. 또한 AWS 비용 및 사용 보고서 쿼리, 리소스 검색, 
아키텍처 다이어그램 저장 및 내보내기 등을 수행할 수 있습니다. 솔루션은 AWS 에서 Workload 
Discovery 를 사용하여 최소한의 운영 노력으로 모든 계정에서 다양한 워크로드의 관계 세부 
정보를 구축하고 매핑할 수 있습니다. 
1. AWS Systems Manager Inventory 를 사용하여 상세 보기 보고서에서 지도 보기를 생성합니다. 
AWS Systems Manager Inventory 는 관리형 인스턴스에서 메타데이터를 수집하여 중앙 Amazon S3 
버킷에 저장하는 기능이므로 이 솔루션은 모든 계정에서 다양한 워크로드의 관계 세부 정보를 
구축하고 매핑해야 하는 요구 사항을 충족하지 않습니다. 워크로드의 맵 보기 또는 아키텍처 
다이어그램을 제공하지 않습니다. 
2. AWS Step Functions 를 사용하여 워크로드 세부 정보를 수집합니다. 워크로드의 아키텍처 
다이어그램을 수동으로 구축합니다. 이 솔루션은 워크로드 세부 정보 수집을 오케스트레이션하고 
아키텍처 다이어그램을 수동으로 구축하기 위해 상태 시스템을 생성 및 관리해야 하므로 최소한의 
운영 노력 요구 사항을 충족하지 않습니다. 
3. AWS X-Ray 를 사용하여 워크로드 세부 정보 보기 관계가 있는 아키텍처 다이어그램을 
구축합니다. 이 솔루션은 워크로드 세부 정보를 수집하고 아키텍처 다이어그램을 수동으로 
구축하기 위해 X-Ray SDK 로 애플리케이션을 구성해야 하므로 최소한의 운영 노력 요구 사항을 
충족하지 않습니다. 
참조: 
https://aws.amazon.com/solutions/implementations/workload-discovery-on-aws/ 
Q455 
회사에서 AWS Organizations 를 사용합니다. 회사는 다른 예산으로 일부 AWS 계정을 운영하려고 
합니다. 회사는 특정 기간 동안 할당된 예산 임계값에 도달하면 알림을 받고 AWS 계정에 추가 
리소스 프로비저닝을 자동으로 방지하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (3 개 선택) 
A. AWS 예산을 사용하여 예산을 생성합니다. 필요한 AWS 계정의 비용 및 사용 보고서 섹션에서 
예산 금액을 설정합니다. 
B. AWS 예산을 사용하여 예산을 생성합니다. 필요한 AWS 계정의 결제 대시보드에서 예산 금액을 
설정합니다. 
C. 필요한 권한으로 예산 작업을 실행하기 위해 AWS 예산에 대한 IAM 사용자를 생성합니다. 
D. 필요한 권한으로 예산 작업을 실행하기 위해 AWS 예산에 대한 IAM 역할을 생성합니다. 
E. 각 계정이 예산 임계값을 충족할 때 회사에 알리는 경고를 추가합니다. 추가 리소스의 
프로비저닝을 방지하기 위해 적절한 구성 규칙으로 생성된 IAM 자격 증명을 선택하는 예산 작업을 
추가합니다. 
F. 각 계정이 예산 임계값을 충족할 때 회사에 알리는 경고를 추가합니다. 추가 리소스의 
프로비저닝을 방지하기 위해 적절한 SCP(서비스 제어 정책)로 생성된 IAM 자격 증명을 선택하는 
예산 작업을 추가합니다. 
Answer: B, D, F 
https://www.examtopics.com/discussions/amazon/view/109522-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q456 
한 회사가 한 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 EC2 
인스턴스를 두 번째 리전에 백업하려고 합니다. 또한 회사는 두 번째 리전에서 EC2 리소스를 
프로비저닝하고 하나의 AWS 계정에서 중앙에서 EC2 인스턴스를 관리하기를 원합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 두 번째 지역에 비슷한 수의 EC2 인스턴스가 있는 재해 복구(DR) 계획을 만듭니다. 데이터 
복제를 구성합니다. 
B. EC2 인스턴스의 특정 시점 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. 
주기적으로 스냅샷을 두 번째 리전에 복사합니다. 
C. AWS Backup 을 사용하여 백업 계획을 생성합니다. EC2 인스턴스의 두 번째 리전에 대한 교차 
리전 백업을 구성합니다. 
D. 두 번째 리전에 비슷한 수의 EC2 인스턴스를 배포합니다. AWS DataSync 를 사용하여 원본 
리전에서 두 번째 리전으로 데이터를 전송합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109523-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q457 
AWS 를 사용하는 회사는 제품 제조업체에 데이터를 전송하는 애플리케이션을 구축하고 있습니다. 
회사에는 자체 ID 공급자(IdP)가 있습니다. 회사는 사용자가 애플리케이션을 사용하여 데이터를 
전송하는 동안 IdP 가 애플리케이션 사용자를 인증하기를 원합니다. 회사는 AS2(Applicability 
Statement 2) 프로토콜을 사용해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS DataSync 를 사용하여 데이터를 전송하십시오. IdP 인증을 위한 AWS Lambda 함수를 
생성합니다. 
B. Amazon AppFlow 흐름을 사용하여 데이터를 전송합니다. IdP 인증을 위한 Amazon Elastic 
Container Service(Amazon ECS) 작업을 생성합니다. 
C. AWS Transfer Family 를 사용하여 데이터를 전송합니다. IdP 인증을 위한 AWS Lambda 함수를 
생성합니다. 
D. AWS Storage Gateway 를 사용하여 데이터를 전송합니다. IdP 인증을 위한 Amazon Cognito 
자격 증명 풀을 생성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109524-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q458 
솔루션 설계자는 현금 회수 서비스를 위해 Amazon API Gateway 에서 RESTAPI 를 설계하고 
있습니다. 응용 프로그램에는 컴퓨팅 리소스를 위해 1GB 의 메모리와 2GB 의 스토리지가 
필요합니다. 애플리케이션은 데이터가 관계형 형식이어야 합니다. 
최소한의 관리 노력으로 이러한 요구 사항을 충족하는 추가 AWS 서비스 조합은 무엇입니까? (2 개 
선택) 
A. Amazon EC2 
B. AWS Lambda 
C. Amazon RDS 
D. Amazon DynamoDB 
E. Amazon Elastic Kubernetes Services (Amazon EKS)  
Answer: B, C 
https://www.examtopics.com/discussions/amazon/view/109435-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q459 
회사는 AWS Organizations 를 사용하여 여러 AWS 계정 내에서 워크로드를 실행합니다. 태깅 
정책은 회사에서 태그를 생성할 때 부서 태그를 AWS 리소스에 추가합니다. 
회계 팀은 Amazon EC2 소비에 대한 지출을 결정해야 합니다. 회계팀은 AWS 계정과 관계없이 
비용을 담당하는 부서를 결정해야 합니다. 회계 팀은 조직 내 모든 AWS 계정에 대해 AWS Cost 
Explorer 에 액세스할 수 있으며 Cost Explorer 의 모든 보고서에 액세스해야 합니다. 
운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 조직 관리 계정 청구 콘솔에서 부서라는 사용자 정의 비용 할당 태그를 활성화합니다. 비용 
탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2 별로 필터링합니다. 
B. Organizations 마스터 계정 결제 콘솔에서 부서라는 AWS 정의 비용 할당 태그를 활성화합니다. 
비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2 별로 
필터링합니다. 
C. 조직 회원 계정 청구 콘솔에서 부서라는 사용자 정의 비용 할당 태그를 활성화합니다. 비용 
탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2 별로 필터링합니다. 
D. Organizations 회원 계정 결제 콘솔에서 부서라는 AWS 정의 비용 할당 태그를 활성화합니다. 
비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2 별로 
필터링합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109440-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q460 
회사는 SaaS(Software as a Service) 애플리케이션 Salesforce 계정과 Amazon S3 간에 데이터를 
안전하게 교환하려고 합니다. 회사는 AWS Key Management Service(AWS KMS) 고객 관리형 
키(CMK)를 사용하여 저장된 데이터를 암호화해야 합니다. 또한 회사는 전송 중인 데이터를 
암호화해야 합니다. 회사에서 Salesforce 계정에 대한 API 액세스를 활성화했습니다. 
A. Salesforce 에서 Amazon S3 로 안전하게 데이터를 전송하는 AWS Lambda 함수를 생성합니다. 
B. AWS Step Functions 워크플로를 생성합니다. Salesforce 에서 Amazon S3 로 안전하게 데이터를 
전송하는 작업을 정의합니다. 
C. Amazon AppFlow 흐름을 생성하여 Salesforce 에서 Amazon S3 로 데이터를 안전하게 
전송합니다. 
D. Salesforce 용 사용자 지정 커넥터를 만들어 Salesforce 에서 Amazon S3 로 데이터를 안전하게 
전송합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109525-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon AppFlow 는 사용자가 SaaS 애플리케이션과 AWS 서비스 간에 안전하게 데이터를 전송할 
수 있도록 하는 완전관리형 통합 서비스입니다. Salesforce 를 소스로, Amazon S3 를 대상으로 
지원합니다. 또한 AWS KMS CMK 를 사용하여 유휴 데이터 암호화 및 SSL/TLS1 을 사용하여 전송 
중인 데이터 암호화를 지원합니다. Amazon AppFlow 를 사용하면 솔루션이 최소한의 개발 노력으로 
요구 사항을 충족할 수 있습니다. 
1. 데이터를 Salesforce 에서 Amazon S3 로 안전하게 전송하는 AWS Lambda 함수를 생성합니다. 
이 솔루션은 Salesforce 및 Amazon S3 API 와 상호 작용하고 인증, 암호화, 오류 처리 및 
모니터링을 처리하기 위한 사용자 지정 코드 작성을 포함하므로 최소한의 개발 노력 요구 사항을 
충족하지 않습니다. 
2. AWS Step Functions 워크플로 생성 Salesforce 에서 Amazon S3 로 데이터를 안전하게 전송하는 
작업을 정의합니다. 이 솔루션은 데이터 전송 작업을 오케스트레이션하기 위한 상태 시스템 정의를 
생성하고 실제 데이터 전송을 수행하기 위해 Lambda 함수 또는 기타 서비스를 호출하기 때문에 
최소한의 개발 노력 요구 사항을 충족하지 않습니다. 
3. Salesforce 용 사용자 지정 커넥터를 생성하여 Salesforce 에서 Amazon S3 로 데이터를 안전하게 
전송합니다. 이 솔루션은 Amazon AppFlow 사용자 지정 커넥터 SDK 를 사용하여 Salesforce 용 
사용자 지정 커넥터를 구축하고 배포하므로 추가 구성 및 관리가 필요하므로 최소한의 개발 노력 
요구 사항을 충족하지 않습니다. 
참조: https://aws.amazon.com/appflow/ 
Q461 
회사가 단일 AWS 리전에서 모바일 게임 앱을 개발하고 있습니다. 앱은 Auto Scaling 그룹의 여러 
Amazon EC2 인스턴스에서 실행됩니다. 회사는 앱 데이터를 Amazon DynamoDB 에 저장합니다. 
앱은 사용자와 서버 간에 TCP 트래픽과 UDP 트래픽을 사용하여 통신합니다. 응용 프로그램은 전 
세계적으로 사용됩니다. 회사는 모든 사용자에게 가능한 가장 낮은 대기 시간을 보장하고자 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS Global Accelerator 를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 사용하고 
TCP 및 UDP 포트에서 수신 대기하는 가속기 엔드포인트 뒤에 Application Load Balancer(ALB)를 
생성합니다. Auto Scaling 그룹을 업데이트하여 ALB 에 인스턴스를 등록합니다. 
B. AWS Global Accelerator 를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 사용하고 
TCP 및 UDP 포트에서 수신 대기하는 가속기 엔드포인트 뒤에 NLB(Network Load Balancer)를 
생성합니다. Auto Scaling 그룹을 업데이트하여 NLB 에 인스턴스를 등록합니다. 
C. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 뒤에 
NLB(Network Load Balancer)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 
그룹을 업데이트하여 NLB 에 인스턴스를 등록합니다. NLB 를 오리진으로 사용하도록 CloudFront 를 
업데이트합니다. 
D. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 뒤에 
Application Load Balancer(ALB)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 
그룹을 업데이트하여 ALB 에 인스턴스를 등록합니다. ALB 를 오리진으로 사용하도록 CloudFront 를 
업데이트합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109446-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS Global Accelerator 는 글로벌 사용자를 위해 애플리케이션의 성능과 가용성을 향상시키는 
네트워킹 서비스입니다. AWS 글로벌 네트워크를 사용하여 사용자 트래픽을 성능 및 상태에 따라 
최적의 엔드포인트로 라우팅합니다. 또한 애플리케이션에 대한 고정 진입점 역할을 하고 TCP 및 
UDP 프로토콜을 모두 지원하는 고정 IP 주소를 제공합니다. 솔루션은 AWS Global Accelerator 를 
사용하여 모든 사용자에게 가능한 최저 지연 시간을 보장할 수 있습니다. 
1. AWS Global Accelerator 를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 사용하고 
TCP 및 UDP 포트에서 수신 대기하는 가속기 엔드포인트 뒤에 Application Load Balancer(ALB)를 
생성합니다. Auto Scaling 그룹을 업데이트하여 ALB 에 인스턴스를 등록합니다. ALB 는 UDP 
프로토콜을 지원하지 않으므로 이 솔루션은 작동하지 않습니다. 
2. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 뒤에 
NLB(Network Load Balancer)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 
그룹을 업데이트하여 NLB 에 인스턴스를 등록합니다. NLB 를 오리진으로 사용하도록 CloudFront 를 
업데이트합니다. CloudFront 는 UDP 프로토콜을 지원하지 않으므로 이 솔루션은 작동하지 
않습니다. 
3. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 뒤에 
Application Load Balancer(ALB)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 
그룹을 업데이트하여 ALB 에 인스턴스를 등록합니다. ALB 를 오리진으로 사용하도록 CloudFront 를 
업데이트합니다. CloudFront 및 ALB 는 UDP 프로토콜을 지원하지 않으므로 이 솔루션은 작동하지 
않습니다. 
참조: https://aws.amazon.com/global-accelerator/ 
Q462 
회사에 고객 주문을 처리하는 애플리케이션이 있습니다. 회사는 주문을 Amazon Aurora 
데이터베이스에 저장하는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 때때로 
트래픽이 높을 때 워크로드가 주문을 충분히 빠르게 처리하지 못합니다. 
가능한 한 빨리 데이터베이스에 주문을 안정적으로 기록하려면 솔루션 설계자가 무엇을 해야 
합니까? 
A. 트래픽이 많을 때 EC2 인스턴스의 인스턴스 크기를 늘립니다. Amazon Simple Notification 
Service(Amazon SNS)에 주문을 작성합니다. SNS 주제에 데이터베이스 엔드포인트를 구독합니다. 
B. Amazon Simple Queue Service(Amazon SQS) 대기열에 주문을 씁니다. Application Load 
Balancer 뒤의 Auto Scaling 그룹에서 EC2 인스턴스를 사용하여 SQS 대기열에서 읽고 주문을 
데이터베이스로 처리합니다. 
C. Amazon Simple Notification Service(Amazon SNS)에 주문을 작성합니다. SNS 주제에 
데이터베이스 엔드포인트를 구독합니다. Application Load Balancer 뒤의 Auto Scaling 그룹에서 
EC2 인스턴스를 사용하여 SNS 주제에서 읽습니다. 
D. EC2 인스턴스가 CPU 임계값 제한에 도달하면 Amazon Simple Queue Service(Amazon SQS) 
대기열에 주문을 씁니다. Application Load Balancer 뒤의 Auto Scaling 그룹에서 EC2 인스턴스의 
예약된 조정을 사용하여 SQS 대기열에서 읽고 데이터베이스로 주문을 처리합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109653-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon SQS 는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 
있는 완전관리형 메시지 대기열 서비스입니다. 애플리케이션은 SQS 대기열에 주문을 기록함으로써 
주문 손실 없이 트래픽 급증을 처리할 수 있습니다. Auto Scaling 그룹의 EC2 인스턴스는 SQS 
대기열에서 읽고 꾸준한 속도로 데이터베이스로 주문을 처리할 수 있습니다. Application Load 
Balancer 는 EC2 인스턴스에 부하를 분산하고 상태 확인을 제공할 수 있습니다. 이 솔루션은 
질문의 모든 요구 사항을 충족하지만 다른 옵션은 그렇지 않습니다. 
참조: 
https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/welcome.html 
https://aws.amazon.com/architecture/serverless/ 
https://aws.amazon.com/sqs/ 
Q463 
IoT 회사는 사용자의 수면에 대한 데이터를 수집하는 센서가 있는 매트리스를 출시하고 있습니다. 
센서는 데이터를 Amazon S3 버킷으로 보냅니다. 센서는 각 매트리스에 대해 매일 밤 약 2MB 의 
데이터를 수집합니다. 회사는 각 매트리스에 대한 데이터를 처리하고 요약해야 합니다. 결과는 
가능한 한 빨리 제공되어야 합니다. 데이터 처리에는 1GB 의 메모리가 필요하며 30 초 이내에 
완료됩니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. Scala 작업에 AWS Glue 사용 
B. Apache Spark 스크립트와 함께 Amazon EMR 사용 
C. Python 스크립트와 함께 AWS Lambda 사용 
D. PySpark 작업과 함께 AWS Glue 사용 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109501-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q464 
회사는 PostgreSQL 단일 AZ DB 인스턴스용 Amazon RDS 에 모든 주문을 저장하는 온라인 쇼핑 
애플리케이션을 호스팅합니다. 경영진은 단일 실패 지점을 제거하기를 원하며 솔루션 설계자에게 
애플리케이션 코드를 변경하지 않고도 데이터베이스 다운타임을 최소화할 수 있는 접근 방식을 
권장하도록 요청했습니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. 데이터베이스 인스턴스를 수정하고 다중 AZ 옵션을 지정하여 기존 데이터베이스 인스턴스를 
다중 AZ 배포로 변환합니다. 
B. 새로운 RDS 다중 AZ 배포를 생성합니다. 현재 RDS 인스턴스의 스냅샷을 만들고 스냅샷으로 
새 다중 AZ 배포를 복원합니다. 
C. 다른 가용 영역에서 PostgreSQL 데이터베이스의 읽기 전용 복제본을 생성합니다. Amazon 
Route 53 가중 레코드 세트를 사용하여 데이터베이스 전체에 요청을 분산합니다. 
D. 최소 그룹 크기가 2 인 Amazon EC2 Auto Scaling 그룹에 RDS for PostgreSQL 데이터베이스를 
배치합니다. Amazon Route 53 가중 레코드 세트를 사용하여 인스턴스 간에 요청을 분산합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109449-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
기존 단일 AZ DB 인스턴스를 다중 AZ 배포로 변환하려면 AWS Management Console 에서 DB 
인스턴스에 해당하는 "수정" 옵션을 사용하십시오. 
참고: 
https://aws.amazon.com/rds/features/multi-az/ 
Q465 
회사에서 고객 요구를 지원하기 위해 애플리케이션을 개발하고 있습니다. 회사는 동일한 가용 영역 
내의 여러 Amazon EC2 Nitro 기반 인스턴스에 애플리케이션을 배포하려고 합니다. 또한 이 회사는 
더 높은 애플리케이션 가용성을 달성하기 위해 여러 EC2 Nitro 기반 인스턴스의 여러 블록 
스토리지 볼륨에 동시에 쓸 수 있는 기능을 애플리케이션에 제공하고자 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon Elastic Block Store(Amazon EBS) 다중 연결에 범용 SSD(gp3) EBS 볼륨 사용 
B. Amazon Elastic Block Store(Amazon EBS) 다중 연결과 함께 처리량 최적화 HDD(st1) EBS 볼륨 
사용 
C. Amazon Elastic Block Store(Amazon EBS) 다중 연결과 함께 프로비저닝된 IOPS SSD(io2) EBS 
볼륨 사용 
D. Amazon Elastic Block Store(Amazon EBS) 다중 연결에 범용 SSD(gp2) EBS 볼륨 사용 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109655-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q466 
한 회사에서 단일 가용 영역과 Amazon RDS 다중 AZ DB 인스턴스에서 Amazon EC2 를 사용하는 
상태 비저장 2 계층 애플리케이션을 설계했습니다. 새로운 회사 경영진은 애플리케이션의 가용성을 
높이려고 합니다. 
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? 
A. 다중 AZ EC2 Auto Scaling 을 사용하도록 애플리케이션을 구성하고 Application Load Balancer 를 
생성합니다. 
B. EC2 인스턴스의 스냅샷을 찍어 다른 AWS 리전으로 보내도록 애플리케이션을 구성합니다. 
C. Amazon Route 53 대기 시간 기반 라우팅을 사용하여 애플리케이션에 요청을 제공하도록 
애플리케이션을 구성합니다. 
D. 들어오는 요청을 처리하고 다중 AZ 애플리케이션 로드 밸런서를 생성하도록 Amazon Route 53 
규칙을 구성합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109450-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
참고: 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html 
Q467 
회사에서 AWS Organizations 를 사용합니다. 멤버 계정이 Compute Savings Plan 을 구입했습니다. 
멤버 계정 내부의 워크로드 변경으로 인해 해당 계정은 더 이상 Compute Savings Plan 약정의 
전체 혜택을 받지 못합니다. 이 회사는 구매한 컴퓨팅 성능의 50% 미만을 사용합니다. 
A. Compute Savings Plan 을 구매한 멤버 계정의 계정 콘솔에 있는 청구 기본 설정 섹션에서 할인 
공유를 켭니다. 
B. 회사의 조직 관리 계정에 있는 계정 콘솔의 청구 기본 설정 섹션에서 할인 공유를 켭니다. 
C. 다른 AWS 계정에서 Compute Savings Plan 이 있는 계정으로 추가 컴퓨팅 워크로드를 
마이그레이션합니다. 
D. 예약 인스턴스 마켓플레이스에서 초과된 Savings Plan 약정을 판매합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109485-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q468 
회사에서 고객을 위한 검색 카탈로그를 제공할 마이크로서비스 애플리케이션을 개발하고 있습니다. 
회사는 REST API 를 사용하여 애플리케이션의 프런트엔드를 사용자에게 제시해야 합니다. REST 
API 는 회사가 프라이빗 VPC 서브넷의 컨테이너에서 호스팅하는 백엔드 서비스에 액세스해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon API Gateway 를 사용하여 WebSocket API 를 설계합니다. 프라이빗 서브넷의 Amazon 
Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS 에 
액세스하기 위해 API Gateway 용 프라이빗 VPC 링크를 생성합니다. 
B. Amazon API Gateway 를 사용하여 REST API 를 설계합니다. 프라이빗 서브넷의 Amazon Elastic 
Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS 에 액세스하기 
위해 API Gateway 용 프라이빗 VPC 링크를 생성합니다. 
C. Amazon API Gateway 를 사용하여 WebSocket API 를 설계합니다. 프라이빗 서브넷의 Amazon 
Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS 에 
액세스하기 위해 API Gateway 에 대한 보안 그룹을 생성합니다. 
D. Amazon API Gateway 를 사용하여 REST API 를 설계합니다. 프라이빗 서브넷의 Amazon Elastic 
Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS 에 액세스하기 
위해 API Gateway 에 대한 보안 그룹을 생성합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109451-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q469 
회사는 수집된 원시 데이터를 Amazon S3 버킷에 저장합니다. 이 데이터는 회사 고객을 대신하여 
여러 유형의 분석에 사용됩니다. 요청된 분석 유형에 따라 S3 객체에 대한 액세스 패턴이 
결정됩니다. 
회사는 접속 패턴을 예측하거나 통제할 수 없습니다. 회사는 S3 비용을 줄이고자 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. S3 복제를 사용하여 자주 액세스하지 않는 개체를 S3 Standard-Infrequent Access(S3 
Standard-IA)로 전환합니다. 
B. S3 수명 주기 규칙을 사용하여 객체를 S3 Standard 에서 Standard-Infrequent Access 로 
전환(S3 Standard-IA) 
C. S3 수명 주기 규칙을 사용하여 객체를 S3 Standard 에서 S3 Intelligent-Tiering 으로 전환 
D. S3 Inventory 를 사용하여 S3 Standard 에서 S3 Intelligent-Tiering 으로 액세스하지 않은 객체를 
식별하고 전환 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109452-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
S3 Intelligent-Tiering 은 액세스 빈도에 따라 가장 비용 효율적인 액세스 계층으로 데이터를 
이동하여 스토리지 비용을 자동으로 줄이는 스토리지 클래스입니다. 여기에는 빈번한 액세스와 
드문 액세스의 두 가지 액세스 계층이 있습니다. 데이터는 기본적으로 빈번한 액세스 계층에 
저장되며 연속 30 일 동안 액세스가 없으면 빈번하지 않은 액세스 계층으로 이동됩니다. 데이터에 
다시 액세스하면 자주 액세스하는 tier1 로 다시 이동됩니다. S3 수명 주기 규칙을 사용하여 개체를 
S3 Standard 에서 S3 Intelligent-Tiering 으로 전환함으로써 솔루션은 액세스 패턴을 알 수 없거나 
변경하는 데이터에 대한 S3 비용을 줄일 수 있습니다. 
1. S3 복제를 사용하여 자주 액세스하지 않는 객체를 S3 Standard-Infrequent Access(S3 
Standard-IA)로 전환합니다. 이 솔루션은 액세스 패턴을 알 수 없거나 변경하는 데이터에 대한 S3 
비용 절감 요구 사항을 충족하지 않습니다. S3 복제는 중복성 또는 규정 준수를 위해 버킷 또는 
리전 간에 개체를 복사하는 기능이기 때문입니다. 액세스 빈도에 따라 개체를 다른 스토리지 
클래스로 자동으로 이동하지 않습니다. 
2. S3 수명 주기 규칙을 사용하여 객체를 S3 Standard 에서 Standard-Infrequent Access(S3 
Standard-IA)로 전환합니다. 이 솔루션은 액세스 패턴을 알 수 없거나 변경하는 데이터에 대한 S3 
비용 절감 요구 사항을 충족하지 않습니다. S3 Standard-IA 는 S3 Standard 보다 낮은 스토리지 
비용을 제공하지만 데이터 액세스에 대한 검색 요금을 부과하는 스토리지 클래스이기 때문입니다. 
액세스 패턴이 변화하는 데이터가 아니라 수명이 길고 자주 액세스하지 않는 데이터에 적합합니다. 
3. S3 Inventory 를 사용하여 S3 Standard 에서 S3 Intelligent-Tiering 으로 액세스하지 않은 객체를 
식별하고 전환합니다. 이 솔루션은 액세스 패턴을 알 수 없거나 변경하는 데이터에 대한 S3 비용 
절감 요구 사항을 충족하지 않습니다. S3 Inventory 는 버킷의 객체 및 해당 메타데이터에 대한 
보고서를 매일 또는 매주 제공하는 기능이기 때문입니다. 액세스 빈도에 따라 개체를 다른 
스토리지 클래스로 자동으로 이동하지 않습니다. 
참조 URL: https://aws.amazon.com/s3/storage-classes/intelligent-tiering/ 
S3 지능형 계층화 
액세스 패턴을 예측할 수 없거나 변경될 때 S3 비용을 줄이기 위한 최상의 솔루션입니다. S3 
Intelligent-Tiering 은 성능에 미치는 영향이나 검색 비용 없이 액세스 빈도를 기준으로 두 액세스 
계층(빈번함 및 비빈번함) 간에 객체를 자동으로 이동합니다. S3 Intelligent-Tiering 에는 거의 
액세스하지 않는 개체에 대한 선택적 아카이브 계층도 있습니다. S3 수명 주기 규칙을 사용하여 
객체를 S3 Standard 에서 S3 Intelligent-Tiering 으로 전환할 수 있습니다. 
참조 URL: 
1 https://aws.amazon.com/s3/storage-classes/intelligent-tiering/ 
2 https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-intelligent-tiering.html 
3 https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering-overview.html 
Q470 
한 회사에 IPv6 주소를 사용하여 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션이 있습니다. 
애플리케이션은 인터넷을 사용하여 다른 외부 애플리케이션과의 통신을 시작해야 합니다. 그러나 
회사의 보안 정책에 따르면 외부 서비스는 EC2 인스턴스에 대한 연결을 시작할 수 없습니다. 
솔루션 설계자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까? 
A. NAT 게이트웨이를 생성하고 이를 서브넷 라우팅 테이블의 대상으로 만듭니다. 
B. 인터넷 게이트웨이를 만들고 이를 서브넷의 라우팅 테이블 대상으로 만듭니다. 
C. 가상 프라이빗 게이트웨이를 만들고 이를 서브넷의 라우팅 테이블 대상으로 만듭니다. 
D. 외부 전용 인터넷 게이트웨이를 만들고 이를 서브넷 라우팅 테이블의 대상으로 만듭니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109334-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
외부 전용 인터넷 게이트웨이는 VPC 의 인스턴스에서 인터넷으로 IPv6 을 통한 아웃바운드 통신을 
허용하고 인터넷이 인스턴스와의 IPv6 연결을 시작하지 못하도록 하는 VPC 구성 요소입니다. 
이것은 회사의 보안 정책 및 요구 사항을 충족합니다. 외부 전용 인터넷 게이트웨이를 사용하려면 
IPv6 인터넷 트래픽(::/0)을 외부 전용 인터넷 게이트웨이로 라우팅하는 경로를 서브넷의 라우팅 
테이블에 추가해야 합니다. 
참조 URL: 
1 https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html 
2 https://dev.to/aws-builders/what-is-an-egress-only-internet-gateways-in-aws-7gp 
3 https://docs.aws.amazon.com/vpc/latest/userguide/route-table-options.html 
Q471 
회사에서 VPC 의 컨테이너에서 실행되는 애플리케이션을 만들고 있습니다. 애플리케이션은 
Amazon S3 버킷에 데이터를 저장하고 액세스합니다. 개발 단계에서 애플리케이션은 매일 Amazon 
S3 에 1TB 의 데이터를 저장하고 액세스합니다. 회사는 비용을 최소화하고 가능한 한 트래픽이 
인터넷을 통과하지 못하도록 막고자 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. S3 버킷에 대해 S3 Intelligent-Tiering 을 활성화합니다. 
B. S3 버킷에 대해 S3 Transfer Acceleration 을 활성화합니다. 
C. Amazon S3 용 게이트웨이 VPC 엔드포인트를 생성합니다. 이 엔드포인트를 VPC 의 모든 라우팅 
테이블과 연결합니다. 
D. VPC 에서 Amazon S3 에 대한 인터페이스 엔드포인트를 생성합니다. 이 엔드포인트를 VPC 의 
모든 라우팅 테이블과 연결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109453-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon S3 용 게이트웨이 VPC 엔드포인트는 인터넷 게이트웨이나 NAT 디바이스가 필요하지 않은 
VPC 와 Amazon S3 간의 프라이빗 연결을 가능하게 합니다. 이렇게 하면 비용이 최소화되고 
트래픽이 인터넷을 통과하는 것을 방지할 수 있습니다. 게이트웨이 VPC 엔드포인트는 트래픽을 
비공개로 Amazon S31 로 라우팅하기 위해 접두사 목록을 VPC 라우팅 테이블의 라우팅 대상으로 
사용합니다. 엔드포인트를 VPC 의 모든 라우팅 테이블과 연결하면 모든 서브넷이 엔드포인트를 
통해 Amazon S3 에 액세스할 수 있습니다. 
옵션 A 는 S3 Intelligent-Tiering 이 변화하는 액세스 패턴을 기반으로 두 액세스 계층 간에 객체를 
자동으로 이동하여 스토리지 비용을 최적화하는 스토리지 클래스이기 때문에 올바르지 않습니다. 
VPC 와 Amazon S3 간의 네트워크 트래픽에는 영향을 미치지 않습니다. 
옵션 B 는 올바르지 않습니다. S3 Transfer Acceleration 은 클라이언트와 S3 버킷 간에 장거리에서 
파일을 빠르고 쉽고 안전하게 전송할 수 있는 기능이기 때문입니다. 트래픽이 인터넷을 통과하는 
것을 막지는 않습니다. 
옵션 D 는 Amazon S3 용 인터페이스 VPC 엔드포인트는 각 서브넷에 프라이빗 IP 주소가 있는 
탄력적 네트워크 인터페이스(ENI)가 필요한 AWS PrivateLink 에 의해 구동되기 때문에 올바르지 
않습니다. 이것은 솔루션에 복잡성과 비용을 추가합니다. 또한 인터페이스 VPC 엔드포인트는 
Amazon S3 에 대한 교차 리전 액세스를 지원하지 않습니다. 
참조 URL: 
https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html  
https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html#sc-dynami
cdata-access 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/transfer-acceleration.html 
https://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon
-s3/ 
Q472 
회사에 Amazon DynamoDB 기반 데이터 저장소가 있는 모바일 채팅 애플리케이션이 있습니다. 
사용자는 가능한 한 짧은 대기 시간으로 새 메시지를 읽기를 원합니다. 솔루션 설계자는 최소한의 
애플리케이션 변경이 필요한 최적의 솔루션을 설계해야 합니다. 
솔루션 설계자는 어떤 방법을 선택해야 합니까? 
A. 새 메시지 테이블에 대해 Amazon DynamoDB Accelerator(DAX)를 구성합니다. DAX 끝점을 
사용하도록 코드를 업데이트합니다. 
B. 증가된 읽기 로드를 처리하기 위해 DynamoDB 읽기 복제본을 추가합니다. 읽기 전용 복제본의 
읽기 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다. 
C. DynamoDB 의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다. 기존 
DynamoDB 엔드포인트를 계속 사용합니다. 
D. Redis 캐시용 Amazon ElastiCache 를 애플리케이션 스택에 추가합니다. DynamoDB 대신 Redis 
캐시 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109454-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
https://aws.amazon.com/premiumsupport/knowledge-center/dynamodb-high-latency/ 
Amazon DynamoDB Accelerator(DAX)는 DynamoDB 를 위한 완전 관리형 인 메모리 캐시로, 
DynamoDB 테이블의 성능을 최대 10 배까지 향상시키고 모든 규모에서 마이크로초 수준의 응답 
시간을 제공합니다. DynamoDB API 작업과 호환되며 use1 에 대한 최소한의 코드 변경이 
필요합니다. 새 메시지 테이블에 대해 DAX 를 구성함으로써 솔루션은 최소한의 애플리케이션 
변경으로 새 메시지를 읽는 대기 시간을 줄일 수 있습니다. 
1. 증가된 읽기 로드를 처리하기 위해 DynamoDB 읽기 replicas 를 추가합니다. 읽기 전용 
복제본의 읽기 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다. DynamoDB 는 읽기 전용 
복제본을 기능으로 지원하지 않으므로 이 솔루션은 작동하지 않습니다. 읽기 전용 복제본은 
DynamoDB 가 아닌 Amazon RDS 에서 사용할 수 있습니다. 
2. DynamoDB 의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다. 기존 
DynamoDB 엔드포인트를 계속 사용합니다. 읽기 용량 단위를 늘리면 성능이나 지연 시간이 
아니라 DynamoDB 의 처리량만 증가하므로 이 솔루션은 가능한 한 적은 지연 시간으로 새 
메시지를 읽어야 한다는 요구 사항을 충족하지 않습니다. 
3. Redis 용 Amazon ElastiCache 캐시를 애플리케이션 스택에 추가합니다. DynamoDB 대신 Redis 
캐시 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다. Redis 용 ElastiCache 를 
추가하려면 먼저 캐시 쿼리, DynamoDB 에 쓴 후 캐시 업데이트, 필요할 때 캐시 무효화와 같은 
캐싱 로직을 구현하기 위해 상당한 코드 변경이 필요하므로 이 솔루션은 최소한의 애플리케이션 
변경 요구 사항을 충족하지 않습니다. 
참조: https://aws.amazon.com/dynamodb/dax/ 
Q473 
회사는 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 인스턴스에서 웹 사이트를 
호스팅합니다. 웹 사이트는 정적 콘텐츠를 제공합니다. 웹 사이트 트래픽이 증가하고 있으며 
회사는 잠재적인 비용 증가에 대해 우려하고 있습니다. 
A. Amazon CloudFront 배포를 생성하여 엣지 로케이션에서 상태 파일을 캐싱합니다. 
B. Amazon ElastiCache 클러스터를 생성합니다. ALB 를 ElastiCache 클러스터에 연결하여 캐싱된 
파일을 제공합니다. 
C. AWS WAF 웹 ACL 을 생성하고 ALB 와 연결합니다. 웹 ACL 에 규칙을 추가하여 정적 파일을 
캐시합니다. 
D. 대체 AWS 리전에서 두 번째 ALB 를 생성합니다. 사용자 트래픽을 가장 가까운 리전으로 
라우팅하여 데이터 전송 비용을 최소화합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109455-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q474 
회사는 다른 리전의 워크로드와 격리된 워크로드를 지원하고 실행하기 위해 AWS 리전에 여러 
VPC 를 보유하고 있습니다. 최근 애플리케이션 시작 요구 사항으로 인해 회사의 VPC 는 모든 
지역의 다른 모든 VPC 와 통신해야 합니다. 
최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. VPC 피어링을 사용하여 단일 리전에서 VPC 통신을 관리합니다. 리전 간 VPC 피어링을 
사용하여 VPC 통신을 관리합니다. 
B. 모든 지역에서 AWS Direct Connect 게이트웨이를 사용하여 여러 지역에서 VPC 를 연결하고 
VPC 통신을 관리합니다. 
C. AWS Transit Gateway 를 사용하여 단일 지역에서 VPC 통신을 관리하고 지역 간 Transit 
Gateway 피어링을 사용하여 VPC 통신을 관리합니다. 
D. 모든 지역에서 AWS PrivateLink 를 사용하여 여러 지역에서 VPC 를 연결하고 VPC 통신을 
관리합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109659-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q475 
회사에서 Amazon Elastic Container Service(Amazon ECS)를 사용할 컨테이너화된 애플리케이션을 
설계하고 있습니다. 애플리케이션은 내구성이 뛰어나고 RPO(복구 지점 목표)가 8 시간인 다른 
AWS 리전에 데이터를 복구할 수 있는 공유 파일 시스템에 액세스해야 합니다. 파일 시스템은 
리전 내의 각 가용 영역에 탑재 대상을 제공해야 합니다. 
솔루션 설계자는 AWS Backup 을 사용하여 다른 리전에 대한 복제를 관리하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 다중 AZ 배포가 있는 Windows 파일 서버용 Amazon FSx 
B. 다중 AZ 배포가 있는 NetApp ONTAP 용 Amazon FSx 
C. 표준 스토리지 클래스가 있는 Amazon Elastic File System(Amazon EFS) 
D. OpenZFS 용 Amazon FSx 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109456-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q476 
회사는 가까운 장래에 급속한 성장을 기대하고 있습니다. 솔루션 설계자는 기존 사용자를 구성하고 
AWS 에서 새 사용자에게 권한을 부여해야 합니다. 솔루션 설계자는 IAM 그룹을 만들기로 
결정했습니다. 솔루션 설계자는 부서를 기반으로 IAM 그룹에 새 사용자를 추가합니다. 
새 사용자에게 권한을 부여하는 가장 안전한 추가 작업은 무엇입니까? 
A. 서비스 제어 정책(SCP)을 적용하여 액세스 권한을 관리합니다. 
B. 최소 권한이 있는 IAM 역할을 생성합니다. 역할을 IAM 그룹에 연결합니다. 
C. 최소 권한을 부여하는 IAM 정책을 생성합니다. 정책을 IAM 그룹에 연결합니다. 
D. IAM 역할을 생성합니다. 최대 권한을 정의하는 권한 경계와 역할을 연결합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109458-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
IAM 정책은 IAM 자격 증명(예: 사용자, 그룹 또는 역할)에 대한 권한을 정의하는 문서입니다. IAM 
정책을 사용하여 부서에 따라 기존 사용자 및 그룹에 권한을 부여할 수 있습니다. 최소 권한 
권한을 부여하는 IAM 정책을 생성할 수 있습니다. 즉, 사용자가 작업을 수행하는 데 필요한 
최소한의 권한만 부여한다는 의미입니다. 그런 다음 정책을 IAM 그룹에 연결하면 해당 그룹의 
모든 사용자에게 정책이 적용됩니다. 이 솔루션은 운영 비용을 줄이고 권한 구성 및 관리를 
단순화합니다. 
참조: 
https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html 
Q477 
그룹에는 Amazon S3 버킷을 나열하고 해당 버킷에서 객체를 삭제할 수 있는 권한이 필요합니다. 
관리자는 버킷에 대한 액세스 권한을 제공하기 위해 다음 IAM 정책을 생성하고 해당 정책을 
그룹에 적용했습니다. 그룹은 버킷의 객체를 삭제할 수 없습니다. 회사는 최소 권한 액세스 규칙을 
따릅니다. 
버킷 액세스를 수정하기 위해 솔루션 설계자가 정책에 추가해야 하는 설명은 무엇입니까? 
A.  
B.  
C.  
D.  
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109459-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q478 
로펌은 대중과 정보를 공유해야 합니다. 이 정보에는 공개적으로 읽을 수 있어야 하는 수백 개의 
파일이 포함됩니다. 지정된 미래 날짜 이전에 누구든지 파일을 수정하거나 삭제하는 것은 
금지됩니다. 
가장 안전한 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 정적 웹 사이트 호스팅용으로 구성된 Amazon S3 버킷에 모든 파일을 업로드합니다. 지정된 
날짜까지 S3 버킷에 액세스하는 모든 AWS 보안 주체에게 읽기 전용 IAM 권한을 부여합니다. 
B. S3 버전 관리가 활성화된 새 Amazon S3 버킷을 생성합니다. 지정된 날짜에 따라 보존 기간이 
있는 S3 Object Lock 을 사용하십시오. 정적 웹 사이트 호스팅을 위해 S3 버킷을 구성합니다. 
객체에 대한 읽기 전용 액세스를 허용하도록 S3 버킷 정책을 설정합니다. 
C. S3 버전 관리가 활성화된 새 Amazon S3 버킷을 생성합니다. 객체 수정 또는 삭제 시 AWS 
Lambda 함수를 실행하도록 이벤트 트리거를 구성합니다. 개체를 프라이빗 S3 버킷의 원래 
버전으로 바꾸도록 Lambda 함수를 구성합니다. 
D. 정적 웹 사이트 호스팅용으로 구성된 Amazon S3 버킷에 모든 파일을 업로드합니다. 파일이 
포함된 폴더를 선택합니다. 지정된 날짜에 따라 보존 기간이 있는 S3 Object Lock 을 사용하십시오. 
S3 버킷에 액세스하는 모든 AWS 보안 주체에게 읽기 전용 IAM 권한을 부여합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109725-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q479 
회사에서 필요한 인프라를 수동으로 프로비저닝하여 새 웹 사이트의 인프라 프로토타입을 만들고 
있습니다. 이 인프라에는 Auto Scaling 그룹, Application Load Balancer 및 Amazon RDS 
데이터베이스가 포함됩니다. 구성이 철저히 검증된 후 회사는 자동화된 방식으로 두 가용 영역에서 
개발 및 프로덕션 사용을 위한 인프라를 즉시 배포할 수 있는 기능을 원합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 
A. AWS Systems Manager 를 사용하여 2 개의 가용 영역에서 프로토타입 인프라를 복제하고 
프로비저닝합니다. 
B. 프로토타입 인프라를 가이드로 사용하여 인프라를 템플릿으로 정의합니다. AWS 
CloudFormation 으로 인프라를 배포하십시오. 
C. AWS Config 를 사용하여 프로토타입 인프라에서 사용되는 리소스 인벤토리를 기록합니다. AWS 
Config 를 사용하여 프로토타입 인프라를 두 개의 가용 영역에 배포합니다. 
D. AWS Elastic Beanstalk 를 사용하고 프로토타입 인프라에 대한 자동 참조를 사용하도록 구성하여 
2 개의 가용 영역에 새 환경을 자동으로 배포합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109461-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS CloudFormation 은 Auto Scaling 그룹, 로드 밸런서, 데이터베이스 등 원하는 모든 리소스를 
설명하는 템플릿을 사용하여 AWS 리소스를 모델링하고 설정할 수 있도록 도와주는 서비스입니다. 
AWS CloudFormation 을 사용하여 여러 환경과 리전에서 자동화되고 일관된 방식으로 인프라를 
배포할 수 있습니다. 또한 AWS CloudFormation 을 사용하여 인프라를 단일 단위로 업데이트하거나 
삭제할 수 있습니다. 
참조 URL: 
1 https://aws.amazon.com/cloudformation/ 
2 https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html 
3 
https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-whatis-concepts.html 
Q480 
비즈니스 애플리케이션은 Amazon EC2 에서 호스팅되며 암호화된 객체 스토리지에 Amazon S3 를 
사용합니다. 최고 정보 보안 책임자는 두 서비스 간의 애플리케이션 트래픽이 공용 인터넷을 
통과해서는 안 된다고 지시했습니다. 
규정 준수 요구 사항을 충족하기 위해 솔루션 설계자가 사용해야 하는 기능은 무엇입니까? 
A. AWS 키 관리 서비스(AWS KMS) 
B. VPC 엔드포인트 
C. 사설 서브넷 
D. 가상 프라이빗 게이트웨이 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109663-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
참고: 
https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints.html 
Q481 
회사는 AWS 클라우드에서 3 계층 웹 애플리케이션을 호스팅합니다. MySQL 용 다중 AZAmazon 
RDS 서버는 데이터베이스 계층을 형성합니다. Amazon ElastiCache 는 캐시 계층을 형성합니다. 
회사는 고객이 데이터베이스에 항목을 추가할 때 캐시의 데이터를 추가하거나 업데이트하는 캐싱 
전략을 원합니다. 캐시의 데이터는 항상 데이터베이스의 데이터와 일치해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 지연 로딩 캐싱 전략 구현 
B. write-through 캐싱 전략 구현 
C. 추가 TTL 캐싱 전략 구현 
D. AWS AppConfig 캐싱 전략 구현 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109462-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q482 
회사는 온프레미스 위치에서 Amazon S3 버킷으로 100GB 의 기록 데이터를 마이그레이션하려고 
합니다. 이 회사는 온프레미스에 100Mbps 인터넷 연결이 있습니다. 회사는 S3 버킷으로 전송되는 
데이터를 암호화해야 합니다. 회사는 새로운 데이터를 Amazon S3 에 직접 저장합니다. 
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. AWS CLI 에서 s3 sync 명령을 사용하여 데이터를 S3 버킷으로 직접 이동합니다. 
B. AWS DataSync 를 사용하여 온프레미스 위치에서 S3 버킷으로 데이터를 마이그레이션합니다. 
C. AWS Snowball 을 사용하여 데이터를 S3 버킷으로 이동합니다. 
D. 온프레미스 위치에서 AWS 로 IPsec VPN 을 설정합니다. AWS CLI 에서 s3 cp 명령을 사용하여 
데이터를 S3 버킷으로 직접 이동합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109490-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS DataSync 는 인터넷 또는 AWS Direct Connect 를 통해 온프레미스 스토리지와 AWS 스토리지 
서비스 간에 대량의 데이터를 온라인으로 쉽게 이동할 수 있게 해주는 데이터 전송 서비스입니다. 
DataSync 는 TLS 암호화를 사용하여 전송 중인 데이터를 자동으로 암호화하고 체크섬을 사용하여 
전송하는 동안 데이터 무결성을 확인합니다. DataSync 는 오픈 소스 도구보다 최대 10 배 빠르게 
데이터를 전송할 수 있으며 전송 예약, 모니터링 및 재개와 같은 작업을 단순화하고 자동화하여 
운영 오버헤드를 줄입니다. 
참조: 
https://aws.amazon.com/datasync/ 
Q483 
회사에서 Windows 컨테이너 아래의 .NET 6 Framework 에서 실행되는 Windows 작업을 
컨테이너화했습니다. 회사는 AWS 클라우드에서 이 작업을 실행하려고 합니다. 작업은 10 분마다 
실행됩니다. 작업의 실행 시간은 1 분에서 3 분 사이입니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 작업의 컨테이너 이미지를 기반으로 AWS Lambda 함수를 생성합니다. 10 분마다 함수를 
호출하도록 Amazon EventBridge 를 구성합니다. 
B. AWS Batch 를 사용하여 AWS Fargate 리소스를 사용하는 작업을 생성합니다. 10 분마다 
실행되도록 작업 일정을 구성합니다. 
C. AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS)를 사용하여 작업을 
실행합니다. 10 분마다 실행할 작업의 컨테이너 이미지를 기반으로 예약된 작업을 만듭니다. 
D. AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS)를 사용하여 작업을 
실행합니다. 작업의 컨테이너 이미지를 기반으로 독립 실행형 작업을 생성합니다. Windows 작업 
스케줄러를 사용하여 10 분마다 작업을 실행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109463-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q484 
한 회사가 많은 독립 실행형 AWS 계정에서 통합된 다중 계정 아키텍처로 이동하려고 합니다. 이 
회사는 다양한 사업부에 대해 많은 새 AWS 계정을 생성할 계획입니다. 회사는 중앙 집중식 회사 
디렉터리 서비스를 사용하여 이러한 AWS 계정에 대한 액세스를 인증해야 합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 작업 조합은 무엇입니까? (2 개 
선택) 
A. 모든 기능을 켠 상태에서 AWS Organizations 에 새 조직을 만듭니다. 조직에서 새 AWS 계정을 
생성합니다. 
B. Amazon Cognito 자격 증명 풀을 설정합니다. Amazon Cognito 인증을 수락하도록 AWS IAM 
Identity Center(AWS Single Sign-On)를 구성합니다. 
C. AWS 계정을 관리하기 위해 서비스 제어 정책(SCP)을 구성합니다. AWS IAM Identity 
Center(AWS Single Sign-On)를 AWS Directory Service 에 추가합니다. 
D. AWS Organizations 에서 새 조직을 생성합니다. AWS Directory Service 를 직접 사용하도록 
조직의 인증 메커니즘을 구성합니다. 
E. 조직에서 AWS IAM Identity Center(AWS Single Sign-On)를 설정합니다. IAM Identity Center 를 
구성하고 회사의 회사 디렉터리 서비스와 통합합니다. 
Answer: A, E 
https://www.examtopics.com/discussions/amazon/view/109467-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
AWS Organizations 는 사용자가 여러 AWS 계정을 중앙에서 관리하고 제어할 수 있도록 도와주는 
서비스입니다. 이를 통해 사용자는 비즈니스 요구 사항 또는 기타 기준에 따라 계정을 그룹화하는 
조직 단위(OU)를 만들 수 있습니다. 또한 사용자는 서비스 제어 정책(SCP)을 정의하고 OU 또는 
계정에 연결하여 계정에서 수행할 수 있는 작업을 제한할 수 있습니다. 모든 기능을 켠 상태에서 
AWS Organizations 에 새 조직을 생성하면 이 솔루션은 서로 다른 비즈니스 단위의 새 AWS 
계정을 통합하고 관리할 수 있습니다. AWS IAM Identity Center(이전에는 AWS Single 
Sign-On 이라고 함)는 모든 AWS 계정 및 클라우드 애플리케이션에 대한 Single Sign-On 액세스를 
제공하는 서비스입니다. AWS Directory Service 를 통해 Microsoft Active Directory 와 연결하여 해당 
디렉터리의 사용자가 기존 Active Directory 사용자 이름과 암호를 사용하여 맞춤형 AWS 액세스 
포털에 로그인할 수 있도록 합니다. AWS 액세스 포털에서 사용자는 권한이 있는 모든 AWS 계정 
및 클라우드 애플리케이션에 액세스할 수 있습니다 2. 조직에 IAM Identity Center 를 설정하고 
회사의 회사 디렉터리 서비스와 통합함으로써 솔루션은 중앙 집중식 회사 디렉터리 서비스를 
사용하여 이러한 AWS 계정에 대한 액세스를 인증할 수 있습니다. 
1. Amazon Cognito 자격 증명 풀을 설정합니다. Amazon Cognito 인증을 수락하도록 AWS IAM 
Identity Center(AWS Single Sign-On)를 구성합니다. 이 솔루션은 중앙 집중식 기업 디렉터리 
서비스를 사용하여 이러한 AWS 계정에 대한 액세스 인증 요구 사항을 충족하지 않습니다. 
Amazon Cognito 는 웹 및 모바일 애플리케이션에 대한 사용자 가입, 로그인 및 액세스 제어를 
제공하는 서비스이기 때문입니다. 기업 디렉토리 서비스. 
2. 서비스 제어 정책(SCP)을 구성하여 AWS 계정을 관리합니다. AWS IAM Identity Center(AWS 
Single Sign-On)를 AWS Directory Service 에 추가합니다. SCP 는 계정 자체를 관리하는 것이 
아니라 조직의 계정이 수행할 수 있는 작업을 제한하는 데 사용되기 때문에 이 솔루션은 작동하지 
않습니다 1. 또한 IAM Identity Center 는 AWS Directory Service 를 통해 Microsoft Active Directory 와 
연결하는 별도의 서비스이므로 AWS Directory Service 에 추가할 수 없습니다. 
3. AWS Organizations 에서 새 조직을 생성합니다. AWS Directory Service 를 직접 사용하도록 
조직의 인증 메커니즘을 구성합니다. AWS Organizations 에는 AWS Directory Service 를 직접 
사용할 수 있는 인증 메커니즘이 없기 때문에 이 솔루션은 작동하지 않습니다. AWS 
Organizations 는 IAM Identity Center 를 사용하여 조직의 계정에 대한 Single Sign-On 액세스를 
제공합니다. 
참조: 
https://docs.aws.amazon.com/organizations/latest/userguide/orgs_integrate_services.html 
Q485 
회사는 오래된 뉴스 영상에서 AWS 에 비디오 아카이브를 저장할 수 있는 솔루션을 찾고 있습니다. 
회사는 비용을 최소화해야 하며 이러한 파일을 복원할 필요가 거의 없습니다. 파일이 필요할 때 
최대 5 분 내에 사용할 수 있어야 합니다. 
가장 비용 효율적인 솔루션은 무엇입니까? 
A. 비디오 아카이브를 Amazon S3 Glacier 에 저장하고 긴급 검색을 사용합니다. 
B. 비디오 아카이브를 Amazon S3 Glacier 에 저장하고 표준 검색을 사용합니다. 
C. 비디오 아카이브를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 저장합니다. 
D. 비디오 아카이브를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)에 저장합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109470-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q486 
한 회사가 AWS 에서 3 계층 애플리케이션을 구축하고 있습니다. 프레젠테이션 계층은 정적 웹 
사이트를 제공합니다. 논리 계층은 컨테이너화된 애플리케이션입니다. 이 응용 프로그램은 관계형 
데이터베이스에 데이터를 저장합니다. 이 회사는 배포를 단순화하고 운영 비용을 절감하기를 
원합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. Amazon S3 를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 위해 AWS Fargate 와 함께 
Amazon Elastic Container Service(Amazon ECS)를 사용합니다. 데이터베이스에 대해 관리형 
Amazon RDS 클러스터를 사용합니다. 
B. Amazon CloudFront 를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 위해 Amazon 
EC2 와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용합니다. 데이터베이스에 대해 
관리형 Amazon RDS 클러스터를 사용합니다. 
C. Amazon S3 를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 위해 AWS Fargate 와 함께 
Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다. 데이터베이스에 대해 관리형 
Amazon RDS 클러스터를 사용합니다. 
D. Amazon EC2 예약 인스턴스를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 위해 
Amazon EC2 와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다. 
데이터베이스에 대해 관리형 Amazon RDS 클러스터를 사용합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109664-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon S3 는 업계 최고의 확장성, 데이터 가용성, 보안 및 성능을 제공하는 객체 스토리지 
서비스입니다. Amazon S3 를 사용하여 HTML 파일, 이미지, 비디오 등과 같은 웹 사이트용 정적 
콘텐츠를 호스팅할 수 있습니다. Amazon Elastic Container Service(Amazon ECS)는 AWS 에서 
컨테이너화된 애플리케이션을 실행하고 확장할 수 있는 완전 관리형 컨테이너 오케스트레이션 
서비스입니다. . 
AWS Fargate 는 Amazon ECS 및 Amazon EKS 모두에서 작동하는 컨테이너용 서버리스 컴퓨팅 
엔진입니다. Fargate 를 사용하면 서버를 프로비저닝하고 관리할 필요가 없으므로 애플리케이션 
구축에 쉽게 집중할 수 있습니다. 컨테이너화된 애플리케이션 논리 계층의 컴퓨팅 성능을 위해 
AWS Fargate 와 함께 Amazon ECS 를 사용할 수 있습니다. Amazon RDS 는 클라우드에서 관계형 
데이터베이스를 쉽게 설정, 운영 및 확장할 수 있게 해주는 관리형 관계형 데이터베이스 
서비스입니다. 애플리케이션의 데이터베이스 계층에 대해 관리형 Amazon RDS 클러스터를 사용할 
수 있습니다. 이 솔루션은 배포를 단순화하고 3 계층 애플리케이션의 운영 비용을 줄여줍니다. 
참조: 
https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html 
https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html 
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html 
Q487 
회사에서 해당 애플리케이션을 위한 스토리지 솔루션을 찾고 있습니다. 솔루션은 가용성과 
확장성이 높아야 합니다. 또한 솔루션은 기본 프로토콜을 통해 AWS 및 온프레미스의 여러 Linux 
인스턴스에 의해 마운트될 수 있고 최소 크기 요구 사항이 없는 파일 시스템으로 작동해야 합니다. 
회사는 온프레미스 네트워크에서 VPC 로 액세스하기 위해 사이트 간 VPN 을 설정했습니다. 
이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까? 
A. Amazon FSx 다중 AZ 배포 
B. Amazon Elastic Block Store(Amazon EBS) 다중 연결 볼륨 
C. 탑재 대상이 여러 개인 Amazon Elastic File System(Amazon EFS) 
D. 단일 탑재 대상 및 여러 액세스 지점이 있는 Amazon Elastic File System(Amazon EFS) 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109665-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q488 
4 년 차 미디어 회사는 AWS 계정을 구성하기 위해 AWS Organizations 모든 기능 기능 세트를 
사용하고 있습니다. 회사의 재무 팀에 따르면 회원 계정의 청구 정보는 회원 계정의 루트 사용자를 
포함하여 누구도 액세스할 수 없어야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 모든 재무 팀 사용자를 IAM 그룹에 추가합니다. Billing 이라는 AWS 관리형 정책을 그룹에 
연결합니다. 
B. 루트 사용자를 포함한 모든 사용자의 청구 정보에 대한 액세스를 거부하는 자격 증명 기반 
정책을 첨부합니다. 
C. 청구 정보에 대한 액세스를 거부하는 서비스 제어 정책(SCP)을 만듭니다. 루트 조직 
단위(OU)에 SCP 를 연결합니다. 
D. 조직의 모든 기능 기능 집합에서 조직 통합 결제 기능 집합으로 변환합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109509-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
서비스 제어 정책(SCP): SCP 는 AWS Organizations 의 필수적인 부분이며 이를 통해 AWS 
Organization 내 조직 단위(OU)에 대한 세분화된 권한을 설정할 수 있습니다. SCP 는 루트 
사용자를 포함하여 멤버 계정에 부여할 수 있는 최대 권한에 대한 중앙 제어를 제공합니다. 청구 
정보에 대한 액세스 거부: SCP 를 만들어 루트 OU 에 연결하면 조직 내 모든 계정의 청구 정보에 
대한 액세스를 명시적으로 거부할 수 있습니다. SCP 는 청구 관련 서비스를 포함하여 다양한 AWS 
서비스 및 작업에 대한 액세스를 제한하는 데 사용할 수 있습니다. 세분화된 제어: SCP 를 
사용하면 조직 단위 수준에서 특정 권한 및 제한을 정의할 수 있습니다. 루트 OU 에서 청구 
정보에 대한 액세스를 거부하면 루트 사용자를 포함한 어떤 멤버 계정도 청구 정보에 액세스할 수 
없습니다. 
Q489 
전자상거래 회사는 온프레미스 웨어하우스 솔루션과 통합된 AWS 클라우드에서 애플리케이션을 
실행합니다. 이 회사는 Amazon Simple Notification Service(Amazon SNS)를 사용하여 주문 
메시지를 온프레미스 HTTPS 엔드포인트로 보내 창고 애플리케이션이 주문을 처리할 수 있도록 
합니다. 로컬 데이터 센터 팀에서 일부 주문 메시지가 수신되지 않은 것을 감지했습니다. 
솔루션 설계자는 전달되지 않은 메시지를 보관하고 최대 14 일 동안 메시지를 분석해야 합니다. 
최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 보존 기간이 14 일인 Amazon Kinesis Data Stream 대상이 있는 Amazon SNS 배달 못한 편지 
대기열을 구성합니다. 
B. 애플리케이션과 Amazon SNS 사이에 보존 기간이 14 일인 Amazon Simple Queue 
Service(Amazon SQS) 대기열을 추가합니다. 
C. 보존 기간이 14 일인 Amazon Simple Queue Service(Amazon SQS) 대상이 있는 Amazon SNS 
데드 레터 대기열을 구성합니다. 
D. 보존 기간이 14 일로 설정된 TTL 속성이 있는 Amazon DynamoDB 대상이 있는 Amazon SNS 
데드 레터 대기열을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109637-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q490 
게임 회사는 Amazon DynamoDB 를 사용하여 지리적 위치, 플레이어 데이터 및 순위표와 같은 
사용자 정보를 저장합니다. 회사는 최소한의 코딩으로 Amazon S3 버킷에 대한 지속적인 백업을 
구성해야 합니다. 백업은 애플리케이션의 가용성에 영향을 미치지 않아야 하며 테이블에 대해 
정의된 읽기 용량 단위(RCU)에 영향을 주지 않아야 합니다. 
어떤 솔루션이 이러한 요구 사항을 충족합니까? 
A. Amazon EMR 클러스터를 사용하십시오. Apache Hive 작업을 생성하여 Amazon S3 에 데이터를 
백업합니다. 
B. 연속 백업을 통해 DynamoDB 에서 Amazon S3 로 직접 데이터를 내보냅니다. 테이블에 대해 
지정 시간 복구를 설정합니다. 
C. Amazon DynamoDB 스트림을 구성합니다. 스트림을 사용하고 데이터를 Amazon S3 버킷으로 
내보내는 AWS Lambda 함수를 생성합니다. 
D. 정기적으로 데이터베이스 테이블에서 Amazon S3 로 데이터를 내보내는 AWS Lambda 함수를 
생성합니다. 테이블에 대해 지정 시간 복구를 설정합니다. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109577-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
참고: 
https://aws.amazon.com/ko/blogs/database/dynamodb-streams-use-cases-and-design-patter
ns/ 
https://repost.aws/ko/knowledge-center/back-up-dynamodb-s3 
Q491 
솔루션 설계자는 은행에 대한 신용 카드 데이터 유효성(검증) 검사 요청을 처리하기 위해 비동기식 
애플리케이션을 설계하고 있습니다. 애플리케이션은 안전해야 하며 각 요청을 한 번 이상 처리할 
수 있어야 합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. AWS Lambda 이벤트 소스 매핑을 사용하십시오. Amazon Simple Queue Service(Amazon SQS) 
표준 대기열을 이벤트 소스로 설정합니다. 암호화에 AWS Key Management Service(SSE-KMS)를 
사용합니다. Lambda 실행 역할에 대한 kms:Decrypt 권한을 추가합니다. 
B. AWS Lambda 이벤트 소스 매핑을 사용합니다. Amazon Simple Queue Service(Amazon SQS) 
FIFO 대기열을 이벤트 소스로 사용합니다. 암호화에 SQS 관리형 암호화 키(SSE-SQS)를 
사용합니다. Lambda 함수에 대한 암호화 키 호출 권한을 추가합니다. 
C. AWS Lambda 이벤트 소스 매핑을 사용합니다. Amazon Simple Queue Service(Amazon SQS) 
FIFO 대기열을 이벤트 소스로 설정합니다. AWS KMS 키(SSE-KMS)를 사용합니다. Lambda 실행 
역할에 대한 kms:Decrypt 권한을 추가합니다. 
D. AWS Lambda 이벤트 소스 매핑을 사용합니다. Amazon Simple Queue Service(Amazon SQS) 
표준 대기열을 이벤트 소스로 설정합니다. 암호화에 AWS KMS 키(SSE-KMS)를 사용합니다. 
Lambda 함수에 대한 암호화 키 호출 권한을 추가합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109513-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q492 
회사에 개발 작업을 위한 여러 AWS 계정이 있습니다. 일부 직원은 지속적으로 대형 Amazon EC2 
인스턴스를 사용하므로 회사가 개발 계정에 대한 연간 예산을 초과하게 됩니다. 회사는 이러한 
계정에서 AWS 리소스 생성을 중앙에서 제한하려고 합니다. 
최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 승인된 EC2 생성 프로세스를 사용하는 AWS Systems Manager 템플릿을 개발합니다. 승인된 
Systems Manager 템플릿을 사용하여 EC2 인스턴스를 프로비저닝합니다. 
B. AWS Organizations 를 사용하여 계정을 조직 단위(OU)로 구성합니다. 서비스 제어 정책(SCP)을 
정의하고 연결하여 EC2 인스턴스 유형의 사용을 제어합니다. 
C. EC2 인스턴스가 생성될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge 규칙을 
구성합니다. 허용되지 않는 EC2 인스턴스 유형을 중지합니다. 
D. 직원이 허용되는 EC2 인스턴스 유형을 생성할 수 있도록 AWS Service Catalog 제품을 
설정합니다. 직원이 서비스 카탈로그 제품을 사용해야만 EC2 인스턴스를 배포할 수 있는지 
확인하십시오. 
Answer: B 
https://www.examtopics.com/discussions/amazon/view/109638-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
동적 조정은 수요 또는 부하에 따라 Auto Scaling 그룹의 EC2 인스턴스 수를 자동으로 조정하는 
일종의 자동 조정입니다. 지정된 지표가 임계값을 초과하면 CloudWatch 경보를 사용하여 조정 
작업을 트리거합니다. 필요에 따라 확장(인스턴스 추가) 또는 축소(인스턴스 제거)할 수 있습니다 1. 
솔루션은 동적 확장을 사용하여 갑작스러운 트래픽 증가 중에 가장 비용 효율적으로 애플리케이션 
성능을 유지할 수 있습니다. 
1. 수동 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 수동 확장은 사용자가 CLI 또는 
콘솔을 통해 인스턴스 수를 수동으로 늘리거나 줄여야 하므로 이 솔루션은 트래픽이 갑자기 
증가하는 동안 애플리케이션 성능을 유지해야 하는 요구 사항을 충족하지 않습니다. 수요나 부하의 
변화에 자동으로 반응하지 않습니다. 
2. 예측 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 이 솔루션은 예측 확장이 기계 
학습 및 인공 지능 도구를 사용하여 트래픽 부하를 평가하고 더 많거나 적은 리소스가 필요할 
때를 예상하므로 대부분의 비용 효율성 요구 사항을 충족하지 않습니다. 주어진 시간에 실제 수요 
또는 로드와 일치하지 않을 수 있는 예측을 기반으로 예약된 조정 작업을 수행합니다. 예측 조정은 
예측 가능한 트래픽 패턴이 있거나 트래픽 부하의 알려진 변경 사항이 있는 시나리오에 더 
적합합니다. 
3. 일정 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 일정 조정은 사용자가 예약한 
특정 시간에 조정 작업을 수행하므로 이 솔루션은 트래픽이 갑자기 증가하는 동안 애플리케이션 
성능을 유지해야 하는 요구 사항을 충족하지 않습니다. 수요나 부하의 변화에 자동으로 반응하지 
않습니다. 일정 조정은 하루 중 특정 시간에 예측 가능한 트래픽 감소 또는 급증이 있는 
시나리오에 더 적합합니다. 
참조: 
https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-ondemand.html 
Q493 
한 회사에서 AI(인공 지능)를 사용하여 고객 서비스 통화 품질을 확인하려고 합니다. 회사는 현재 
영어를 포함하여 4 개 언어로 통화를 관리합니다. 회사는 앞으로 새로운 언어를 제공할 것입니다. 
회사는 기계 학습(ML) 모델을 정기적으로 유지 관리할 리소스가 없습니다. 
회사는 고객 서비스 통화 녹음에서 서면 감정 분석 보고서를 작성해야 합니다. 고객 서비스 통화 
녹음 텍스트는 영어로 번역되어야 합니다. 
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3 개 선택) 
A. Amazon Comprehend 를 사용하여 오디오 녹음을 영어로 번역하십시오. 
B. Amazon Lex 를 사용하여 작성된 감정 분석 보고서를 생성합니다. 
C. Amazon Polly 를 사용하여 오디오 녹음을 텍스트로 변환합니다. 
D. Amazon Transcribe 를 사용하여 모든 언어의 오디오 녹음을 텍스트로 변환합니다. 
E. Amazon Translate 를 사용하여 모든 언어의 텍스트를 영어로 번역합니다. 
F. Amazon Comprehend 를 사용하여 감정 분석 보고서를 생성합니다. 
Answer: D, E, F 
https://www.examtopics.com/discussions/amazon/view/109639-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
이러한 답변은 모든 언어로 된 고객 서비스 통화 녹음에서 서면 감정 분석 보고서를 작성하고 
이를 영어로 번역하는 요구 사항을 충족하므로 정확합니다. Amazon Transcribe 는 고급 기계 학습 
기술을 사용하여 오디오 파일의 음성을 인식하고 텍스트로 변환하는 서비스입니다. Amazon 
Transcribe 를 사용하여 모든 언어의 오디오 녹음을 텍스트로 변환하고 소스 오디오의 언어 코드를 
지정할 수 있습니다. Amazon Translate 는 빠르고 고품질의 저렴한 언어 번역을 제공하는 신경망 
기계 번역 서비스입니다. Amazon Translate 를 사용하여 모든 언어의 텍스트를 영어로 번역하고 
소스 및 대상 언어 코드를 지정할 수 있습니다. Amazon Comprehend 는 기계 학습을 사용하여 
텍스트에서 통찰력과 관계를 찾는 자연어 처리(NLP) 서비스입니다. Amazon Comprehend 를 
사용하여 텍스트가 긍정적인지, 부정적인지, 중립적인지 또는 혼합되어 있는지 판단하는 감정 분석 
보고서를 생성할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html 
https://docs.aws.amazon.com/translate/latest/dg/what-is.html 
https://docs.aws.amazon.com/comprehend/latest/dg/how-sentiment.html 
Q494 
회사는 Amazon EC2 인스턴스를 사용하여 내부 시스템을 호스팅합니다. 배포 작업의 일부로 
관리자는 AWS CLI 를 사용하여 EC2 인스턴스를 종료하려고 합니다. 그러나 관리자는 403(액세스 
거부) 오류 메시지를 받습니다. 
관리자는 다음 IAM 정책이 연결된 IAM 역할을 사용하고 있습니다. 
실패한 요청의 원인은 무엇입니까? 
A. EC2 인스턴스에는 Deny 문이 포함된 리소스 기반 정책이 있습니다. 
B. 정책 설명에 주체가 지정되지 않았습니다. 
C. "Action" 필드는 EC2 인스턴스를 종료하는 데 필요한 조치를 부여하지 않습니다. 
D. EC2 인스턴스 종료 요청은 CIDR 블록 192.0.2.0/24 또는 203.0.113.0/24 에서 시작되지 
않습니다. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109727-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q495 
회사에서 내부 감사를 실시하고 있습니다. 회사는 회사의 AWS Lake Formation 데이터 레이크와 
연결된 Amazon S3 버킷의 데이터에 민감한 고객 또는 직원 데이터가 포함되지 않도록 하려고 
합니다. 회사는 개인 식별 정보(PII) 또는 여권 번호 및 신용 카드 번호를 포함한 금융 정보를 
검색하려고 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 계정에서 AWS Audit Manager 를 구성합니다. 감사를 위해 PCI DSS(Payment Card Industry Data 
Security Standards)를 선택합니다. 
B. S3 버킷에서 Amazon S3 인벤토리 구성 인벤토리를 쿼리하도록 Amazon Athena 를 구성합니다. 
C. 필요한 데이터 유형에 대해 관리형 식별자를 사용하는 데이터 검색 작업을 실행하도록 Amazon 
Macie 를 구성합니다. 
D. Amazon S3 Select 를 사용하여 S3 버킷에서 보고서를 실행합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109666-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
Amazon Macie 는 기계 학습 및 패턴 일치를 사용하여 AWS 에서 중요한 데이터를 검색하고 
보호하는 완전 관리형 데이터 보안 및 데이터 개인 정보 보호 서비스입니다. Macie 는 다양한 
유형의 PII 또는 금융 정보(예: 여권 번호 및 신용 카드 번호)에 대해 관리형 식별자를 사용하는 
데이터 검색 작업을 실행할 수 있습니다. Macie 는 또한 데이터의 잠재적인 문제나 위험을 
경고하는 결과를 생성할 수 있습니다. 
참조: 
https://docs.aws.amazon.com/macie/latest/userguide/macie-identifiers.html 
Q496 
회사는 온프레미스 서버를 사용하여 애플리케이션을 호스팅합니다. 회사의 저장 용량이 부족합니다. 
애플리케이션은 블록 스토리지와 NFS 스토리지를 모두 사용합니다. 회사는 기존 애플리케이션을 
재설계하지 않고 로컬 캐싱을 지원하는 고성능 솔루션이 필요합니다. 
이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? (2 개 
선택) 
A. Amazon S3 를 온프레미스 서버에 파일 시스템으로 탑재합니다. 
B. NFS 스토리지를 대체할 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 
C. AWS Snowball Edge 를 배포하여 온프레미스 서버에 NFS 마운트를 프로비저닝합니다. 
D. 블록 스토리지를 대체할 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. 
E. Amazon Elastic File System(Amazon EFS) 볼륨을 배포하고 온프레미스 서버에 탑재합니다. 
Answer: B, D 
https://www.examtopics.com/discussions/amazon/view/109552-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
https://aws.amazon.com/storagegateway/file/ 
파일 게이트웨이는 애플리케이션 데이터 파일과 백업 이미지를 Amazon S3 클라우드 스토리지에 
내구성 있는 개체로 저장하기 위해 클라우드에 원활하게 연결할 수 있는 방법을 제공합니다. 파일 
게이트웨이는 로컬 캐싱을 통해 Amazon S3 의 데이터에 대한 SMB 또는 NFS 기반 액세스를 
제공합니다. 온프레미스 애플리케이션과 S3 객체 스토리지에 대한 파일 프로토콜 액세스가 필요한 
Amazon EC2 기반 애플리케이션에 사용할 수 있습니다. 
https://aws.amazon.com/storagegateway/volume/ 
볼륨 게이트웨이는 온프레미스 애플리케이션에 클라우드 지원 iSCSI 블록 스토리지 볼륨을 
제공합니다. 
볼륨 게이트웨이는 사용자를 대신하여 Amazon S3 에 온프레미스 데이터를 저장하고 관리하며 캐시 
모드 또는 저장 모드에서 작동합니다. 캐싱된 볼륨 게이트웨이 모드에서 기본 데이터는 Amazon 
S3 에 저장되는 반면 자주 액세스하는 데이터는 짧은 지연 시간 액세스를 위해 캐시에 로컬로 
유지됩니다. 
Q497 
회사에는 동일한 AWS 리전의 Amazon S3 버킷에서 대량의 데이터를 읽고 쓰는 서비스가 있습니다. 
이 서비스는 VPC 의 프라이빗 서브넷 내 Amazon EC2 인스턴스에 배포됩니다. 이 서비스는 퍼블릭 
서브넷의 NAT 게이트웨이를 통해 Amazon S3 와 통신합니다. 그러나 회사는 데이터 출력 비용을 
줄일 수 있는 솔루션을 원합니다. 
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? 
A. 퍼블릭 서브넷에서 전용 EC2 NAT 인스턴스를 프로비저닝합니다. 이 인스턴스의 탄력적 
네트워크 인터페이스를 모든 S3 트래픽의 대상으로 사용하도록 프라이빗 서브넷에 대한 라우팅 
테이블을 구성합니다. 
B. 프라이빗 서브넷에서 전용 EC2 NAT 인스턴스를 프로비저닝합니다. 이 인스턴스의 탄력적 
네트워크 인터페이스를 모든 S3 트래픽의 대상으로 사용하도록 퍼블릭 서브넷에 대한 라우팅 
테이블을 구성합니다. 
C. VPC 게이트웨이 엔드포인트를 프로비저닝합니다. 게이트웨이 엔드포인트를 모든 S3 트래픽의 
경로로 사용하도록 프라이빗 서브넷에 대한 경로 테이블을 구성합니다. 
D. 두 번째 NAT 게이트웨이를 프로비저닝합니다. 이 NAT 게이트웨이를 모든 S3 트래픽의 
대상으로 사용하도록 프라이빗 서브넷에 대한 라우팅 테이블을 구성합니다. 
Answer: C 
https://www.examtopics.com/discussions/amazon/view/109667-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명: 
이를 통해 회사는 VPC 의 Amazon EC2 인스턴스에서 Amazon S3 에 액세스하기 위한 데이터 출력 
비용을 줄일 수 있습니다. 회사는 VPC 게이트웨이 엔드포인트를 프로비저닝함으로써 VPC 와 S3 
간의 프라이빗 연결을 활성화할 수 있습니다. 게이트웨이 엔드포인트를 모든 S3 트래픽의 경로로 
사용하도록 프라이빗 서브넷의 라우팅 테이블을 구성함으로써 회사는 데이터 처리 및 데이터 전송 
비용을 청구하는 NAT 게이트웨이 사용을 피할 수 있습니다. 
Q498 
회사는 Amazon S3 를 사용하여 고해상도 사진을 S3 버킷에 저장합니다. 애플리케이션 변경을 
최소화하기 위해 회사는 사진을 S3 개체의 최신 버전으로 저장합니다. 회사는 사진의 가장 최근 
버전 두 개만 유지하면 됩니다. 
회사는 비용을 줄이고 싶어합니다. 회사는 S3 버킷을 큰 비용으로 식별했습니다. 
최소한의 운영 오버헤드로 S3 비용을 줄이는 솔루션은 무엇입니까? 
A. S3 수명 주기를 사용하여 만료된 객체 버전을 삭제하고 가장 최근 버전 2 개를 유지합니다. 
B. AWS Lambda 함수를 사용하여 이전 버전을 확인하고 가장 최근 버전 2 개를 제외한 모든 
버전을 삭제합니다. 
C. S3 배치 작업을 사용하여 최신이 아닌 객체 버전을 삭제하고 가장 최근 버전 2 개만 
유지합니다. 
D. S3 버킷에서 버전 관리를 비활성화하고 가장 최근 버전 2 개를 유지합니다. 
Answer: A 
https://www.examtopics.com/discussions/amazon/view/109668-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
Q499 
회사는 1Gbps AWS Direct Connect 연결 비용을 최소화해야 합니다. 회사의 평균 연결 사용률은 
10% 미만입니다. 솔루션 설계자는 보안을 손상시키지 않으면서 비용을 절감할 솔루션을 추천해야 
합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 
A. 새로운 1Gbps Direct Connect 연결을 설정합니다. 다른 AWS 계정과 연결을 공유합니다. 
B. AWS Management Console 에서 새로운 200Mbps Direct Connect 연결을 설정합니다. 
C. 1Gbps 연결을 주문하려면 AWS Direct Connect 파트너에게 문의하십시오. 다른 AWS 계정과 
연결을 공유합니다. 
D. 기존 AWS 계정에 대한 200Mbps 호스팅 연결을 주문하려면 AWS Direct Connect 파트너에게 
문의하십시오. 
Answer: D 
https://www.examtopics.com/discussions/amazon/view/109515-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명 
회사는 더 저렴한 연결(200M)을 설정해야 하지만 호스트 연결로 더 많은 유연성을 위해 1, 10 
또는 100Gbps 의 포트 속도만 주문할 수 있기 때문에 B 는 올바르지 않습니다. 50Mbps 에서 
10Gbps 사이의 포트 속도를 주문할 수 있습니다. 
https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-directcon
nect.html 
Q500 
회사에는 온프레미스에 여러 Windows 파일 서버가 있습니다. 이 회사는 파일을 Windows File 
Server 파일 시스템용 Amazon FSx 로 마이그레이션하고 통합하려고 합니다. 액세스 권한이 
변경되지 않도록 하려면 파일 권한을 보존해야 합니다. 
이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) 
A. 온프레미스에 AWS DataSync 에이전트를 배포합니다. 데이터를 FSx for Windows 파일 서버 
파일 시스템으로 전송하도록 DataSync 작업을 예약합니다. 
B. AWS CLI 를 사용하여 각 파일 서버의 공유를 Amazon S3 버킷에 복사합니다. 데이터를 FSx for 
Windows File Server 파일 시스템으로 전송하도록 AWS DataSync 작업을 예약합니다. 
C. 각 파일 서버에서 드라이브를 제거합니다. Amazon S3 로 가져오기 위해 드라이브를 AWS 로 
배송합니다. 데이터를 FSx for Windows File Server 파일 시스템으로 전송하도록 AWS DataSync 
작업을 예약합니다. 
D. AWS Snowcone 디바이스를 주문합니다. 장치를 온프레미스 네트워크에 연결합니다. 
디바이스에서 AWS DataSync 에이전트를 시작합니다. 데이터를 FSx for Windows 파일 서버 파일 
시스템으로 전송하도록 DataSync 작업을 예약합니다. 
E. AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 장치를 온프레미스 네트워크에 
연결합니다. AWS CLI 를 사용하여 디바이스에 데이터를 복사합니다. Amazon S3 로 가져오기 위해 
디바이스를 AWS로 반송합니다. 데이터를 FSx for Windows File Server 파일 시스템으로 전송하도록 
AWS DataSync 작업을 예약합니다. 
Answer: A, D 
https://www.examtopics.com/discussions/amazon/view/109689-exam-aws-certified-solutions-
architect-associate-saa-c03/ 
설명:・ 
A 이 옵션에는 온프레미스 파일 서버에 DataSync 에이전트를 배포하고 DataSync 를 사용하여 
데이터를 FSx for Windows File Server 로 직접 전송하는 작업이 포함됩니다. DataSync 는 
마이그레이션 프로세스 중에 파일 권한이 보존되도록 합니다. 
D 이 옵션에는 휴대용 데이터 전송 장치인 AWS Snowcone 장치 사용이 포함됩니다. Snowcone 
디바이스를 온프레미스 네트워크에 연결하고 디바이스에서 DataSync 에이전트를 시작하고 
DataSync 작업을 예약하여 데이터를 FSx for Windows File Server 로 전송합니다. 
DataSync 는 파일 권한을 유지하면서 마이그레이션 프로세스를 처리합니다.